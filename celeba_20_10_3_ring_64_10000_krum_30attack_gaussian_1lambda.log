Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.6854 ± 0.0807 | min=0.4745 max=0.7528
         : test loss mean=189548696.5482 ± 514599697.1783
         : individual accs = ['0.702632', '0.693437', '0.700089', '0.699482', '0.693122', '0.705677', '0.724891', '0.709849', '0.749120', '0.720745', '0.705420', '0.728000', '0.745660', '0.504310', '0.517794', '0.752838', '0.740901', '0.731211', '0.474503', '0.708151']
         : correct/total = [(801, 1140), (803, 1158), (789, 1127), (810, 1158), (786, 1134), (808, 1145), (830, 1145), (800, 1127), (851, 1136), (813, 1128), (807, 1144), (819, 1125), (859, 1152), (585, 1160), (582, 1124), (862, 1145), (855, 1154), (827, 1131), (549, 1157), (808, 1141)]
         : compromised: 0.6132, honest: 0.7163
Round 002: test acc mean=0.7598 ± 0.1284 | min=0.4840 max=0.8671
         : test loss mean=214299827.5259 ± 429931712.6303
         : individual accs = ['0.774561', '0.835924', '0.782609', '0.821244', '0.820106', '0.834061', '0.854148', '0.821650', '0.786972', '0.856383', '0.867133', '0.857778', '0.835938', '0.536207', '0.483986', '0.813974', '0.775563', '0.488064', '0.528090', '0.821209']
         : correct/total = [(883, 1140), (968, 1158), (882, 1127), (951, 1158), (930, 1134), (955, 1145), (978, 1145), (926, 1127), (894, 1136), (966, 1128), (992, 1144), (965, 1125), (963, 1152), (622, 1160), (544, 1124), (932, 1145), (895, 1154), (552, 1131), (611, 1157), (937, 1141)]
         : compromised: 0.6177, honest: 0.8207
Round 003: test acc mean=0.8076 ± 0.1291 | min=0.4982 max=0.8895
         : test loss mean=372935363.3348 ± 959490239.9171
         : individual accs = ['0.842982', '0.889465', '0.856256', '0.855786', '0.843034', '0.862009', '0.873362', '0.858030', '0.875000', '0.873227', '0.881119', '0.834667', '0.842882', '0.506034', '0.498221', '0.867249', '0.878683', '0.849691', '0.502161', '0.862401']
         : correct/total = [(961, 1140), (1030, 1158), (965, 1127), (991, 1158), (956, 1134), (987, 1145), (1000, 1145), (967, 1127), (994, 1136), (985, 1128), (1008, 1144), (939, 1125), (971, 1152), (587, 1160), (560, 1124), (993, 1145), (1014, 1154), (961, 1131), (581, 1157), (984, 1141)]
         : compromised: 0.6768, honest: 0.8637
Round 004: test acc mean=0.8213 ± 0.1315 | min=0.5043 max=0.8924
         : test loss mean=154752476.9254 ± 389540229.4510
         : individual accs = ['0.885965', '0.885147', '0.874002', '0.872193', '0.875661', '0.870742', '0.885590', '0.880213', '0.874120', '0.890957', '0.877622', '0.892444', '0.886285', '0.504310', '0.511566', '0.847162', '0.867418', '0.848806', '0.512532', '0.882559']
         : correct/total = [(1010, 1140), (1025, 1158), (985, 1127), (1010, 1158), (993, 1134), (997, 1145), (1014, 1145), (992, 1127), (993, 1136), (1005, 1128), (1004, 1144), (1004, 1125), (1021, 1152), (585, 1160), (575, 1124), (970, 1145), (1001, 1154), (960, 1131), (593, 1157), (1007, 1141)]
         : compromised: 0.6890, honest: 0.8779
Round 005: test acc mean=0.8000 ± 0.1506 | min=0.4780 max=0.8978
         : test loss mean=338018252.6558 ± 714461142.9816
         : individual accs = ['0.839474', '0.892919', '0.869565', '0.895509', '0.876543', '0.864629', '0.897817', '0.850932', '0.857394', '0.880319', '0.887238', '0.872000', '0.484375', '0.545690', '0.496441', '0.870742', '0.886482', '0.873563', '0.477960', '0.880806']
         : correct/total = [(957, 1140), (1034, 1158), (980, 1127), (1037, 1158), (994, 1134), (990, 1145), (1028, 1145), (959, 1127), (974, 1136), (993, 1128), (1015, 1144), (981, 1125), (558, 1152), (633, 1160), (558, 1124), (997, 1145), (1023, 1154), (988, 1131), (553, 1157), (1005, 1141)]
         : compromised: 0.6238, honest: 0.8756
Round 006: test acc mean=0.8058 ± 0.1585 | min=0.4831 max=0.9047
         : test loss mean=395354379.8229 ± 907925051.6530
         : individual accs = ['0.896491', '0.892919', '0.884650', '0.895509', '0.858025', '0.851528', '0.883843', '0.902396', '0.881162', '0.879433', '0.901224', '0.896000', '0.488715', '0.483621', '0.505338', '0.868122', '0.904679', '0.868258', '0.483146', '0.891323']
         : correct/total = [(1022, 1140), (1034, 1158), (997, 1127), (1037, 1158), (973, 1134), (975, 1145), (1012, 1145), (1017, 1127), (1001, 1136), (992, 1128), (1031, 1144), (1008, 1125), (563, 1152), (561, 1160), (568, 1124), (994, 1145), (1044, 1154), (982, 1131), (559, 1157), (1017, 1141)]
         : compromised: 0.6134, honest: 0.8883
Round 007: test acc mean=0.7941 ± 0.1741 | min=0.4698 max=0.9099
         : test loss mean=545416955.9982 ± 1071693606.2564
         : individual accs = ['0.898246', '0.890328', '0.888199', '0.904145', '0.886243', '0.899563', '0.896943', '0.907720', '0.880282', '0.890071', '0.898601', '0.889778', '0.496528', '0.469828', '0.526690', '0.877729', '0.909879', '0.491600', '0.482282', '0.897458']
         : correct/total = [(1024, 1140), (1031, 1158), (1001, 1127), (1047, 1158), (1005, 1134), (1030, 1145), (1027, 1145), (1023, 1127), (1000, 1136), (1004, 1128), (1028, 1144), (1001, 1125), (572, 1152), (545, 1160), (592, 1124), (1005, 1145), (1050, 1154), (556, 1131), (558, 1157), (1024, 1141)]
         : compromised: 0.5611, honest: 0.8940
Round 008: test acc mean=0.8170 ± 0.1551 | min=0.4909 max=0.9116
         : test loss mean=323321537.1104 ± 654368460.7858
         : individual accs = ['0.900000', '0.897237', '0.886424', '0.898964', '0.891534', '0.902183', '0.889956', '0.889973', '0.883803', '0.899823', '0.890734', '0.900444', '0.894965', '0.506034', '0.514235', '0.882096', '0.911612', '0.518126', '0.490925', '0.891323']
         : correct/total = [(1026, 1140), (1039, 1158), (999, 1127), (1041, 1158), (1011, 1134), (1033, 1145), (1019, 1145), (1003, 1127), (1004, 1136), (1015, 1128), (1019, 1144), (1013, 1125), (1031, 1152), (587, 1160), (578, 1124), (1010, 1145), (1052, 1154), (586, 1131), (568, 1157), (1017, 1141)]
         : compromised: 0.6377, honest: 0.8939
Round 009: test acc mean=0.8346 ± 0.1423 | min=0.4804 max=0.9118
         : test loss mean=361598380.2052 ± 910517951.3526
         : individual accs = ['0.886842', '0.896373', '0.897072', '0.902418', '0.897707', '0.892576', '0.911790', '0.895297', '0.871479', '0.895390', '0.895105', '0.897778', '0.892361', '0.509483', '0.480427', '0.882096', '0.909012', '0.878868', '0.500432', '0.900088']
         : correct/total = [(1011, 1140), (1038, 1158), (1011, 1127), (1045, 1158), (1018, 1134), (1022, 1145), (1044, 1145), (1009, 1127), (990, 1136), (1010, 1128), (1024, 1144), (1010, 1125), (1028, 1152), (591, 1160), (540, 1124), (1010, 1145), (1049, 1154), (994, 1131), (579, 1157), (1027, 1141)]
         : compromised: 0.6924, honest: 0.8956
Round 010: test acc mean=0.7917 ± 0.1788 | min=0.4474 max=0.9151
         : test loss mean=366298931.3208 ± 810004089.2304
         : individual accs = ['0.899123', '0.898100', '0.888199', '0.903282', '0.895062', '0.895197', '0.907424', '0.894410', '0.882923', '0.880319', '0.888112', '0.908444', '0.497396', '0.493966', '0.482206', '0.865502', '0.915078', '0.447392', '0.494382', '0.898335']
         : correct/total = [(1025, 1140), (1040, 1158), (1001, 1127), (1046, 1158), (1015, 1134), (1025, 1145), (1039, 1145), (1008, 1127), (1003, 1136), (993, 1128), (1016, 1144), (1022, 1125), (573, 1152), (573, 1160), (542, 1124), (991, 1145), (1056, 1154), (506, 1131), (572, 1157), (1025, 1141)]
         : compromised: 0.5518, honest: 0.8946

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: ring, Aggregation: krum
Attack: gaussian, 30.0% compromised
Final accuracy - Compromised: 0.5518, Honest: 0.8946
Overall test accuracy: mean=0.7917 ± 0.1788
