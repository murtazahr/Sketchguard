Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: directed_deviation, lambda: 1.0
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5154 ± 0.0185 | min=0.4896 max=0.5757
         : test loss mean=34.9146 ± 90.1270
         : individual accs = ['0.528947', '0.489637', '0.493345', '0.497409', '0.522046', '0.514410', '0.493450', '0.519077', '0.575704', '0.491135', '0.525350', '0.527111', '0.518229', '0.510345', '0.522242', '0.517031', '0.515598', '0.507515', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (567, 1158), (556, 1127), (576, 1158), (592, 1134), (589, 1145), (565, 1145), (585, 1127), (654, 1136), (554, 1128), (601, 1144), (593, 1125), (597, 1152), (592, 1160), (587, 1124), (592, 1145), (595, 1154), (574, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5124, honest: 0.5158
Round 002: test acc mean=0.5146 ± 0.0136 | min=0.4907 max=0.5458
         : test loss mean=2.1040 ± 2.3935
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.531088', '0.522046', '0.514410', '0.508297', '0.503993', '0.545775', '0.491135', '0.525350', '0.490667', '0.522569', '0.506897', '0.518683', '0.515284', '0.515598', '0.506631', '0.522040', '0.520596']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (615, 1158), (592, 1134), (589, 1145), (582, 1145), (568, 1127), (620, 1136), (554, 1128), (601, 1144), (552, 1125), (602, 1152), (588, 1160), (583, 1124), (590, 1145), (595, 1154), (573, 1131), (604, 1157), (594, 1141)]
         : compromised: 0.5107, honest: 0.5150
Round 003: test acc mean=0.5168 ± 0.0153 | min=0.4911 max=0.5625
         : test loss mean=0.8459 ± 0.2986
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.533217', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.516464', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (610, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (596, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5107, honest: 0.5175
Round 004: test acc mean=0.5165 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=7.5473 ± 15.7408
         : individual accs = ['0.529825', '0.508636', '0.493345', '0.529361', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.499556', '0.522569', '0.506897', '0.517794', '0.517904', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(604, 1140), (589, 1158), (556, 1127), (613, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (562, 1125), (602, 1152), (588, 1160), (582, 1124), (593, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5107, honest: 0.5172
Round 005: test acc mean=0.6354 ± 0.1185 | min=0.4621 max=0.8813
         : test loss mean=2.9592 ± 7.6271
         : individual accs = ['0.566667', '0.678756', '0.829636', '0.574266', '0.602293', '0.619214', '0.527511', '0.649512', '0.462148', '0.835993', '0.846154', '0.523556', '0.585938', '0.600862', '0.567616', '0.620087', '0.881282', '0.586207', '0.658600', '0.492550']
         : correct/total = [(646, 1140), (786, 1158), (935, 1127), (665, 1158), (683, 1134), (709, 1145), (604, 1145), (732, 1127), (525, 1136), (943, 1128), (968, 1144), (589, 1125), (675, 1152), (697, 1160), (638, 1124), (710, 1145), (1017, 1154), (663, 1131), (762, 1157), (562, 1141)]
         : compromised: 0.6100, honest: 0.6383
Round 006: test acc mean=0.5894 ± 0.1335 | min=0.4437 max=0.8995
         : test loss mean=1.4361 ± 2.6456
         : individual accs = ['0.528947', '0.510363', '0.796806', '0.555268', '0.582011', '0.514410', '0.500437', '0.515528', '0.443662', '0.812943', '0.868881', '0.517333', '0.522569', '0.506897', '0.556940', '0.621834', '0.899480', '0.527851', '0.522040', '0.483786']
         : correct/total = [(603, 1140), (591, 1158), (898, 1127), (643, 1158), (660, 1134), (589, 1145), (573, 1145), (581, 1127), (504, 1136), (917, 1128), (994, 1144), (582, 1125), (602, 1152), (588, 1160), (626, 1124), (712, 1145), (1038, 1154), (597, 1131), (604, 1157), (552, 1141)]
         : compromised: 0.5107, honest: 0.5981
Round 007: test acc mean=0.5831 ± 0.0766 | min=0.5132 max=0.8077
         : test loss mean=2.3697 ± 3.8875
         : individual accs = ['0.586842', '0.605354', '0.621118', '0.525043', '0.534392', '0.559825', '0.516157', '0.584738', '0.513204', '0.734929', '0.807692', '0.540444', '0.577257', '0.554310', '0.520463', '0.530131', '0.695841', '0.561450', '0.570441', '0.523225']
         : correct/total = [(669, 1140), (701, 1158), (700, 1127), (608, 1158), (606, 1134), (641, 1145), (591, 1145), (659, 1127), (583, 1136), (829, 1128), (924, 1144), (608, 1125), (665, 1152), (643, 1160), (585, 1124), (607, 1145), (803, 1154), (635, 1131), (660, 1157), (597, 1141)]
         : compromised: 0.5571, honest: 0.5860
Round 008: test acc mean=0.5876 ± 0.1387 | min=0.4692 max=0.8977
         : test loss mean=1.6038 ± 2.0586
         : individual accs = ['0.528947', '0.520725', '0.828749', '0.535406', '0.558201', '0.514410', '0.510917', '0.511091', '0.469190', '0.843972', '0.897727', '0.519111', '0.522569', '0.507759', '0.519573', '0.520524', '0.878683', '0.516357', '0.523768', '0.524102']
         : correct/total = [(603, 1140), (603, 1158), (934, 1127), (620, 1158), (633, 1134), (589, 1145), (585, 1145), (576, 1127), (533, 1136), (952, 1128), (1027, 1144), (584, 1125), (602, 1152), (589, 1160), (584, 1124), (596, 1145), (1014, 1154), (584, 1131), (606, 1157), (598, 1141)]
         : compromised: 0.5111, honest: 0.5961
Round 009: test acc mean=0.5760 ± 0.1564 | min=0.4419 max=0.9126
         : test loss mean=2.8210 ± 7.2642
         : individual accs = ['0.489474', '0.529361', '0.886424', '0.481865', '0.540564', '0.485590', '0.502183', '0.527950', '0.441901', '0.869681', '0.912587', '0.519111', '0.479167', '0.491379', '0.496441', '0.509170', '0.874350', '0.501326', '0.496111', '0.484663']
         : correct/total = [(558, 1140), (613, 1158), (999, 1127), (558, 1158), (613, 1134), (556, 1145), (575, 1145), (595, 1127), (502, 1136), (981, 1128), (1044, 1144), (584, 1125), (552, 1152), (570, 1160), (558, 1124), (583, 1145), (1009, 1154), (567, 1131), (574, 1157), (553, 1141)]
         : compromised: 0.4885, honest: 0.5857
Round 010: test acc mean=0.5812 ± 0.1248 | min=0.4987 max=0.8715
         : test loss mean=7.4541 ± 13.9517
         : individual accs = ['0.528947', '0.512090', '0.780834', '0.528497', '0.522046', '0.517904', '0.521397', '0.503993', '0.562500', '0.842199', '0.871503', '0.498667', '0.522569', '0.509483', '0.517794', '0.517031', '0.816291', '0.508400', '0.522904', '0.517967']
         : correct/total = [(603, 1140), (593, 1158), (880, 1127), (612, 1158), (592, 1134), (593, 1145), (597, 1145), (568, 1127), (639, 1136), (950, 1128), (997, 1144), (561, 1125), (602, 1152), (591, 1160), (582, 1124), (592, 1145), (942, 1154), (575, 1131), (605, 1157), (591, 1141)]
         : compromised: 0.5137, honest: 0.5886

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: directed_deviation, 10.0% compromised
Final accuracy - Compromised: 0.5137, Honest: 0.5886
Overall test accuracy: mean=0.5812 ± 0.1248
