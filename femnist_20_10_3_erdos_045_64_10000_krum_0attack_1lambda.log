Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5439 ± 0.0129 | min=0.5241 max=0.5654
         : test loss mean=1.7343 ± 0.0516
         : individual accs = ['0.538275', '0.564121', '0.546190', '0.555504', '0.524077', '0.554934', '0.539232', '0.539204', '0.540205', '0.540566', '0.525706', '0.547579', '0.549230', '0.539909', '0.565400', '0.531646', '0.526848', '0.558929', '0.563173', '0.527616']
         : correct/total = [(2222, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2144, 4091), (2379, 4287), (2261, 4193), (2345, 4349), (2264, 4191), (2312, 4277), (2178, 4143), (2296, 4193), (2248, 4093), (2266, 4197), (2291, 4052), (2142, 4029), (2188, 4153), (2338, 4183), (2300, 4084), (2178, 4128)]
Round 002: test acc mean=0.7331 ± 0.0077 | min=0.7149 max=0.7441
         : test loss mean=0.8921 ± 0.0262
         : individual accs = ['0.727713', '0.724483', '0.721882', '0.733903', '0.730384', '0.744110', '0.737420', '0.739020', '0.738487', '0.742810', '0.734733', '0.731696', '0.741510', '0.729807', '0.743583', '0.736163', '0.724296', '0.728186', '0.736778', '0.714874']
         : correct/total = [(3004, 4128), (3045, 4203), (2946, 4081), (3180, 4333), (2988, 4091), (3190, 4287), (3092, 4193), (3214, 4349), (3095, 4191), (3177, 4277), (3044, 4143), (3068, 4193), (3035, 4093), (3063, 4197), (3013, 4052), (2966, 4029), (3008, 4153), (3046, 4183), (3009, 4084), (2951, 4128)]
Round 003: test acc mean=0.7631 ± 0.0098 | min=0.7434 max=0.7854
         : test loss mean=0.7501 ± 0.0400
         : individual accs = ['0.750000', '0.778967', '0.743445', '0.766213', '0.752872', '0.777233', '0.768662', '0.754886', '0.768790', '0.785364', '0.761525', '0.752445', '0.762766', '0.761496', '0.764067', '0.759990', '0.757284', '0.767392', '0.764202', '0.765262']
         : correct/total = [(3096, 4128), (3274, 4203), (3034, 4081), (3320, 4333), (3080, 4091), (3332, 4287), (3223, 4193), (3283, 4349), (3222, 4191), (3359, 4277), (3155, 4143), (3155, 4193), (3122, 4093), (3196, 4197), (3096, 4052), (3062, 4029), (3145, 4153), (3210, 4183), (3121, 4084), (3159, 4128)]
Round 004: test acc mean=0.7958 ± 0.0087 | min=0.7829 max=0.8179
         : test loss mean=0.6395 ± 0.0290
         : individual accs = ['0.789729', '0.796098', '0.789267', '0.792753', '0.782938', '0.790763', '0.796566', '0.809381', '0.817943', '0.795885', '0.788559', '0.792034', '0.794283', '0.798189', '0.794916', '0.806404', '0.785938', '0.804686', '0.803869', '0.784884']
         : correct/total = [(3260, 4128), (3346, 4203), (3221, 4081), (3435, 4333), (3203, 4091), (3390, 4287), (3340, 4193), (3520, 4349), (3428, 4191), (3404, 4277), (3267, 4143), (3321, 4193), (3251, 4093), (3350, 4197), (3221, 4052), (3249, 4029), (3264, 4153), (3366, 4183), (3283, 4084), (3240, 4128)]
Round 005: test acc mean=0.8032 ± 0.0055 | min=0.7900 max=0.8116
         : test loss mean=0.6081 ± 0.0210
         : individual accs = ['0.799419', '0.811563', '0.799559', '0.810524', '0.808604', '0.801959', '0.803720', '0.808922', '0.811024', '0.806406', '0.790007', '0.800620', '0.801368', '0.804384', '0.807502', '0.796972', '0.804479', '0.800143', '0.797747', '0.798207']
         : correct/total = [(3300, 4128), (3411, 4203), (3263, 4081), (3512, 4333), (3308, 4091), (3438, 4287), (3370, 4193), (3518, 4349), (3399, 4191), (3449, 4277), (3273, 4143), (3357, 4193), (3280, 4093), (3376, 4197), (3272, 4052), (3211, 4029), (3341, 4153), (3347, 4183), (3258, 4084), (3295, 4128)]
Round 006: test acc mean=0.8127 ± 0.0082 | min=0.7962 max=0.8251
         : test loss mean=0.5704 ± 0.0255
         : individual accs = ['0.809351', '0.818463', '0.809851', '0.796215', '0.797604', '0.818521', '0.823754', '0.816050', '0.825101', '0.819733', '0.811007', '0.811114', '0.821402', '0.809626', '0.815647', '0.801191', '0.807368', '0.812097', '0.823457', '0.806202']
         : correct/total = [(3341, 4128), (3440, 4203), (3305, 4081), (3450, 4333), (3263, 4091), (3509, 4287), (3454, 4193), (3549, 4349), (3458, 4191), (3506, 4277), (3360, 4143), (3401, 4193), (3362, 4093), (3398, 4197), (3305, 4052), (3228, 4029), (3353, 4153), (3397, 4183), (3363, 4084), (3328, 4128)]
Round 007: test acc mean=0.8224 ± 0.0069 | min=0.8050 max=0.8372
         : test loss mean=0.5453 ± 0.0242
         : individual accs = ['0.819767', '0.824649', '0.821857', '0.814216', '0.816915', '0.818521', '0.834963', '0.830536', '0.826056', '0.823474', '0.804972', '0.820653', '0.820181', '0.824160', '0.826259', '0.825267', '0.822297', '0.819508', '0.837169', '0.817103']
         : correct/total = [(3384, 4128), (3466, 4203), (3354, 4081), (3528, 4333), (3342, 4091), (3509, 4287), (3501, 4193), (3612, 4349), (3462, 4191), (3522, 4277), (3335, 4143), (3441, 4193), (3357, 4093), (3459, 4197), (3348, 4052), (3325, 4029), (3415, 4153), (3428, 4183), (3419, 4084), (3373, 4128)]
Round 008: test acc mean=0.8263 ± 0.0078 | min=0.8076 max=0.8380
         : test loss mean=0.5230 ± 0.0239
         : individual accs = ['0.827277', '0.825363', '0.832639', '0.825294', '0.815937', '0.817588', '0.836155', '0.835135', '0.837986', '0.825345', '0.807627', '0.822084', '0.827999', '0.834882', '0.827739', '0.813353', '0.827113', '0.831461', '0.831048', '0.824370']
         : correct/total = [(3415, 4128), (3469, 4203), (3398, 4081), (3576, 4333), (3338, 4091), (3505, 4287), (3506, 4193), (3632, 4349), (3512, 4191), (3530, 4277), (3346, 4143), (3447, 4193), (3389, 4093), (3504, 4197), (3354, 4052), (3277, 4029), (3435, 4153), (3478, 4183), (3394, 4084), (3403, 4128)]
Round 009: test acc mean=0.8263 ± 0.0098 | min=0.8088 max=0.8434
         : test loss mean=0.5267 ± 0.0301
         : individual accs = ['0.815407', '0.838687', '0.826513', '0.830602', '0.834759', '0.822720', '0.839733', '0.843412', '0.831544', '0.818798', '0.808834', '0.830193', '0.827022', '0.835359', '0.812685', '0.817573', '0.810498', '0.833612', '0.821254', '0.827519']
         : correct/total = [(3366, 4128), (3525, 4203), (3373, 4081), (3599, 4333), (3415, 4091), (3527, 4287), (3521, 4193), (3668, 4349), (3485, 4191), (3502, 4277), (3351, 4143), (3481, 4193), (3385, 4093), (3506, 4197), (3293, 4052), (3294, 4029), (3366, 4153), (3487, 4183), (3354, 4084), (3416, 4128)]
Round 010: test acc mean=0.8257 ± 0.0084 | min=0.8114 max=0.8399
         : test loss mean=0.5124 ± 0.0204
         : individual accs = ['0.813953', '0.834642', '0.833374', '0.834757', '0.823271', '0.836016', '0.814214', '0.822488', '0.822954', '0.836801', '0.823075', '0.826377', '0.816760', '0.839886', '0.822063', '0.811368', '0.828558', '0.833373', '0.824682', '0.816134']
         : correct/total = [(3360, 4128), (3508, 4203), (3401, 4081), (3617, 4333), (3368, 4091), (3584, 4287), (3414, 4193), (3577, 4349), (3449, 4191), (3579, 4277), (3410, 4143), (3465, 4193), (3343, 4093), (3525, 4197), (3331, 4052), (3269, 4029), (3441, 4153), (3486, 4183), (3368, 4084), (3369, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Overall test accuracy: mean=0.8257 ± 0.0084
