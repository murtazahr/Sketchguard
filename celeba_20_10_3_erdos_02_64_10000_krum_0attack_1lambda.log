Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.8888 ± 0.0177 | min=0.8351 max=0.9089
         : test loss mean=0.2750 ± 0.0430
         : individual accs = ['0.835088', '0.858377', '0.883762', '0.905872', '0.907407', '0.891703', '0.889956', '0.908607', '0.889965', '0.902482', '0.903846', '0.894222', '0.875868', '0.882759', '0.883452', '0.883843', '0.893414', '0.900088', '0.877269', '0.908852']
         : correct/total = [(952, 1140), (994, 1158), (996, 1127), (1049, 1158), (1029, 1134), (1021, 1145), (1019, 1145), (1024, 1127), (1011, 1136), (1018, 1128), (1034, 1144), (1006, 1125), (1009, 1152), (1024, 1160), (993, 1124), (1012, 1145), (1031, 1154), (1018, 1131), (1015, 1157), (1037, 1141)]
Round 002: test acc mean=0.9032 ± 0.0119 | min=0.8651 max=0.9173
         : test loss mean=0.2616 ± 0.0425
         : individual accs = ['0.913158', '0.899827', '0.865129', '0.909326', '0.898589', '0.910044', '0.913537', '0.907720', '0.904049', '0.904255', '0.909965', '0.917333', '0.907986', '0.916379', '0.895018', '0.900437', '0.902946', '0.894783', '0.883319', '0.909728']
         : correct/total = [(1041, 1140), (1042, 1158), (975, 1127), (1053, 1158), (1019, 1134), (1042, 1145), (1046, 1145), (1023, 1127), (1027, 1136), (1020, 1128), (1041, 1144), (1032, 1125), (1046, 1152), (1063, 1160), (1006, 1124), (1031, 1145), (1042, 1154), (1012, 1131), (1022, 1157), (1038, 1141)]
Round 003: test acc mean=0.9059 ± 0.0115 | min=0.8799 max=0.9264
         : test loss mean=0.2434 ± 0.0277
         : individual accs = ['0.915789', '0.883420', '0.894410', '0.906736', '0.906526', '0.901310', '0.912664', '0.926353', '0.889965', '0.915780', '0.909965', '0.918222', '0.910590', '0.912069', '0.907473', '0.900437', '0.914211', '0.900973', '0.879862', '0.910605']
         : correct/total = [(1044, 1140), (1023, 1158), (1008, 1127), (1050, 1158), (1028, 1134), (1032, 1145), (1045, 1145), (1044, 1127), (1011, 1136), (1033, 1128), (1041, 1144), (1033, 1125), (1049, 1152), (1058, 1160), (1020, 1124), (1031, 1145), (1055, 1154), (1019, 1131), (1018, 1157), (1039, 1141)]
Round 004: test acc mean=0.9086 ± 0.0092 | min=0.8920 max=0.9237
         : test loss mean=0.2438 ± 0.0334
         : individual accs = ['0.921930', '0.903282', '0.893523', '0.904145', '0.912698', '0.910044', '0.914410', '0.923691', '0.892606', '0.906028', '0.900350', '0.914667', '0.914062', '0.914655', '0.913701', '0.909170', '0.919411', '0.899204', '0.891962', '0.912358']
         : correct/total = [(1051, 1140), (1046, 1158), (1007, 1127), (1047, 1158), (1035, 1134), (1042, 1145), (1047, 1145), (1041, 1127), (1014, 1136), (1022, 1128), (1030, 1144), (1029, 1125), (1053, 1152), (1061, 1160), (1027, 1124), (1041, 1145), (1061, 1154), (1017, 1131), (1032, 1157), (1041, 1141)]
Round 005: test acc mean=0.9066 ± 0.0109 | min=0.8817 max=0.9307
         : test loss mean=0.2616 ± 0.0459
         : individual accs = ['0.930702', '0.908463', '0.897959', '0.881693', '0.914462', '0.917031', '0.912664', '0.919255', '0.904930', '0.911348', '0.903846', '0.912889', '0.909722', '0.905172', '0.893238', '0.898690', '0.907279', '0.904509', '0.886776', '0.911481']
         : correct/total = [(1061, 1140), (1052, 1158), (1012, 1127), (1021, 1158), (1037, 1134), (1050, 1145), (1045, 1145), (1036, 1127), (1028, 1136), (1028, 1128), (1034, 1144), (1027, 1125), (1048, 1152), (1050, 1160), (1004, 1124), (1029, 1145), (1047, 1154), (1023, 1131), (1026, 1157), (1040, 1141)]
Round 006: test acc mean=0.9078 ± 0.0105 | min=0.8781 max=0.9223
         : test loss mean=0.2651 ± 0.0464
         : individual accs = ['0.905263', '0.897237', '0.906832', '0.911917', '0.914462', '0.917904', '0.922271', '0.918367', '0.904930', '0.913121', '0.895105', '0.912000', '0.914062', '0.910345', '0.894128', '0.903057', '0.916811', '0.900973', '0.878133', '0.919369']
         : correct/total = [(1032, 1140), (1039, 1158), (1022, 1127), (1056, 1158), (1037, 1134), (1051, 1145), (1056, 1145), (1035, 1127), (1028, 1136), (1030, 1128), (1024, 1144), (1026, 1125), (1053, 1152), (1056, 1160), (1005, 1124), (1034, 1145), (1058, 1154), (1019, 1131), (1016, 1157), (1049, 1141)]
Round 007: test acc mean=0.9079 ± 0.0111 | min=0.8920 max=0.9325
         : test loss mean=0.2742 ± 0.0434
         : individual accs = ['0.932456', '0.900691', '0.903283', '0.918826', '0.921517', '0.909170', '0.911790', '0.921029', '0.896127', '0.907801', '0.893357', '0.918222', '0.898438', '0.905172', '0.895907', '0.908297', '0.920277', '0.893899', '0.891962', '0.908852']
         : correct/total = [(1063, 1140), (1043, 1158), (1018, 1127), (1064, 1158), (1045, 1134), (1041, 1145), (1044, 1145), (1038, 1127), (1018, 1136), (1024, 1128), (1022, 1144), (1033, 1125), (1035, 1152), (1050, 1160), (1007, 1124), (1040, 1145), (1062, 1154), (1011, 1131), (1032, 1157), (1037, 1141)]
Round 008: test acc mean=0.9106 ± 0.0100 | min=0.8872 max=0.9325
         : test loss mean=0.3067 ± 0.0634
         : individual accs = ['0.932456', '0.904145', '0.904170', '0.907599', '0.921517', '0.910044', '0.917904', '0.917480', '0.904049', '0.907801', '0.887238', '0.922667', '0.919271', '0.913793', '0.902135', '0.910044', '0.915078', '0.915119', '0.895419', '0.904470']
         : correct/total = [(1063, 1140), (1047, 1158), (1019, 1127), (1051, 1158), (1045, 1134), (1042, 1145), (1051, 1145), (1034, 1127), (1027, 1136), (1024, 1128), (1015, 1144), (1038, 1125), (1059, 1152), (1060, 1160), (1014, 1124), (1042, 1145), (1056, 1154), (1035, 1131), (1036, 1157), (1032, 1141)]
Round 009: test acc mean=0.9048 ± 0.0115 | min=0.8773 max=0.9281
         : test loss mean=0.2981 ± 0.0539
         : individual accs = ['0.928070', '0.905009', '0.902396', '0.897237', '0.916226', '0.910917', '0.912664', '0.921029', '0.899648', '0.904255', '0.888986', '0.904000', '0.892361', '0.905172', '0.896797', '0.896070', '0.911612', '0.908930', '0.877269', '0.917616']
         : correct/total = [(1058, 1140), (1048, 1158), (1017, 1127), (1039, 1158), (1039, 1134), (1043, 1145), (1045, 1145), (1038, 1127), (1022, 1136), (1020, 1128), (1017, 1144), (1017, 1125), (1028, 1152), (1050, 1160), (1008, 1124), (1026, 1145), (1052, 1154), (1028, 1131), (1015, 1157), (1047, 1141)]
Round 010: test acc mean=0.9083 ± 0.0083 | min=0.8946 max=0.9263
         : test loss mean=0.2970 ± 0.0617
         : individual accs = ['0.926316', '0.907599', '0.905058', '0.902418', '0.919753', '0.909170', '0.911790', '0.916593', '0.897887', '0.908688', '0.902972', '0.896000', '0.918403', '0.906034', '0.903915', '0.917904', '0.903813', '0.901857', '0.894555', '0.914987']
         : correct/total = [(1056, 1140), (1051, 1158), (1020, 1127), (1045, 1158), (1043, 1134), (1041, 1145), (1044, 1145), (1033, 1127), (1020, 1136), (1025, 1128), (1033, 1144), (1008, 1125), (1058, 1152), (1051, 1160), (1016, 1124), (1051, 1145), (1043, 1154), (1020, 1131), (1035, 1157), (1044, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: krum
Overall test accuracy: mean=0.9083 ± 0.0083
