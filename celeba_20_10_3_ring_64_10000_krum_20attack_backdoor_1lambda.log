Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 4 compromised nodes
Round 001: test acc mean=0.6957 ± 0.0603 | min=0.5009 max=0.7491
         : test loss mean=2450.5054 ± 7650.4757
         : individual accs = ['0.702632', '0.693437', '0.700089', '0.699482', '0.693122', '0.705677', '0.724891', '0.709849', '0.749120', '0.720745', '0.705420', '0.728000', '0.543403', '0.500862', '0.719751', '0.702183', '0.740901', '0.731211', '0.734659', '0.708151']
         : correct/total = [(801, 1140), (803, 1158), (789, 1127), (810, 1158), (786, 1134), (808, 1145), (830, 1145), (800, 1127), (851, 1136), (813, 1128), (807, 1144), (819, 1125), (626, 1152), (581, 1160), (809, 1124), (804, 1145), (855, 1154), (827, 1131), (850, 1157), (808, 1141)]
         : compromised: 0.6203, honest: 0.7145
Round 002: test acc mean=0.7869 ± 0.0956 | min=0.5069 max=0.8671
         : test loss mean=3392103.3533 ± 10257916.7681
         : individual accs = ['0.774561', '0.835924', '0.782609', '0.821244', '0.820106', '0.834061', '0.854148', '0.821650', '0.786972', '0.856383', '0.867133', '0.857778', '0.522569', '0.506897', '0.771352', '0.818341', '0.775563', '0.771883', '0.837511', '0.821209']
         : correct/total = [(883, 1140), (968, 1158), (882, 1127), (951, 1158), (930, 1134), (955, 1145), (978, 1145), (926, 1127), (894, 1136), (966, 1128), (992, 1144), (965, 1125), (602, 1152), (588, 1160), (867, 1124), (937, 1145), (895, 1154), (873, 1131), (969, 1157), (937, 1141)]
         : compromised: 0.6589, honest: 0.8189
Round 003: test acc mean=0.8272 ± 0.1051 | min=0.5069 max=0.8895
         : test loss mean=4254062.0881 ± 12924585.1282
         : individual accs = ['0.842982', '0.889465', '0.856256', '0.855786', '0.843034', '0.862009', '0.873362', '0.858030', '0.875000', '0.873227', '0.881119', '0.834667', '0.522569', '0.506897', '0.871886', '0.859389', '0.878683', '0.849691', '0.847018', '0.862401']
         : correct/total = [(961, 1140), (1030, 1158), (965, 1127), (991, 1158), (956, 1134), (987, 1145), (1000, 1145), (967, 1127), (994, 1136), (985, 1128), (1008, 1144), (939, 1125), (602, 1152), (588, 1160), (980, 1124), (984, 1145), (1014, 1154), (961, 1131), (980, 1157), (984, 1141)]
         : compromised: 0.6853, honest: 0.8626
Round 004: test acc mean=0.8394 ± 0.1088 | min=0.5069 max=0.8924
         : test loss mean=0.3724 ± 0.2438
         : individual accs = ['0.885965', '0.885147', '0.874002', '0.872193', '0.875661', '0.870742', '0.885590', '0.880213', '0.874120', '0.890957', '0.877622', '0.892444', '0.522569', '0.506897', '0.876335', '0.852402', '0.867418', '0.848806', '0.866897', '0.882559']
         : correct/total = [(1010, 1140), (1025, 1158), (985, 1127), (1010, 1158), (993, 1134), (997, 1145), (1014, 1145), (992, 1127), (993, 1136), (1005, 1128), (1004, 1144), (1004, 1125), (602, 1152), (588, 1160), (985, 1124), (976, 1145), (1001, 1154), (960, 1131), (1003, 1157), (1007, 1141)]
         : compromised: 0.6873, honest: 0.8775
Round 005: test acc mean=0.8343 ± 0.1161 | min=0.4774 max=0.8978
         : test loss mean=0.3374 ± 0.1259
         : individual accs = ['0.839474', '0.892919', '0.869565', '0.895509', '0.876543', '0.864629', '0.897817', '0.850932', '0.857394', '0.880319', '0.887238', '0.872000', '0.477431', '0.506897', '0.896797', '0.874236', '0.886482', '0.873563', '0.806396', '0.880806']
         : correct/total = [(957, 1140), (1034, 1158), (980, 1127), (1037, 1158), (994, 1134), (990, 1145), (1028, 1145), (959, 1127), (974, 1136), (993, 1128), (1015, 1144), (981, 1125), (550, 1152), (588, 1160), (1008, 1124), (1001, 1145), (1023, 1154), (988, 1131), (933, 1157), (1005, 1141)]
         : compromised: 0.6806, honest: 0.8728
Round 006: test acc mean=0.8473 ± 0.1119 | min=0.5078 max=0.9047
         : test loss mean=7152467.4542 ± 21457401.8214
         : individual accs = ['0.896491', '0.892919', '0.884650', '0.895509', '0.858025', '0.851528', '0.883843', '0.902396', '0.881162', '0.879433', '0.901224', '0.896000', '0.521701', '0.507759', '0.896797', '0.862882', '0.904679', '0.868258', '0.868626', '0.891323']
         : correct/total = [(1022, 1140), (1034, 1158), (997, 1127), (1037, 1158), (973, 1134), (975, 1145), (1012, 1145), (1017, 1127), (1001, 1136), (992, 1128), (1031, 1144), (1008, 1125), (601, 1152), (589, 1160), (1008, 1124), (988, 1145), (1044, 1154), (982, 1131), (1005, 1157), (1017, 1141)]
         : compromised: 0.6873, honest: 0.8872
Round 007: test acc mean=0.8538 ± 0.1136 | min=0.5069 max=0.9099
         : test loss mean=383749840.5106 ± 1151250906.9749
         : individual accs = ['0.898246', '0.890328', '0.888199', '0.904145', '0.886243', '0.899563', '0.896943', '0.907720', '0.880282', '0.890071', '0.898601', '0.889778', '0.522569', '0.506897', '0.892349', '0.873362', '0.909879', '0.878868', '0.864304', '0.897458']
         : correct/total = [(1024, 1140), (1031, 1158), (1001, 1127), (1047, 1158), (1005, 1134), (1030, 1145), (1027, 1145), (1023, 1127), (1000, 1136), (1004, 1128), (1028, 1144), (1001, 1125), (602, 1152), (588, 1160), (1003, 1124), (1000, 1145), (1050, 1154), (994, 1131), (1000, 1157), (1024, 1141)]
         : compromised: 0.7020, honest: 0.8917
Round 008: test acc mean=0.8544 ± 0.1136 | min=0.5069 max=0.9116
         : test loss mean=417232964.3405 ± 1252184703.9800
         : individual accs = ['0.900000', '0.897237', '0.886424', '0.898964', '0.891534', '0.902183', '0.889956', '0.889973', '0.883803', '0.899823', '0.890734', '0.900444', '0.522569', '0.506897', '0.889680', '0.885590', '0.911612', '0.877100', '0.871219', '0.891323']
         : correct/total = [(1026, 1140), (1039, 1158), (999, 1127), (1041, 1158), (1011, 1134), (1033, 1145), (1019, 1145), (1003, 1127), (1004, 1136), (1015, 1128), (1019, 1144), (1013, 1125), (602, 1152), (588, 1160), (1000, 1124), (1014, 1145), (1052, 1154), (992, 1131), (1008, 1157), (1017, 1141)]
         : compromised: 0.7022, honest: 0.8924
Round 009: test acc mean=0.8549 ± 0.1141 | min=0.5069 max=0.9118
         : test loss mean=154693203.6450 ± 464407957.3648
         : individual accs = ['0.886842', '0.896373', '0.897072', '0.902418', '0.897707', '0.892576', '0.911790', '0.895297', '0.871479', '0.895390', '0.895105', '0.897778', '0.522569', '0.506897', '0.903915', '0.879476', '0.909012', '0.878868', '0.857390', '0.900088']
         : correct/total = [(1011, 1140), (1038, 1158), (1011, 1127), (1045, 1158), (1018, 1134), (1022, 1145), (1044, 1145), (1009, 1127), (990, 1136), (1010, 1128), (1024, 1144), (1010, 1125), (602, 1152), (588, 1160), (1016, 1124), (1007, 1145), (1049, 1154), (994, 1131), (992, 1157), (1027, 1141)]
         : compromised: 0.7002, honest: 0.8936
Round 010: test acc mean=0.8523 ± 0.1230 | min=0.4774 max=0.9151
         : test loss mean=17825520.4494 ± 53496763.9690
         : individual accs = ['0.899123', '0.898100', '0.888199', '0.903282', '0.895062', '0.895197', '0.907424', '0.894410', '0.882923', '0.880319', '0.888112', '0.908444', '0.477431', '0.493103', '0.901246', '0.881223', '0.915078', '0.885942', '0.853933', '0.898335']
         : correct/total = [(1025, 1140), (1040, 1158), (1001, 1127), (1046, 1158), (1015, 1134), (1025, 1145), (1039, 1145), (1008, 1127), (1003, 1136), (993, 1128), (1016, 1144), (1022, 1125), (550, 1152), (572, 1160), (1013, 1124), (1009, 1145), (1056, 1154), (1002, 1131), (988, 1157), (1025, 1141)]
         : compromised: 0.6879, honest: 0.8935

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: ring, Aggregation: krum
Attack: backdoor, 20.0% compromised
Final accuracy - Compromised: 0.6879, Honest: 0.8935
Overall test accuracy: mean=0.8523 ± 0.1230

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.4831 ± 0.1651
Honest nodes ASR: 0.5394 ± 0.0387
Compromised nodes ASR: 0.2578 ± 0.2587
Note: Higher ASR indicates more successful backdoor attack
