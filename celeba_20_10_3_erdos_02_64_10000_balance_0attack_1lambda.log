Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
BALANCE algorithm:
  - Model dimension: 30,758 parameters
  - Complexity: O(N×d) = O(20×30,758)
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.8309 ± 0.1130
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 002: test acc mean=0.5176 ± 0.0141 | min=0.4911 max=0.5625
         : test loss mean=0.7521 ± 0.0799
         : individual accs = ['0.528947', '0.508636', '0.512866', '0.528497', '0.522046', '0.514410', '0.521397', '0.504880', '0.562500', '0.491135', '0.527098', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522904', '0.518843']
         : correct/total = [(603, 1140), (589, 1158), (578, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (569, 1127), (639, 1136), (554, 1128), (603, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (605, 1157), (592, 1141)]
Round 003: test acc mean=0.5457 ± 0.0424 | min=0.4911 max=0.6465
         : test loss mean=0.6554 ± 0.0603
         : individual accs = ['0.646491', '0.516408', '0.503993', '0.529361', '0.555556', '0.519651', '0.632314', '0.507542', '0.598592', '0.491135', '0.561189', '0.516444', '0.572049', '0.514655', '0.523132', '0.518777', '0.588388', '0.508400', '0.547969', '0.561788']
         : correct/total = [(737, 1140), (598, 1158), (568, 1127), (613, 1158), (630, 1134), (595, 1145), (724, 1145), (572, 1127), (680, 1136), (554, 1128), (642, 1144), (581, 1125), (659, 1152), (597, 1160), (588, 1124), (594, 1145), (679, 1154), (575, 1131), (634, 1157), (641, 1141)]
Round 004: test acc mean=0.6130 ± 0.0596 | min=0.4956 max=0.7169
         : test loss mean=0.5884 ± 0.0481
         : individual accs = ['0.565789', '0.517271', '0.658385', '0.590674', '0.595238', '0.625328', '0.698690', '0.567879', '0.610915', '0.495567', '0.715035', '0.669333', '0.662326', '0.584483', '0.629893', '0.549345', '0.576256', '0.625995', '0.605013', '0.716915']
         : correct/total = [(645, 1140), (599, 1158), (742, 1127), (684, 1158), (675, 1134), (716, 1145), (800, 1145), (640, 1127), (694, 1136), (559, 1128), (818, 1144), (753, 1125), (763, 1152), (678, 1160), (708, 1124), (629, 1145), (665, 1154), (708, 1131), (700, 1157), (818, 1141)]
Round 005: test acc mean=0.6713 ± 0.0705 | min=0.5044 max=0.7769
         : test loss mean=0.5460 ± 0.0529
         : individual accs = ['0.650000', '0.641623', '0.685004', '0.732297', '0.571429', '0.619214', '0.725764', '0.557232', '0.727993', '0.504433', '0.720280', '0.752000', '0.776910', '0.633621', '0.704626', '0.620087', '0.687175', '0.644562', '0.729473', '0.741455']
         : correct/total = [(741, 1140), (743, 1158), (772, 1127), (848, 1158), (648, 1134), (709, 1145), (831, 1145), (628, 1127), (827, 1136), (569, 1128), (824, 1144), (846, 1125), (895, 1152), (735, 1160), (792, 1124), (710, 1145), (793, 1154), (729, 1131), (844, 1157), (846, 1141)]
Round 006: test acc mean=0.7684 ± 0.0602 | min=0.6105 max=0.8440
         : test loss mean=0.4731 ± 0.0492
         : individual accs = ['0.788596', '0.610535', '0.778172', '0.832470', '0.632275', '0.798253', '0.806114', '0.765750', '0.840669', '0.713652', '0.817308', '0.749333', '0.802951', '0.800000', '0.754448', '0.773799', '0.743501', '0.791335', '0.724287', '0.843996']
         : correct/total = [(899, 1140), (707, 1158), (877, 1127), (964, 1158), (717, 1134), (914, 1145), (923, 1145), (863, 1127), (955, 1136), (805, 1128), (935, 1144), (843, 1125), (925, 1152), (928, 1160), (848, 1124), (886, 1145), (858, 1154), (895, 1131), (838, 1157), (963, 1141)]
Round 007: test acc mean=0.8129 ± 0.0398 | min=0.7314 max=0.8799
         : test loss mean=0.4375 ± 0.0433
         : individual accs = ['0.844737', '0.731434', '0.787045', '0.845423', '0.768078', '0.825328', '0.816594', '0.841171', '0.873239', '0.736702', '0.814685', '0.810667', '0.824653', '0.832759', '0.762456', '0.805240', '0.785962', '0.851459', '0.821089', '0.879930']
         : correct/total = [(963, 1140), (847, 1158), (887, 1127), (979, 1158), (871, 1134), (945, 1145), (935, 1145), (948, 1127), (992, 1136), (831, 1128), (932, 1144), (912, 1125), (950, 1152), (966, 1160), (857, 1124), (922, 1145), (907, 1154), (963, 1131), (950, 1157), (1004, 1141)]
Round 008: test acc mean=0.8222 ± 0.0526 | min=0.6640 max=0.8833
         : test loss mean=0.4221 ± 0.0507
         : individual accs = ['0.792982', '0.720207', '0.821650', '0.857513', '0.778660', '0.871616', '0.815721', '0.834073', '0.831866', '0.664007', '0.842657', '0.830222', '0.855035', '0.859483', '0.864769', '0.773799', '0.855286', '0.883289', '0.852204', '0.839614']
         : correct/total = [(904, 1140), (834, 1158), (926, 1127), (993, 1158), (883, 1134), (998, 1145), (934, 1145), (940, 1127), (945, 1136), (749, 1128), (964, 1144), (934, 1125), (985, 1152), (997, 1160), (972, 1124), (886, 1145), (987, 1154), (999, 1131), (986, 1157), (958, 1141)]
Round 009: test acc mean=0.8456 ± 0.0342 | min=0.7535 max=0.9097
         : test loss mean=0.3941 ± 0.0459
         : individual accs = ['0.825439', '0.842832', '0.848270', '0.890328', '0.823633', '0.881223', '0.856769', '0.862467', '0.854754', '0.753546', '0.856643', '0.846222', '0.853299', '0.877586', '0.824733', '0.786026', '0.818024', '0.840849', '0.859118', '0.909728']
         : correct/total = [(941, 1140), (976, 1158), (956, 1127), (1031, 1158), (934, 1134), (1009, 1145), (981, 1145), (972, 1127), (971, 1136), (850, 1128), (980, 1144), (952, 1125), (983, 1152), (1018, 1160), (927, 1124), (900, 1145), (944, 1154), (951, 1131), (994, 1157), (1038, 1141)]
Round 010: test acc mean=0.8665 ± 0.0287 | min=0.7943 max=0.9082
         : test loss mean=0.3650 ± 0.0433
         : individual accs = ['0.860526', '0.823834', '0.845608', '0.887737', '0.835097', '0.884716', '0.857642', '0.873114', '0.882042', '0.794326', '0.908217', '0.883556', '0.893229', '0.868966', '0.878114', '0.821834', '0.870017', '0.885057', '0.869490', '0.906223']
         : correct/total = [(981, 1140), (954, 1158), (953, 1127), (1028, 1158), (947, 1134), (1013, 1145), (982, 1145), (984, 1127), (1002, 1136), (896, 1128), (1039, 1144), (994, 1125), (1029, 1152), (1008, 1160), (987, 1124), (941, 1145), (1004, 1154), (1001, 1131), (1006, 1157), (1034, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: balance
Overall test accuracy: mean=0.8665 ± 0.0287

=== BALANCE SUMMARY ===
Node 0: acceptance=1.000
Node 1: acceptance=1.000
Node 2: acceptance=1.000
Node 3: acceptance=1.000
Node 4: acceptance=1.000
Node 5: acceptance=1.000
Node 6: acceptance=1.000
Node 7: acceptance=1.000
Node 8: acceptance=1.000
Node 9: acceptance=1.000
Node 10: acceptance=1.000
Node 11: acceptance=1.000
Node 12: acceptance=1.000
Node 13: acceptance=1.000
Node 14: acceptance=1.000
Node 15: acceptance=1.000
Node 16: acceptance=1.000
Node 17: acceptance=1.000
Node 18: acceptance=1.000
Node 19: acceptance=1.000

Performance Summary:
  - Distance computation time: 0.747s (38.7%)
  - Filtering time: 0.882s (45.7%)
  - Aggregation time: 0.300s (15.6%)
  - Total time: 1.930s
  - Mean acceptance rate: 1.000

BALANCE Algorithm Properties:
  - Model dimension: 30,758
  - No compression: Full parameter comparison
  - Theoretical complexity: O(deg(i)×d)
  - Approach: Full parameter filtering + averaging
