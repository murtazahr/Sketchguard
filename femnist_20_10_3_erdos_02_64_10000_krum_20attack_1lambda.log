Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0580 ± 0.0100 | min=0.0401 max=0.0857
         : test loss mean=30957.8289 ± 93089.8804
         : individual accs = ['0.059593', '0.052344', '0.050723', '0.052850', '0.074554', '0.040121', '0.057000', '0.058174', '0.085660', '0.074117', '0.050447', '0.061770', '0.058637', '0.046938', '0.061204', '0.056342', '0.058271', '0.050203', '0.055583', '0.054506']
         : correct/total = [(246, 4128), (220, 4203), (207, 4081), (229, 4333), (305, 4091), (172, 4287), (239, 4193), (253, 4349), (359, 4191), (317, 4277), (209, 4143), (259, 4193), (240, 4093), (197, 4197), (248, 4052), (227, 4029), (242, 4153), (210, 4183), (227, 4084), (225, 4128)]
         : compromised: 0.0490, honest: 0.0602
Round 002: test acc mean=0.0511 ± 0.0036 | min=0.0453 max=0.0579
         : test loss mean=nan ± nan
         : individual accs = ['0.049176', '0.048775', '0.055624', '0.052850', '0.057932', '0.045253', '0.057000', '0.049207', '0.051062', '0.047697', '0.047309', '0.045314', '0.054239', '0.049083', '0.051826', '0.054604', '0.054418', '0.049486', '0.053379', '0.048450']
         : correct/total = [(203, 4128), (205, 4203), (227, 4081), (229, 4333), (237, 4091), (194, 4287), (239, 4193), (214, 4349), (214, 4191), (204, 4277), (196, 4143), (190, 4193), (222, 4093), (206, 4197), (210, 4052), (220, 4029), (226, 4153), (207, 4183), (218, 4084), (200, 4128)]
         : compromised: 0.0495, honest: 0.0515
Round 003: test acc mean=0.0552 ± 0.0132 | min=0.0441 max=0.1052
         : test loss mean=nan ± nan
         : individual accs = ['0.066860', '0.059719', '0.050723', '0.044080', '0.059888', '0.045253', '0.044598', '0.051736', '0.058936', '0.044657', '0.049964', '0.063916', '0.054239', '0.049083', '0.051826', '0.056342', '0.105225', '0.049486', '0.052889', '0.044331']
         : correct/total = [(276, 4128), (251, 4203), (207, 4081), (191, 4333), (245, 4091), (194, 4287), (187, 4193), (225, 4349), (247, 4191), (191, 4277), (207, 4143), (268, 4193), (222, 4093), (206, 4197), (210, 4052), (227, 4029), (437, 4153), (207, 4183), (216, 4084), (183, 4128)]
         : compromised: 0.0495, honest: 0.0566
Round 004: test acc mean=0.0724 ± 0.0299 | min=0.0453 max=0.1305
         : test loss mean=nan ± nan
         : individual accs = ['0.060078', '0.121104', '0.059054', '0.057466', '0.128819', '0.045253', '0.117100', '0.052886', '0.116679', '0.059154', '0.063239', '0.130456', '0.054239', '0.049083', '0.051826', '0.054852', '0.074645', '0.049486', '0.054114', '0.048934']
         : correct/total = [(248, 4128), (509, 4203), (241, 4081), (249, 4333), (527, 4091), (194, 4287), (491, 4193), (230, 4349), (489, 4191), (253, 4277), (262, 4143), (547, 4193), (222, 4093), (206, 4197), (210, 4052), (221, 4029), (310, 4153), (207, 4183), (221, 4084), (202, 4128)]
         : compromised: 0.0495, honest: 0.0782
Round 005: test acc mean=0.0961 ± 0.0400 | min=0.0453 max=0.1696
         : test loss mean=nan ± nan
         : individual accs = ['0.085271', '0.098263', '0.169566', '0.074313', '0.101687', '0.045253', '0.162414', '0.102552', '0.162014', '0.075520', '0.137340', '0.074171', '0.054239', '0.049083', '0.051826', '0.067759', '0.108355', '0.049486', '0.103575', '0.149467']
         : correct/total = [(352, 4128), (413, 4203), (692, 4081), (322, 4333), (416, 4091), (194, 4287), (681, 4193), (446, 4349), (679, 4191), (323, 4277), (569, 4143), (311, 4193), (222, 4093), (206, 4197), (210, 4052), (273, 4029), (450, 4153), (207, 4183), (423, 4084), (617, 4128)]
         : compromised: 0.0495, honest: 0.1078
Round 006: test acc mean=0.1192 ± 0.0483 | min=0.0453 max=0.1840
         : test loss mean=nan ± nan
         : individual accs = ['0.112403', '0.176541', '0.170056', '0.114932', '0.179907', '0.045253', '0.118769', '0.142562', '0.164639', '0.127893', '0.063239', '0.142619', '0.054239', '0.049083', '0.051826', '0.159593', '0.183963', '0.049486', '0.130020', '0.147045']
         : correct/total = [(464, 4128), (742, 4203), (694, 4081), (498, 4333), (736, 4091), (194, 4287), (498, 4193), (620, 4349), (690, 4191), (547, 4277), (262, 4143), (598, 4193), (222, 4093), (206, 4197), (210, 4052), (643, 4029), (764, 4153), (207, 4183), (531, 4084), (607, 4128)]
         : compromised: 0.0495, honest: 0.1366
Round 007: test acc mean=0.1358 ± 0.0747 | min=0.0453 max=0.2738
         : test loss mean=nan ± nan
         : individual accs = ['0.171269', '0.067095', '0.174712', '0.125317', '0.106087', '0.045253', '0.230145', '0.065072', '0.236698', '0.128127', '0.110065', '0.213212', '0.054239', '0.049083', '0.051826', '0.261852', '0.158921', '0.049486', '0.273751', '0.143653']
         : correct/total = [(707, 4128), (282, 4203), (713, 4081), (543, 4333), (434, 4091), (194, 4287), (965, 4193), (283, 4349), (992, 4191), (548, 4277), (456, 4143), (894, 4193), (222, 4093), (206, 4197), (210, 4052), (1055, 4029), (660, 4153), (207, 4183), (1118, 4084), (593, 4128)]
         : compromised: 0.0495, honest: 0.1574
Round 008: test acc mean=0.1666 ± 0.0720 | min=0.0453 max=0.2815
         : test loss mean=nan ± nan
         : individual accs = ['0.187016', '0.238877', '0.212448', '0.175860', '0.214617', '0.045253', '0.226091', '0.213382', '0.171081', '0.184007', '0.165822', '0.197949', '0.054239', '0.049083', '0.051826', '0.281459', '0.228991', '0.049486', '0.190744', '0.193072']
         : correct/total = [(772, 4128), (1004, 4203), (867, 4081), (762, 4333), (878, 4091), (194, 4287), (948, 4193), (928, 4349), (717, 4191), (787, 4277), (687, 4143), (830, 4193), (222, 4093), (206, 4197), (210, 4052), (1134, 4029), (951, 4153), (207, 4183), (779, 4084), (797, 4128)]
         : compromised: 0.0495, honest: 0.1958
Round 009: test acc mean=0.2177 ± 0.1016 | min=0.0453 max=0.3569
         : test loss mean=nan ± nan
         : individual accs = ['0.328004', '0.241256', '0.288410', '0.243249', '0.246883', '0.045253', '0.261388', '0.244424', '0.309711', '0.253682', '0.245716', '0.279275', '0.054239', '0.049083', '0.051826', '0.356912', '0.310619', '0.049486', '0.245593', '0.248062']
         : correct/total = [(1354, 4128), (1014, 4203), (1177, 4081), (1054, 4333), (1010, 4091), (194, 4287), (1096, 4193), (1063, 4349), (1298, 4191), (1085, 4277), (1018, 4143), (1171, 4193), (222, 4093), (206, 4197), (210, 4052), (1438, 4029), (1290, 4153), (207, 4183), (1003, 4084), (1024, 4128)]
         : compromised: 0.0495, honest: 0.2597
Round 010: test acc mean=0.2692 ± 0.1274 | min=0.0453 max=0.3763
         : test loss mean=nan ± nan
         : individual accs = ['0.333091', '0.319296', '0.370007', '0.325640', '0.352237', '0.045253', '0.327451', '0.338239', '0.349559', '0.338789', '0.341057', '0.330312', '0.054239', '0.049083', '0.051826', '0.376272', '0.362870', '0.049486', '0.346229', '0.322432']
         : correct/total = [(1375, 4128), (1342, 4203), (1510, 4081), (1411, 4333), (1441, 4091), (194, 4287), (1373, 4193), (1471, 4349), (1465, 4191), (1449, 4277), (1413, 4143), (1385, 4193), (222, 4093), (206, 4197), (210, 4052), (1516, 4029), (1507, 4153), (207, 4183), (1414, 4084), (1331, 4128)]
         : compromised: 0.0495, honest: 0.3241

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: directed_deviation, 20.0% compromised
Final accuracy - Compromised: 0.0495, Honest: 0.3241
Overall test accuracy: mean=0.2692 ± 0.1274
