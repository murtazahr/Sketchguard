Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.9
  - Stage 1: Distance-based filtering (select 90% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 2 compromised nodes
Round 001: test acc mean=0.6294 ± 0.0650 | min=0.5069 max=0.7158
         : test loss mean=365.5841 ± 1107.2966
         : individual accs = ['0.684211', '0.645078', '0.626442', '0.684801', '0.562610', '0.514410', '0.660262', '0.578527', '0.636444', '0.702128', '0.667832', '0.614222', '0.707465', '0.506897', '0.678826', '0.670742', '0.715771', '0.651636', '0.559205', '0.521472']
         : correct/total = [(780, 1140), (747, 1158), (706, 1127), (793, 1158), (638, 1134), (589, 1145), (756, 1145), (652, 1127), (723, 1136), (792, 1128), (764, 1144), (691, 1125), (815, 1152), (588, 1160), (763, 1124), (768, 1145), (826, 1154), (737, 1131), (647, 1157), (595, 1141)]
         : compromised: 0.5107, honest: 0.6426
         : ubar stats = ['Node 0: s1=0.833, s2=0.400', 'Node 1: s1=0.833, s2=0.800', 'Node 2: s1=0.800, s2=0.250']...
Round 002: test acc mean=0.6831 ± 0.0749 | min=0.5043 max=0.7745
         : test loss mean=17.7246 ± 66.5247
         : individual accs = ['0.709649', '0.688256', '0.651287', '0.750432', '0.602293', '0.515284', '0.734498', '0.614020', '0.737676', '0.736702', '0.774476', '0.716444', '0.701389', '0.504310', '0.631673', '0.721397', '0.764298', '0.663130', '0.690579', '0.753725']
         : correct/total = [(809, 1140), (797, 1158), (734, 1127), (869, 1158), (683, 1134), (590, 1145), (841, 1145), (692, 1127), (838, 1136), (831, 1128), (886, 1144), (806, 1125), (808, 1152), (585, 1160), (710, 1124), (826, 1145), (882, 1154), (750, 1131), (799, 1157), (860, 1141)]
         : compromised: 0.5098, honest: 0.7023
         : ubar stats = ['Node 0: s1=0.833, s2=0.600', 'Node 1: s1=0.833, s2=0.800', 'Node 2: s1=0.800, s2=0.250']...
Round 003: test acc mean=0.7350 ± 0.1112 | min=0.4943 max=0.8601
         : test loss mean=3424807279.5967 ± 14779751204.2912
         : individual accs = ['0.782456', '0.737478', '0.773736', '0.841969', '0.569665', '0.494323', '0.772926', '0.644188', '0.815141', '0.812943', '0.860140', '0.835556', '0.689236', '0.502586', '0.610320', '0.707424', '0.774697', '0.819629', '0.811582', '0.844873']
         : correct/total = [(892, 1140), (854, 1158), (872, 1127), (975, 1158), (646, 1134), (566, 1145), (885, 1145), (726, 1127), (926, 1136), (917, 1128), (984, 1144), (940, 1125), (794, 1152), (583, 1160), (686, 1124), (810, 1145), (894, 1154), (927, 1131), (939, 1157), (964, 1141)]
         : compromised: 0.4985, honest: 0.7613
         : ubar stats = ['Node 0: s1=0.833, s2=0.533', 'Node 1: s1=0.833, s2=0.733', 'Node 2: s1=0.800, s2=0.333']...
Round 004: test acc mean=0.7841 ± 0.1082 | min=0.5069 max=0.8972
         : test loss mean=nan ± nan
         : individual accs = ['0.835965', '0.725389', '0.787045', '0.862694', '0.697531', '0.514410', '0.832314', '0.827862', '0.852113', '0.897163', '0.869755', '0.861333', '0.783854', '0.506897', '0.673488', '0.788646', '0.785095', '0.862953', '0.848747', '0.869413']
         : correct/total = [(953, 1140), (840, 1158), (887, 1127), (999, 1158), (791, 1134), (589, 1145), (953, 1145), (933, 1127), (968, 1136), (1012, 1128), (995, 1144), (969, 1125), (903, 1152), (588, 1160), (757, 1124), (903, 1145), (906, 1154), (976, 1131), (982, 1157), (992, 1141)]
         : compromised: 0.5107, honest: 0.8145
         : ubar stats = ['Node 0: s1=0.833, s2=0.450', 'Node 1: s1=0.833, s2=0.650', 'Node 2: s1=0.800, s2=0.312']...
Round 005: test acc mean=0.8157 ± 0.1052 | min=0.5069 max=0.8989
         : test loss mean=nan ± nan
         : individual accs = ['0.850000', '0.856649', '0.859805', '0.878238', '0.795414', '0.514410', '0.850655', '0.867791', '0.877641', '0.898936', '0.880245', '0.843556', '0.829861', '0.506897', '0.806940', '0.798253', '0.826690', '0.862069', '0.840104', '0.870289']
         : correct/total = [(969, 1140), (992, 1158), (969, 1127), (1017, 1158), (902, 1134), (589, 1145), (974, 1145), (978, 1127), (997, 1136), (1014, 1128), (1007, 1144), (949, 1125), (956, 1152), (588, 1160), (907, 1124), (914, 1145), (954, 1154), (975, 1131), (972, 1157), (993, 1141)]
         : compromised: 0.5107, honest: 0.8496
         : ubar stats = ['Node 0: s1=0.833, s2=0.560', 'Node 1: s1=0.833, s2=0.560', 'Node 2: s1=0.800, s2=0.300']...
Round 006: test acc mean=0.8147 ± 0.1161 | min=0.5069 max=0.8942
         : test loss mean=nan ± nan
         : individual accs = ['0.889474', '0.669257', '0.881988', '0.892055', '0.843034', '0.514410', '0.860262', '0.779059', '0.882923', '0.888298', '0.894231', '0.888889', '0.850694', '0.506897', '0.784698', '0.758079', '0.874350', '0.881521', '0.866033', '0.886941']
         : correct/total = [(1014, 1140), (775, 1158), (994, 1127), (1033, 1158), (956, 1134), (589, 1145), (985, 1145), (878, 1127), (1003, 1136), (1002, 1128), (1023, 1144), (1000, 1125), (980, 1152), (588, 1160), (882, 1124), (868, 1145), (1009, 1154), (997, 1131), (1002, 1157), (1012, 1141)]
         : compromised: 0.5107, honest: 0.8484
         : ubar stats = ['Node 0: s1=0.833, s2=0.500', 'Node 1: s1=0.833, s2=0.533', 'Node 2: s1=0.800, s2=0.292']...
Round 007: test acc mean=0.8205 ± 0.1151 | min=0.5069 max=0.9016
         : test loss mean=nan ± nan
         : individual accs = ['0.860526', '0.822971', '0.888199', '0.899827', '0.884480', '0.514410', '0.871616', '0.737356', '0.888204', '0.901596', '0.898601', '0.890667', '0.800347', '0.506897', '0.718861', '0.822707', '0.884749', '0.884173', '0.842697', '0.891323']
         : correct/total = [(981, 1140), (953, 1158), (1001, 1127), (1042, 1158), (1003, 1134), (589, 1145), (998, 1145), (831, 1127), (1009, 1136), (1017, 1128), (1028, 1144), (1002, 1125), (922, 1152), (588, 1160), (808, 1124), (942, 1145), (1021, 1154), (1000, 1131), (975, 1157), (1017, 1141)]
         : compromised: 0.5107, honest: 0.8549
         : ubar stats = ['Node 0: s1=0.833, s2=0.457', 'Node 1: s1=0.833, s2=0.543', 'Node 2: s1=0.800, s2=0.286']...
Round 008: test acc mean=0.8321 ± 0.1095 | min=0.5069 max=0.8998
         : test loss mean=nan ± nan
         : individual accs = ['0.827193', '0.861831', '0.881988', '0.899827', '0.896825', '0.514410', '0.851528', '0.834960', '0.862676', '0.891844', '0.898601', '0.874667', '0.821181', '0.506897', '0.870996', '0.866376', '0.839688', '0.877984', '0.868626', '0.893076']
         : correct/total = [(943, 1140), (998, 1158), (994, 1127), (1042, 1158), (1017, 1134), (589, 1145), (975, 1145), (941, 1127), (980, 1136), (1006, 1128), (1028, 1144), (984, 1125), (946, 1152), (588, 1160), (979, 1124), (992, 1145), (969, 1154), (993, 1131), (1005, 1157), (1019, 1141)]
         : compromised: 0.5107, honest: 0.8678
         : ubar stats = ['Node 0: s1=0.833, s2=0.425', 'Node 1: s1=0.833, s2=0.600', 'Node 2: s1=0.800, s2=0.281']...
Round 009: test acc mean=0.8362 ± 0.1118 | min=0.5069 max=0.9102
         : test loss mean=nan ± nan
         : individual accs = ['0.821053', '0.883420', '0.889973', '0.908463', '0.873016', '0.514410', '0.880349', '0.818988', '0.879401', '0.893617', '0.902972', '0.910222', '0.834201', '0.506897', '0.831851', '0.868122', '0.883016', '0.881521', '0.850475', '0.892200']
         : correct/total = [(936, 1140), (1023, 1158), (1003, 1127), (1052, 1158), (990, 1134), (589, 1145), (1008, 1145), (923, 1127), (999, 1136), (1008, 1128), (1033, 1144), (1024, 1125), (961, 1152), (588, 1160), (935, 1124), (994, 1145), (1019, 1154), (997, 1131), (984, 1157), (1018, 1141)]
         : compromised: 0.5107, honest: 0.8724
         : ubar stats = ['Node 0: s1=0.833, s2=0.400', 'Node 1: s1=0.833, s2=0.578', 'Node 2: s1=0.800, s2=0.278']...
Round 010: test acc mean=0.8512 ± 0.1144 | min=0.5069 max=0.9128
         : test loss mean=nan ± nan
         : individual accs = ['0.903509', '0.888601', '0.881100', '0.912781', '0.886243', '0.514410', '0.881223', '0.893523', '0.890845', '0.904255', '0.907343', '0.909333', '0.885417', '0.506897', '0.846975', '0.870742', '0.882149', '0.881521', '0.885912', '0.892200']
         : correct/total = [(1030, 1140), (1029, 1158), (993, 1127), (1057, 1158), (1005, 1134), (589, 1145), (1009, 1145), (1007, 1127), (1012, 1136), (1020, 1128), (1038, 1144), (1023, 1125), (1020, 1152), (588, 1160), (952, 1124), (997, 1145), (1018, 1154), (997, 1131), (1025, 1157), (1018, 1141)]
         : compromised: 0.5107, honest: 0.8891
         : ubar stats = ['Node 0: s1=0.833, s2=0.380', 'Node 1: s1=0.833, s2=0.580', 'Node 2: s1=0.800, s2=0.275']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: ubar
Attack: backdoor, 10.0% compromised
Final accuracy - Compromised: 0.5107, Honest: 0.8891
Overall test accuracy: mean=0.8512 ± 0.1144

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.6041 ± 0.1372
Honest nodes ASR: 0.5602 ± 0.0398
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== UBAR SUMMARY ===
Node 0: stage1=0.833, stage2=0.380, overall=0.317
Node 1: stage1=0.833, stage2=0.580, overall=0.483
Node 2: stage1=0.800, stage2=0.275, overall=0.220
Node 3: stage1=0.750, stage2=0.367, overall=0.275
Node 4: stage1=0.750, stage2=0.767, overall=0.575
Node 5: stage1=0.800, stage2=0.475, overall=0.380
Node 6: stage1=0.800, stage2=0.450, overall=0.360
Node 7: stage1=0.800, stage2=0.425, overall=0.340
Node 8: stage1=0.500, stage2=1.000, overall=0.500
Node 9: stage1=0.667, stage2=0.550, overall=0.367
Node 10: stage1=0.750, stage2=0.333, overall=0.250
Node 11: stage1=0.857, stage2=0.350, overall=0.300
Node 12: stage1=0.857, stage2=0.517, overall=0.443
Node 13: stage1=0.750, stage2=0.533, overall=0.400
Node 14: stage1=0.857, stage2=0.517, overall=0.443
Node 15: stage1=0.833, stage2=0.420, overall=0.350
Node 16: stage1=0.800, stage2=0.625, overall=0.500
Node 17: stage1=0.800, stage2=0.300, overall=0.240
Node 18: stage1=0.750, stage2=0.533, overall=0.400
Node 19: stage1=0.500, stage2=1.000, overall=0.500

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.021s (10.2%)
    - Loss computation: 0.185s (87.3%)
    - Aggregation: 0.005s (2.6%)
  TOTALS:
    - Total computation: 0.212s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.212s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.013s
  - Loss computation: 0.139s
  - Aggregation: 0.004s
  - Model transfer: 0.000s
  - Total per node: 0.156s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.253s
  - Total loss computation: 2.787s
  - Total aggregation: 0.072s
  - Total model transfer: 0.000s
  - Grand total: 3.112s
  - Mean Stage 1 acceptance rate: 0.764
  - Mean Stage 2 acceptance rate: 0.520
  - Overall acceptance rate: 0.397

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.9
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 90% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
