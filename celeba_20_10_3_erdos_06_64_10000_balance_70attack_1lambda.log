Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Attack: Compromised 14/20 nodes: [1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 17, 18, 19]
Attack type: directed_deviation, lambda: 1.0
BALANCE algorithm:
  - Model dimension: 30,758 parameters
  - Complexity: O(N×d) = O(20×30,758)
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5160 ± 0.0156 | min=0.4907 max=0.5625
         : test loss mean=nan ± nan
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.490667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (552, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5166, honest: 0.5145
Round 002: test acc mean=0.5130 ± 0.0128 | min=0.4893 max=0.5298
         : test loss mean=6.2296 ± 4.0454
         : individual accs = ['0.529825', '0.515544', '0.493345', '0.528497', '0.509700', '0.514410', '0.524017', '0.502218', '0.522007', '0.492021', '0.525350', '0.520889', '0.523438', '0.489655', '0.489324', '0.517031', '0.515598', '0.508400', '0.522040', '0.516214']
         : correct/total = [(604, 1140), (597, 1158), (556, 1127), (612, 1158), (578, 1134), (589, 1145), (600, 1145), (566, 1127), (593, 1136), (555, 1128), (601, 1144), (586, 1125), (603, 1152), (568, 1160), (550, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (589, 1141)]
         : compromised: 0.5132, honest: 0.5125
Round 003: test acc mean=0.5120 ± 0.0187 | min=0.4715 max=0.5625
         : test loss mean=0.7064 ± 0.0146
         : individual accs = ['0.528947', '0.491364', '0.493345', '0.471503', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.493103', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (569, 1158), (556, 1127), (546, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (572, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5109, honest: 0.5145
Round 004: test acc mean=0.5646 ± 0.0322 | min=0.5142 max=0.6326
         : test loss mean=10.1899 ± 3.9883
         : individual accs = ['0.590351', '0.532815', '0.540373', '0.542314', '0.585538', '0.553712', '0.625328', '0.514641', '0.595951', '0.570035', '0.553322', '0.584889', '0.534722', '0.594828', '0.514235', '0.567686', '0.632582', '0.556145', '0.562662', '0.539877']
         : correct/total = [(673, 1140), (617, 1158), (609, 1127), (628, 1158), (664, 1134), (634, 1145), (716, 1145), (580, 1127), (677, 1136), (643, 1128), (633, 1144), (658, 1125), (616, 1152), (690, 1160), (578, 1124), (650, 1145), (730, 1154), (629, 1131), (651, 1157), (616, 1141)]
         : compromised: 0.5604, honest: 0.5744
Round 005: test acc mean=0.5123 ± 0.0224 | min=0.4375 max=0.5581
         : test loss mean=0.6941 ± 0.0035
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.558079', '0.521397', '0.503993', '0.437500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (639, 1145), (597, 1145), (568, 1127), (497, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5113, honest: 0.5145
Round 006: test acc mean=0.6605 ± 0.0415 | min=0.5839 max=0.7356
         : test loss mean=12.5948 ± 4.2484
         : individual accs = ['0.633333', '0.694301', '0.617569', '0.715889', '0.683422', '0.657642', '0.685590', '0.599823', '0.669894', '0.644504', '0.583916', '0.723556', '0.656250', '0.674138', '0.604982', '0.705677', '0.632582', '0.735632', '0.630078', '0.661700']
         : correct/total = [(722, 1140), (804, 1158), (696, 1127), (829, 1158), (775, 1134), (753, 1145), (785, 1145), (676, 1127), (761, 1136), (727, 1128), (668, 1144), (814, 1125), (756, 1152), (782, 1160), (680, 1124), (808, 1145), (730, 1154), (832, 1131), (729, 1157), (755, 1141)]
         : compromised: 0.6738, honest: 0.6296
Round 007: test acc mean=0.5175 ± 0.0190 | min=0.4911 max=0.5863
         : test loss mean=0.6981 ± 0.0059
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.586268', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (666, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5189, honest: 0.5145
Round 008: test acc mean=0.7138 ± 0.0417 | min=0.6500 max=0.7867
         : test loss mean=9.3673 ± 3.7655
         : individual accs = ['0.682456', '0.753886', '0.728483', '0.759931', '0.747795', '0.701310', '0.751092', '0.718722', '0.657570', '0.734043', '0.652098', '0.786667', '0.710938', '0.656034', '0.709964', '0.758079', '0.681976', '0.762157', '0.649957', '0.673094']
         : correct/total = [(778, 1140), (873, 1158), (821, 1127), (880, 1158), (848, 1134), (803, 1145), (860, 1145), (810, 1127), (747, 1136), (828, 1128), (746, 1144), (885, 1125), (819, 1152), (761, 1160), (798, 1124), (868, 1145), (787, 1154), (862, 1131), (752, 1157), (768, 1141)]
         : compromised: 0.7185, honest: 0.7028
Round 009: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.7026 ± 0.0086
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5172, honest: 0.5145
Round 010: test acc mean=0.7721 ± 0.0320 | min=0.6974 max=0.8230
         : test loss mean=5.6324 ± 1.9352
         : individual accs = ['0.771053', '0.788428', '0.760426', '0.822971', '0.804233', '0.765066', '0.779913', '0.814552', '0.735035', '0.812057', '0.756993', '0.813333', '0.760417', '0.697414', '0.769573', '0.781659', '0.750433', '0.791335', '0.736387', '0.730938']
         : correct/total = [(879, 1140), (913, 1158), (857, 1127), (953, 1158), (912, 1134), (876, 1145), (893, 1145), (918, 1127), (835, 1136), (916, 1128), (866, 1144), (915, 1125), (876, 1152), (809, 1160), (865, 1124), (895, 1145), (866, 1154), (895, 1131), (852, 1157), (834, 1141)]
         : compromised: 0.7666, honest: 0.7849

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: balance
Attack: directed_deviation, 70.0% compromised
Final accuracy - Compromised: 0.7666, Honest: 0.7849
Overall test accuracy: mean=0.7721 ± 0.0320

=== BALANCE SUMMARY ===
Node 0: acceptance=1.000
Node 1: acceptance=1.000
Node 2: acceptance=1.000
Node 3: acceptance=1.000
Node 4: acceptance=1.000
Node 5: acceptance=1.000
Node 6: acceptance=1.000
Node 7: acceptance=1.000
Node 8: acceptance=1.000
Node 9: acceptance=1.000
Node 10: acceptance=1.000
Node 11: acceptance=1.000
Node 12: acceptance=1.000
Node 13: acceptance=1.000
Node 14: acceptance=1.000
Node 15: acceptance=1.000
Node 16: acceptance=1.000
Node 17: acceptance=1.000
Node 18: acceptance=1.000
Node 19: acceptance=1.000

Performance Summary:
  - Distance computation time: 1.947s (42.5%)
  - Filtering time: 2.089s (45.6%)
  - Aggregation time: 0.546s (11.9%)
  - Total time: 4.582s
  - Mean acceptance rate: 1.000

BALANCE Algorithm Properties:
  - Model dimension: 30,758
  - No compression: Full parameter comparison
  - Theoretical complexity: O(deg(i)×d)
  - Approach: Full parameter filtering + averaging
