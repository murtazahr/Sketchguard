# Experiment: coarse k=16 dataset=femnist
# Timestamp: 2025-09-20T12:24:52.375655
# Device: CPU (forced for consistent performance)
# Command: python decentralized_fl_sim.py --dataset femnist --rounds 3 --local-epochs 1 --seed 987654321 --batch-size 64 --lr 0.01 --max-samples 10000 --agg coarse --attack-percentage 0.5 --attack-type directed_deviation --verbose --graph k-regular --k 16 --num-nodes 20
================================================================================

Device: cpu
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: k-regular, nodes: 20, edges: 160
Degree statistics: avg=16.00, min=16, max=16
k-regular with k=16 (each node has exactly 16 neighbors)
Attack: Compromised 10/20 nodes: [1, 2, 5, 11, 12, 13, 14, 15, 17, 18]
Attack type: directed_deviation, lambda: 1.0
COARSE Node 0:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 1:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 2:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 3:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 4:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 5:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 6:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 7:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 8:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 9:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 10:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 11:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 12:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 13:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 14:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 15:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 16:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 17:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 18:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 19:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE ALGORITHM (Sketch-based Filtering + State Aggregation)
  - Model dimension: 6,603,710 parameters
  - Sketch size: 1000
  - Compression ratio: 6603.7x
  - Complexity: O(d + N×k) = O(6,603,710 + 20×1000)
  - Theoretical speedup vs BALANCE: 19.9x
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0569 ± 0.0138 | min=0.0433 max=0.1038
         : test loss mean=4.0317 ± 0.0118
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.057150', '0.053422', '0.055875', '0.057266', '0.043255', '0.051895', '0.064155', '0.048131', '0.052895', '0.086130', '0.046662', '0.053937', '0.103753', '0.048482', '0.049903']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (245, 4287), (224, 4193), (243, 4349), (240, 4191), (185, 4277), (215, 4143), (269, 4193), (197, 4093), (222, 4197), (349, 4052), (188, 4029), (224, 4153), (434, 4183), (198, 4084), (206, 4128)]
         : compromised: 0.0622, honest: 0.0517
         : coarse stats = ['Node 0: acc_rate=0.062', 'Node 1: acc_rate=0.562', 'Node 2: acc_rate=0.562']...
Round 002: test acc mean=0.0580 ± 0.0176 | min=0.0428 max=0.1104
         : test loss mean=3.8541 ± 0.0500
         : individual accs = ['0.084302', '0.052819', '0.046802', '0.049850', '0.046443', '0.058782', '0.053422', '0.046907', '0.050823', '0.042787', '0.048274', '0.046983', '0.048375', '0.049083', '0.050099', '0.055845', '0.083072', '0.110447', '0.086190', '0.047965']
         : correct/total = [(348, 4128), (222, 4203), (191, 4081), (216, 4333), (190, 4091), (252, 4287), (224, 4193), (204, 4349), (213, 4191), (183, 4277), (200, 4143), (197, 4193), (198, 4093), (206, 4197), (203, 4052), (225, 4029), (345, 4153), (462, 4183), (352, 4084), (198, 4128)]
         : compromised: 0.0605, honest: 0.0554
         : coarse stats = ['Node 0: acc_rate=0.062', 'Node 1: acc_rate=0.281', 'Node 2: acc_rate=0.281']...
Round 003: test acc mean=0.0758 ± 0.0503 | min=0.0455 max=0.2255
         : test loss mean=3.6890 ± 0.0938
         : individual accs = ['0.225533', '0.057340', '0.049743', '0.049850', '0.052066', '0.045486', '0.053422', '0.052656', '0.057266', '0.072715', '0.051895', '0.051514', '0.062301', '0.054801', '0.055281', '0.073964', '0.209487', '0.128855', '0.054358', '0.057413']
         : correct/total = [(931, 4128), (241, 4203), (203, 4081), (216, 4333), (213, 4091), (195, 4287), (224, 4193), (229, 4349), (240, 4191), (311, 4277), (215, 4143), (216, 4193), (255, 4093), (230, 4197), (224, 4052), (298, 4029), (870, 4153), (539, 4183), (222, 4084), (237, 4128)]
         : compromised: 0.0634, honest: 0.0882
         : coarse stats = ['Node 0: acc_rate=0.062', 'Node 1: acc_rate=0.188', 'Node 2: acc_rate=0.188']...

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: k-regular, Aggregation: coarse
Attack: directed_deviation, 50.0% compromised
Final accuracy - Compromised: 0.0634, Honest: 0.0882
Overall test accuracy: mean=0.0758 ± 0.0503

=== COARSE SUMMARY ===
Node 0: acceptance=0.062
Node 1: acceptance=0.188
Node 2: acceptance=0.188
Node 3: acceptance=0.188
Node 4: acceptance=0.229
Node 5: acceptance=0.125
Node 6: acceptance=0.208
Node 7: acceptance=0.229
Node 8: acceptance=0.125
Node 9: acceptance=0.146
Node 10: acceptance=0.146
Node 11: acceptance=0.146
Node 12: acceptance=0.188
Node 13: acceptance=0.167
Node 14: acceptance=0.167
Node 15: acceptance=0.062
Node 16: acceptance=0.146
Node 17: acceptance=0.083
Node 18: acceptance=0.146
Node 19: acceptance=0.146

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Sketch transfer: 0.000s (0.0%)
    - Model fetch (accepted): 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Sketching: 0.317s (88.2%)
    - Filtering: 0.001s (0.2%)
    - Aggregation: 0.042s (11.7%)
  TOTALS:
    - Total computation: 0.360s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.360s

=== PER-NODE AVERAGE TIME ===
  - Sketching: 0.253s
  - Filtering: 0.000s
  - Aggregation: 0.027s
  - Sketch transfer: 0.000s
  - Model fetch: 0.000s
  - Total per node: 0.280s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total sketching: 5.064s
  - Total filtering: 0.008s
  - Total aggregation: 0.537s
  - Total sketch transfer: 0.000s
  - Total model fetch: 0.000s
  - Grand total: 5.609s
  - Mean acceptance rate: 0.154

COARSE Algorithm Properties:
  - Original dimension: 6,603,710
  - Sketch size: 1000
  - Compression ratio: 19.9x
  - Single repetition: No repetitions needed
  - Theoretical complexity: O(d + N×k)
  - Approach: Sketch filtering + state aggregation


# Experiment completed successfully
