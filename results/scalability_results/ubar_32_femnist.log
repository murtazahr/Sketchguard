# Experiment: ubar k=32 dataset=femnist
# Timestamp: 2025-09-20T13:12:44.805366
# Device: CPU (forced for consistent performance)
# Command: python decentralized_fl_sim.py --dataset femnist --rounds 3 --local-epochs 1 --seed 987654321 --batch-size 64 --lr 0.01 --max-samples 10000 --agg ubar --ubar-rho 0.5 --attack-percentage 0.5 --attack-type directed_deviation --verbose --graph k-regular --k 32 --num-nodes 35
================================================================================

Device: cpu
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 35 clients
Users per client: 102 (with 27 clients getting +1 user)
Train partition sizes: [21379, 21329, 21288, 21243, 20794, 20346, 20690, 20761, 21128, 20375, 22599, 20872, 21087, 21364, 21281, 22440, 22559, 21849, 20779, 20335, 19894, 21226, 20880, 20651, 21065, 20022, 20242, 21678, 21032, 21502, 19372, 20573, 19550, 21897, 20381]
Test partition sizes: [2426, 2425, 2419, 2410, 2360, 2309, 2348, 2360, 2401, 2315, 2566, 2368, 2393, 2423, 2416, 2540, 2558, 2483, 2362, 2314, 2262, 2410, 2368, 2343, 2390, 2278, 2299, 2457, 2387, 2438, 2206, 2334, 2226, 2479, 2315]
  Client 0: 21379 train samples, 62 unique classes
  Client 1: 21329 train samples, 62 unique classes
  Client 2: 21288 train samples, 62 unique classes
  Client 3: 21243 train samples, 62 unique classes
  Client 4: 20794 train samples, 62 unique classes
  Client 5: 20346 train samples, 62 unique classes
  Client 6: 20690 train samples, 62 unique classes
  Client 7: 20761 train samples, 62 unique classes
  Client 8: 21128 train samples, 62 unique classes
  Client 9: 20375 train samples, 62 unique classes
  Client 10: 22599 train samples, 62 unique classes
  Client 11: 20872 train samples, 62 unique classes
  Client 12: 21087 train samples, 62 unique classes
  Client 13: 21364 train samples, 62 unique classes
  Client 14: 21281 train samples, 62 unique classes
  Client 15: 22440 train samples, 62 unique classes
  Client 16: 22559 train samples, 62 unique classes
  Client 17: 21849 train samples, 62 unique classes
  Client 18: 20779 train samples, 62 unique classes
  Client 19: 20335 train samples, 62 unique classes
  Client 20: 19894 train samples, 62 unique classes
  Client 21: 21226 train samples, 62 unique classes
  Client 22: 20880 train samples, 62 unique classes
  Client 23: 20651 train samples, 62 unique classes
  Client 24: 21065 train samples, 62 unique classes
  Client 25: 20022 train samples, 62 unique classes
  Client 26: 20242 train samples, 62 unique classes
  Client 27: 21678 train samples, 62 unique classes
  Client 28: 21032 train samples, 62 unique classes
  Client 29: 21502 train samples, 62 unique classes
  Client 30: 19372 train samples, 62 unique classes
  Client 31: 20573 train samples, 62 unique classes
  Client 32: 19550 train samples, 62 unique classes
  Client 33: 21897 train samples, 62 unique classes
  Client 34: 20381 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: k-regular, nodes: 35, edges: 560
Degree statistics: avg=32.00, min=32, max=32
k-regular with k=32 (each node has exactly 32 neighbors)
Attack: Compromised 17/35 nodes: [3, 5, 6, 10, 11, 12, 14, 16, 22, 24, 26, 27, 28, 29, 31, 32, 33]
Attack type: directed_deviation, lambda: 1.0
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 6,603,710 parameters
  - Rho parameter: 0.5
  - Stage 1: Distance-based filtering (select 50% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.0170 ± 0.0167
Round 001: test acc mean=0.0622 ± 0.0170 | min=0.0456 max=0.1140
         : test loss mean=4.0114 ± 0.0375
         : individual accs = ['0.055235', '0.093196', '0.054155', '0.081743', '0.050847', '0.056301', '0.053237', '0.068644', '0.063307', '0.051836', '0.049493', '0.054899', '0.059758', '0.063970', '0.063742', '0.086614', '0.047303', '0.113975', '0.093141', '0.054451', '0.068523', '0.059751', '0.051520', '0.063594', '0.049791', '0.106673', '0.053502', '0.045584', '0.048597', '0.046349', '0.048957', '0.052271', '0.052111', '0.051230', '0.063067']
         : correct/total = [(134, 2426), (226, 2425), (131, 2419), (197, 2410), (120, 2360), (130, 2309), (125, 2348), (162, 2360), (152, 2401), (120, 2315), (127, 2566), (130, 2368), (143, 2393), (155, 2423), (154, 2416), (220, 2540), (121, 2558), (283, 2483), (220, 2362), (126, 2314), (155, 2262), (144, 2410), (122, 2368), (149, 2343), (119, 2390), (243, 2278), (123, 2299), (112, 2457), (116, 2387), (113, 2438), (108, 2206), (122, 2334), (116, 2226), (127, 2479), (146, 2315)]
         : compromised: 0.0540, honest: 0.0700
         : ubar stats = ['Node 0: s1=0.500, s2=0.938', 'Node 1: s1=0.500, s2=0.250', 'Node 2: s1=0.500, s2=0.312']...
Round 002: test acc mean=0.0577 ± 0.0164 | min=0.0402 max=0.1126
         : test loss mean=3.9287 ± 0.0524
         : individual accs = ['0.055647', '0.056082', '0.051674', '0.078838', '0.055932', '0.099177', '0.053237', '0.048305', '0.057893', '0.053564', '0.051052', '0.062922', '0.059758', '0.062319', '0.042632', '0.040157', '0.046130', '0.045107', '0.061389', '0.046672', '0.060124', '0.052697', '0.051520', '0.049509', '0.112552', '0.044337', '0.052197', '0.045584', '0.048597', '0.046349', '0.089755', '0.055698', '0.048967', '0.089956', '0.044492']
         : correct/total = [(135, 2426), (136, 2425), (125, 2419), (190, 2410), (132, 2360), (229, 2309), (125, 2348), (114, 2360), (139, 2401), (124, 2315), (131, 2566), (149, 2368), (143, 2393), (151, 2423), (103, 2416), (102, 2540), (118, 2558), (112, 2483), (145, 2362), (108, 2314), (136, 2262), (127, 2410), (122, 2368), (116, 2343), (269, 2390), (101, 2278), (120, 2299), (112, 2457), (116, 2387), (113, 2438), (198, 2206), (130, 2334), (109, 2226), (223, 2479), (103, 2315)]
         : compromised: 0.0615, honest: 0.0542
         : ubar stats = ['Node 0: s1=0.500, s2=0.906', 'Node 1: s1=0.500, s2=0.531', 'Node 2: s1=0.500, s2=0.188']...
Round 003: test acc mean=0.0610 ± 0.0167 | min=0.0402 max=0.1233
         : test loss mean=3.8260 ± 0.0379
         : individual accs = ['0.055235', '0.056082', '0.054155', '0.049378', '0.048729', '0.056301', '0.053237', '0.073305', '0.052062', '0.086393', '0.049493', '0.123311', '0.059758', '0.062319', '0.051738', '0.040157', '0.051603', '0.079742', '0.088484', '0.055748', '0.060124', '0.063900', '0.048142', '0.049936', '0.089121', '0.055751', '0.052197', '0.061457', '0.057813', '0.046349', '0.091568', '0.055698', '0.052111', '0.051230', '0.052700']
         : correct/total = [(134, 2426), (136, 2425), (131, 2419), (119, 2410), (115, 2360), (130, 2309), (125, 2348), (173, 2360), (125, 2401), (200, 2315), (127, 2566), (292, 2368), (143, 2393), (151, 2423), (125, 2416), (102, 2540), (132, 2558), (198, 2483), (209, 2362), (129, 2314), (136, 2262), (154, 2410), (114, 2368), (117, 2343), (213, 2390), (127, 2278), (120, 2299), (151, 2457), (138, 2387), (113, 2438), (202, 2206), (130, 2334), (116, 2226), (127, 2479), (122, 2315)]
         : compromised: 0.0593, honest: 0.0626
         : ubar stats = ['Node 0: s1=0.500, s2=0.917', 'Node 1: s1=0.500, s2=0.521', 'Node 2: s1=0.500, s2=0.167']...

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 35, Graph: k-regular, Aggregation: ubar
Attack: directed_deviation, 50.0% compromised
Final accuracy - Compromised: 0.0593, Honest: 0.0626
Overall test accuracy: mean=0.0610 ± 0.0167

=== UBAR SUMMARY ===
Node 0: stage1=0.500, stage2=0.917, overall=0.458
Node 1: stage1=0.500, stage2=0.521, overall=0.260
Node 2: stage1=0.500, stage2=0.167, overall=0.083
Node 3: stage1=0.500, stage2=0.438, overall=0.219
Node 4: stage1=0.500, stage2=0.562, overall=0.281
Node 5: stage1=0.500, stage2=0.271, overall=0.135
Node 6: stage1=0.500, stage2=0.333, overall=0.167
Node 7: stage1=0.500, stage2=0.500, overall=0.250
Node 8: stage1=0.500, stage2=0.271, overall=0.135
Node 9: stage1=0.500, stage2=0.208, overall=0.104
Node 10: stage1=0.500, stage2=0.333, overall=0.167
Node 11: stage1=0.500, stage2=0.062, overall=0.031
Node 12: stage1=0.500, stage2=0.562, overall=0.281
Node 13: stage1=0.500, stage2=0.938, overall=0.469
Node 14: stage1=0.500, stage2=0.229, overall=0.115
Node 15: stage1=0.500, stage2=0.292, overall=0.146
Node 16: stage1=0.500, stage2=0.812, overall=0.406
Node 17: stage1=0.500, stage2=0.625, overall=0.312
Node 18: stage1=0.500, stage2=0.104, overall=0.052
Node 19: stage1=0.500, stage2=0.479, overall=0.240
Node 20: stage1=0.500, stage2=0.188, overall=0.094
Node 21: stage1=0.500, stage2=0.521, overall=0.260
Node 22: stage1=0.500, stage2=0.458, overall=0.229
Node 23: stage1=0.500, stage2=0.354, overall=0.177
Node 24: stage1=0.500, stage2=0.062, overall=0.031
Node 25: stage1=0.500, stage2=0.750, overall=0.375
Node 26: stage1=0.500, stage2=0.688, overall=0.344
Node 27: stage1=0.500, stage2=0.646, overall=0.323
Node 28: stage1=0.500, stage2=0.062, overall=0.031
Node 29: stage1=0.500, stage2=0.729, overall=0.365
Node 30: stage1=0.500, stage2=0.562, overall=0.281
Node 31: stage1=0.500, stage2=0.146, overall=0.073
Node 32: stage1=0.500, stage2=0.583, overall=0.292
Node 33: stage1=0.500, stage2=0.708, overall=0.354
Node 34: stage1=0.500, stage2=0.479, overall=0.240

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.138s (39.5%)
    - Loss computation: 0.162s (46.4%)
    - Aggregation: 0.050s (14.2%)
  TOTALS:
    - Total computation: 0.350s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.350s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.116s
  - Loss computation: 0.137s
  - Aggregation: 0.024s
  - Model transfer: 0.000s
  - Total per node: 0.278s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 4.052s
  - Total loss computation: 4.809s
  - Total aggregation: 0.852s
  - Total model transfer: 0.000s
  - Grand total: 9.713s
  - Mean Stage 1 acceptance rate: 0.500
  - Mean Stage 2 acceptance rate: 0.445
  - Overall acceptance rate: 0.222

UBAR Algorithm Properties:
  - Model dimension: 6,603,710
  - Rho parameter: 0.5
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 50% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation


# Experiment completed successfully
