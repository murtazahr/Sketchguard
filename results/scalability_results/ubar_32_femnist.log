# Experiment: ubar k=32 dataset=femnist
# Timestamp: 2025-09-19T16:44:19.157012
# Command: python decentralized_fl_sim.py --dataset femnist --rounds 3 --local-epochs 1 --seed 987654321 --batch-size 64 --lr 0.01 --max-samples 10000 --agg ubar --ubar-rho 0.5 --attack-percentage 0.5 --attack-type directed_deviation --verbose --graph k-regular --k 32 --num-nodes 35
================================================================================

Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 35 clients
Users per client: 102 (with 27 clients getting +1 user)
Train partition sizes: [21379, 21329, 21288, 21243, 20794, 20346, 20690, 20761, 21128, 20375, 22599, 20872, 21087, 21364, 21281, 22440, 22559, 21849, 20779, 20335, 19894, 21226, 20880, 20651, 21065, 20022, 20242, 21678, 21032, 21502, 19372, 20573, 19550, 21897, 20381]
Test partition sizes: [2426, 2425, 2419, 2410, 2360, 2309, 2348, 2360, 2401, 2315, 2566, 2368, 2393, 2423, 2416, 2540, 2558, 2483, 2362, 2314, 2262, 2410, 2368, 2343, 2390, 2278, 2299, 2457, 2387, 2438, 2206, 2334, 2226, 2479, 2315]
  Client 0: 21379 train samples, 62 unique classes
  Client 1: 21329 train samples, 62 unique classes
  Client 2: 21288 train samples, 62 unique classes
  Client 3: 21243 train samples, 62 unique classes
  Client 4: 20794 train samples, 62 unique classes
  Client 5: 20346 train samples, 62 unique classes
  Client 6: 20690 train samples, 62 unique classes
  Client 7: 20761 train samples, 62 unique classes
  Client 8: 21128 train samples, 62 unique classes
  Client 9: 20375 train samples, 62 unique classes
  Client 10: 22599 train samples, 62 unique classes
  Client 11: 20872 train samples, 62 unique classes
  Client 12: 21087 train samples, 62 unique classes
  Client 13: 21364 train samples, 62 unique classes
  Client 14: 21281 train samples, 62 unique classes
  Client 15: 22440 train samples, 62 unique classes
  Client 16: 22559 train samples, 62 unique classes
  Client 17: 21849 train samples, 62 unique classes
  Client 18: 20779 train samples, 62 unique classes
  Client 19: 20335 train samples, 62 unique classes
  Client 20: 19894 train samples, 62 unique classes
  Client 21: 21226 train samples, 62 unique classes
  Client 22: 20880 train samples, 62 unique classes
  Client 23: 20651 train samples, 62 unique classes
  Client 24: 21065 train samples, 62 unique classes
  Client 25: 20022 train samples, 62 unique classes
  Client 26: 20242 train samples, 62 unique classes
  Client 27: 21678 train samples, 62 unique classes
  Client 28: 21032 train samples, 62 unique classes
  Client 29: 21502 train samples, 62 unique classes
  Client 30: 19372 train samples, 62 unique classes
  Client 31: 20573 train samples, 62 unique classes
  Client 32: 19550 train samples, 62 unique classes
  Client 33: 21897 train samples, 62 unique classes
  Client 34: 20381 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: k-regular, nodes: 35, edges: 560
Degree statistics: avg=32.00, min=32, max=32
k-regular with k=32 (each node has exactly 32 neighbors)
Attack: Compromised 17/35 nodes: [3, 5, 6, 10, 11, 12, 14, 16, 22, 24, 26, 27, 28, 29, 31, 32, 33]
Attack type: directed_deviation, lambda: 1.0
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 6,603,710 parameters
  - Rho parameter: 0.5
  - Stage 1: Distance-based filtering (select 50% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.0170 ± 0.0167
Round 001: test acc mean=0.0666 ± 0.0185 | min=0.0456 max=0.0996
         : test loss mean=4.0155 ± 0.0340
         : individual accs = ['0.055235', '0.096495', '0.054155', '0.095436', '0.099576', '0.099177', '0.053237', '0.068644', '0.052062', '0.051836', '0.049493', '0.068834', '0.059758', '0.086257', '0.076987', '0.092126', '0.087177', '0.086992', '0.055885', '0.054451', '0.056145', '0.048133', '0.051520', '0.052070', '0.092469', '0.099210', '0.053502', '0.045584', '0.074990', '0.046349', '0.048957', '0.055698', '0.052111', '0.051230', '0.059611']
         : correct/total = [(134, 2426), (234, 2425), (131, 2419), (230, 2410), (235, 2360), (229, 2309), (125, 2348), (162, 2360), (125, 2401), (120, 2315), (127, 2566), (163, 2368), (143, 2393), (209, 2423), (186, 2416), (234, 2540), (223, 2558), (216, 2483), (132, 2362), (126, 2314), (127, 2262), (116, 2410), (122, 2368), (122, 2343), (221, 2390), (226, 2278), (123, 2299), (112, 2457), (179, 2387), (113, 2438), (108, 2206), (130, 2334), (116, 2226), (127, 2479), (138, 2315)]
         : compromised: 0.0655, honest: 0.0677
         : ubar stats = ['Node 0: s1=0.500, s2=0.812', 'Node 1: s1=0.500, s2=0.312', 'Node 2: s1=0.500, s2=0.188']...
Round 002: test acc mean=0.0611 ± 0.0202 | min=0.0402 max=0.1428
         : test loss mean=3.9356 ± 0.0419
         : individual accs = ['0.082852', '0.056082', '0.054155', '0.072199', '0.055932', '0.086184', '0.053237', '0.048305', '0.057893', '0.050972', '0.092751', '0.056588', '0.059758', '0.062319', '0.042632', '0.040157', '0.046130', '0.045107', '0.088061', '0.046672', '0.060124', '0.052697', '0.051520', '0.092616', '0.057322', '0.055751', '0.052197', '0.045584', '0.051529', '0.046349', '0.142792', '0.055698', '0.049416', '0.081888', '0.044492']
         : correct/total = [(201, 2426), (136, 2425), (131, 2419), (174, 2410), (132, 2360), (199, 2309), (125, 2348), (114, 2360), (139, 2401), (118, 2315), (238, 2566), (134, 2368), (143, 2393), (151, 2423), (103, 2416), (102, 2540), (118, 2558), (112, 2483), (208, 2362), (108, 2314), (136, 2262), (127, 2410), (122, 2368), (217, 2343), (137, 2390), (127, 2278), (120, 2299), (112, 2457), (123, 2387), (113, 2438), (315, 2206), (130, 2334), (110, 2226), (203, 2479), (103, 2315)]
         : compromised: 0.0589, honest: 0.0632
         : ubar stats = ['Node 0: s1=0.500, s2=0.875', 'Node 1: s1=0.500, s2=0.562', 'Node 2: s1=0.500, s2=0.281']...
Round 003: test acc mean=0.0646 ± 0.0317 | min=0.0364 max=0.1872
         : test loss mean=3.8095 ± 0.0583
         : individual accs = ['0.055235', '0.056082', '0.054155', '0.097925', '0.048729', '0.056301', '0.053237', '0.068644', '0.052062', '0.051404', '0.088075', '0.046453', '0.059758', '0.062319', '0.051738', '0.040157', '0.054730', '0.073298', '0.178239', '0.055748', '0.060124', '0.061826', '0.048142', '0.049936', '0.053556', '0.055751', '0.052197', '0.061457', '0.036447', '0.046349', '0.187217', '0.089117', '0.050314', '0.051230', '0.052700']
         : correct/total = [(134, 2426), (136, 2425), (131, 2419), (236, 2410), (115, 2360), (130, 2309), (125, 2348), (162, 2360), (125, 2401), (119, 2315), (226, 2566), (110, 2368), (143, 2393), (151, 2423), (125, 2416), (102, 2540), (140, 2558), (182, 2483), (421, 2362), (129, 2314), (136, 2262), (149, 2410), (114, 2368), (117, 2343), (128, 2390), (127, 2278), (120, 2299), (151, 2457), (87, 2387), (113, 2438), (413, 2206), (208, 2334), (112, 2226), (127, 2479), (122, 2315)]
         : compromised: 0.0586, honest: 0.0702
         : ubar stats = ['Node 0: s1=0.500, s2=0.667', 'Node 1: s1=0.500, s2=0.479', 'Node 2: s1=0.500, s2=0.396']...

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 35, Graph: k-regular, Aggregation: ubar
Attack: directed_deviation, 50.0% compromised
Final accuracy - Compromised: 0.0586, Honest: 0.0702
Overall test accuracy: mean=0.0646 ± 0.0317

=== UBAR SUMMARY ===
Node 0: stage1=0.500, stage2=0.667, overall=0.333
Node 1: stage1=0.500, stage2=0.479, overall=0.240
Node 2: stage1=0.500, stage2=0.396, overall=0.198
Node 3: stage1=0.500, stage2=0.208, overall=0.104
Node 4: stage1=0.500, stage2=0.688, overall=0.344
Node 5: stage1=0.500, stage2=0.062, overall=0.031
Node 6: stage1=0.500, stage2=0.708, overall=0.354
Node 7: stage1=0.500, stage2=0.646, overall=0.323
Node 8: stage1=0.500, stage2=0.354, overall=0.177
Node 9: stage1=0.500, stage2=0.375, overall=0.188
Node 10: stage1=0.500, stage2=0.208, overall=0.104
Node 11: stage1=0.500, stage2=0.083, overall=0.042
Node 12: stage1=0.500, stage2=0.646, overall=0.323
Node 13: stage1=0.500, stage2=0.500, overall=0.250
Node 14: stage1=0.500, stage2=0.271, overall=0.135
Node 15: stage1=0.500, stage2=0.250, overall=0.125
Node 16: stage1=0.500, stage2=0.458, overall=0.229
Node 17: stage1=0.500, stage2=0.562, overall=0.281
Node 18: stage1=0.500, stage2=0.250, overall=0.125
Node 19: stage1=0.500, stage2=0.458, overall=0.229
Node 20: stage1=0.500, stage2=0.417, overall=0.208
Node 21: stage1=0.500, stage2=0.583, overall=0.292
Node 22: stage1=0.500, stage2=0.500, overall=0.250
Node 23: stage1=0.500, stage2=0.396, overall=0.198
Node 24: stage1=0.500, stage2=0.083, overall=0.042
Node 25: stage1=0.500, stage2=0.583, overall=0.292
Node 26: stage1=0.500, stage2=0.708, overall=0.354
Node 27: stage1=0.500, stage2=0.667, overall=0.333
Node 28: stage1=0.500, stage2=0.354, overall=0.177
Node 29: stage1=0.500, stage2=0.458, overall=0.229
Node 30: stage1=0.500, stage2=0.250, overall=0.125
Node 31: stage1=0.500, stage2=0.062, overall=0.031
Node 32: stage1=0.500, stage2=0.292, overall=0.146
Node 33: stage1=0.500, stage2=0.604, overall=0.302
Node 34: stage1=0.500, stage2=0.417, overall=0.208

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.047s (1.0%)
    - Loss computation: 4.844s (98.9%)
    - Aggregation: 0.009s (0.2%)
  TOTALS:
    - Total computation: 4.899s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 4.899s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.037s
  - Loss computation: 4.658s
  - Aggregation: 0.005s
  - Model transfer: 0.000s
  - Total per node: 4.700s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 1.280s
  - Total loss computation: 163.033s
  - Total aggregation: 0.180s
  - Total model transfer: 0.000s
  - Grand total: 164.493s
  - Mean Stage 1 acceptance rate: 0.500
  - Mean Stage 2 acceptance rate: 0.418
  - Overall acceptance rate: 0.209

UBAR Algorithm Properties:
  - Model dimension: 6,603,710
  - Rho parameter: 0.5
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 50% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation


# Experiment completed successfully
