Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0546 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=4.1016 ± 0.0015
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057504', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (241, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
Round 002: test acc mean=0.5151 ± 0.0143 | min=0.4905 max=0.5431
         : test loss mean=2.9278 ± 0.0784
         : individual accs = ['0.519138', '0.523911', '0.510659', '0.515809', '0.530433', '0.521344', '0.497257', '0.499425', '0.543068', '0.490531', '0.490949', '0.507990', '0.523333', '0.530617', '0.527147', '0.503599', '0.501324', '0.511834', '0.531587', '0.522287']
         : correct/total = [(2143, 4128), (2202, 4203), (2084, 4081), (2235, 4333), (2170, 4091), (2235, 4287), (2085, 4193), (2172, 4349), (2276, 4191), (2098, 4277), (2034, 4143), (2130, 4193), (2142, 4093), (2227, 4197), (2136, 4052), (2029, 4029), (2082, 4153), (2141, 4183), (2171, 4084), (2156, 4128)]
Round 003: test acc mean=0.7242 ± 0.0080 | min=0.7031 max=0.7361
         : test loss mean=0.9959 ± 0.0294
         : individual accs = ['0.718508', '0.726624', '0.719677', '0.733903', '0.721828', '0.734080', '0.727880', '0.727294', '0.736101', '0.719897', '0.709631', '0.722633', '0.731248', '0.727186', '0.725074', '0.726979', '0.703106', '0.723643', '0.731391', '0.716812']
         : correct/total = [(2966, 4128), (3054, 4203), (2937, 4081), (3180, 4333), (2953, 4091), (3147, 4287), (3052, 4193), (3163, 4349), (3085, 4191), (3079, 4277), (2940, 4143), (3030, 4193), (2993, 4093), (3052, 4197), (2938, 4052), (2929, 4029), (2920, 4153), (3027, 4183), (2987, 4084), (2959, 4128)]
Round 004: test acc mean=0.7825 ± 0.0072 | min=0.7625 max=0.7932
         : test loss mean=0.7012 ± 0.0223
         : individual accs = ['0.777859', '0.785391', '0.777260', '0.781445', '0.768027', '0.788430', '0.790126', '0.785928', '0.791219', '0.785130', '0.762491', '0.785595', '0.784999', '0.782464', '0.793189', '0.787044', '0.779918', '0.781257', '0.784525', '0.778101']
         : correct/total = [(3211, 4128), (3301, 4203), (3172, 4081), (3386, 4333), (3142, 4091), (3380, 4287), (3313, 4193), (3418, 4349), (3316, 4191), (3358, 4277), (3159, 4143), (3294, 4193), (3213, 4093), (3284, 4197), (3214, 4052), (3171, 4029), (3239, 4153), (3268, 4183), (3204, 4084), (3212, 4128)]
Round 005: test acc mean=0.8104 ± 0.0074 | min=0.7900 max=0.8196
         : test loss mean=0.6008 ± 0.0206
         : individual accs = ['0.799903', '0.815370', '0.810341', '0.810062', '0.798582', '0.815489', '0.814453', '0.816050', '0.815796', '0.811083', '0.790007', '0.806582', '0.812363', '0.812723', '0.819595', '0.815835', '0.810498', '0.818551', '0.812684', '0.801599']
         : correct/total = [(3302, 4128), (3427, 4203), (3307, 4081), (3510, 4333), (3267, 4091), (3496, 4287), (3415, 4193), (3549, 4349), (3419, 4191), (3469, 4277), (3273, 4143), (3382, 4193), (3325, 4093), (3411, 4197), (3321, 4052), (3287, 4029), (3366, 4153), (3424, 4183), (3319, 4084), (3309, 4128)]
Round 006: test acc mean=0.8251 ± 0.0058 | min=0.8108 max=0.8335
         : test loss mean=0.5448 ± 0.0196
         : individual accs = ['0.815891', '0.828932', '0.823573', '0.826679', '0.816671', '0.828551', '0.830670', '0.831915', '0.833453', '0.829086', '0.810765', '0.822561', '0.821647', '0.824637', '0.829467', '0.825515', '0.826150', '0.831222', '0.825661', '0.818556']
         : correct/total = [(3368, 4128), (3484, 4203), (3361, 4081), (3582, 4333), (3341, 4091), (3552, 4287), (3483, 4193), (3618, 4349), (3493, 4191), (3546, 4277), (3359, 4143), (3449, 4193), (3363, 4093), (3461, 4197), (3361, 4052), (3326, 4029), (3431, 4153), (3477, 4183), (3372, 4084), (3379, 4128)]
Round 007: test acc mean=0.8344 ± 0.0061 | min=0.8202 max=0.8451
         : test loss mean=0.5102 ± 0.0196
         : individual accs = ['0.821463', '0.840590', '0.836805', '0.835680', '0.828159', '0.836016', '0.839971', '0.836744', '0.845144', '0.836801', '0.820179', '0.829478', '0.832152', '0.839647', '0.840326', '0.835691', '0.836985', '0.834568', '0.833007', '0.829215']
         : correct/total = [(3391, 4128), (3533, 4203), (3415, 4081), (3621, 4333), (3388, 4091), (3584, 4287), (3522, 4193), (3639, 4349), (3542, 4191), (3579, 4277), (3398, 4143), (3478, 4193), (3406, 4093), (3524, 4197), (3405, 4052), (3367, 4029), (3476, 4153), (3491, 4183), (3402, 4084), (3423, 4128)]
Round 008: test acc mean=0.8404 ± 0.0052 | min=0.8277 max=0.8474
         : test loss mean=0.4871 ± 0.0200
         : individual accs = ['0.828731', '0.842731', '0.843421', '0.843988', '0.834515', '0.842780', '0.847365', '0.845482', '0.844190', '0.843348', '0.827661', '0.837586', '0.838260', '0.841077', '0.843040', '0.844130', '0.842042', '0.840545', '0.842311', '0.834787']
         : correct/total = [(3421, 4128), (3542, 4203), (3442, 4081), (3657, 4333), (3414, 4091), (3613, 4287), (3553, 4193), (3677, 4349), (3538, 4191), (3607, 4277), (3429, 4143), (3512, 4193), (3431, 4093), (3530, 4197), (3416, 4052), (3401, 4029), (3497, 4153), (3516, 4183), (3440, 4084), (3446, 4128)]
Round 009: test acc mean=0.8465 ± 0.0056 | min=0.8353 max=0.8552
         : test loss mean=0.4667 ± 0.0199
         : individual accs = ['0.835271', '0.851059', '0.848812', '0.848604', '0.836226', '0.845580', '0.852135', '0.853759', '0.855166', '0.851999', '0.836350', '0.843072', '0.841437', '0.849178', '0.846742', '0.848349', '0.847098', '0.849151', '0.847453', '0.842297']
         : correct/total = [(3448, 4128), (3577, 4203), (3464, 4081), (3677, 4333), (3421, 4091), (3625, 4287), (3573, 4193), (3713, 4349), (3584, 4191), (3644, 4277), (3465, 4143), (3535, 4193), (3444, 4093), (3564, 4197), (3431, 4052), (3418, 4029), (3518, 4153), (3552, 4183), (3461, 4084), (3477, 4128)]
Round 010: test acc mean=0.8503 ± 0.0050 | min=0.8388 max=0.8573
         : test loss mean=0.4533 ± 0.0192
         : individual accs = ['0.841085', '0.855103', '0.852487', '0.852758', '0.843803', '0.848146', '0.853565', '0.856289', '0.857313', '0.856441', '0.838764', '0.847365', '0.847300', '0.853228', '0.852419', '0.854058', '0.848543', '0.852020', '0.849902', '0.845930']
         : correct/total = [(3472, 4128), (3594, 4203), (3479, 4081), (3695, 4333), (3452, 4091), (3636, 4287), (3579, 4193), (3724, 4349), (3593, 4191), (3663, 4277), (3475, 4143), (3553, 4193), (3468, 4093), (3581, 4197), (3454, 4052), (3441, 4029), (3524, 4153), (3564, 4183), (3471, 4084), (3492, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Overall test accuracy: mean=0.8503 ± 0.0050
