Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: directed_deviation, lambda: 1.0
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5574 ± 0.0110 | min=0.5356 max=0.5776
         : test loss mean=1.6703 ± 0.0362
         : individual accs = ['0.562016', '0.564121', '0.546190', '0.555504', '0.553899', '0.577560', '0.571667', '0.556450', '0.568122', '0.540566', '0.535602', '0.563081', '0.553872', '0.558971', '0.566140', '0.554480', '0.544426', '0.558929', '0.573213', '0.543605']
         : correct/total = [(2320, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2266, 4091), (2476, 4287), (2397, 4193), (2420, 4349), (2381, 4191), (2312, 4277), (2219, 4143), (2361, 4193), (2267, 4093), (2346, 4197), (2294, 4052), (2234, 4029), (2261, 4153), (2338, 4183), (2341, 4084), (2244, 4128)]
         : compromised: 0.5623, honest: 0.5562
Round 002: test acc mean=0.7364 ± 0.0058 | min=0.7253 max=0.7473
         : test loss mean=0.8866 ± 0.0214
         : individual accs = ['0.735223', '0.747323', '0.725312', '0.742442', '0.733317', '0.738745', '0.738135', '0.740170', '0.743737', '0.739303', '0.728458', '0.737896', '0.734425', '0.730045', '0.740375', '0.733184', '0.729352', '0.737987', '0.743144', '0.728440']
         : correct/total = [(3035, 4128), (3141, 4203), (2960, 4081), (3217, 4333), (3000, 4091), (3167, 4287), (3095, 4193), (3219, 4349), (3117, 4191), (3162, 4277), (3018, 4143), (3094, 4193), (3006, 4093), (3064, 4197), (3000, 4052), (2954, 4029), (3029, 4153), (3087, 4183), (3035, 4084), (3007, 4128)]
         : compromised: 0.7353, honest: 0.7366
Round 003: test acc mean=0.7663 ± 0.0078 | min=0.7517 max=0.7841
         : test loss mean=0.7348 ± 0.0237
         : individual accs = ['0.771318', '0.778492', '0.762803', '0.765982', '0.757761', '0.771635', '0.772955', '0.774891', '0.784061', '0.762217', '0.762008', '0.769616', '0.760567', '0.765070', '0.766782', '0.764458', '0.751746', '0.766914', '0.763712', '0.752422']
         : correct/total = [(3184, 4128), (3272, 4203), (3113, 4081), (3319, 4333), (3100, 4091), (3308, 4287), (3241, 4193), (3370, 4349), (3286, 4191), (3260, 4277), (3157, 4143), (3227, 4193), (3113, 4093), (3211, 4197), (3107, 4052), (3080, 4029), (3122, 4153), (3208, 4183), (3119, 4084), (3106, 4128)]
         : compromised: 0.7660, honest: 0.7663
Round 004: test acc mean=0.7881 ± 0.0064 | min=0.7717 max=0.7967
         : test loss mean=0.6583 ± 0.0215
         : individual accs = ['0.788517', '0.791102', '0.779956', '0.792753', '0.784894', '0.793795', '0.786072', '0.795815', '0.796707', '0.794248', '0.771663', '0.784641', '0.789885', '0.793662', '0.794423', '0.786796', '0.787864', '0.790103', '0.780362', '0.778585']
         : correct/total = [(3255, 4128), (3325, 4203), (3183, 4081), (3435, 4333), (3211, 4091), (3403, 4287), (3296, 4193), (3461, 4349), (3339, 4191), (3397, 4277), (3197, 4143), (3290, 4193), (3233, 4093), (3331, 4197), (3219, 4052), (3170, 4029), (3272, 4153), (3305, 4183), (3187, 4084), (3214, 4128)]
         : compromised: 0.7919, honest: 0.7871
Round 005: test acc mean=0.8067 ± 0.0065 | min=0.7936 max=0.8144
         : test loss mean=0.6009 ± 0.0228
         : individual accs = ['0.812984', '0.811087', '0.802499', '0.807062', '0.794916', '0.810823', '0.810160', '0.810761', '0.814364', '0.811083', '0.795317', '0.803005', '0.802834', '0.811532', '0.814166', '0.806404', '0.800385', '0.806598', '0.813908', '0.793605']
         : correct/total = [(3356, 4128), (3409, 4203), (3275, 4081), (3497, 4333), (3252, 4091), (3476, 4287), (3397, 4193), (3526, 4349), (3413, 4191), (3469, 4277), (3295, 4143), (3367, 4193), (3286, 4093), (3406, 4197), (3299, 4052), (3249, 4029), (3324, 4153), (3374, 4183), (3324, 4084), (3276, 4128)]
         : compromised: 0.8079, honest: 0.8064
Round 006: test acc mean=0.8068 ± 0.0064 | min=0.7857 max=0.8139
         : test loss mean=0.6036 ± 0.0239
         : individual accs = ['0.809593', '0.809660', '0.805930', '0.806601', '0.804449', '0.812690', '0.810637', '0.810531', '0.810546', '0.813888', '0.785663', '0.802051', '0.804056', '0.812247', '0.811204', '0.808637', '0.799422', '0.807554', '0.812194', '0.799419']
         : correct/total = [(3342, 4128), (3403, 4203), (3289, 4081), (3495, 4333), (3291, 4091), (3484, 4287), (3399, 4193), (3525, 4349), (3397, 4191), (3481, 4277), (3255, 4143), (3363, 4193), (3291, 4093), (3409, 4197), (3287, 4052), (3258, 4029), (3320, 4153), (3378, 4183), (3317, 4084), (3300, 4128)]
         : compromised: 0.8091, honest: 0.8063
Round 007: test acc mean=0.8199 ± 0.0069 | min=0.8026 max=0.8288
         : test loss mean=0.5574 ± 0.0248
         : individual accs = ['0.828004', '0.827742', '0.817202', '0.828756', '0.814960', '0.822720', '0.819699', '0.828236', '0.822000', '0.820435', '0.808110', '0.811829', '0.817738', '0.820348', '0.827739', '0.823281', '0.814592', '0.823093', '0.819295', '0.802568']
         : correct/total = [(3418, 4128), (3479, 4203), (3335, 4081), (3591, 4333), (3334, 4091), (3527, 4287), (3437, 4193), (3602, 4349), (3445, 4191), (3509, 4277), (3348, 4143), (3404, 4193), (3347, 4093), (3443, 4197), (3354, 4052), (3317, 4029), (3383, 4153), (3443, 4183), (3346, 4084), (3313, 4128)]
         : compromised: 0.8210, honest: 0.8197
Round 008: test acc mean=0.8237 ± 0.0065 | min=0.8069 max=0.8328
         : test loss mean=0.5431 ± 0.0246
         : individual accs = ['0.829942', '0.823935', '0.823573', '0.829679', '0.813004', '0.825519', '0.829716', '0.832835', '0.827487', '0.828151', '0.806903', '0.823277', '0.820425', '0.831308', '0.824531', '0.823033', '0.822056', '0.825245', '0.820764', '0.811773']
         : correct/total = [(3426, 4128), (3463, 4203), (3361, 4081), (3595, 4333), (3326, 4091), (3539, 4287), (3479, 4193), (3622, 4349), (3468, 4191), (3542, 4277), (3343, 4143), (3452, 4193), (3358, 4093), (3489, 4197), (3341, 4052), (3316, 4029), (3414, 4153), (3452, 4183), (3352, 4084), (3351, 4128)]
         : compromised: 0.8256, honest: 0.8232
Round 009: test acc mean=0.8200 ± 0.0065 | min=0.8069 max=0.8301
         : test loss mean=0.5487 ± 0.0247
         : individual accs = ['0.824128', '0.828218', '0.821857', '0.816524', '0.810804', '0.815489', '0.829478', '0.824097', '0.830112', '0.824176', '0.806903', '0.818269', '0.813828', '0.823207', '0.825271', '0.823778', '0.811943', '0.822854', '0.818071', '0.811773']
         : correct/total = [(3402, 4128), (3481, 4203), (3354, 4081), (3538, 4333), (3317, 4091), (3496, 4287), (3478, 4193), (3584, 4349), (3479, 4191), (3525, 4277), (3343, 4143), (3431, 4193), (3331, 4093), (3455, 4197), (3344, 4052), (3319, 4029), (3372, 4153), (3442, 4183), (3341, 4084), (3351, 4128)]
         : compromised: 0.8188, honest: 0.8203
Round 010: test acc mean=0.8266 ± 0.0071 | min=0.8098 max=0.8368
         : test loss mean=0.5299 ± 0.0248
         : individual accs = ['0.834302', '0.833928', '0.828963', '0.819986', '0.814471', '0.827852', '0.833055', '0.827317', '0.836793', '0.829320', '0.809800', '0.824231', '0.829465', '0.832023', '0.824038', '0.830727', '0.819167', '0.829070', '0.832027', '0.816134']
         : correct/total = [(3444, 4128), (3505, 4203), (3383, 4081), (3553, 4333), (3332, 4091), (3549, 4287), (3493, 4193), (3598, 4349), (3507, 4191), (3547, 4277), (3355, 4143), (3456, 4193), (3395, 4093), (3492, 4197), (3339, 4052), (3347, 4029), (3402, 4153), (3468, 4183), (3398, 4084), (3369, 4128)]
         : compromised: 0.8296, honest: 0.8259

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: krum
Attack: directed_deviation, 20.0% compromised
Final accuracy - Compromised: 0.8296, Honest: 0.8259
Overall test accuracy: mean=0.8266 ± 0.0071
