Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5450 ± 0.0178 | min=0.5088 max=0.5860
         : test loss mean=1.7141 ± 0.0593
         : individual accs = ['0.538275', '0.555556', '0.546190', '0.527117', '0.553899', '0.554934', '0.539232', '0.539204', '0.586018', '0.541501', '0.508810', '0.546148', '0.549230', '0.539909', '0.565400', '0.531646', '0.526848', '0.540521', '0.581538', '0.527616']
         : correct/total = [(2222, 4128), (2335, 4203), (2229, 4081), (2284, 4333), (2266, 4091), (2379, 4287), (2261, 4193), (2345, 4349), (2456, 4191), (2316, 4277), (2108, 4143), (2290, 4193), (2248, 4093), (2266, 4197), (2291, 4052), (2142, 4029), (2188, 4153), (2261, 4183), (2375, 4084), (2178, 4128)]
Round 002: test acc mean=0.7333 ± 0.0110 | min=0.7105 max=0.7548
         : test loss mean=0.8862 ± 0.0388
         : individual accs = ['0.727713', '0.743517', '0.721882', '0.744057', '0.711073', '0.744110', '0.731219', '0.730513', '0.731806', '0.710545', '0.741974', '0.754829', '0.731981', '0.729807', '0.743583', '0.736163', '0.724296', '0.728186', '0.745103', '0.733527']
         : correct/total = [(3004, 4128), (3125, 4203), (2946, 4081), (3224, 4333), (2909, 4091), (3190, 4287), (3066, 4193), (3177, 4349), (3067, 4191), (3039, 4277), (3074, 4143), (3165, 4193), (2996, 4093), (3063, 4197), (3013, 4052), (2966, 4029), (3008, 4153), (3046, 4183), (3043, 4084), (3028, 4128)]
Round 003: test acc mean=0.7751 ± 0.0113 | min=0.7581 max=0.7970
         : test loss mean=0.7184 ± 0.0362
         : individual accs = ['0.779797', '0.780395', '0.764273', '0.786522', '0.766072', '0.777233', '0.789649', '0.767533', '0.779766', '0.759645', '0.758146', '0.759361', '0.796970', '0.761496', '0.790227', '0.783073', '0.777510', '0.774803', '0.783546', '0.765746']
         : correct/total = [(3219, 4128), (3280, 4203), (3119, 4081), (3408, 4333), (3134, 4091), (3332, 4287), (3311, 4193), (3338, 4349), (3268, 4191), (3249, 4277), (3141, 4143), (3184, 4193), (3262, 4093), (3196, 4197), (3202, 4052), (3155, 4029), (3229, 4153), (3241, 4183), (3200, 4084), (3161, 4128)]
Round 004: test acc mean=0.7988 ± 0.0101 | min=0.7784 max=0.8131
         : test loss mean=0.6345 ± 0.0302
         : individual accs = ['0.790455', '0.795622', '0.791228', '0.811678', '0.782205', '0.807324', '0.791557', '0.813060', '0.796469', '0.802665', '0.785904', '0.802290', '0.807476', '0.807243', '0.810711', '0.807893', '0.797977', '0.778389', '0.806807', '0.788760']
         : correct/total = [(3263, 4128), (3344, 4203), (3229, 4081), (3517, 4333), (3200, 4091), (3461, 4287), (3319, 4193), (3536, 4349), (3338, 4191), (3433, 4277), (3256, 4143), (3364, 4193), (3305, 4093), (3388, 4197), (3285, 4052), (3255, 4029), (3314, 4153), (3256, 4183), (3295, 4084), (3256, 4128)]
Round 005: test acc mean=0.8127 ± 0.0066 | min=0.7991 max=0.8282
         : test loss mean=0.5875 ± 0.0233
         : individual accs = ['0.805717', '0.822032', '0.814506', '0.808447', '0.807626', '0.818754', '0.812545', '0.806392', '0.828203', '0.820435', '0.804490', '0.813022', '0.810897', '0.814391', '0.799112', '0.808389', '0.812666', '0.818312', '0.812194', '0.815407']
         : correct/total = [(3326, 4128), (3455, 4203), (3324, 4081), (3503, 4333), (3304, 4091), (3510, 4287), (3407, 4193), (3507, 4349), (3471, 4191), (3509, 4277), (3333, 4143), (3409, 4193), (3319, 4093), (3418, 4197), (3238, 4052), (3257, 4029), (3375, 4153), (3423, 4183), (3317, 4084), (3366, 4128)]
Round 006: test acc mean=0.8209 ± 0.0056 | min=0.8120 max=0.8361
         : test loss mean=0.5508 ± 0.0212
         : individual accs = ['0.812016', '0.826790', '0.819652', '0.830833', '0.822537', '0.815022', '0.818746', '0.820418', '0.836077', '0.825111', '0.818489', '0.819699', '0.825312', '0.812962', '0.817621', '0.816332', '0.820852', '0.821659', '0.817581', '0.820010']
         : correct/total = [(3352, 4128), (3475, 4203), (3345, 4081), (3600, 4333), (3365, 4091), (3494, 4287), (3433, 4193), (3568, 4349), (3504, 4191), (3529, 4277), (3391, 4143), (3437, 4193), (3378, 4093), (3412, 4197), (3313, 4052), (3289, 4029), (3409, 4153), (3437, 4183), (3339, 4084), (3385, 4128)]
Round 007: test acc mean=0.8253 ± 0.0105 | min=0.7999 max=0.8392
         : test loss mean=0.5319 ± 0.0245
         : individual accs = ['0.799903', '0.823697', '0.826513', '0.829448', '0.806160', '0.828318', '0.820176', '0.834905', '0.839179', '0.835399', '0.803765', '0.834486', '0.826533', '0.835120', '0.830948', '0.832216', '0.825187', '0.822137', '0.828355', '0.823401']
         : correct/total = [(3302, 4128), (3462, 4203), (3373, 4081), (3594, 4333), (3298, 4091), (3551, 4287), (3439, 4193), (3631, 4349), (3517, 4191), (3573, 4277), (3330, 4143), (3499, 4193), (3383, 4093), (3505, 4197), (3367, 4052), (3353, 4029), (3427, 4153), (3439, 4183), (3383, 4084), (3399, 4128)]
Round 008: test acc mean=0.8283 ± 0.0096 | min=0.8088 max=0.8460
         : test loss mean=0.5179 ± 0.0296
         : individual accs = ['0.824128', '0.822984', '0.831169', '0.841219', '0.808849', '0.846046', '0.835202', '0.836514', '0.825579', '0.839140', '0.829592', '0.828285', '0.826533', '0.836550', '0.813425', '0.826508', '0.815314', '0.829787', '0.834721', '0.815407']
         : correct/total = [(3402, 4128), (3459, 4203), (3392, 4081), (3645, 4333), (3309, 4091), (3627, 4287), (3502, 4193), (3638, 4349), (3460, 4191), (3589, 4277), (3437, 4143), (3473, 4193), (3383, 4093), (3511, 4197), (3296, 4052), (3330, 4029), (3386, 4153), (3471, 4183), (3409, 4084), (3366, 4128)]
Round 009: test acc mean=0.8323 ± 0.0069 | min=0.8209 max=0.8487
         : test loss mean=0.5049 ± 0.0220
         : individual accs = ['0.824128', '0.842256', '0.838030', '0.838680', '0.835493', '0.833450', '0.825662', '0.831226', '0.848723', '0.836801', '0.823075', '0.833055', '0.829465', '0.831546', '0.821816', '0.830727', '0.830243', '0.820942', '0.835945', '0.835029']
         : correct/total = [(3402, 4128), (3540, 4203), (3420, 4081), (3634, 4333), (3418, 4091), (3573, 4287), (3462, 4193), (3615, 4349), (3557, 4191), (3579, 4277), (3410, 4143), (3493, 4193), (3395, 4093), (3490, 4197), (3330, 4052), (3347, 4029), (3448, 4153), (3434, 4183), (3414, 4084), (3447, 4128)]
Round 010: test acc mean=0.8363 ± 0.0092 | min=0.8187 max=0.8472
         : test loss mean=0.4948 ± 0.0232
         : individual accs = ['0.820494', '0.847014', '0.818672', '0.844680', '0.827182', '0.836016', '0.846172', '0.845252', '0.843951', '0.835866', '0.822592', '0.838779', '0.836795', '0.841792', '0.847236', '0.845371', '0.838912', '0.826679', '0.827130', '0.835029']
         : correct/total = [(3387, 4128), (3560, 4203), (3341, 4081), (3660, 4333), (3384, 4091), (3584, 4287), (3548, 4193), (3676, 4349), (3537, 4191), (3575, 4277), (3408, 4143), (3517, 4193), (3425, 4093), (3533, 4197), (3433, 4052), (3406, 4029), (3484, 4153), (3458, 4183), (3378, 4084), (3447, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Overall test accuracy: mean=0.8363 ± 0.0092
