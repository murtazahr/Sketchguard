Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.5275 ± 0.0287 | min=0.4920 max=0.6076
         : test loss mean=0.6927 ± 0.0003
         : individual accs = ['0.566667', '0.509499', '0.493345', '0.528497', '0.522928', '0.514410', '0.528384', '0.503993', '0.578345', '0.492021', '0.524476', '0.502222', '0.522569', '0.506897', '0.556050', '0.535371', '0.517331', '0.508400', '0.607606', '0.531113']
         : correct/total = [(646, 1140), (590, 1158), (556, 1127), (612, 1158), (593, 1134), (589, 1145), (605, 1145), (568, 1127), (657, 1136), (555, 1128), (600, 1144), (565, 1125), (602, 1152), (588, 1160), (625, 1124), (613, 1145), (597, 1154), (575, 1131), (703, 1157), (606, 1141)]
Round 002: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6923 ± 0.0009
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 003: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6919 ± 0.0012
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 004: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6909 ± 0.0014
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 005: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6873 ± 0.0017
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 006: test acc mean=0.6275 ± 0.0131 | min=0.6059 max=0.6549
         : test loss mean=0.6633 ± 0.0037
         : individual accs = ['0.615789', '0.621762', '0.613132', '0.623489', '0.611993', '0.631441', '0.633188', '0.611358', '0.654930', '0.620567', '0.647727', '0.635556', '0.642361', '0.622414', '0.605872', '0.616594', '0.634315', '0.631300', '0.631806', '0.645048']
         : correct/total = [(702, 1140), (720, 1158), (691, 1127), (722, 1158), (694, 1134), (723, 1145), (725, 1145), (689, 1127), (744, 1136), (700, 1128), (741, 1144), (715, 1125), (740, 1152), (722, 1160), (681, 1124), (706, 1145), (732, 1154), (714, 1131), (731, 1157), (736, 1141)]
Round 007: test acc mean=0.6821 ± 0.0137 | min=0.6526 max=0.7066
         : test loss mean=0.6063 ± 0.0098
         : individual accs = ['0.652632', '0.667530', '0.677019', '0.685665', '0.679894', '0.697817', '0.706550', '0.671695', '0.690141', '0.685284', '0.673951', '0.703111', '0.692708', '0.685345', '0.667260', '0.668122', '0.695841', '0.694960', '0.671564', '0.673970']
         : correct/total = [(744, 1140), (773, 1158), (763, 1127), (794, 1158), (771, 1134), (799, 1145), (809, 1145), (757, 1127), (784, 1136), (773, 1128), (771, 1144), (791, 1125), (798, 1152), (795, 1160), (750, 1124), (765, 1145), (803, 1154), (786, 1131), (777, 1157), (769, 1141)]
Round 008: test acc mean=0.7492 ± 0.0116 | min=0.7258 max=0.7751
         : test loss mean=0.5302 ± 0.0121
         : individual accs = ['0.746491', '0.752159', '0.755989', '0.752159', '0.744268', '0.764192', '0.759825', '0.725821', '0.743838', '0.758865', '0.749126', '0.775111', '0.756076', '0.741379', '0.747331', '0.728384', '0.759099', '0.738285', '0.736387', '0.748466']
         : correct/total = [(851, 1140), (871, 1158), (852, 1127), (871, 1158), (844, 1134), (875, 1145), (870, 1145), (818, 1127), (845, 1136), (856, 1128), (857, 1144), (872, 1125), (871, 1152), (860, 1160), (840, 1124), (834, 1145), (876, 1154), (835, 1131), (852, 1157), (854, 1141)]
Round 009: test acc mean=0.7907 ± 0.0139 | min=0.7702 max=0.8120
         : test loss mean=0.4589 ± 0.0134
         : individual accs = ['0.779825', '0.797064', '0.800355', '0.778066', '0.776014', '0.805240', '0.801747', '0.770186', '0.779049', '0.807624', '0.800699', '0.810667', '0.783854', '0.785345', '0.786477', '0.772926', '0.811958', '0.785146', '0.772688', '0.808940']
         : correct/total = [(889, 1140), (923, 1158), (902, 1127), (901, 1158), (880, 1134), (922, 1145), (918, 1145), (868, 1127), (885, 1136), (911, 1128), (916, 1144), (912, 1125), (903, 1152), (911, 1160), (884, 1124), (885, 1145), (937, 1154), (888, 1131), (894, 1157), (923, 1141)]
Round 010: test acc mean=0.8202 ± 0.0130 | min=0.7865 max=0.8462
         : test loss mean=0.4041 ± 0.0158
         : individual accs = ['0.816667', '0.824698', '0.832298', '0.808290', '0.806878', '0.835808', '0.821834', '0.818988', '0.816021', '0.828901', '0.846154', '0.835556', '0.809028', '0.813793', '0.819395', '0.806987', '0.827556', '0.818744', '0.786517', '0.830850']
         : correct/total = [(931, 1140), (955, 1158), (938, 1127), (936, 1158), (915, 1134), (957, 1145), (941, 1145), (923, 1127), (927, 1136), (935, 1128), (968, 1144), (940, 1125), (932, 1152), (944, 1160), (921, 1124), (924, 1145), (955, 1154), (926, 1131), (910, 1157), (948, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Overall test accuracy: mean=0.8202 ± 0.0130
