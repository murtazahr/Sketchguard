Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: directed_deviation, lambda: 1.0
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5574 ± 0.0110 | min=0.5356 max=0.5776
         : test loss mean=1.6703 ± 0.0362
         : individual accs = ['0.562016', '0.564121', '0.546190', '0.555504', '0.553899', '0.577560', '0.571667', '0.556450', '0.568122', '0.540566', '0.535602', '0.563081', '0.553872', '0.558971', '0.566140', '0.554480', '0.544426', '0.558929', '0.573213', '0.543605']
         : correct/total = [(2320, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2266, 4091), (2476, 4287), (2397, 4193), (2420, 4349), (2381, 4191), (2312, 4277), (2219, 4143), (2361, 4193), (2267, 4093), (2346, 4197), (2294, 4052), (2234, 4029), (2261, 4153), (2338, 4183), (2341, 4084), (2244, 4128)]
         : compromised: 0.5648, honest: 0.5543
Round 002: test acc mean=0.7364 ± 0.0058 | min=0.7253 max=0.7473
         : test loss mean=0.8866 ± 0.0214
         : individual accs = ['0.735223', '0.747323', '0.725312', '0.742442', '0.733317', '0.738745', '0.738135', '0.740170', '0.743737', '0.739303', '0.728458', '0.737896', '0.734425', '0.730045', '0.740375', '0.733184', '0.729352', '0.737987', '0.743144', '0.728440']
         : correct/total = [(3035, 4128), (3141, 4203), (2960, 4081), (3217, 4333), (3000, 4091), (3167, 4287), (3095, 4193), (3219, 4349), (3117, 4191), (3162, 4277), (3018, 4143), (3094, 4193), (3006, 4093), (3064, 4197), (3000, 4052), (2954, 4029), (3029, 4153), (3087, 4183), (3035, 4084), (3007, 4128)]
         : compromised: 0.7375, honest: 0.7359
Round 003: test acc mean=0.7663 ± 0.0078 | min=0.7517 max=0.7841
         : test loss mean=0.7348 ± 0.0237
         : individual accs = ['0.771318', '0.778492', '0.762803', '0.765982', '0.757761', '0.771635', '0.772955', '0.774891', '0.784061', '0.762217', '0.762008', '0.769616', '0.760567', '0.765070', '0.766782', '0.764458', '0.751746', '0.766914', '0.763712', '0.752422']
         : correct/total = [(3184, 4128), (3272, 4203), (3113, 4081), (3319, 4333), (3100, 4091), (3308, 4287), (3241, 4193), (3370, 4349), (3286, 4191), (3260, 4277), (3157, 4143), (3227, 4193), (3113, 4093), (3211, 4197), (3107, 4052), (3080, 4029), (3122, 4153), (3208, 4183), (3119, 4084), (3106, 4128)]
         : compromised: 0.7658, honest: 0.7665
Round 004: test acc mean=0.8045 ± 0.0061 | min=0.7914 max=0.8182
         : test loss mean=0.6110 ± 0.0227
         : individual accs = ['0.797965', '0.808946', '0.807400', '0.802908', '0.799804', '0.807091', '0.807059', '0.813520', '0.818182', '0.806640', '0.794111', '0.804913', '0.801368', '0.804861', '0.809970', '0.805907', '0.797977', '0.804686', '0.806072', '0.791424']
         : correct/total = [(3294, 4128), (3400, 4203), (3295, 4081), (3479, 4333), (3272, 4091), (3460, 4287), (3384, 4193), (3538, 4349), (3429, 4191), (3450, 4277), (3290, 4143), (3375, 4193), (3280, 4093), (3378, 4197), (3282, 4052), (3247, 4029), (3314, 4153), (3366, 4183), (3292, 4084), (3267, 4128)]
         : compromised: 0.8057, honest: 0.8041
Round 005: test acc mean=0.8102 ± 0.0070 | min=0.7963 max=0.8249
         : test loss mean=0.5992 ± 0.0243
         : individual accs = ['0.803779', '0.808232', '0.807155', '0.807524', '0.797604', '0.812456', '0.819938', '0.822718', '0.824863', '0.812252', '0.796283', '0.812068', '0.816760', '0.808911', '0.809724', '0.811864', '0.807609', '0.807554', '0.809990', '0.806202']
         : correct/total = [(3318, 4128), (3397, 4203), (3294, 4081), (3499, 4333), (3263, 4091), (3483, 4287), (3438, 4193), (3578, 4349), (3457, 4191), (3474, 4277), (3299, 4143), (3405, 4193), (3343, 4093), (3395, 4197), (3281, 4052), (3271, 4029), (3354, 4153), (3378, 4183), (3308, 4084), (3328, 4128)]
         : compromised: 0.8109, honest: 0.8099
Round 006: test acc mean=0.8179 ± 0.0056 | min=0.8096 max=0.8344
         : test loss mean=0.5735 ± 0.0265
         : individual accs = ['0.810804', '0.820366', '0.818182', '0.819063', '0.809582', '0.815255', '0.823754', '0.822028', '0.834407', '0.823942', '0.810765', '0.820176', '0.817249', '0.817727', '0.815647', '0.816828', '0.814110', '0.819747', '0.818560', '0.810078']
         : correct/total = [(3347, 4128), (3448, 4203), (3339, 4081), (3549, 4333), (3312, 4091), (3495, 4287), (3454, 4193), (3575, 4349), (3497, 4191), (3524, 4277), (3359, 4143), (3439, 4193), (3345, 4093), (3432, 4197), (3305, 4052), (3291, 4029), (3381, 4153), (3429, 4183), (3343, 4084), (3344, 4128)]
         : compromised: 0.8174, honest: 0.8181
Round 007: test acc mean=0.8193 ± 0.0060 | min=0.8074 max=0.8363
         : test loss mean=0.5558 ± 0.0240
         : individual accs = ['0.808866', '0.821794', '0.823083', '0.822756', '0.816182', '0.823886', '0.820415', '0.821798', '0.836316', '0.823241', '0.811489', '0.817792', '0.820669', '0.822016', '0.818115', '0.816083', '0.817481', '0.817595', '0.818560', '0.807413']
         : correct/total = [(3339, 4128), (3454, 4203), (3359, 4081), (3565, 4333), (3339, 4091), (3532, 4287), (3440, 4193), (3574, 4349), (3505, 4191), (3521, 4277), (3362, 4143), (3429, 4193), (3359, 4093), (3450, 4197), (3315, 4052), (3288, 4029), (3395, 4153), (3420, 4183), (3343, 4084), (3333, 4128)]
         : compromised: 0.8201, honest: 0.8189
Round 008: test acc mean=0.8230 ± 0.0082 | min=0.8084 max=0.8447
         : test loss mean=0.5314 ± 0.0272
         : individual accs = ['0.808382', '0.827504', '0.822347', '0.829910', '0.819848', '0.822253', '0.825900', '0.829616', '0.844667', '0.829086', '0.812696', '0.818030', '0.821158', '0.833214', '0.825271', '0.815339', '0.820852', '0.825006', '0.820029', '0.809351']
         : correct/total = [(3337, 4128), (3478, 4203), (3356, 4081), (3596, 4333), (3354, 4091), (3525, 4287), (3463, 4193), (3608, 4349), (3540, 4191), (3546, 4277), (3367, 4143), (3430, 4193), (3361, 4093), (3497, 4197), (3344, 4052), (3285, 4029), (3409, 4153), (3451, 4183), (3349, 4084), (3341, 4128)]
         : compromised: 0.8245, honest: 0.8224
Round 009: test acc mean=0.8258 ± 0.0073 | min=0.8137 max=0.8454
         : test loss mean=0.5300 ± 0.0252
         : individual accs = ['0.816618', '0.832976', '0.821612', '0.824140', '0.813737', '0.821087', '0.827808', '0.828006', '0.845383', '0.831892', '0.814144', '0.825185', '0.823601', '0.836073', '0.829714', '0.824026', '0.824223', '0.825962', '0.828844', '0.820010']
         : correct/total = [(3371, 4128), (3501, 4203), (3353, 4081), (3571, 4333), (3329, 4091), (3520, 4287), (3471, 4193), (3601, 4349), (3543, 4191), (3558, 4277), (3373, 4143), (3460, 4193), (3371, 4093), (3509, 4197), (3362, 4052), (3320, 4029), (3423, 4153), (3455, 4183), (3385, 4084), (3385, 4128)]
         : compromised: 0.8275, honest: 0.8250
Round 010: test acc mean=0.8228 ± 0.0083 | min=0.8050 max=0.8435
         : test loss mean=0.5304 ± 0.0278
         : individual accs = ['0.813227', '0.825363', '0.813771', '0.825294', '0.820826', '0.825519', '0.832340', '0.826627', '0.843474', '0.829553', '0.804972', '0.819461', '0.822868', '0.832976', '0.821570', '0.819310', '0.823983', '0.824528', '0.817581', '0.812258']
         : correct/total = [(3357, 4128), (3469, 4203), (3321, 4081), (3576, 4333), (3358, 4091), (3539, 4287), (3490, 4193), (3595, 4349), (3535, 4191), (3548, 4277), (3335, 4143), (3436, 4193), (3368, 4093), (3496, 4197), (3329, 4052), (3301, 4029), (3422, 4153), (3449, 4183), (3339, 4084), (3353, 4128)]
         : compromised: 0.8242, honest: 0.8222

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: krum
Attack: directed_deviation, 30.0% compromised
Final accuracy - Compromised: 0.8242, Honest: 0.8222
Overall test accuracy: mean=0.8228 ± 0.0083
