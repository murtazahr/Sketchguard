Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: gaussian, lambda: 1.0
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5477 ± 0.0194 | min=0.5088 max=0.5860
         : test loss mean=1.6975 ± 0.0682
         : individual accs = ['0.538275', '0.555556', '0.546190', '0.534964', '0.553899', '0.554934', '0.539232', '0.539204', '0.586018', '0.541501', '0.508810', '0.548056', '0.549230', '0.584227', '0.565400', '0.531646', '0.526848', '0.540521', '0.581538', '0.527616']
         : correct/total = [(2222, 4128), (2335, 4203), (2229, 4081), (2318, 4333), (2266, 4091), (2379, 4287), (2261, 4193), (2345, 4349), (2456, 4191), (2316, 4277), (2108, 4143), (2298, 4193), (2248, 4093), (2452, 4197), (2291, 4052), (2142, 4029), (2188, 4153), (2261, 4183), (2375, 4084), (2178, 4128)]
         : compromised: 0.5696, honest: 0.5453
Round 002: test acc mean=0.7330 ± 0.0101 | min=0.7111 max=0.7515
         : test loss mean=0.8868 ± 0.0375
         : individual accs = ['0.727713', '0.732810', '0.721882', '0.749135', '0.711073', '0.744110', '0.731219', '0.745459', '0.731806', '0.737667', '0.741974', '0.751491', '0.731981', '0.729807', '0.732971', '0.736163', '0.724296', '0.728186', '0.716210', '0.733527']
         : correct/total = [(3004, 4128), (3080, 4203), (2946, 4081), (3246, 4333), (2909, 4091), (3190, 4287), (3066, 4193), (3242, 4349), (3067, 4191), (3155, 4277), (3074, 4143), (3151, 4193), (2996, 4093), (3063, 4197), (2970, 4052), (2966, 4029), (3008, 4153), (3046, 4183), (2925, 4084), (3028, 4128)]
         : compromised: 0.7370, honest: 0.7325
Round 003: test acc mean=0.7785 ± 0.0104 | min=0.7581 max=0.7970
         : test loss mean=0.7046 ± 0.0408
         : individual accs = ['0.779797', '0.786581', '0.767214', '0.793676', '0.768027', '0.775367', '0.789649', '0.786618', '0.786447', '0.789806', '0.758146', '0.784164', '0.796970', '0.773171', '0.780355', '0.770414', '0.777510', '0.774803', '0.765916', '0.765746']
         : correct/total = [(3219, 4128), (3306, 4203), (3131, 4081), (3439, 4333), (3142, 4091), (3324, 4287), (3311, 4193), (3421, 4349), (3296, 4191), (3378, 4277), (3141, 4143), (3288, 4193), (3262, 4093), (3245, 4197), (3162, 4052), (3104, 4029), (3229, 4153), (3241, 4183), (3128, 4084), (3161, 4128)]
         : compromised: 0.7743, honest: 0.7790
Round 004: test acc mean=0.7997 ± 0.0091 | min=0.7859 max=0.8172
         : test loss mean=0.6308 ± 0.0276
         : individual accs = ['0.790455', '0.802998', '0.801029', '0.805216', '0.792227', '0.807791', '0.791557', '0.810991', '0.817227', '0.814823', '0.785904', '0.791557', '0.793794', '0.795092', '0.810217', '0.801440', '0.796051', '0.786278', '0.805093', '0.793605']
         : correct/total = [(3263, 4128), (3375, 4203), (3269, 4081), (3489, 4333), (3241, 4091), (3463, 4287), (3319, 4193), (3527, 4349), (3425, 4191), (3485, 4277), (3256, 4143), (3319, 4193), (3249, 4093), (3337, 4197), (3283, 4052), (3229, 4029), (3306, 4153), (3289, 4183), (3288, 4084), (3276, 4128)]
         : compromised: 0.8014, honest: 0.7995
Round 005: test acc mean=0.8093 ± 0.0075 | min=0.7970 max=0.8223
         : test loss mean=0.5931 ± 0.0274
         : individual accs = ['0.796996', '0.815370', '0.805440', '0.818371', '0.818626', '0.802892', '0.812545', '0.822258', '0.819375', '0.813654', '0.804972', '0.800620', '0.802345', '0.807958', '0.814413', '0.798958', '0.801830', '0.815922', '0.810480', '0.802810']
         : correct/total = [(3290, 4128), (3427, 4203), (3287, 4081), (3546, 4333), (3349, 4091), (3442, 4287), (3407, 4193), (3576, 4349), (3434, 4191), (3480, 4277), (3335, 4143), (3357, 4193), (3284, 4093), (3391, 4197), (3300, 4052), (3219, 4029), (3330, 4153), (3413, 4183), (3310, 4084), (3314, 4128)]
         : compromised: 0.8054, honest: 0.8097
Round 006: test acc mean=0.8182 ± 0.0075 | min=0.7956 max=0.8318
         : test loss mean=0.5541 ± 0.0231
         : individual accs = ['0.808382', '0.821556', '0.814016', '0.822986', '0.820582', '0.814322', '0.816361', '0.821108', '0.831782', '0.821838', '0.819696', '0.795612', '0.824090', '0.818442', '0.823791', '0.823529', '0.807127', '0.818073', '0.823213', '0.817829']
         : correct/total = [(3337, 4128), (3453, 4203), (3322, 4081), (3566, 4333), (3357, 4091), (3491, 4287), (3423, 4193), (3571, 4349), (3486, 4191), (3515, 4277), (3396, 4143), (3336, 4193), (3373, 4093), (3435, 4197), (3338, 4052), (3318, 4029), (3352, 4153), (3422, 4183), (3362, 4084), (3376, 4128)]
         : compromised: 0.8164, honest: 0.8184
Round 007: test acc mean=0.8268 ± 0.0054 | min=0.8176 max=0.8399
         : test loss mean=0.5288 ± 0.0230
         : individual accs = ['0.826308', '0.839876', '0.829944', '0.826217', '0.822048', '0.818988', '0.817553', '0.833985', '0.836793', '0.823708', '0.823558', '0.822323', '0.829221', '0.825590', '0.821816', '0.829486', '0.827113', '0.824767', '0.827865', '0.829457']
         : correct/total = [(3411, 4128), (3530, 4203), (3387, 4081), (3580, 4333), (3363, 4091), (3511, 4287), (3428, 4193), (3627, 4349), (3507, 4191), (3523, 4277), (3412, 4143), (3448, 4193), (3394, 4093), (3465, 4197), (3330, 4052), (3342, 4029), (3435, 4153), (3450, 4183), (3381, 4084), (3424, 4128)]
         : compromised: 0.8223, honest: 0.8273
Round 008: test acc mean=0.8274 ± 0.0093 | min=0.8080 max=0.8424
         : test loss mean=0.5208 ± 0.0344
         : individual accs = ['0.813227', '0.837973', '0.827738', '0.842372', '0.832070', '0.828785', '0.833055', '0.838124', '0.837270', '0.832593', '0.823316', '0.824708', '0.825312', '0.829164', '0.807996', '0.832713', '0.814592', '0.821181', '0.833497', '0.812742']
         : correct/total = [(3357, 4128), (3522, 4203), (3378, 4081), (3650, 4333), (3404, 4091), (3553, 4287), (3493, 4193), (3645, 4349), (3509, 4191), (3561, 4277), (3411, 4143), (3458, 4193), (3378, 4093), (3480, 4197), (3274, 4052), (3355, 4029), (3383, 4153), (3435, 4183), (3404, 4084), (3355, 4128)]
         : compromised: 0.8290, honest: 0.8272
Round 009: test acc mean=0.8337 ± 0.0098 | min=0.8118 max=0.8478
         : test loss mean=0.5053 ± 0.0260
         : individual accs = ['0.811773', '0.842256', '0.835580', '0.844219', '0.822782', '0.827618', '0.822323', '0.845022', '0.847769', '0.847089', '0.817282', '0.831386', '0.828732', '0.835835', '0.842053', '0.831224', '0.830966', '0.836481', '0.841577', '0.832849']
         : correct/total = [(3351, 4128), (3540, 4203), (3410, 4081), (3658, 4333), (3366, 4091), (3548, 4287), (3448, 4193), (3675, 4349), (3553, 4191), (3623, 4277), (3386, 4143), (3486, 4193), (3392, 4093), (3508, 4197), (3412, 4052), (3349, 4029), (3451, 4153), (3499, 4183), (3437, 4084), (3438, 4128)]
         : compromised: 0.8317, honest: 0.8340
Round 010: test acc mean=0.8355 ± 0.0085 | min=0.8133 max=0.8486
         : test loss mean=0.4948 ± 0.0220
         : individual accs = ['0.835514', '0.840114', '0.813281', '0.844219', '0.837204', '0.828551', '0.848557', '0.838354', '0.847292', '0.835399', '0.824041', '0.834725', '0.831908', '0.839647', '0.837364', '0.846860', '0.829039', '0.840067', '0.823947', '0.833576']
         : correct/total = [(3449, 4128), (3531, 4203), (3319, 4081), (3658, 4333), (3425, 4091), (3552, 4287), (3558, 4193), (3646, 4349), (3551, 4191), (3573, 4277), (3414, 4143), (3500, 4193), (3405, 4093), (3524, 4197), (3393, 4052), (3412, 4029), (3443, 4153), (3514, 4183), (3365, 4084), (3441, 4128)]
         : compromised: 0.8341, honest: 0.8356

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 10.0% compromised
Final accuracy - Compromised: 0.8341, Honest: 0.8356
Overall test accuracy: mean=0.8355 ± 0.0085
