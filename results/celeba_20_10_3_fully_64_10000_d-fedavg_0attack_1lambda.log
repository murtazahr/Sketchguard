Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.8331 ± 0.0174
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 002: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.7549 ± 0.0157
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517904', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (593, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 003: test acc mean=0.9078 ± 0.0065 | min=0.8902 max=0.9162
         : test loss mean=0.2244 ± 0.0127
         : individual accs = ['0.914035', '0.910190', '0.895297', '0.916235', '0.915344', '0.908297', '0.909170', '0.913931', '0.900528', '0.903369', '0.907343', '0.911111', '0.908854', '0.910345', '0.906584', '0.914410', '0.908146', '0.901857', '0.890233', '0.910605']
         : correct/total = [(1042, 1140), (1054, 1158), (1009, 1127), (1061, 1158), (1038, 1134), (1040, 1145), (1041, 1145), (1030, 1127), (1023, 1136), (1019, 1128), (1038, 1144), (1025, 1125), (1047, 1152), (1056, 1160), (1019, 1124), (1047, 1145), (1048, 1154), (1020, 1131), (1030, 1157), (1039, 1141)]
Round 004: test acc mean=0.9139 ± 0.0072 | min=0.8920 max=0.9206
         : test loss mean=0.2123 ± 0.0172
         : individual accs = ['0.918421', '0.905009', '0.901508', '0.920553', '0.918871', '0.913537', '0.920524', '0.909494', '0.911972', '0.913121', '0.917832', '0.916444', '0.915799', '0.914655', '0.919929', '0.917904', '0.919411', '0.911583', '0.891962', '0.920245']
         : correct/total = [(1047, 1140), (1048, 1158), (1016, 1127), (1066, 1158), (1042, 1134), (1046, 1145), (1054, 1145), (1025, 1127), (1036, 1136), (1030, 1128), (1050, 1144), (1031, 1125), (1055, 1152), (1061, 1160), (1034, 1124), (1051, 1145), (1061, 1154), (1031, 1131), (1032, 1157), (1050, 1141)]
Round 005: test acc mean=0.9181 ± 0.0075 | min=0.8971 max=0.9283
         : test loss mean=0.2041 ± 0.0182
         : individual accs = ['0.923684', '0.911054', '0.905945', '0.928325', '0.918871', '0.919651', '0.923144', '0.922804', '0.913732', '0.914894', '0.919580', '0.927111', '0.921875', '0.919828', '0.922598', '0.919651', '0.923744', '0.908046', '0.897148', '0.920245']
         : correct/total = [(1053, 1140), (1055, 1158), (1021, 1127), (1075, 1158), (1042, 1134), (1053, 1145), (1057, 1145), (1040, 1127), (1038, 1136), (1032, 1128), (1052, 1144), (1043, 1125), (1062, 1152), (1067, 1160), (1037, 1124), (1053, 1145), (1066, 1154), (1027, 1131), (1038, 1157), (1050, 1141)]
Round 006: test acc mean=0.9169 ± 0.0073 | min=0.8954 max=0.9293
         : test loss mean=0.2093 ± 0.0199
         : individual accs = ['0.924561', '0.910190', '0.913931', '0.922280', '0.917108', '0.918777', '0.929258', '0.916593', '0.912852', '0.915780', '0.913462', '0.921778', '0.922743', '0.912931', '0.925267', '0.920524', '0.920277', '0.906278', '0.895419', '0.918493']
         : correct/total = [(1054, 1140), (1054, 1158), (1030, 1127), (1068, 1158), (1040, 1134), (1052, 1145), (1064, 1145), (1033, 1127), (1037, 1136), (1033, 1128), (1045, 1144), (1037, 1125), (1063, 1152), (1059, 1160), (1040, 1124), (1054, 1145), (1062, 1154), (1025, 1131), (1036, 1157), (1048, 1141)]
Round 007: test acc mean=0.9175 ± 0.0074 | min=0.8963 max=0.9284
         : test loss mean=0.2091 ± 0.0205
         : individual accs = ['0.924561', '0.911917', '0.913931', '0.921416', '0.918871', '0.917904', '0.928384', '0.919255', '0.909331', '0.914894', '0.915210', '0.923556', '0.922743', '0.912931', '0.922598', '0.924891', '0.923744', '0.907162', '0.896283', '0.920245']
         : correct/total = [(1054, 1140), (1056, 1158), (1030, 1127), (1067, 1158), (1042, 1134), (1051, 1145), (1063, 1145), (1036, 1127), (1033, 1136), (1032, 1128), (1047, 1144), (1039, 1125), (1063, 1152), (1059, 1160), (1037, 1124), (1059, 1145), (1066, 1154), (1026, 1131), (1037, 1157), (1050, 1141)]
Round 008: test acc mean=0.9191 ± 0.0072 | min=0.8997 max=0.9293
         : test loss mean=0.2068 ± 0.0199
         : individual accs = ['0.928070', '0.912781', '0.914818', '0.924870', '0.916226', '0.921397', '0.929258', '0.919255', '0.912852', '0.915780', '0.913462', '0.925333', '0.924479', '0.916379', '0.927936', '0.922271', '0.922010', '0.909814', '0.899741', '0.925504']
         : correct/total = [(1058, 1140), (1057, 1158), (1031, 1127), (1071, 1158), (1039, 1134), (1055, 1145), (1064, 1145), (1036, 1127), (1037, 1136), (1033, 1128), (1045, 1144), (1041, 1125), (1065, 1152), (1063, 1160), (1043, 1124), (1056, 1145), (1064, 1154), (1029, 1131), (1041, 1157), (1056, 1141)]
Round 009: test acc mean=0.9209 ± 0.0086 | min=0.9006 max=0.9369
         : test loss mean=0.2029 ± 0.0202
         : individual accs = ['0.934211', '0.914508', '0.909494', '0.929188', '0.922399', '0.918777', '0.930131', '0.920142', '0.911092', '0.920213', '0.914336', '0.925333', '0.923611', '0.919828', '0.921708', '0.924891', '0.928076', '0.912467', '0.900605', '0.936897']
         : correct/total = [(1065, 1140), (1059, 1158), (1025, 1127), (1076, 1158), (1046, 1134), (1052, 1145), (1065, 1145), (1037, 1127), (1035, 1136), (1038, 1128), (1046, 1144), (1041, 1125), (1064, 1152), (1067, 1160), (1036, 1124), (1059, 1145), (1071, 1154), (1032, 1131), (1042, 1157), (1069, 1141)]
Round 010: test acc mean=0.9204 ± 0.0079 | min=0.9041 max=0.9325
         : test loss mean=0.2044 ± 0.0209
         : individual accs = ['0.930702', '0.916235', '0.906832', '0.925734', '0.918871', '0.919651', '0.931004', '0.922804', '0.911092', '0.920213', '0.911713', '0.921778', '0.923611', '0.918966', '0.924377', '0.929258', '0.926343', '0.911583', '0.904062', '0.932515']
         : correct/total = [(1061, 1140), (1061, 1158), (1022, 1127), (1072, 1158), (1042, 1134), (1053, 1145), (1066, 1145), (1040, 1127), (1035, 1136), (1038, 1128), (1043, 1144), (1037, 1125), (1064, 1152), (1066, 1160), (1039, 1124), (1064, 1145), (1069, 1154), (1031, 1131), (1046, 1157), (1064, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: fully, Aggregation: d-fedavg
Overall test accuracy: mean=0.9204 ± 0.0079
