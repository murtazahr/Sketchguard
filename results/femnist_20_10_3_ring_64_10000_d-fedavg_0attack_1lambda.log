Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.2253 ± 0.0660 | min=0.1224 max=0.3946
         : test loss mean=3.9643 ± 0.0241
         : individual accs = ['0.211240', '0.310493', '0.228865', '0.170321', '0.241017', '0.238628', '0.279513', '0.394573', '0.215223', '0.154314', '0.216993', '0.312425', '0.122404', '0.163450', '0.155726', '0.280963', '0.182759', '0.245039', '0.240695', '0.141957']
         : correct/total = [(872, 4128), (1305, 4203), (934, 4081), (738, 4333), (986, 4091), (1023, 4287), (1172, 4193), (1716, 4349), (902, 4191), (660, 4277), (899, 4143), (1310, 4193), (501, 4093), (686, 4197), (631, 4052), (1132, 4029), (759, 4153), (1025, 4183), (983, 4084), (586, 4128)]
Round 002: test acc mean=0.6938 ± 0.0219 | min=0.6350 max=0.7289
         : test loss mean=1.8314 ± 0.1186
         : individual accs = ['0.711483', '0.708066', '0.685371', '0.681283', '0.706184', '0.728948', '0.717386', '0.703380', '0.714149', '0.694880', '0.693700', '0.722871', '0.694356', '0.678818', '0.679664', '0.680069', '0.657597', '0.634951', '0.700539', '0.682897']
         : correct/total = [(2937, 4128), (2976, 4203), (2797, 4081), (2952, 4333), (2889, 4091), (3125, 4287), (3008, 4193), (3059, 4349), (2993, 4191), (2972, 4277), (2874, 4143), (3031, 4193), (2842, 4093), (2849, 4197), (2754, 4052), (2740, 4029), (2731, 4153), (2656, 4183), (2861, 4084), (2819, 4128)]
Round 003: test acc mean=0.7729 ± 0.0083 | min=0.7555 max=0.7874
         : test loss mean=0.9989 ± 0.0410
         : individual accs = ['0.773256', '0.772781', '0.772850', '0.787445', '0.775849', '0.782365', '0.780587', '0.781559', '0.780959', '0.769932', '0.755491', '0.774147', '0.771561', '0.779366', '0.774432', '0.770663', '0.771972', '0.755678', '0.759305', '0.767200']
         : correct/total = [(3192, 4128), (3248, 4203), (3154, 4081), (3412, 4333), (3174, 4091), (3354, 4287), (3273, 4193), (3399, 4349), (3273, 4191), (3293, 4277), (3130, 4143), (3246, 4193), (3158, 4093), (3271, 4197), (3138, 4052), (3105, 4029), (3206, 4153), (3161, 4183), (3101, 4084), (3167, 4128)]
Round 004: test acc mean=0.8006 ± 0.0074 | min=0.7827 max=0.8094
         : test loss mean=0.7603 ± 0.0191
         : individual accs = ['0.782703', '0.805139', '0.797599', '0.803831', '0.799560', '0.804759', '0.806582', '0.805013', '0.809115', '0.806640', '0.789042', '0.789172', '0.797948', '0.808196', '0.807256', '0.809382', '0.801589', '0.791537', '0.799461', '0.796996']
         : correct/total = [(3231, 4128), (3384, 4203), (3255, 4081), (3483, 4333), (3271, 4091), (3450, 4287), (3382, 4193), (3501, 4349), (3391, 4191), (3450, 4277), (3269, 4143), (3309, 4193), (3266, 4093), (3392, 4197), (3271, 4052), (3261, 4029), (3329, 4153), (3311, 4183), (3265, 4084), (3290, 4128)]
Round 005: test acc mean=0.8110 ± 0.0047 | min=0.8021 max=0.8196
         : test loss mean=0.6714 ± 0.0235
         : individual accs = ['0.805959', '0.813229', '0.812301', '0.813986', '0.802738', '0.809424', '0.817792', '0.814900', '0.817466', '0.813421', '0.802076', '0.809444', '0.806010', '0.809864', '0.807749', '0.819558', '0.813629', '0.813053', '0.808766', '0.807655']
         : correct/total = [(3327, 4128), (3418, 4203), (3315, 4081), (3527, 4333), (3284, 4091), (3470, 4287), (3429, 4193), (3544, 4349), (3426, 4191), (3479, 4277), (3323, 4143), (3394, 4193), (3299, 4093), (3399, 4197), (3273, 4052), (3302, 4029), (3379, 4153), (3401, 4183), (3303, 4084), (3334, 4128)]
Round 006: test acc mean=0.8241 ± 0.0051 | min=0.8154 max=0.8327
         : test loss mean=0.6056 ± 0.0165
         : individual accs = ['0.819767', '0.818701', '0.820387', '0.827833', '0.817160', '0.823420', '0.829478', '0.831456', '0.827487', '0.825812', '0.815351', '0.821846', '0.820425', '0.829640', '0.825765', '0.832713', '0.830966', '0.823333', '0.821988', '0.818314']
         : correct/total = [(3384, 4128), (3441, 4203), (3348, 4081), (3587, 4333), (3343, 4091), (3530, 4287), (3478, 4193), (3616, 4349), (3468, 4191), (3532, 4277), (3378, 4143), (3446, 4193), (3358, 4093), (3482, 4197), (3346, 4052), (3355, 4029), (3451, 4153), (3444, 4183), (3357, 4084), (3378, 4128)]
Round 007: test acc mean=0.8302 ± 0.0056 | min=0.8195 max=0.8406
         : test loss mean=0.5693 ± 0.0187
         : individual accs = ['0.819525', '0.834166', '0.829209', '0.830833', '0.823026', '0.828318', '0.835917', '0.836974', '0.840611', '0.829787', '0.821385', '0.827093', '0.832641', '0.837265', '0.830207', '0.831968', '0.835300', '0.829548', '0.828355', '0.821948']
         : correct/total = [(3383, 4128), (3506, 4203), (3384, 4081), (3600, 4333), (3367, 4091), (3551, 4287), (3505, 4193), (3640, 4349), (3523, 4191), (3549, 4277), (3403, 4143), (3468, 4193), (3408, 4093), (3514, 4197), (3364, 4052), (3352, 4029), (3469, 4153), (3470, 4183), (3383, 4084), (3393, 4128)]
Round 008: test acc mean=0.8326 ± 0.0065 | min=0.8169 max=0.8436
         : test loss mean=0.5400 ± 0.0178
         : individual accs = ['0.821463', '0.830359', '0.833864', '0.837295', '0.829137', '0.836716', '0.842833', '0.829616', '0.833691', '0.833061', '0.828144', '0.834486', '0.829954', '0.838218', '0.841560', '0.843634', '0.826150', '0.832178', '0.832762', '0.816860']
         : correct/total = [(3391, 4128), (3490, 4203), (3403, 4081), (3628, 4333), (3392, 4091), (3587, 4287), (3534, 4193), (3608, 4349), (3494, 4191), (3563, 4277), (3431, 4143), (3499, 4193), (3397, 4093), (3518, 4197), (3410, 4052), (3399, 4029), (3431, 4153), (3481, 4183), (3401, 4084), (3372, 4128)]
Round 009: test acc mean=0.8386 ± 0.0058 | min=0.8290 max=0.8482
         : test loss mean=0.5204 ± 0.0198
         : individual accs = ['0.828973', '0.841304', '0.833619', '0.845142', '0.829382', '0.841614', '0.843787', '0.842952', '0.848246', '0.843114', '0.830799', '0.832101', '0.839482', '0.840362', '0.844768', '0.842393', '0.839875', '0.838872', '0.836925', '0.829215']
         : correct/total = [(3422, 4128), (3536, 4203), (3402, 4081), (3662, 4333), (3393, 4091), (3608, 4287), (3538, 4193), (3666, 4349), (3555, 4191), (3606, 4277), (3442, 4143), (3489, 4193), (3436, 4093), (3527, 4197), (3423, 4052), (3394, 4029), (3488, 4153), (3509, 4183), (3418, 4084), (3423, 4128)]
Round 010: test acc mean=0.8424 ± 0.0057 | min=0.8318 max=0.8501
         : test loss mean=0.5033 ± 0.0165
         : individual accs = ['0.836725', '0.843683', '0.835825', '0.847911', '0.831826', '0.839981', '0.848557', '0.850080', '0.846815', '0.843582', '0.832730', '0.838779', '0.844857', '0.847510', '0.846249', '0.850087', '0.847821', '0.842219', '0.838394', '0.834787']
         : correct/total = [(3454, 4128), (3546, 4203), (3411, 4081), (3674, 4333), (3403, 4091), (3601, 4287), (3558, 4193), (3697, 4349), (3549, 4191), (3608, 4277), (3450, 4143), (3517, 4193), (3458, 4093), (3557, 4197), (3429, 4052), (3425, 4029), (3521, 4153), (3523, 4183), (3424, 4084), (3446, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: ring, Aggregation: d-fedavg
Overall test accuracy: mean=0.8424 ± 0.0057
