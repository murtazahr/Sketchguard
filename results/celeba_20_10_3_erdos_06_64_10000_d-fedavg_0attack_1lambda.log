Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.5465 ± 0.0441 | min=0.4929 max=0.6620
         : test loss mean=0.6929 ± 0.0002
         : individual accs = ['0.582456', '0.506908', '0.493345', '0.532815', '0.582011', '0.521397', '0.524017', '0.503993', '0.661972', '0.492908', '0.525350', '0.501333', '0.522569', '0.575862', '0.560498', '0.601747', '0.551993', '0.508400', '0.596370', '0.584575']
         : correct/total = [(664, 1140), (587, 1158), (556, 1127), (617, 1158), (660, 1134), (597, 1145), (600, 1145), (568, 1127), (752, 1136), (556, 1128), (601, 1144), (564, 1125), (602, 1152), (668, 1160), (630, 1124), (689, 1145), (637, 1154), (575, 1131), (690, 1157), (667, 1141)]
Round 002: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6923 ± 0.0009
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 003: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6920 ± 0.0012
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 004: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6912 ± 0.0013
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 005: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.6885 ± 0.0015
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 006: test acc mean=0.5978 ± 0.0131 | min=0.5765 max=0.6303
         : test loss mean=0.6721 ± 0.0026
         : individual accs = ['0.594737', '0.586356', '0.585626', '0.599309', '0.597884', '0.593886', '0.595633', '0.582964', '0.630282', '0.600177', '0.619755', '0.613333', '0.611979', '0.591379', '0.576512', '0.585153', '0.598787', '0.584439', '0.605877', '0.601227']
         : correct/total = [(678, 1140), (679, 1158), (660, 1127), (694, 1158), (678, 1134), (680, 1145), (682, 1145), (657, 1127), (716, 1136), (677, 1128), (709, 1144), (690, 1125), (705, 1152), (686, 1160), (648, 1124), (670, 1145), (691, 1154), (661, 1131), (701, 1157), (686, 1141)]
Round 007: test acc mean=0.6683 ± 0.0140 | min=0.6468 max=0.6914
         : test loss mean=0.6171 ± 0.0090
         : individual accs = ['0.648246', '0.649396', '0.660160', '0.671848', '0.673721', '0.679476', '0.689956', '0.655723', '0.678697', '0.665780', '0.659091', '0.688000', '0.682292', '0.663793', '0.646797', '0.658515', '0.683709', '0.691424', '0.657736', '0.660824']
         : correct/total = [(739, 1140), (752, 1158), (744, 1127), (778, 1158), (764, 1134), (778, 1145), (790, 1145), (739, 1127), (771, 1136), (751, 1128), (754, 1144), (774, 1125), (786, 1152), (770, 1160), (727, 1124), (754, 1145), (789, 1154), (782, 1131), (761, 1157), (754, 1141)]
Round 008: test acc mean=0.7364 ± 0.0122 | min=0.7152 max=0.7636
         : test loss mean=0.5448 ± 0.0117
         : individual accs = ['0.719298', '0.736615', '0.746229', '0.735751', '0.736332', '0.746725', '0.750218', '0.715173', '0.724472', '0.744681', '0.736888', '0.763556', '0.736979', '0.737931', '0.736655', '0.715284', '0.753899', '0.732980', '0.725151', '0.733567']
         : correct/total = [(820, 1140), (853, 1158), (841, 1127), (852, 1158), (835, 1134), (855, 1145), (859, 1145), (806, 1127), (823, 1136), (840, 1128), (843, 1144), (859, 1125), (849, 1152), (856, 1160), (828, 1124), (819, 1145), (870, 1154), (829, 1131), (839, 1157), (837, 1141)]
Round 009: test acc mean=0.7839 ± 0.0134 | min=0.7622 max=0.8032
         : test loss mean=0.4703 ± 0.0131
         : individual accs = ['0.781579', '0.783247', '0.799468', '0.771157', '0.777778', '0.797380', '0.793886', '0.762201', '0.775528', '0.803191', '0.793706', '0.802667', '0.773438', '0.772414', '0.789146', '0.766812', '0.796360', '0.773652', '0.764045', '0.800175']
         : correct/total = [(891, 1140), (907, 1158), (901, 1127), (893, 1158), (882, 1134), (913, 1145), (909, 1145), (859, 1127), (881, 1136), (906, 1128), (908, 1144), (903, 1125), (891, 1152), (896, 1160), (887, 1124), (878, 1145), (919, 1154), (875, 1131), (884, 1157), (913, 1141)]
Round 010: test acc mean=0.8118 ± 0.0144 | min=0.7805 max=0.8339
         : test loss mean=0.4175 ± 0.0156
         : individual accs = ['0.807895', '0.816926', '0.825200', '0.799655', '0.790123', '0.823581', '0.819214', '0.803904', '0.816021', '0.825355', '0.833916', '0.824000', '0.799479', '0.803448', '0.812278', '0.791266', '0.830156', '0.806366', '0.780467', '0.827344']
         : correct/total = [(921, 1140), (946, 1158), (930, 1127), (926, 1158), (896, 1134), (943, 1145), (938, 1145), (906, 1127), (927, 1136), (931, 1128), (954, 1144), (927, 1125), (921, 1152), (932, 1160), (913, 1124), (906, 1145), (958, 1154), (912, 1131), (903, 1157), (944, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Overall test accuracy: mean=0.8118 ± 0.0144
