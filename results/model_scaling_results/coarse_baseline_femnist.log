# Model Scaling Experiment
# Algorithm: coarse
# Model variant: baseline
# Dataset: femnist
# Timestamp: 2025-09-22T22:50:29.758378
# Device: CPU (forced for consistent performance)
# Command: python decentralized_fl_sim.py --dataset femnist --model-variant baseline --rounds 3 --local-epochs 1 --seed 42 --batch-size 32 --lr 0.01 --agg coarse --attack-percentage 0.5 --attack-type directed_deviation --verbose --graph ring --num-nodes 20
================================================================================

Device: cpu
Seed: 42
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [37676, 37670, 37261, 34625, 36810, 35667, 37466, 36404, 36175, 36710, 37122, 37538, 35969, 37590, 36705, 36474, 36699, 37182, 36951, 35769]
Test partition sizes: [4275, 4276, 4227, 3941, 4171, 4051, 4253, 4138, 4112, 4169, 4218, 4252, 4082, 4263, 4169, 4143, 4173, 4221, 4187, 4067]
  Client 0: 37676 train samples, 62 unique classes
  Client 1: 37670 train samples, 62 unique classes
  Client 2: 37261 train samples, 62 unique classes
  Client 3: 34625 train samples, 62 unique classes
  Client 4: 36810 train samples, 62 unique classes
  Client 5: 35667 train samples, 62 unique classes
  Client 6: 37466 train samples, 62 unique classes
  Client 7: 36404 train samples, 62 unique classes
  Client 8: 36175 train samples, 62 unique classes
  Client 9: 36710 train samples, 62 unique classes
  Client 10: 37122 train samples, 62 unique classes
  Client 11: 37538 train samples, 62 unique classes
  Client 12: 35969 train samples, 62 unique classes
  Client 13: 37590 train samples, 62 unique classes
  Client 14: 36705 train samples, 62 unique classes
  Client 15: 36474 train samples, 62 unique classes
  Client 16: 36699 train samples, 62 unique classes
  Client 17: 37182 train samples, 62 unique classes
  Client 18: 36951 train samples, 62 unique classes
  Client 19: 35769 train samples, 62 unique classes
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Attack: Compromised 10/20 nodes: [0, 1, 2, 3, 7, 8, 10, 11, 16, 17]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
COARSE Node 0:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 1:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 2:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 3:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 4:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 5:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 6:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 7:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 8:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 9:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 10:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 11:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 12:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 13:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 14:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 15:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 16:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 17:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 18:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE Node 19:
  Model dim: 6,603,710 → Sketch size: 1000
  Compression ratio: 6603.7x
  Using model parameters for aggregation, sketches for filtering
COARSE ALGORITHM (Sketch-based Filtering + State Aggregation)
  - Model dimension: 6,603,710 parameters
  - Sketch size: 1000
  - Compression ratio: 6603.7x
  - Complexity: O(d + N×k) = O(6,603,710 + 20×1000)
  - Theoretical speedup vs BALANCE: 19.9x
Initial test acc across nodes: mean=0.0169 ± 0.0158
Round 001: test acc mean=0.5359 ± 0.2258 | min=0.0119 max=0.7111
         : test loss mean=2550.2709 ± 6201.2791
         : individual accs = ['0.643743', '0.011927', '0.037379', '0.612535', '0.711100', '0.689459', '0.687750', '0.640164', '0.618920', '0.042696', '0.689426', '0.691675', '0.453209', '0.467277', '0.456704', '0.658219', '0.598131', '0.626392', '0.691187', '0.690927']
         : correct/total = [(2752, 4275), (51, 4276), (158, 4227), (2414, 3941), (2966, 4171), (2793, 4051), (2925, 4253), (2649, 4138), (2545, 4112), (178, 4169), (2908, 4218), (2941, 4252), (1850, 4082), (1992, 4263), (1904, 4169), (2727, 4143), (2496, 4173), (2644, 4221), (2894, 4187), (2810, 4067)]
         : compromised: 0.5170, honest: 0.5549
         : coarse stats = ['Node 0: acc_rate=0.500', 'Node 1: acc_rate=0.000', 'Node 2: acc_rate=0.000']...
Round 002: test acc mean=0.5289 ± 0.3596 | min=0.0173 max=0.8147
         : test loss mean=nan ± nan
         : individual accs = ['0.049123', '0.044434', '0.046132', '0.049734', '0.813953', '0.800543', '0.797790', '0.761721', '0.025049', '0.043416', '0.017307', '0.788570', '0.773885', '0.802017', '0.799952', '0.775525', '0.794153', '0.773276', '0.814664', '0.807229']
         : correct/total = [(210, 4275), (190, 4276), (195, 4227), (196, 3941), (3395, 4171), (3243, 4051), (3393, 4253), (3152, 4138), (103, 4112), (181, 4169), (73, 4218), (3353, 4252), (3159, 4082), (3419, 4263), (3335, 4169), (3213, 4143), (3314, 4173), (3264, 4221), (3411, 4187), (3283, 4067)]
         : compromised: 0.3349, honest: 0.7229
         : coarse stats = ['Node 0: acc_rate=0.250', 'Node 1: acc_rate=0.250', 'Node 2: acc_rate=0.000']...
Round 003: test acc mean=0.5551 ± 0.3722 | min=0.0434 max=0.8466
         : test loss mean=nan ± nan
         : individual accs = ['0.049123', '0.045136', '0.046132', '0.049734', '0.846560', '0.825722', '0.826240', '0.820203', '0.053988', '0.043416', '0.048838', '0.817027', '0.814062', '0.837438', '0.835692', '0.814627', '0.820273', '0.838427', '0.835204', '0.835014']
         : correct/total = [(210, 4275), (193, 4276), (195, 4227), (196, 3941), (3531, 4171), (3345, 4051), (3514, 4253), (3394, 4138), (222, 4112), (181, 4169), (206, 4218), (3474, 4252), (3323, 4082), (3570, 4263), (3484, 4169), (3375, 4143), (3423, 4173), (3539, 4221), (3497, 4187), (3396, 4067)]
         : compromised: 0.3589, honest: 0.7514
         : coarse stats = ['Node 0: acc_rate=0.167', 'Node 1: acc_rate=0.167', 'Node 2: acc_rate=0.000']...

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: ring, Aggregation: coarse
Attack: directed_deviation, 50.0% compromised
Final accuracy - Compromised: 0.3589, Honest: 0.7514
Overall test accuracy: mean=0.5551 ± 0.3722

=== COARSE SUMMARY ===
Node 0: acceptance=0.167
Node 1: acceptance=0.167
Node 2: acceptance=0.000
Node 3: acceptance=0.167
Node 4: acceptance=0.333
Node 5: acceptance=1.000
Node 6: acceptance=0.333
Node 7: acceptance=0.167
Node 8: acceptance=0.167
Node 9: acceptance=0.667
Node 10: acceptance=0.167
Node 11: acceptance=0.167
Node 12: acceptance=0.167
Node 13: acceptance=0.667
Node 14: acceptance=0.667
Node 15: acceptance=0.333
Node 16: acceptance=0.167
Node 17: acceptance=0.167
Node 18: acceptance=0.333
Node 19: acceptance=0.500

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Sketch transfer: 0.000s (0.0%)
    - Model fetch (accepted): 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Sketching: 0.327s (88.9%)
    - Filtering: 0.000s (0.1%)
    - Aggregation: 0.041s (11.0%)
  TOTALS:
    - Total computation: 0.368s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.368s

=== PER-NODE AVERAGE TIME ===
  - Sketching: 0.259s
  - Filtering: 0.000s
  - Aggregation: 0.029s
  - Sketch transfer: 0.000s
  - Model fetch: 0.000s
  - Total per node: 0.289s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total sketching: 5.187s
  - Total filtering: 0.004s
  - Total aggregation: 0.583s
  - Total sketch transfer: 0.000s
  - Total model fetch: 0.000s
  - Grand total: 5.774s
  - Mean acceptance rate: 0.325

COARSE Algorithm Properties:
  - Original dimension: 6,603,710
  - Sketch size: 1000
  - Compression ratio: 19.9x
  - Single repetition: No repetitions needed
  - Theoretical complexity: O(d + N×k)
  - Approach: Sketch filtering + state aggregation


# Experiment completed successfully
