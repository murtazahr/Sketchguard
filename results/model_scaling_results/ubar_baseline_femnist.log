# Model Scaling Experiment
# Algorithm: ubar
# Model variant: baseline
# Dataset: femnist
# Timestamp: 2025-09-23T03:55:10.295302
# Device: CPU (forced for consistent performance)
# Command: python decentralized_fl_sim.py --dataset femnist --model-variant baseline --rounds 3 --local-epochs 1 --seed 42 --batch-size 32 --lr 0.01 --agg ubar --ubar-rho 0.4 --attack-percentage 0.5 --attack-type directed_deviation --verbose --graph ring --num-nodes 20
================================================================================

Device: cpu
Seed: 42
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [37676, 37670, 37261, 34625, 36810, 35667, 37466, 36404, 36175, 36710, 37122, 37538, 35969, 37590, 36705, 36474, 36699, 37182, 36951, 35769]
Test partition sizes: [4275, 4276, 4227, 3941, 4171, 4051, 4253, 4138, 4112, 4169, 4218, 4252, 4082, 4263, 4169, 4143, 4173, 4221, 4187, 4067]
  Client 0: 37676 train samples, 62 unique classes
  Client 1: 37670 train samples, 62 unique classes
  Client 2: 37261 train samples, 62 unique classes
  Client 3: 34625 train samples, 62 unique classes
  Client 4: 36810 train samples, 62 unique classes
  Client 5: 35667 train samples, 62 unique classes
  Client 6: 37466 train samples, 62 unique classes
  Client 7: 36404 train samples, 62 unique classes
  Client 8: 36175 train samples, 62 unique classes
  Client 9: 36710 train samples, 62 unique classes
  Client 10: 37122 train samples, 62 unique classes
  Client 11: 37538 train samples, 62 unique classes
  Client 12: 35969 train samples, 62 unique classes
  Client 13: 37590 train samples, 62 unique classes
  Client 14: 36705 train samples, 62 unique classes
  Client 15: 36474 train samples, 62 unique classes
  Client 16: 36699 train samples, 62 unique classes
  Client 17: 37182 train samples, 62 unique classes
  Client 18: 36951 train samples, 62 unique classes
  Client 19: 35769 train samples, 62 unique classes
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Attack: Compromised 10/20 nodes: [0, 1, 2, 3, 7, 8, 10, 11, 16, 17]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 6,603,710 parameters
  - Rho parameter: 0.4
  - Stage 1: Distance-based filtering (select 40% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.0169 ± 0.0158
Round 001: test acc mean=0.5353 ± 0.2281 | min=0.0090 max=0.7111
         : test loss mean=2208.9459 ± 5483.6561
         : individual accs = ['0.643743', '0.013330', '0.008990', '0.612535', '0.711100', '0.694890', '0.687750', '0.640164', '0.618920', '0.051571', '0.689426', '0.691675', '0.453209', '0.467277', '0.456704', '0.658219', '0.598131', '0.626392', '0.691187', '0.690927']
         : correct/total = [(2752, 4275), (57, 4276), (38, 4227), (2414, 3941), (2966, 4171), (2815, 4051), (2925, 4253), (2649, 4138), (2545, 4112), (215, 4169), (2908, 4218), (2941, 4252), (1850, 4082), (1992, 4263), (1904, 4169), (2727, 4143), (2496, 4173), (2644, 4221), (2894, 4187), (2810, 4067)]
         : compromised: 0.5143, honest: 0.5563
         : ubar stats = ['Node 0: s1=0.500, s2=1.000', 'Node 1: s1=0.500, s2=1.000', 'Node 2: s1=0.500, s2=1.000']...
Round 002: test acc mean=0.6058 ± 0.3233 | min=0.0389 max=0.8147
         : test loss mean=121891174158955.0312 ± 365646693928296.5000
         : individual accs = ['0.794152', '0.047007', '0.051573', '0.789901', '0.802685', '0.807455', '0.799201', '0.761721', '0.038911', '0.050132', '0.043860', '0.788570', '0.773885', '0.802017', '0.799952', '0.775525', '0.794153', '0.773276', '0.814664', '0.807229']
         : correct/total = [(3395, 4275), (201, 4276), (218, 4227), (3113, 3941), (3348, 4171), (3271, 4051), (3399, 4253), (3152, 4138), (160, 4112), (209, 4169), (185, 4218), (3353, 4252), (3159, 4082), (3419, 4263), (3335, 4169), (3213, 4143), (3314, 4173), (3264, 4221), (3411, 4187), (3283, 4067)]
         : compromised: 0.4883, honest: 0.7233
         : ubar stats = ['Node 0: s1=0.500, s2=1.000', 'Node 1: s1=0.500, s2=1.000', 'Node 2: s1=0.500, s2=1.000']...
Round 003: test acc mean=0.6329 ± 0.3388 | min=0.0341 max=0.8449
         : test loss mean=14787614.0932 ± 64456048.5467
         : individual accs = ['0.829006', '0.034144', '0.041401', '0.820858', '0.844881', '0.822760', '0.831883', '0.825036', '0.048152', '0.047254', '0.060929', '0.817027', '0.814062', '0.837438', '0.840010', '0.814627', '0.820273', '0.838427', '0.835204', '0.835014']
         : correct/total = [(3544, 4275), (146, 4276), (175, 4227), (3235, 3941), (3524, 4171), (3333, 4051), (3538, 4253), (3414, 4138), (198, 4112), (197, 4169), (257, 4218), (3474, 4252), (3323, 4082), (3570, 4263), (3502, 4169), (3375, 4143), (3423, 4173), (3539, 4221), (3497, 4187), (3396, 4067)]
         : compromised: 0.5135, honest: 0.7523
         : ubar stats = ['Node 0: s1=0.500, s2=1.000', 'Node 1: s1=0.500, s2=1.000', 'Node 2: s1=0.500, s2=1.000']...

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: ring, Aggregation: ubar
Attack: directed_deviation, 50.0% compromised
Final accuracy - Compromised: 0.5135, Honest: 0.7523
Overall test accuracy: mean=0.6329 ± 0.3388

=== UBAR SUMMARY ===
Node 0: stage1=0.500, stage2=1.000, overall=0.500
Node 1: stage1=0.500, stage2=1.000, overall=0.500
Node 2: stage1=0.500, stage2=1.000, overall=0.500
Node 3: stage1=0.500, stage2=1.000, overall=0.500
Node 4: stage1=0.500, stage2=1.000, overall=0.500
Node 5: stage1=0.500, stage2=1.000, overall=0.500
Node 6: stage1=0.500, stage2=1.000, overall=0.500
Node 7: stage1=0.500, stage2=1.000, overall=0.500
Node 8: stage1=0.500, stage2=1.000, overall=0.500
Node 9: stage1=0.500, stage2=1.000, overall=0.500
Node 10: stage1=0.500, stage2=1.000, overall=0.500
Node 11: stage1=0.500, stage2=1.000, overall=0.500
Node 12: stage1=0.500, stage2=1.000, overall=0.500
Node 13: stage1=0.500, stage2=1.000, overall=0.500
Node 14: stage1=0.500, stage2=1.000, overall=0.500
Node 15: stage1=0.500, stage2=1.000, overall=0.500
Node 16: stage1=0.500, stage2=1.000, overall=0.500
Node 17: stage1=0.500, stage2=1.000, overall=0.500
Node 18: stage1=0.500, stage2=1.000, overall=0.500
Node 19: stage1=0.500, stage2=1.000, overall=0.500

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.015s (20.2%)
    - Loss computation: 0.042s (55.7%)
    - Aggregation: 0.018s (24.0%)
  TOTALS:
    - Total computation: 0.075s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.075s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.010s
  - Loss computation: 0.018s
  - Aggregation: 0.012s
  - Model transfer: 0.000s
  - Total per node: 0.040s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.200s
  - Total loss computation: 0.360s
  - Total aggregation: 0.246s
  - Total model transfer: 0.000s
  - Grand total: 0.806s
  - Mean Stage 1 acceptance rate: 0.500
  - Mean Stage 2 acceptance rate: 1.000
  - Overall acceptance rate: 0.500

UBAR Algorithm Properties:
  - Model dimension: 6,603,710
  - Rho parameter: 0.4
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 40% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation


# Experiment completed successfully
