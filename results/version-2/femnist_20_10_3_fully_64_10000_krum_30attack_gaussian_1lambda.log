Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0514 ± 0.0034 | min=0.0469 max=0.0618
         : test loss mean=3.6911 ± 0.0153
         : individual accs = ['0.051599', '0.051630', '0.050723', '0.048465', '0.051088', '0.048052', '0.049130', '0.051276', '0.047960', '0.053075', '0.050447', '0.061770', '0.053750', '0.046938', '0.048124', '0.056342', '0.055141', '0.050203', '0.052889', '0.048450']
         : correct/total = [(213, 4128), (217, 4203), (207, 4081), (210, 4333), (209, 4091), (206, 4287), (206, 4193), (223, 4349), (201, 4191), (227, 4277), (209, 4143), (259, 4193), (220, 4093), (197, 4197), (195, 4052), (227, 4029), (229, 4153), (210, 4183), (216, 4084), (200, 4128)]
         : compromised: 0.0500, honest: 0.0519
Round 002: test acc mean=0.0514 ± 0.0034 | min=0.0469 max=0.0618
         : test loss mean=3.6798 ± 0.0186
         : individual accs = ['0.051599', '0.051630', '0.050723', '0.048465', '0.051088', '0.048052', '0.049130', '0.051276', '0.047960', '0.053075', '0.050447', '0.061770', '0.053750', '0.046938', '0.048124', '0.056342', '0.055141', '0.050203', '0.052889', '0.048450']
         : correct/total = [(213, 4128), (217, 4203), (207, 4081), (210, 4333), (209, 4091), (206, 4287), (206, 4193), (223, 4349), (201, 4191), (227, 4277), (209, 4143), (259, 4193), (220, 4093), (197, 4197), (195, 4052), (227, 4029), (229, 4153), (210, 4183), (216, 4084), (200, 4128)]
         : compromised: 0.0500, honest: 0.0519
Round 003: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.6745 ± 0.0163
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0566, honest: 0.0559
Round 004: test acc mean=0.0525 ± 0.0036 | min=0.0474 max=0.0637
         : test loss mean=3.6661 ± 0.0174
         : individual accs = ['0.052568', '0.052106', '0.051948', '0.049388', '0.051821', '0.048752', '0.050083', '0.052426', '0.049869', '0.054477', '0.051412', '0.063678', '0.055216', '0.047415', '0.049605', '0.057334', '0.056104', '0.051877', '0.055093', '0.049176']
         : correct/total = [(217, 4128), (219, 4203), (212, 4081), (214, 4333), (212, 4091), (209, 4287), (210, 4193), (228, 4349), (209, 4191), (233, 4277), (213, 4143), (267, 4193), (226, 4093), (199, 4197), (201, 4052), (231, 4029), (233, 4153), (217, 4183), (225, 4084), (203, 4128)]
         : compromised: 0.0513, honest: 0.0530
Round 005: test acc mean=0.0806 ± 0.0050 | min=0.0724 max=0.0916
         : test loss mean=3.6575 ± 0.0168
         : individual accs = ['0.082849', '0.075660', '0.090909', '0.075698', '0.079443', '0.078610', '0.078226', '0.079099', '0.078979', '0.077391', '0.083514', '0.076318', '0.084779', '0.087682', '0.091560', '0.081162', '0.080665', '0.072436', '0.082027', '0.075097']
         : correct/total = [(342, 4128), (318, 4203), (371, 4081), (328, 4333), (325, 4091), (337, 4287), (328, 4193), (344, 4349), (331, 4191), (331, 4277), (346, 4143), (320, 4193), (347, 4093), (368, 4197), (371, 4052), (327, 4029), (335, 4153), (303, 4183), (335, 4084), (310, 4128)]
         : compromised: 0.0828, honest: 0.0796
Round 006: test acc mean=0.0903 ± 0.0046 | min=0.0804 max=0.0975
         : test loss mean=3.6390 ± 0.0192
         : individual accs = ['0.091328', '0.083988', '0.085518', '0.087699', '0.090198', '0.081875', '0.087527', '0.089216', '0.093772', '0.090718', '0.080377', '0.090627', '0.090887', '0.092685', '0.097236', '0.097543', '0.091982', '0.092517', '0.093291', '0.096172']
         : correct/total = [(377, 4128), (353, 4203), (349, 4081), (380, 4333), (369, 4091), (351, 4287), (367, 4193), (388, 4349), (393, 4191), (388, 4277), (333, 4143), (380, 4193), (372, 4093), (389, 4197), (394, 4052), (393, 4029), (382, 4153), (387, 4183), (381, 4084), (397, 4128)]
         : compromised: 0.0914, honest: 0.0898
Round 007: test acc mean=0.1891 ± 0.0089 | min=0.1736 max=0.2098
         : test loss mean=3.5932 ± 0.0188
         : individual accs = ['0.198159', '0.187485', '0.209753', '0.173552', '0.188462', '0.187077', '0.183162', '0.192228', '0.176807', '0.182838', '0.184407', '0.193895', '0.191058', '0.187991', '0.199161', '0.197071', '0.199133', '0.180253', '0.192948', '0.175872']
         : correct/total = [(818, 4128), (788, 4203), (856, 4081), (752, 4333), (771, 4091), (802, 4287), (768, 4193), (836, 4349), (741, 4191), (782, 4277), (764, 4143), (813, 4193), (782, 4093), (789, 4197), (807, 4052), (794, 4029), (827, 4153), (754, 4183), (788, 4084), (726, 4128)]
         : compromised: 0.1897, honest: 0.1888
Round 008: test acc mean=0.2003 ± 0.0088 | min=0.1782 max=0.2164
         : test loss mean=3.4893 ± 0.0199
         : individual accs = ['0.205184', '0.194861', '0.216369', '0.178168', '0.210706', '0.197341', '0.196280', '0.202115', '0.190885', '0.193126', '0.195028', '0.206296', '0.202785', '0.198952', '0.209279', '0.209481', '0.206357', '0.193880', '0.208129', '0.189922']
         : correct/total = [(847, 4128), (819, 4203), (883, 4081), (772, 4333), (862, 4091), (846, 4287), (823, 4193), (879, 4349), (800, 4191), (826, 4277), (808, 4143), (865, 4193), (830, 4093), (835, 4197), (848, 4052), (844, 4029), (857, 4153), (811, 4183), (850, 4084), (784, 4128)]
         : compromised: 0.2017, honest: 0.1996
Round 009: test acc mean=0.2906 ± 0.0116 | min=0.2559 max=0.3090
         : test loss mean=3.1982 ± 0.0248
         : individual accs = ['0.300145', '0.291458', '0.308993', '0.255943', '0.297971', '0.291812', '0.282614', '0.293401', '0.279885', '0.277297', '0.284335', '0.296208', '0.297337', '0.295687', '0.300099', '0.302060', '0.300024', '0.280421', '0.295299', '0.281492']
         : correct/total = [(1239, 4128), (1225, 4203), (1261, 4081), (1109, 4333), (1219, 4091), (1251, 4287), (1185, 4193), (1276, 4349), (1173, 4191), (1186, 4277), (1178, 4143), (1242, 4193), (1217, 4093), (1241, 4197), (1216, 4052), (1217, 4029), (1246, 4153), (1173, 4183), (1206, 4084), (1162, 4128)]
         : compromised: 0.2934, honest: 0.2894
Round 010: test acc mean=0.3637 ± 0.0113 | min=0.3346 max=0.3810
         : test loss mean=2.8003 ± 0.0280
         : individual accs = ['0.368944', '0.369736', '0.381034', '0.334641', '0.371547', '0.369023', '0.349630', '0.361692', '0.355285', '0.346505', '0.358436', '0.369902', '0.367457', '0.370264', '0.375617', '0.369819', '0.363833', '0.361224', '0.377816', '0.350775']
         : correct/total = [(1523, 4128), (1554, 4203), (1555, 4081), (1450, 4333), (1520, 4091), (1582, 4287), (1466, 4193), (1573, 4349), (1489, 4191), (1482, 4277), (1485, 4143), (1551, 4193), (1504, 4093), (1554, 4197), (1522, 4052), (1490, 4029), (1511, 4153), (1511, 4183), (1543, 4084), (1448, 4128)]
         : compromised: 0.3702, honest: 0.3608

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: krum
Attack: gaussian, 30.0% compromised
Final accuracy - Compromised: 0.3702, Honest: 0.3608
Overall test accuracy: mean=0.3637 ± 0.0113
