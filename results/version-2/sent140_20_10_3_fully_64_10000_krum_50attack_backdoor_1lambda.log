Device: cuda
Seed: 987654321
Loading 1 LEAF Sent140 train files...
LEAF Sent140 train: 254555 users, 908652 samples
Building vocabulary (max_size=10000)...
Vocabulary size: 10000
Loading 1 LEAF Sent140 test files...
LEAF Sent140 test: 254555 users, 286281 samples
Found 254555 train users, 254555 test users, 254555 common users
User sample counts range: 494 (max) to 1 (min)
Distributed ALL 254555 users across 20 clients
Users per client: 12727 (with 15 clients getting +1 user)
Train partition sizes: [44353, 44290, 44657, 44907, 44696, 45843, 45801, 45619, 45069, 45639, 45821, 45311, 45779, 46056, 45625, 45984, 46428, 44737, 45540, 46497]
Test partition sizes: [14232, 14235, 14266, 14217, 14238, 14373, 14346, 14334, 14294, 14373, 14344, 14302, 14354, 14362, 14320, 14395, 14389, 14257, 14251, 14399]
  Client 0: 44353 train samples, 2 unique classes
  Client 1: 44290 train samples, 2 unique classes
  Client 2: 44657 train samples, 2 unique classes
  Client 3: 44907 train samples, 2 unique classes
  Client 4: 44696 train samples, 2 unique classes
  Client 5: 45843 train samples, 2 unique classes
  Client 6: 45801 train samples, 2 unique classes
  Client 7: 45619 train samples, 2 unique classes
  Client 8: 45069 train samples, 2 unique classes
  Client 9: 45639 train samples, 2 unique classes
  Client 10: 45821 train samples, 2 unique classes
  Client 11: 45311 train samples, 2 unique classes
  Client 12: 45779 train samples, 2 unique classes
  Client 13: 46056 train samples, 2 unique classes
  Client 14: 45625 train samples, 2 unique classes
  Client 15: 45984 train samples, 2 unique classes
  Client 16: 46428 train samples, 2 unique classes
  Client 17: 44737 train samples, 2 unique classes
  Client 18: 45540 train samples, 2 unique classes
  Client 19: 46497 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 10/20 nodes: [1, 2, 5, 11, 12, 13, 14, 15, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 1, trigger size: 3
Model variant: baseline
Model parameters: 1,174,986
Initial test acc across nodes: mean=0.4965 ± 0.0152
Backdoor attack: Created poisoned datasets for 10 compromised nodes
Round 001: test acc mean=0.5018 ± 0.0065 | min=0.4910 max=0.5169
         : test loss mean=5.8102 ± 1.7352
         : individual accs = ['0.512648', '0.509449', '0.505047', '0.499683', '0.506321', '0.516941', '0.500558', '0.501186', '0.490975', '0.494817', '0.500279', '0.497483', '0.500209', '0.491784', '0.494832', '0.500938', '0.504691', '0.507470', '0.501860', '0.498576']
         : correct/total = [(7296, 14232), (7252, 14235), (7205, 14266), (7104, 14217), (7209, 14238), (7430, 14373), (7181, 14346), (7184, 14334), (7018, 14294), (7112, 14373), (7176, 14344), (7115, 14302), (7180, 14354), (7063, 14362), (7086, 14320), (7211, 14395), (7262, 14389), (7235, 14257), (7152, 14251), (7179, 14399)]
         : compromised: 0.5026, honest: 0.5010
Round 002: test acc mean=0.5050 ± 0.0052 | min=0.4923 max=0.5133
         : test loss mean=12.7196 ± 0.1482
         : individual accs = ['0.511172', '0.513312', '0.512477', '0.508194', '0.504565', '0.506366', '0.502928', '0.503837', '0.511194', '0.506436', '0.502719', '0.507831', '0.502996', '0.492271', '0.504260', '0.500452', '0.500035', '0.496668', '0.509508', '0.502604']
         : correct/total = [(7275, 14232), (7307, 14235), (7311, 14266), (7225, 14217), (7184, 14238), (7278, 14373), (7215, 14346), (7222, 14334), (7307, 14294), (7279, 14373), (7211, 14344), (7263, 14302), (7220, 14354), (7070, 14362), (7221, 14320), (7204, 14395), (7195, 14389), (7081, 14257), (7261, 14251), (7237, 14399)]
         : compromised: 0.5046, honest: 0.5054
Round 003: test acc mean=0.5051 ± 0.0056 | min=0.4914 max=0.5139
         : test loss mean=5.7373 ± 0.0751
         : individual accs = ['0.510891', '0.513734', '0.513949', '0.507772', '0.505900', '0.506157', '0.502440', '0.504814', '0.511543', '0.506992', '0.500976', '0.507971', '0.500488', '0.491436', '0.504190', '0.501633', '0.500243', '0.496949', '0.511262', '0.503646']
         : correct/total = [(7271, 14232), (7313, 14235), (7332, 14266), (7219, 14217), (7203, 14238), (7275, 14373), (7208, 14346), (7236, 14334), (7312, 14294), (7287, 14373), (7186, 14344), (7265, 14302), (7184, 14354), (7058, 14362), (7220, 14320), (7221, 14395), (7198, 14389), (7085, 14257), (7286, 14251), (7252, 14399)]
         : compromised: 0.5048, honest: 0.5055
Round 004: test acc mean=0.4949 ± 0.0056 | min=0.4861 max=0.5086
         : test loss mean=18.4313 ± 0.2129
         : individual accs = ['0.489109', '0.486336', '0.486051', '0.492228', '0.494100', '0.493843', '0.497560', '0.495186', '0.488457', '0.493008', '0.499024', '0.492029', '0.499512', '0.508564', '0.495810', '0.498367', '0.499757', '0.503051', '0.488738', '0.496354']
         : correct/total = [(6961, 14232), (6923, 14235), (6934, 14266), (6998, 14217), (7035, 14238), (7098, 14373), (7138, 14346), (7098, 14334), (6982, 14294), (7086, 14373), (7158, 14344), (7037, 14302), (7170, 14354), (7304, 14362), (7100, 14320), (7174, 14395), (7191, 14389), (7172, 14257), (6965, 14251), (7147, 14399)]
         : compromised: 0.4952, honest: 0.4945
Round 005: test acc mean=0.4949 ± 0.0056 | min=0.4861 max=0.5086
         : test loss mean=41.7237 ± 0.4513
         : individual accs = ['0.489109', '0.486266', '0.486051', '0.492228', '0.494100', '0.493843', '0.497560', '0.495186', '0.488457', '0.493008', '0.499024', '0.492029', '0.499512', '0.508564', '0.495810', '0.498367', '0.499757', '0.503051', '0.488738', '0.496354']
         : correct/total = [(6961, 14232), (6922, 14235), (6934, 14266), (6998, 14217), (7035, 14238), (7098, 14373), (7138, 14346), (7098, 14334), (6982, 14294), (7086, 14373), (7158, 14344), (7037, 14302), (7170, 14354), (7304, 14362), (7100, 14320), (7174, 14395), (7191, 14389), (7172, 14257), (6965, 14251), (7147, 14399)]
         : compromised: 0.4952, honest: 0.4945
Round 006: test acc mean=0.5052 ± 0.0056 | min=0.4912 max=0.5143
         : test loss mean=7.1626 ± 0.0825
         : individual accs = ['0.510891', '0.513734', '0.514300', '0.507913', '0.505549', '0.506297', '0.502509', '0.504674', '0.511473', '0.506992', '0.501255', '0.508251', '0.500488', '0.491227', '0.504120', '0.501633', '0.500174', '0.496879', '0.511403', '0.503854']
         : correct/total = [(7271, 14232), (7313, 14235), (7337, 14266), (7221, 14217), (7198, 14238), (7277, 14373), (7209, 14346), (7234, 14334), (7311, 14294), (7287, 14373), (7190, 14344), (7269, 14302), (7184, 14354), (7055, 14362), (7219, 14320), (7221, 14395), (7197, 14389), (7084, 14257), (7288, 14251), (7255, 14399)]
         : compromised: 0.5048, honest: 0.5055
Round 007: test acc mean=0.5051 ± 0.0056 | min=0.4914 max=0.5139
         : test loss mean=5.3728 ± 0.0668
         : individual accs = ['0.510891', '0.513734', '0.513949', '0.507772', '0.505900', '0.506157', '0.502440', '0.504814', '0.511543', '0.506992', '0.500976', '0.507971', '0.500488', '0.491436', '0.504190', '0.501633', '0.500243', '0.496949', '0.511262', '0.503646']
         : correct/total = [(7271, 14232), (7313, 14235), (7332, 14266), (7219, 14217), (7203, 14238), (7275, 14373), (7208, 14346), (7236, 14334), (7312, 14294), (7287, 14373), (7186, 14344), (7265, 14302), (7184, 14354), (7058, 14362), (7220, 14320), (7221, 14395), (7198, 14389), (7085, 14257), (7286, 14251), (7252, 14399)]
         : compromised: 0.5048, honest: 0.5055
Round 008: test acc mean=0.4898 ± 0.0046 | min=0.4814 max=0.4979
         : test loss mean=1.2517 ± 0.0147
         : individual accs = ['0.489039', '0.482192', '0.487102', '0.486460', '0.491853', '0.482502', '0.494354', '0.488419', '0.487827', '0.491825', '0.489891', '0.487484', '0.490316', '0.497911', '0.494483', '0.496492', '0.496629', '0.490075', '0.488878', '0.481353']
         : correct/total = [(6960, 14232), (6864, 14235), (6949, 14266), (6916, 14217), (7003, 14238), (6935, 14373), (7092, 14346), (7001, 14334), (6973, 14294), (7069, 14373), (7027, 14344), (6972, 14302), (7038, 14354), (7151, 14362), (7081, 14320), (7147, 14395), (7146, 14389), (6987, 14257), (6967, 14251), (6931, 14399)]
         : compromised: 0.4897, honest: 0.4898
Round 009: test acc mean=0.5101 ± 0.0044 | min=0.5040 max=0.5203
         : test loss mean=1.1901 ± 0.0163
         : individual accs = ['0.505551', '0.504672', '0.507500', '0.508616', '0.516154', '0.508245', '0.513105', '0.510395', '0.508955', '0.504905', '0.511712', '0.505244', '0.514073', '0.520331', '0.507263', '0.512817', '0.509486', '0.517360', '0.504035', '0.512188']
         : correct/total = [(7195, 14232), (7184, 14235), (7240, 14266), (7231, 14217), (7349, 14238), (7305, 14373), (7361, 14346), (7316, 14334), (7275, 14294), (7257, 14373), (7340, 14344), (7226, 14302), (7379, 14354), (7473, 14362), (7264, 14320), (7382, 14395), (7331, 14389), (7376, 14257), (7183, 14251), (7375, 14399)]
         : compromised: 0.5102, honest: 0.5101
Round 010: test acc mean=0.5056 ± 0.0041 | min=0.4974 max=0.5142
         : test loss mean=0.7663 ± 0.0034
         : individual accs = ['0.505832', '0.506709', '0.505678', '0.501723', '0.506181', '0.502122', '0.504740', '0.509976', '0.509724', '0.503166', '0.501603', '0.503985', '0.514212', '0.512672', '0.497416', '0.505592', '0.500730', '0.503472', '0.505789', '0.510244']
         : correct/total = [(7199, 14232), (7213, 14235), (7214, 14266), (7133, 14217), (7207, 14238), (7217, 14373), (7241, 14346), (7310, 14334), (7286, 14294), (7232, 14373), (7195, 14344), (7208, 14302), (7381, 14354), (7363, 14362), (7123, 14320), (7278, 14395), (7205, 14389), (7178, 14257), (7208, 14251), (7347, 14399)]
         : compromised: 0.5058, honest: 0.5054

=== FINAL RESULTS ===
Dataset: sent140, Nodes: 20, Graph: fully, Aggregation: krum
Attack: backdoor, 50.0% compromised
Final accuracy - Compromised: 0.5058, Honest: 0.5054
Overall test accuracy: mean=0.5056 ± 0.0041

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 1
Trigger size: 3x3
Overall ASR: 0.7520 ± 0.0058
Honest nodes ASR: 0.7522 ± 0.0069
Compromised nodes ASR: 0.7518 ± 0.0046
Note: Higher ASR indicates more successful backdoor attack
