Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: krum, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0225 ± 0.0165 | min=0.0017 max=0.0579
         : test loss mean=34.4875 ± 13.4164
         : individual accs = ['0.031008', '0.051630', '0.026464', '0.024694', '0.057932', '0.013296', '0.010017', '0.044608', '0.012646', '0.039280', '0.019792', '0.004770', '0.016858', '0.007863', '0.037266', '0.006205', '0.001686', '0.033230', '0.006121', '0.005087']
         : correct/total = [(128, 4128), (217, 4203), (108, 4081), (107, 4333), (237, 4091), (57, 4287), (42, 4193), (194, 4349), (53, 4191), (168, 4277), (82, 4143), (20, 4193), (69, 4093), (33, 4197), (151, 4052), (25, 4029), (7, 4153), (139, 4183), (25, 4084), (21, 4128)]
         : compromised: 0.0106, honest: 0.0238
Round 002: test acc mean=0.0077 ± 0.0011 | min=0.0049 max=0.0093
         : test loss mean=28.9634 ± 0.1577
         : individual accs = ['0.008479', '0.007138', '0.009311', '0.007385', '0.008066', '0.007698', '0.007870', '0.006668', '0.008351', '0.008885', '0.007965', '0.005724', '0.004886', '0.007624', '0.007157', '0.008439', '0.007224', '0.009084', '0.008570', '0.007025']
         : correct/total = [(35, 4128), (30, 4203), (38, 4081), (32, 4333), (33, 4091), (33, 4287), (33, 4193), (29, 4349), (35, 4191), (38, 4277), (33, 4143), (24, 4193), (20, 4093), (32, 4197), (29, 4052), (34, 4029), (30, 4153), (38, 4183), (35, 4084), (29, 4128)]
         : compromised: 0.0077, honest: 0.0077
Round 003: test acc mean=0.0493 ± 0.0035 | min=0.0430 max=0.0545
         : test loss mean=4.0557 ± 0.0017
         : individual accs = ['0.050145', '0.048775', '0.053418', '0.043157', '0.043021', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.052889', '0.054506']
         : correct/total = [(207, 4128), (205, 4203), (218, 4081), (187, 4333), (176, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0472, honest: 0.0495
Round 004: test acc mean=0.1079 ± 0.0044 | min=0.1009 max=0.1164
         : test loss mean=4.0465 ± 0.0368
         : individual accs = ['0.112403', '0.105639', '0.108552', '0.100854', '0.110731', '0.104035', '0.109230', '0.108531', '0.102839', '0.102642', '0.109582', '0.103744', '0.111410', '0.112938', '0.112537', '0.116406', '0.105466', '0.100885', '0.113124', '0.106347']
         : correct/total = [(464, 4128), (444, 4203), (443, 4081), (437, 4333), (453, 4091), (446, 4287), (458, 4193), (472, 4349), (431, 4191), (439, 4277), (454, 4143), (435, 4193), (456, 4093), (474, 4197), (456, 4052), (469, 4029), (438, 4153), (422, 4183), (462, 4084), (439, 4128)]
         : compromised: 0.1085, honest: 0.1078
Round 005: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.7856 ± 0.0106
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0561
Round 006: test acc mean=0.3624 ± 0.0076 | min=0.3478 max=0.3741
         : test loss mean=2.9031 ± 0.0324
         : individual accs = ['0.355862', '0.362360', '0.371478', '0.347796', '0.372525', '0.361791', '0.352492', '0.354564', '0.359341', '0.350245', '0.360608', '0.362986', '0.358172', '0.363117', '0.374136', '0.373294', '0.371539', '0.368396', '0.363369', '0.363372']
         : correct/total = [(1469, 4128), (1523, 4203), (1516, 4081), (1507, 4333), (1524, 4091), (1551, 4287), (1478, 4193), (1542, 4349), (1506, 4191), (1498, 4277), (1494, 4143), (1522, 4193), (1466, 4093), (1524, 4197), (1516, 4052), (1504, 4029), (1543, 4153), (1541, 4183), (1484, 4084), (1500, 4128)]
         : compromised: 0.3625, honest: 0.3624
Round 007: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.6928 ± 0.0154
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0561
Round 008: test acc mean=0.4393 ± 0.0081 | min=0.4180 max=0.4525
         : test loss mean=2.3715 ± 0.0301
         : individual accs = ['0.437500', '0.433024', '0.449645', '0.417955', '0.448301', '0.452531', '0.429048', '0.441021', '0.432594', '0.435352', '0.436399', '0.432149', '0.440753', '0.443888', '0.450148', '0.446265', '0.440886', '0.439876', '0.443683', '0.435078']
         : correct/total = [(1806, 4128), (1820, 4203), (1835, 4081), (1811, 4333), (1834, 4091), (1940, 4287), (1799, 4193), (1918, 4349), (1813, 4191), (1862, 4277), (1808, 4143), (1812, 4193), (1804, 4093), (1863, 4197), (1824, 4052), (1798, 4029), (1831, 4153), (1840, 4183), (1812, 4084), (1796, 4128)]
         : compromised: 0.4482, honest: 0.4383
Round 009: test acc mean=0.0997 ± 0.0051 | min=0.0885 max=0.1091
         : test loss mean=3.6555 ± 0.0173
         : individual accs = ['0.103924', '0.088508', '0.107327', '0.091622', '0.098264', '0.101470', '0.101836', '0.099563', '0.096636', '0.095862', '0.101859', '0.098974', '0.099438', '0.102454', '0.109082', '0.104741', '0.104744', '0.093713', '0.099657', '0.093508']
         : correct/total = [(429, 4128), (372, 4203), (438, 4081), (397, 4333), (402, 4091), (435, 4287), (427, 4193), (433, 4349), (405, 4191), (410, 4277), (422, 4143), (415, 4193), (407, 4093), (430, 4197), (442, 4052), (422, 4029), (435, 4153), (392, 4183), (407, 4084), (386, 4128)]
         : compromised: 0.1020, honest: 0.0994
Round 010: test acc mean=0.4966 ± 0.0082 | min=0.4825 max=0.5192
         : test loss mean=2.0787 ± 0.0326
         : individual accs = ['0.493944', '0.493933', '0.505758', '0.482806', '0.501344', '0.519244', '0.482471', '0.494137', '0.489143', '0.498013', '0.491673', '0.497257', '0.500611', '0.492733', '0.501234', '0.500124', '0.497953', '0.499402', '0.504407', '0.486192']
         : correct/total = [(2039, 4128), (2076, 4203), (2064, 4081), (2092, 4333), (2051, 4091), (2226, 4287), (2023, 4193), (2149, 4349), (2050, 4191), (2130, 4277), (2037, 4143), (2085, 4193), (2049, 4093), (2068, 4197), (2031, 4052), (2015, 4029), (2068, 4153), (2089, 4183), (2060, 4084), (2007, 4128)]
         : compromised: 0.5060, honest: 0.4956

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: d-fedavg
Attack: krum, 10.0% compromised
Final accuracy - Compromised: 0.5060, Honest: 0.4956
Overall test accuracy: mean=0.4966 ± 0.0082
