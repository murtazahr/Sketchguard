Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 14/20 nodes: [1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 17, 18, 19]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0160 ± 0.0186 | min=0.0029 max=0.0613
         : test loss mean=73819.2808 ± 30799.6905
         : individual accs = ['0.014293', '0.040685', '0.013722', '0.006000', '0.004155', '0.003266', '0.006439', '0.003219', '0.010260', '0.003040', '0.061308', '0.013356', '0.002932', '0.004051', '0.003208', '0.004219', '0.054418', '0.005738', '0.014202', '0.050872']
         : correct/total = [(59, 4128), (171, 4203), (56, 4081), (26, 4333), (17, 4091), (14, 4287), (27, 4193), (14, 4349), (43, 4191), (13, 4277), (254, 4143), (56, 4193), (12, 4093), (17, 4197), (13, 4052), (17, 4029), (226, 4153), (24, 4183), (58, 4084), (210, 4128)]
         : compromised: 0.0128, honest: 0.0234
Round 002: test acc mean=0.0493 ± 0.0031 | min=0.0432 max=0.0553
         : test loss mean=370023305665749.9375 ± 1612892519549036.2500
         : individual accs = ['0.049661', '0.050916', '0.054889', '0.043157', '0.048643', '0.048519', '0.048414', '0.051276', '0.044619', '0.044891', '0.050447', '0.046745', '0.052040', '0.055278', '0.045656', '0.050385', '0.051047', '0.048291', '0.050196', '0.050145']
         : correct/total = [(205, 4128), (214, 4203), (224, 4081), (187, 4333), (199, 4091), (208, 4287), (203, 4193), (223, 4349), (187, 4191), (192, 4277), (209, 4143), (196, 4193), (213, 4093), (232, 4197), (185, 4052), (203, 4029), (212, 4153), (202, 4183), (205, 4084), (207, 4128)]
         : compromised: 0.0492, honest: 0.0493
Round 003: test acc mean=0.0492 ± 0.0036 | min=0.0439 max=0.0553
         : test loss mean=2490927151.8905 ± 586955223.3507
         : individual accs = ['0.049661', '0.050916', '0.045087', '0.047773', '0.052066', '0.048752', '0.043883', '0.053116', '0.044619', '0.044891', '0.055274', '0.054376', '0.049841', '0.045747', '0.045656', '0.053860', '0.044546', '0.053311', '0.050196', '0.050145']
         : correct/total = [(205, 4128), (214, 4203), (184, 4081), (207, 4333), (213, 4091), (209, 4287), (184, 4193), (231, 4349), (187, 4191), (192, 4277), (229, 4143), (228, 4193), (204, 4093), (192, 4197), (185, 4052), (217, 4029), (185, 4153), (223, 4183), (205, 4084), (207, 4128)]
         : compromised: 0.0489, honest: 0.0499
Round 004: test acc mean=0.0503 ± 0.0032 | min=0.0439 max=0.0553
         : test loss mean=123541059.3945 ± 115953740.4444
         : individual accs = ['0.051599', '0.050916', '0.054889', '0.048465', '0.052066', '0.048052', '0.043883', '0.053116', '0.051062', '0.044891', '0.047550', '0.054376', '0.053750', '0.055278', '0.045656', '0.050881', '0.051047', '0.050203', '0.050196', '0.048450']
         : correct/total = [(213, 4128), (214, 4203), (224, 4081), (210, 4333), (213, 4091), (206, 4287), (184, 4193), (231, 4349), (214, 4191), (192, 4277), (197, 4143), (228, 4193), (220, 4093), (232, 4197), (185, 4052), (205, 4029), (212, 4153), (210, 4183), (205, 4084), (200, 4128)]
         : compromised: 0.0504, honest: 0.0500
Round 005: test acc mean=0.0395 ± 0.0091 | min=0.0250 max=0.0618
         : test loss mean=13182.6317 ± 20198.6069
         : individual accs = ['0.030523', '0.034737', '0.024994', '0.048465', '0.042288', '0.048052', '0.049130', '0.051276', '0.034359', '0.039280', '0.050447', '0.061770', '0.033716', '0.028592', '0.037759', '0.032266', '0.040212', '0.037533', '0.033301', '0.032219']
         : correct/total = [(126, 4128), (146, 4203), (102, 4081), (210, 4333), (173, 4091), (206, 4287), (206, 4193), (223, 4349), (144, 4191), (168, 4277), (209, 4143), (259, 4193), (138, 4093), (120, 4197), (153, 4052), (130, 4029), (167, 4153), (157, 4183), (136, 4084), (133, 4128)]
         : compromised: 0.0383, honest: 0.0423
Round 006: test acc mean=0.0497 ± 0.0034 | min=0.0439 max=0.0561
         : test loss mean=40.5111 ± 61.4735
         : individual accs = ['0.049661', '0.050916', '0.056114', '0.046619', '0.052066', '0.045953', '0.043883', '0.053116', '0.054880', '0.044891', '0.047550', '0.054376', '0.052040', '0.046462', '0.045656', '0.050881', '0.049362', '0.048291', '0.050196', '0.050145']
         : correct/total = [(205, 4128), (214, 4203), (229, 4081), (202, 4333), (213, 4091), (197, 4287), (184, 4193), (231, 4349), (230, 4191), (192, 4277), (197, 4143), (228, 4193), (213, 4093), (195, 4197), (185, 4052), (205, 4029), (205, 4153), (202, 4183), (205, 4084), (207, 4128)]
         : compromised: 0.0497, honest: 0.0494
Round 007: test acc mean=0.0528 ± 0.0098 | min=0.0241 max=0.0612
         : test loss mean=4.2225 ± 0.2193
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.025292', '0.053776', '0.055998', '0.053899', '0.058637', '0.024065', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (106, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (101, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0509, honest: 0.0573
Round 008: test acc mean=0.0528 ± 0.0098 | min=0.0241 max=0.0612
         : test loss mean=4.1528 ± 0.1196
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.025292', '0.053776', '0.055998', '0.053899', '0.058637', '0.024065', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (106, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (101, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0509, honest: 0.0573
Round 009: test acc mean=0.0528 ± 0.0098 | min=0.0241 max=0.0612
         : test loss mean=4.1646 ± 0.2394
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.025292', '0.053776', '0.055998', '0.053899', '0.058637', '0.024065', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (106, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (101, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0509, honest: 0.0573
Round 010: test acc mean=0.0548 ± 0.0039 | min=0.0457 max=0.0612
         : test loss mean=4.0980 ± 0.1295
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.048414', '0.058174', '0.051539', '0.053776', '0.055998', '0.053899', '0.058637', '0.045747', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (203, 4193), (253, 4349), (216, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (192, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0537, honest: 0.0573

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: directed_deviation, 70.0% compromised
Final accuracy - Compromised: 0.0537, Honest: 0.0573
Overall test accuracy: mean=0.0548 ± 0.0039
