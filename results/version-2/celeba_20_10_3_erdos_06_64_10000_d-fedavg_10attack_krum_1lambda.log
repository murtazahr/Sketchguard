Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: krum, lambda: 1.0
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.4980 ± 0.0224 | min=0.4524 max=0.5634
         : test loss mean=11.5313 ± 18.8604
         : individual accs = ['0.481579', '0.479275', '0.503993', '0.495682', '0.500882', '0.494323', '0.452402', '0.487134', '0.563380', '0.492908', '0.490385', '0.476444', '0.503472', '0.514655', '0.489324', '0.510917', '0.476603', '0.502210', '0.528954', '0.516214']
         : correct/total = [(549, 1140), (555, 1158), (568, 1127), (574, 1158), (568, 1134), (566, 1145), (518, 1145), (549, 1127), (640, 1136), (556, 1128), (561, 1144), (536, 1125), (580, 1152), (597, 1160), (550, 1124), (585, 1145), (550, 1154), (568, 1131), (612, 1157), (589, 1141)]
         : compromised: 0.5045, honest: 0.4973
Round 002: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=32.1052 ± 34.4982
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5107, honest: 0.5170
Round 003: test acc mean=0.5148 ± 0.0192 | min=0.4891 max=0.5599
         : test loss mean=0.6980 ± 0.0197
         : individual accs = ['0.521930', '0.493955', '0.527950', '0.525907', '0.499118', '0.514410', '0.524017', '0.559894', '0.536972', '0.492908', '0.529720', '0.547556', '0.492188', '0.511207', '0.491993', '0.489083', '0.500867', '0.507515', '0.512532', '0.516214']
         : correct/total = [(595, 1140), (572, 1158), (595, 1127), (609, 1158), (566, 1134), (589, 1145), (600, 1145), (631, 1127), (610, 1136), (556, 1128), (606, 1144), (616, 1125), (567, 1152), (593, 1160), (553, 1124), (560, 1145), (578, 1154), (574, 1131), (593, 1157), (589, 1141)]
         : compromised: 0.5128, honest: 0.5150
Round 004: test acc mean=0.6337 ± 0.0346 | min=0.5466 max=0.6805
         : test loss mean=1.1271 ± 1.2341
         : individual accs = ['0.621930', '0.680484', '0.546584', '0.658031', '0.677249', '0.624454', '0.605240', '0.672582', '0.583627', '0.662234', '0.680070', '0.600000', '0.629340', '0.602586', '0.622776', '0.664629', '0.654246', '0.633952', '0.628349', '0.625767']
         : correct/total = [(709, 1140), (788, 1158), (616, 1127), (762, 1158), (768, 1134), (715, 1145), (693, 1145), (758, 1127), (663, 1136), (747, 1128), (778, 1144), (675, 1125), (725, 1152), (699, 1160), (700, 1124), (761, 1145), (755, 1154), (717, 1131), (727, 1157), (714, 1141)]
         : compromised: 0.6135, honest: 0.6359
Round 005: test acc mean=0.5452 ± 0.0328 | min=0.4982 max=0.6053
         : test loss mean=0.6895 ± 0.0181
         : individual accs = ['0.547368', '0.510363', '0.591837', '0.526770', '0.522046', '0.589520', '0.579913', '0.515528', '0.568662', '0.498227', '0.532343', '0.605333', '0.519965', '0.593103', '0.575623', '0.514410', '0.515598', '0.518126', '0.531547', '0.546889']
         : correct/total = [(624, 1140), (591, 1158), (667, 1127), (610, 1158), (592, 1134), (675, 1145), (664, 1145), (581, 1127), (646, 1136), (562, 1128), (609, 1144), (681, 1125), (599, 1152), (688, 1160), (647, 1124), (589, 1145), (595, 1154), (586, 1131), (615, 1157), (624, 1141)]
         : compromised: 0.5913, honest: 0.5400
Round 006: test acc mean=0.7350 ± 0.0325 | min=0.6720 max=0.7763
         : test loss mean=0.8933 ± 0.8474
         : individual accs = ['0.769298', '0.749568', '0.703638', '0.776339', '0.753968', '0.774672', '0.738865', '0.678793', '0.686620', '0.671986', '0.751748', '0.763556', '0.691840', '0.729310', '0.763345', '0.750218', '0.705373', '0.735632', '0.757131', '0.748466']
         : correct/total = [(877, 1140), (868, 1158), (793, 1127), (899, 1158), (855, 1134), (887, 1145), (846, 1145), (765, 1127), (780, 1136), (758, 1128), (860, 1144), (859, 1125), (797, 1152), (846, 1160), (858, 1124), (859, 1145), (814, 1154), (832, 1131), (876, 1157), (854, 1141)]
         : compromised: 0.7520, honest: 0.7331
Round 007: test acc mean=0.6363 ± 0.0496 | min=0.5613 max=0.7048
         : test loss mean=0.6448 ± 0.0583
         : individual accs = ['0.687719', '0.561313', '0.636202', '0.691710', '0.584656', '0.704803', '0.652402', '0.595386', '0.601232', '0.578901', '0.673077', '0.645333', '0.577257', '0.643966', '0.679715', '0.575546', '0.567591', '0.699381', '0.674157', '0.695004']
         : correct/total = [(784, 1140), (650, 1158), (717, 1127), (801, 1158), (663, 1134), (807, 1145), (747, 1145), (671, 1127), (683, 1136), (653, 1128), (770, 1144), (726, 1125), (665, 1152), (747, 1160), (764, 1124), (659, 1145), (655, 1154), (791, 1131), (780, 1157), (793, 1141)]
         : compromised: 0.6744, honest: 0.6320
Round 008: test acc mean=0.8088 ± 0.0262 | min=0.7254 max=0.8402
         : test loss mean=0.7736 ± 0.7698
         : individual accs = ['0.826316', '0.840242', '0.760426', '0.835060', '0.827160', '0.826201', '0.798253', '0.817214', '0.725352', '0.796986', '0.819056', '0.800889', '0.799479', '0.790517', '0.814947', '0.813100', '0.818024', '0.821397', '0.813310', '0.832603']
         : correct/total = [(942, 1140), (973, 1158), (857, 1127), (967, 1158), (938, 1134), (946, 1145), (914, 1145), (921, 1127), (824, 1136), (899, 1128), (937, 1144), (901, 1125), (921, 1152), (917, 1160), (916, 1124), (931, 1145), (944, 1154), (929, 1131), (941, 1157), (950, 1141)]
         : compromised: 0.8084, honest: 0.8089
Round 009: test acc mean=0.7579 ± 0.0514 | min=0.6426 max=0.8479
         : test loss mean=0.5348 ± 0.1051
         : individual accs = ['0.730702', '0.823834', '0.682343', '0.799655', '0.802469', '0.744978', '0.702183', '0.788820', '0.642606', '0.788121', '0.847902', '0.712000', '0.788194', '0.695690', '0.729537', '0.792140', '0.772964', '0.800177', '0.735523', '0.779141']
         : correct/total = [(833, 1140), (954, 1158), (769, 1127), (926, 1158), (910, 1134), (853, 1145), (804, 1145), (889, 1127), (730, 1136), (889, 1128), (970, 1144), (801, 1125), (908, 1152), (807, 1160), (820, 1124), (907, 1145), (892, 1154), (905, 1131), (851, 1157), (889, 1141)]
         : compromised: 0.7203, honest: 0.7621
Round 010: test acc mean=0.8318 ± 0.0226 | min=0.7562 max=0.8571
         : test loss mean=0.6280 ± 0.5785
         : individual accs = ['0.848246', '0.853195', '0.793256', '0.853195', '0.843034', '0.849782', '0.820087', '0.834073', '0.756162', '0.819149', '0.836538', '0.830222', '0.835069', '0.825000', '0.847865', '0.826201', '0.840555', '0.835544', '0.832325', '0.857143']
         : correct/total = [(967, 1140), (988, 1158), (894, 1127), (988, 1158), (956, 1134), (973, 1145), (939, 1145), (940, 1127), (859, 1136), (924, 1128), (957, 1144), (934, 1125), (962, 1152), (957, 1160), (953, 1124), (946, 1145), (970, 1154), (945, 1131), (963, 1157), (978, 1141)]
         : compromised: 0.8374, honest: 0.8312

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: krum, 10.0% compromised
Final accuracy - Compromised: 0.8374, Honest: 0.8312
Overall test accuracy: mean=0.8318 ± 0.0226
