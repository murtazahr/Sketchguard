Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0549 ± 0.0107 | min=0.0417 max=0.0857
         : test loss mean=3.6899 ± 0.0174
         : individual accs = ['0.045785', '0.052344', '0.050723', '0.052850', '0.051088', '0.050618', '0.042213', '0.058174', '0.085660', '0.074117', '0.050447', '0.071309', '0.058637', '0.047177', '0.046644', '0.041698', '0.058271', '0.050203', '0.055583', '0.054506']
         : correct/total = [(189, 4128), (220, 4203), (207, 4081), (229, 4333), (209, 4091), (217, 4287), (177, 4193), (253, 4349), (359, 4191), (317, 4277), (209, 4143), (299, 4193), (240, 4093), (198, 4197), (189, 4052), (168, 4029), (242, 4153), (210, 4183), (227, 4084), (225, 4128)]
         : compromised: 0.0489, honest: 0.0556
Round 002: test acc mean=0.0602 ± 0.0166 | min=0.0446 max=0.1127
         : test loss mean=3.6838 ± 0.0154
         : individual accs = ['0.044574', '0.048775', '0.066895', '0.069005', '0.112686', '0.045253', '0.088242', '0.045068', '0.051062', '0.068506', '0.045619', '0.045314', '0.065233', '0.062902', '0.064413', '0.067014', '0.063569', '0.048291', '0.053379', '0.048450']
         : correct/total = [(184, 4128), (205, 4203), (273, 4081), (299, 4333), (461, 4091), (194, 4287), (370, 4193), (196, 4349), (214, 4191), (293, 4277), (189, 4143), (190, 4193), (267, 4093), (264, 4197), (261, 4052), (270, 4029), (264, 4153), (202, 4183), (218, 4084), (200, 4128)]
         : compromised: 0.0541, honest: 0.0609
Round 003: test acc mean=0.0559 ± 0.0118 | min=0.0432 max=0.0884
         : test loss mean=3.6789 ± 0.0163
         : individual accs = ['0.050145', '0.049726', '0.057829', '0.043157', '0.074798', '0.088407', '0.057000', '0.051276', '0.058936', '0.082301', '0.050447', '0.049606', '0.050574', '0.049083', '0.048124', '0.050633', '0.058753', '0.050203', '0.052889', '0.044331']
         : correct/total = [(207, 4128), (209, 4203), (236, 4081), (187, 4333), (306, 4091), (379, 4287), (239, 4193), (223, 4349), (247, 4191), (352, 4277), (209, 4143), (208, 4193), (207, 4093), (206, 4197), (195, 4052), (204, 4029), (244, 4153), (210, 4183), (216, 4084), (183, 4128)]
         : compromised: 0.0687, honest: 0.0545
Round 004: test acc mean=0.0820 ± 0.0302 | min=0.0451 max=0.1261
         : test loss mean=3.6717 ± 0.0160
         : individual accs = ['0.059593', '0.047109', '0.057584', '0.114009', '0.069910', '0.045253', '0.110422', '0.045068', '0.116679', '0.119710', '0.099203', '0.063678', '0.054239', '0.115797', '0.052567', '0.126086', '0.124488', '0.098733', '0.070519', '0.048934']
         : correct/total = [(246, 4128), (198, 4203), (235, 4081), (494, 4333), (286, 4091), (194, 4287), (463, 4193), (196, 4349), (489, 4191), (512, 4277), (411, 4143), (267, 4193), (222, 4093), (486, 4197), (213, 4052), (508, 4029), (517, 4153), (413, 4183), (288, 4084), (202, 4128)]
         : compromised: 0.0805, honest: 0.0821
Round 005: test acc mean=0.0974 ± 0.0407 | min=0.0434 max=0.1721
         : test loss mean=3.6639 ± 0.0162
         : individual accs = ['0.129360', '0.123245', '0.071306', '0.062543', '0.114642', '0.043387', '0.054138', '0.047827', '0.162014', '0.064765', '0.172098', '0.067255', '0.050086', '0.084108', '0.096249', '0.088856', '0.081628', '0.161367', '0.123408', '0.149467']
         : correct/total = [(534, 4128), (518, 4203), (291, 4081), (271, 4333), (469, 4091), (186, 4287), (227, 4193), (208, 4349), (679, 4191), (277, 4277), (713, 4143), (282, 4193), (205, 4093), (353, 4197), (390, 4052), (358, 4029), (339, 4153), (675, 4183), (504, 4084), (617, 4128)]
         : compromised: 0.0637, honest: 0.1011
Round 006: test acc mean=0.1090 ± 0.0424 | min=0.0446 max=0.1646
         : test loss mean=3.6483 ± 0.0161
         : individual accs = ['0.044574', '0.148703', '0.048272', '0.086314', '0.112198', '0.101703', '0.146912', '0.114049', '0.164639', '0.149638', '0.060101', '0.161698', '0.064012', '0.065761', '0.151283', '0.155870', '0.158199', '0.059766', '0.119980', '0.066618']
         : correct/total = [(184, 4128), (625, 4203), (197, 4081), (374, 4333), (459, 4091), (436, 4287), (616, 4193), (496, 4349), (690, 4191), (640, 4277), (249, 4143), (678, 4193), (262, 4093), (276, 4197), (613, 4052), (628, 4029), (657, 4153), (250, 4183), (490, 4084), (275, 4128)]
         : compromised: 0.0837, honest: 0.1118
Round 007: test acc mean=0.1329 ± 0.0478 | min=0.0582 max=0.2176
         : test loss mean=3.6203 ± 0.0183
         : individual accs = ['0.210514', '0.093505', '0.217594', '0.159935', '0.058176', '0.067180', '0.154305', '0.074040', '0.207826', '0.126724', '0.137581', '0.136418', '0.160274', '0.158447', '0.117720', '0.093572', '0.177221', '0.133636', '0.060970', '0.111676']
         : correct/total = [(869, 4128), (393, 4203), (888, 4081), (693, 4333), (238, 4091), (288, 4287), (647, 4193), (322, 4349), (871, 4191), (542, 4277), (570, 4143), (572, 4193), (656, 4093), (665, 4197), (477, 4052), (377, 4029), (736, 4153), (559, 4183), (249, 4084), (461, 4128)]
         : compromised: 0.1128, honest: 0.1351
Round 008: test acc mean=0.1764 ± 0.0411 | min=0.0930 max=0.2353
         : test loss mean=3.5581 ± 0.0334
         : individual accs = ['0.141715', '0.190340', '0.218329', '0.094161', '0.221217', '0.192676', '0.202957', '0.197287', '0.131472', '0.158990', '0.202269', '0.093012', '0.215490', '0.143198', '0.148075', '0.226855', '0.195040', '0.152044', '0.235309', '0.168120']
         : correct/total = [(585, 4128), (800, 4203), (891, 4081), (408, 4333), (905, 4091), (826, 4287), (851, 4193), (858, 4349), (551, 4191), (680, 4277), (838, 4143), (390, 4193), (882, 4093), (601, 4197), (600, 4052), (914, 4029), (810, 4153), (636, 4183), (961, 4084), (694, 4128)]
         : compromised: 0.1679, honest: 0.1774
Round 009: test acc mean=0.2262 ± 0.0216 | min=0.1894 max=0.2728
         : test loss mean=3.4127 ± 0.0469
         : individual accs = ['0.215843', '0.229122', '0.248469', '0.238634', '0.233439', '0.210404', '0.206535', '0.209933', '0.244333', '0.238485', '0.200821', '0.248032', '0.218422', '0.272814', '0.224334', '0.221147', '0.208765', '0.201291', '0.264202', '0.189438']
         : correct/total = [(891, 4128), (963, 4203), (1014, 4081), (1034, 4333), (955, 4091), (902, 4287), (866, 4193), (913, 4349), (1024, 4191), (1020, 4277), (832, 4143), (1040, 4193), (894, 4093), (1145, 4197), (909, 4052), (891, 4029), (867, 4153), (842, 4183), (1079, 4084), (782, 4128)]
         : compromised: 0.2416, honest: 0.2245
Round 010: test acc mean=0.2890 ± 0.0238 | min=0.2358 max=0.3384
         : test loss mean=3.0936 ± 0.0366
         : individual accs = ['0.291182', '0.303355', '0.338397', '0.276714', '0.289905', '0.287614', '0.288099', '0.302138', '0.267239', '0.317980', '0.235819', '0.247078', '0.304667', '0.303550', '0.273939', '0.314718', '0.301228', '0.288788', '0.289422', '0.258479']
         : correct/total = [(1202, 4128), (1275, 4203), (1381, 4081), (1199, 4333), (1186, 4091), (1233, 4287), (1208, 4193), (1314, 4349), (1120, 4191), (1360, 4277), (977, 4143), (1036, 4193), (1247, 4093), (1274, 4197), (1110, 4052), (1268, 4029), (1251, 4153), (1208, 4183), (1182, 4084), (1067, 4128)]
         : compromised: 0.2956, honest: 0.2883

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 10.0% compromised
Final accuracy - Compromised: 0.2956, Honest: 0.2883
Overall test accuracy: mean=0.2890 ± 0.0238
