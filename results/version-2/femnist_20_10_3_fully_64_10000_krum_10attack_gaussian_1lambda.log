Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0514 ± 0.0034 | min=0.0469 max=0.0618
         : test loss mean=3.6915 ± 0.0176
         : individual accs = ['0.051599', '0.051630', '0.050723', '0.048465', '0.051088', '0.048052', '0.049130', '0.051276', '0.047960', '0.053075', '0.050447', '0.061770', '0.053750', '0.046938', '0.048124', '0.056342', '0.055141', '0.050203', '0.052889', '0.048450']
         : correct/total = [(213, 4128), (217, 4203), (207, 4081), (210, 4333), (209, 4091), (206, 4287), (206, 4193), (223, 4349), (201, 4191), (227, 4277), (209, 4143), (259, 4193), (220, 4093), (197, 4197), (195, 4052), (227, 4029), (229, 4153), (210, 4183), (216, 4084), (200, 4128)]
         : compromised: 0.0475, honest: 0.0518
Round 002: test acc mean=0.0835 ± 0.0039 | min=0.0748 max=0.0923
         : test loss mean=3.6807 ± 0.0180
         : individual accs = ['0.085029', '0.085891', '0.085518', '0.074775', '0.085065', '0.088407', '0.082280', '0.081858', '0.078502', '0.082768', '0.080618', '0.078941', '0.085268', '0.081249', '0.086871', '0.092331', '0.081387', '0.081999', '0.088639', '0.081880']
         : correct/total = [(351, 4128), (361, 4203), (349, 4081), (324, 4333), (348, 4091), (379, 4287), (345, 4193), (356, 4349), (329, 4191), (354, 4277), (334, 4143), (331, 4193), (349, 4093), (341, 4197), (352, 4052), (372, 4029), (338, 4153), (343, 4183), (362, 4084), (338, 4128)]
         : compromised: 0.0848, honest: 0.0833
Round 003: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.6751 ± 0.0163
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0561
Round 004: test acc mean=0.0519 ± 0.0037 | min=0.0469 max=0.0637
         : test loss mean=3.6672 ± 0.0173
         : individual accs = ['0.052326', '0.052106', '0.051458', '0.049158', '0.051577', '0.048519', '0.049368', '0.051506', '0.048676', '0.053542', '0.050929', '0.063678', '0.054728', '0.046938', '0.048865', '0.056590', '0.055863', '0.050681', '0.053624', '0.048692']
         : correct/total = [(216, 4128), (219, 4203), (210, 4081), (213, 4333), (211, 4091), (208, 4287), (207, 4193), (224, 4349), (204, 4191), (229, 4277), (211, 4143), (267, 4193), (224, 4093), (197, 4197), (198, 4052), (228, 4029), (232, 4153), (212, 4183), (219, 4084), (201, 4128)]
         : compromised: 0.0477, honest: 0.0524
Round 005: test acc mean=0.0673 ± 0.0036 | min=0.0616 max=0.0755
         : test loss mean=3.6579 ± 0.0168
         : individual accs = ['0.068798', '0.063526', '0.072286', '0.061620', '0.065265', '0.062515', '0.066539', '0.067832', '0.065378', '0.063596', '0.067825', '0.065824', '0.071586', '0.071480', '0.075518', '0.068752', '0.069829', '0.063352', '0.069785', '0.063953']
         : correct/total = [(284, 4128), (267, 4203), (295, 4081), (267, 4333), (267, 4091), (268, 4287), (279, 4193), (295, 4349), (274, 4191), (272, 4277), (281, 4143), (276, 4193), (293, 4093), (300, 4197), (306, 4052), (277, 4029), (290, 4153), (265, 4183), (285, 4084), (264, 4128)]
         : compromised: 0.0670, honest: 0.0673
Round 006: test acc mean=0.0992 ± 0.0042 | min=0.0903 max=0.1083
         : test loss mean=3.6399 ± 0.0191
         : individual accs = ['0.100048', '0.090887', '0.098995', '0.097392', '0.097776', '0.092839', '0.098736', '0.097724', '0.102362', '0.099369', '0.090273', '0.098974', '0.099438', '0.102216', '0.108342', '0.104989', '0.103299', '0.099211', '0.100637', '0.100533']
         : correct/total = [(413, 4128), (382, 4203), (404, 4081), (422, 4333), (400, 4091), (398, 4287), (414, 4193), (425, 4349), (429, 4191), (425, 4277), (374, 4143), (415, 4193), (407, 4093), (429, 4197), (439, 4052), (423, 4029), (429, 4153), (415, 4183), (411, 4084), (415, 4128)]
         : compromised: 0.0975, honest: 0.0994
Round 007: test acc mean=0.1953 ± 0.0084 | min=0.1806 max=0.2154
         : test loss mean=3.5971 ± 0.0185
         : individual accs = ['0.198159', '0.194385', '0.215388', '0.180706', '0.192374', '0.193609', '0.189363', '0.196137', '0.180625', '0.189853', '0.194545', '0.202719', '0.202541', '0.192995', '0.204097', '0.203524', '0.199615', '0.187664', '0.202253', '0.184835']
         : correct/total = [(818, 4128), (817, 4203), (879, 4081), (783, 4333), (787, 4091), (830, 4287), (794, 4193), (853, 4349), (757, 4191), (812, 4277), (806, 4143), (850, 4193), (829, 4093), (810, 4197), (827, 4052), (820, 4029), (829, 4153), (785, 4183), (826, 4084), (763, 4128)]
         : compromised: 0.1933, honest: 0.1955
Round 008: test acc mean=0.1918 ± 0.0081 | min=0.1786 max=0.2061
         : test loss mean=3.5060 ± 0.0195
         : individual accs = ['0.193314', '0.189151', '0.206077', '0.178629', '0.196773', '0.188010', '0.186740', '0.191998', '0.181818', '0.180500', '0.184890', '0.199141', '0.199120', '0.190851', '0.202369', '0.203028', '0.197688', '0.185274', '0.199314', '0.181444']
         : correct/total = [(798, 4128), (795, 4203), (841, 4081), (774, 4333), (805, 4091), (806, 4287), (783, 4193), (835, 4349), (762, 4191), (772, 4277), (766, 4143), (835, 4193), (815, 4093), (801, 4197), (820, 4052), (818, 4029), (821, 4153), (775, 4183), (814, 4084), (749, 4128)]
         : compromised: 0.1894, honest: 0.1921
Round 009: test acc mean=0.2733 ± 0.0111 | min=0.2492 max=0.2928
         : test loss mean=3.2601 ± 0.0246
         : individual accs = ['0.286095', '0.273852', '0.292820', '0.249250', '0.285260', '0.270585', '0.262104', '0.273856', '0.258411', '0.261866', '0.266956', '0.278083', '0.282678', '0.275911', '0.280355', '0.287913', '0.276427', '0.263208', '0.279138', '0.261870']
         : correct/total = [(1181, 4128), (1151, 4203), (1195, 4081), (1080, 4333), (1167, 4091), (1160, 4287), (1099, 4193), (1191, 4349), (1083, 4191), (1120, 4277), (1106, 4143), (1166, 4193), (1157, 4093), (1158, 4197), (1136, 4052), (1160, 4029), (1148, 4153), (1101, 4183), (1140, 4084), (1081, 4128)]
         : compromised: 0.2732, honest: 0.2733
Round 010: test acc mean=0.3467 ± 0.0126 | min=0.3157 max=0.3666
         : test loss mean=2.8565 ± 0.0278
         : individual accs = ['0.356105', '0.341899', '0.366577', '0.315717', '0.362747', '0.352927', '0.331982', '0.346287', '0.336674', '0.330606', '0.341540', '0.351777', '0.356462', '0.346914', '0.364511', '0.356416', '0.346978', '0.339230', '0.354065', '0.334060']
         : correct/total = [(1470, 4128), (1437, 4203), (1496, 4081), (1368, 4333), (1484, 4091), (1513, 4287), (1392, 4193), (1506, 4349), (1411, 4191), (1414, 4277), (1415, 4143), (1475, 4193), (1459, 4093), (1456, 4197), (1477, 4052), (1436, 4029), (1441, 4153), (1419, 4183), (1446, 4084), (1379, 4128)]
         : compromised: 0.3499, honest: 0.3463

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: krum
Attack: gaussian, 10.0% compromised
Final accuracy - Compromised: 0.3499, Honest: 0.3463
Overall test accuracy: mean=0.3467 ± 0.0126
