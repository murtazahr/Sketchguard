Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0587 ± 0.0097 | min=0.0469 max=0.0857
         : test loss mean=3.6886 ± 0.0167
         : individual accs = ['0.059593', '0.052344', '0.050723', '0.052850', '0.074554', '0.068813', '0.057000', '0.058174', '0.085660', '0.074117', '0.050447', '0.061770', '0.058637', '0.046938', '0.048124', '0.056342', '0.058271', '0.050203', '0.055583', '0.054506']
         : correct/total = [(246, 4128), (220, 4203), (207, 4081), (229, 4333), (305, 4091), (295, 4287), (239, 4193), (253, 4349), (359, 4191), (317, 4277), (209, 4143), (259, 4193), (240, 4093), (197, 4197), (195, 4052), (227, 4029), (242, 4153), (210, 4183), (227, 4084), (225, 4128)]
         : compromised: 0.0561, honest: 0.0594
Round 002: test acc mean=0.0557 ± 0.0168 | min=0.0453 max=0.1230
         : test loss mean=3.6837 ± 0.0167
         : individual accs = ['0.049176', '0.048775', '0.123009', '0.052850', '0.057932', '0.050618', '0.057000', '0.049207', '0.051062', '0.047697', '0.047309', '0.045314', '0.049841', '0.076483', '0.046890', '0.056342', '0.054418', '0.048291', '0.053379', '0.048450']
         : correct/total = [(203, 4128), (205, 4203), (502, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (214, 4349), (214, 4191), (204, 4277), (196, 4143), (190, 4193), (204, 4093), (321, 4197), (190, 4052), (227, 4029), (226, 4153), (202, 4183), (218, 4084), (200, 4128)]
         : compromised: 0.0563, honest: 0.0556
Round 003: test acc mean=0.0551 ± 0.0081 | min=0.0441 max=0.0676
         : test loss mean=3.6758 ± 0.0169
         : individual accs = ['0.066860', '0.052344', '0.067630', '0.044080', '0.059888', '0.046419', '0.044598', '0.058174', '0.058936', '0.044657', '0.049964', '0.063916', '0.062301', '0.050274', '0.048124', '0.064036', '0.065736', '0.053311', '0.055583', '0.044331']
         : correct/total = [(276, 4128), (220, 4203), (276, 4081), (191, 4333), (245, 4091), (199, 4287), (187, 4193), (253, 4349), (247, 4191), (191, 4277), (207, 4143), (268, 4193), (255, 4093), (211, 4197), (195, 4052), (258, 4029), (273, 4153), (223, 4183), (227, 4084), (183, 4128)]
         : compromised: 0.0531, honest: 0.0556
Round 004: test acc mean=0.0730 ± 0.0263 | min=0.0502 max=0.1249
         : test loss mean=3.6664 ± 0.0170
         : individual accs = ['0.060078', '0.050202', '0.122519', '0.057466', '0.124908', '0.096571', '0.062485', '0.052886', '0.116679', '0.059154', '0.063239', '0.059623', '0.059125', '0.066953', '0.060217', '0.124845', '0.058512', '0.051399', '0.054114', '0.058382']
         : correct/total = [(248, 4128), (211, 4203), (500, 4081), (249, 4333), (511, 4091), (414, 4287), (262, 4193), (230, 4349), (489, 4191), (253, 4277), (262, 4143), (250, 4193), (242, 4093), (281, 4197), (244, 4052), (503, 4029), (243, 4153), (215, 4183), (221, 4084), (241, 4128)]
         : compromised: 0.0685, honest: 0.0741
Round 005: test acc mean=0.1017 ± 0.0402 | min=0.0434 max=0.1624
         : test loss mean=3.6573 ± 0.0170
         : individual accs = ['0.085271', '0.124673', '0.057829', '0.074313', '0.057932', '0.043387', '0.162414', '0.136813', '0.162014', '0.075520', '0.057205', '0.074171', '0.128756', '0.133905', '0.119941', '0.134276', '0.058512', '0.053072', '0.141773', '0.152374']
         : correct/total = [(352, 4128), (524, 4203), (236, 4081), (322, 4333), (237, 4091), (186, 4287), (681, 4193), (595, 4349), (679, 4191), (323, 4277), (237, 4143), (311, 4193), (527, 4093), (562, 4197), (486, 4052), (541, 4029), (243, 4153), (222, 4183), (579, 4084), (629, 4128)]
         : compromised: 0.0898, honest: 0.1047
Round 006: test acc mean=0.1140 ± 0.0375 | min=0.0600 max=0.1871
         : test loss mean=3.6392 ± 0.0189
         : individual accs = ['0.112403', '0.079467', '0.088214', '0.114932', '0.180885', '0.122230', '0.082518', '0.060934', '0.164639', '0.127893', '0.060825', '0.142619', '0.123870', '0.127949', '0.092300', '0.133035', '0.187094', '0.060005', '0.140548', '0.076793']
         : correct/total = [(464, 4128), (334, 4203), (360, 4081), (498, 4333), (740, 4091), (524, 4287), (346, 4193), (265, 4349), (690, 4191), (547, 4277), (252, 4143), (598, 4193), (507, 4093), (537, 4197), (374, 4052), (536, 4029), (777, 4153), (251, 4183), (574, 4084), (317, 4128)]
         : compromised: 0.1085, honest: 0.1153
Round 007: test acc mean=0.1791 ± 0.0397 | min=0.1064 max=0.2546
         : test loss mean=3.6008 ± 0.0178
         : individual accs = ['0.202035', '0.179396', '0.254594', '0.125317', '0.170374', '0.184278', '0.175769', '0.183490', '0.236698', '0.128127', '0.106445', '0.213212', '0.134376', '0.228735', '0.194719', '0.131546', '0.195521', '0.180253', '0.215230', '0.141231']
         : correct/total = [(834, 4128), (754, 4203), (1039, 4081), (543, 4333), (697, 4091), (790, 4287), (737, 4193), (798, 4349), (992, 4191), (548, 4277), (441, 4143), (894, 4193), (550, 4093), (960, 4197), (789, 4052), (530, 4029), (812, 4153), (754, 4183), (879, 4084), (583, 4128)]
         : compromised: 0.1819, honest: 0.1784
Round 008: test acc mean=0.2108 ± 0.0231 | min=0.1711 max=0.2486
         : test loss mean=3.5051 ± 0.0208
         : individual accs = ['0.187016', '0.248632', '0.245773', '0.175860', '0.216084', '0.211103', '0.240401', '0.211543', '0.171081', '0.184007', '0.210717', '0.197949', '0.221109', '0.208482', '0.208292', '0.227848', '0.242716', '0.230218', '0.183643', '0.192829']
         : correct/total = [(772, 4128), (1045, 4203), (1003, 4081), (762, 4333), (884, 4091), (905, 4287), (1008, 4193), (920, 4349), (717, 4191), (787, 4277), (873, 4143), (830, 4193), (905, 4093), (875, 4197), (844, 4052), (918, 4029), (1008, 4153), (963, 4183), (750, 4084), (796, 4128)]
         : compromised: 0.2177, honest: 0.2090
Round 009: test acc mean=0.2780 ± 0.0285 | min=0.2278 max=0.3280
         : test loss mean=3.2430 ± 0.0307
         : individual accs = ['0.328004', '0.279800', '0.299681', '0.243249', '0.287216', '0.272452', '0.267827', '0.232927', '0.309711', '0.253682', '0.232682', '0.279275', '0.303934', '0.276864', '0.287759', '0.288409', '0.298579', '0.227827', '0.325171', '0.265262']
         : correct/total = [(1354, 4128), (1176, 4203), (1223, 4081), (1054, 4333), (1175, 4091), (1168, 4287), (1123, 4193), (1013, 4349), (1298, 4191), (1085, 4277), (964, 4143), (1171, 4193), (1244, 4093), (1162, 4197), (1166, 4052), (1162, 4029), (1240, 4153), (953, 4183), (1328, 4084), (1095, 4128)]
         : compromised: 0.2703, honest: 0.2800
Round 010: test acc mean=0.3373 ± 0.0160 | min=0.3041 max=0.3699
         : test loss mean=2.8532 ± 0.0361
         : individual accs = ['0.350048', '0.338330', '0.326881', '0.325640', '0.349303', '0.344297', '0.304078', '0.334330', '0.319256', '0.338789', '0.339850', '0.330312', '0.356218', '0.349774', '0.369941', '0.358650', '0.312064', '0.334688', '0.344270', '0.319525']
         : correct/total = [(1445, 4128), (1422, 4203), (1334, 4081), (1411, 4333), (1429, 4091), (1476, 4287), (1275, 4193), (1454, 4349), (1338, 4191), (1449, 4277), (1408, 4143), (1385, 4193), (1458, 4093), (1468, 4197), (1499, 4052), (1445, 4029), (1296, 4153), (1400, 4183), (1406, 4084), (1319, 4128)]
         : compromised: 0.3462, honest: 0.3351

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 20.0% compromised
Final accuracy - Compromised: 0.3462, Honest: 0.3351
Overall test accuracy: mean=0.3373 ± 0.0160
