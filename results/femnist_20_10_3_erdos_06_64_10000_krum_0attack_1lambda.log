Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5439 ± 0.0129 | min=0.5241 max=0.5654
         : test loss mean=1.7343 ± 0.0516
         : individual accs = ['0.538275', '0.564121', '0.546190', '0.555504', '0.524077', '0.554934', '0.539232', '0.539204', '0.540205', '0.540566', '0.525706', '0.547579', '0.549230', '0.539909', '0.565400', '0.531646', '0.526848', '0.558929', '0.563173', '0.527616']
         : correct/total = [(2222, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2144, 4091), (2379, 4287), (2261, 4193), (2345, 4349), (2264, 4191), (2312, 4277), (2178, 4143), (2296, 4193), (2248, 4093), (2266, 4197), (2291, 4052), (2142, 4029), (2188, 4153), (2338, 4183), (2300, 4084), (2178, 4128)]
Round 002: test acc mean=0.7318 ± 0.0103 | min=0.6985 max=0.7441
         : test loss mean=0.8975 ± 0.0295
         : individual accs = ['0.727713', '0.724483', '0.721882', '0.733903', '0.730384', '0.744110', '0.737420', '0.739020', '0.739919', '0.742810', '0.698528', '0.731696', '0.741510', '0.729807', '0.743583', '0.736163', '0.724296', '0.728186', '0.736778', '0.724322']
         : correct/total = [(3004, 4128), (3045, 4203), (2946, 4081), (3180, 4333), (2988, 4091), (3190, 4287), (3092, 4193), (3214, 4349), (3101, 4191), (3177, 4277), (2894, 4143), (3068, 4193), (3035, 4093), (3063, 4197), (3013, 4052), (2966, 4029), (3008, 4153), (3046, 4183), (3009, 4084), (2990, 4128)]
Round 003: test acc mean=0.7609 ± 0.0090 | min=0.7434 max=0.7790
         : test loss mean=0.7607 ± 0.0368
         : individual accs = ['0.750000', '0.778967', '0.743445', '0.766213', '0.752872', '0.761605', '0.768662', '0.754886', '0.768790', '0.766893', '0.753319', '0.752445', '0.762766', '0.761496', '0.777641', '0.759990', '0.753190', '0.767392', '0.764202', '0.754118']
         : correct/total = [(3096, 4128), (3274, 4203), (3034, 4081), (3320, 4333), (3080, 4091), (3265, 4287), (3223, 4193), (3283, 4349), (3222, 4191), (3280, 4277), (3121, 4143), (3155, 4193), (3122, 4093), (3196, 4197), (3151, 4052), (3062, 4029), (3128, 4153), (3210, 4183), (3121, 4084), (3113, 4128)]
Round 004: test acc mean=0.7961 ± 0.0068 | min=0.7806 max=0.8052
         : test loss mean=0.6344 ± 0.0244
         : individual accs = ['0.796027', '0.796574', '0.783877', '0.801523', '0.789049', '0.805225', '0.798474', '0.800184', '0.797423', '0.799860', '0.780594', '0.792034', '0.799902', '0.798189', '0.801579', '0.803922', '0.797737', '0.791537', '0.803869', '0.785126']
         : correct/total = [(3286, 4128), (3348, 4203), (3199, 4081), (3473, 4333), (3228, 4091), (3452, 4287), (3348, 4193), (3480, 4349), (3342, 4191), (3421, 4277), (3234, 4143), (3321, 4193), (3274, 4093), (3350, 4197), (3248, 4052), (3239, 4029), (3313, 4153), (3311, 4183), (3283, 4084), (3241, 4128)]
Round 005: test acc mean=0.8081 ± 0.0094 | min=0.7822 max=0.8232
         : test loss mean=0.5941 ± 0.0257
         : individual accs = ['0.801599', '0.815132', '0.810586', '0.809139', '0.798093', '0.812456', '0.815168', '0.811681', '0.823193', '0.816460', '0.797007', '0.797043', '0.806743', '0.815583', '0.807256', '0.807893', '0.807850', '0.804925', '0.822723', '0.782219']
         : correct/total = [(3309, 4128), (3426, 4203), (3308, 4081), (3506, 4333), (3265, 4091), (3483, 4287), (3418, 4193), (3530, 4349), (3450, 4191), (3492, 4277), (3302, 4143), (3342, 4193), (3302, 4093), (3423, 4197), (3271, 4052), (3255, 4029), (3355, 4153), (3367, 4183), (3360, 4084), (3229, 4128)]
Round 006: test acc mean=0.8120 ± 0.0074 | min=0.7976 max=0.8223
         : test loss mean=0.5793 ± 0.0191
         : individual accs = ['0.815165', '0.816560', '0.808380', '0.797600', '0.809826', '0.820854', '0.818269', '0.822258', '0.815080', '0.819733', '0.806903', '0.811114', '0.806010', '0.807005', '0.820336', '0.804666', '0.798700', '0.822137', '0.813418', '0.805475']
         : correct/total = [(3365, 4128), (3432, 4203), (3299, 4081), (3456, 4333), (3313, 4091), (3519, 4287), (3431, 4193), (3576, 4349), (3416, 4191), (3506, 4277), (3343, 4143), (3401, 4193), (3299, 4093), (3387, 4197), (3324, 4052), (3242, 4029), (3317, 4153), (3439, 4183), (3322, 4084), (3325, 4128)]
Round 007: test acc mean=0.8237 ± 0.0076 | min=0.8074 max=0.8368
         : test loss mean=0.5349 ± 0.0276
         : individual accs = ['0.824612', '0.836783', '0.822347', '0.826448', '0.814960', '0.821554', '0.835202', '0.832835', '0.822715', '0.830489', '0.807386', '0.818746', '0.814561', '0.824160', '0.822063', '0.823778', '0.825909', '0.816878', '0.835945', '0.816860']
         : correct/total = [(3404, 4128), (3517, 4203), (3356, 4081), (3581, 4333), (3334, 4091), (3522, 4287), (3502, 4193), (3622, 4349), (3448, 4191), (3552, 4277), (3345, 4143), (3433, 4193), (3334, 4093), (3459, 4197), (3331, 4052), (3319, 4029), (3430, 4153), (3417, 4183), (3414, 4084), (3372, 4128)]
Round 008: test acc mean=0.8193 ± 0.0083 | min=0.8089 max=0.8393
         : test loss mean=0.5463 ± 0.0280
         : individual accs = ['0.808866', '0.823222', '0.826268', '0.810985', '0.813982', '0.818055', '0.832817', '0.839273', '0.821284', '0.814823', '0.809800', '0.811352', '0.820425', '0.823922', '0.819842', '0.815587', '0.814110', '0.821181', '0.832027', '0.808866']
         : correct/total = [(3339, 4128), (3460, 4203), (3372, 4081), (3514, 4333), (3330, 4091), (3507, 4287), (3492, 4193), (3650, 4349), (3442, 4191), (3485, 4277), (3355, 4143), (3402, 4193), (3358, 4093), (3458, 4197), (3322, 4052), (3286, 4029), (3381, 4153), (3435, 4183), (3398, 4084), (3339, 4128)]
Round 009: test acc mean=0.8279 ± 0.0063 | min=0.8156 max=0.8382
         : test loss mean=0.5198 ± 0.0238
         : individual accs = ['0.823159', '0.838211', '0.825778', '0.832679', '0.818871', '0.827618', '0.834725', '0.832835', '0.834646', '0.828384', '0.823799', '0.827570', '0.826289', '0.830117', '0.825765', '0.831472', '0.816037', '0.838154', '0.827130', '0.815649']
         : correct/total = [(3398, 4128), (3523, 4203), (3370, 4081), (3608, 4333), (3350, 4091), (3548, 4287), (3500, 4193), (3622, 4349), (3498, 4191), (3543, 4277), (3413, 4143), (3470, 4193), (3382, 4093), (3484, 4197), (3346, 4052), (3350, 4029), (3389, 4153), (3506, 4183), (3378, 4084), (3367, 4128)]
Round 010: test acc mean=0.8225 ± 0.0092 | min=0.8110 max=0.8409
         : test loss mean=0.5250 ± 0.0266
         : individual accs = ['0.811047', '0.832976', '0.813771', '0.822756', '0.816182', '0.830651', '0.840925', '0.839963', '0.820568', '0.831892', '0.814144', '0.823754', '0.815783', '0.816059', '0.820829', '0.814346', '0.811221', '0.833373', '0.825416', '0.814196']
         : correct/total = [(3348, 4128), (3501, 4203), (3321, 4081), (3565, 4333), (3339, 4091), (3561, 4287), (3526, 4193), (3653, 4349), (3439, 4191), (3558, 4277), (3373, 4143), (3454, 4193), (3339, 4093), (3425, 4197), (3326, 4052), (3281, 4029), (3369, 4153), (3486, 4183), (3371, 4084), (3361, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Overall test accuracy: mean=0.8225 ± 0.0092
