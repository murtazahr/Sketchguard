Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.7144 ± 0.0269 | min=0.6560 max=0.7729
         : test loss mean=0.5860 ± 0.0378
         : individual accs = ['0.698246', '0.661485', '0.708075', '0.699482', '0.693122', '0.718777', '0.772926', '0.710736', '0.749120', '0.656028', '0.722028', '0.728889', '0.723958', '0.732759', '0.722420', '0.752838', '0.719237', '0.696729', '0.713051', '0.708151']
         : correct/total = [(796, 1140), (766, 1158), (798, 1127), (810, 1158), (786, 1134), (823, 1145), (885, 1145), (801, 1127), (851, 1136), (740, 1128), (826, 1144), (820, 1125), (834, 1152), (850, 1160), (812, 1124), (862, 1145), (830, 1154), (788, 1131), (825, 1157), (808, 1141)]
         : compromised: 0.7179, honest: 0.7129
Round 002: test acc mean=0.7814 ± 0.0613 | min=0.6316 max=0.8603
         : test loss mean=0.4666 ± 0.0943
         : individual accs = ['0.631579', '0.810881', '0.777285', '0.642487', '0.800705', '0.845415', '0.860262', '0.821650', '0.786972', '0.738475', '0.818182', '0.680889', '0.835938', '0.830172', '0.772242', '0.786900', '0.809359', '0.778073', '0.796889', '0.802805']
         : correct/total = [(720, 1140), (939, 1158), (876, 1127), (744, 1158), (908, 1134), (968, 1145), (985, 1145), (926, 1127), (894, 1136), (833, 1128), (936, 1144), (766, 1125), (963, 1152), (963, 1160), (868, 1124), (901, 1145), (934, 1154), (880, 1131), (922, 1157), (916, 1141)]
         : compromised: 0.8098, honest: 0.7692
Round 003: test acc mean=0.8067 ± 0.0516 | min=0.7087 max=0.8759
         : test loss mean=0.4175 ± 0.0889
         : individual accs = ['0.794737', '0.857513', '0.870453', '0.750432', '0.846561', '0.750218', '0.772052', '0.839397', '0.875000', '0.786348', '0.875874', '0.746667', '0.763889', '0.743103', '0.851423', '0.824454', '0.776430', '0.839965', '0.708729', '0.861525']
         : correct/total = [(906, 1140), (993, 1158), (981, 1127), (869, 1158), (960, 1134), (859, 1145), (884, 1145), (946, 1127), (994, 1136), (887, 1128), (1002, 1144), (840, 1125), (880, 1152), (862, 1160), (957, 1124), (944, 1145), (896, 1154), (950, 1131), (820, 1157), (983, 1141)]
         : compromised: 0.7762, honest: 0.8198
Round 004: test acc mean=0.8462 ± 0.0368 | min=0.7642 max=0.8891
         : test loss mean=0.3457 ± 0.0631
         : individual accs = ['0.780702', '0.829879', '0.882875', '0.818653', '0.880952', '0.889083', '0.819214', '0.881100', '0.874120', '0.859929', '0.886364', '0.836444', '0.812500', '0.823276', '0.764235', '0.864629', '0.876950', '0.854996', '0.804667', '0.882559']
         : correct/total = [(890, 1140), (961, 1158), (995, 1127), (948, 1158), (999, 1134), (1018, 1145), (938, 1145), (993, 1127), (993, 1136), (970, 1128), (1014, 1144), (941, 1125), (936, 1152), (955, 1160), (859, 1124), (990, 1145), (1012, 1154), (967, 1131), (931, 1157), (1007, 1141)]
         : compromised: 0.8248, honest: 0.8553
Round 005: test acc mean=0.8581 ± 0.0325 | min=0.7596 max=0.8995
         : test loss mean=0.3211 ± 0.0528
         : individual accs = ['0.759649', '0.835924', '0.873114', '0.873921', '0.840388', '0.834934', '0.858515', '0.890861', '0.857394', '0.866135', '0.886364', '0.863111', '0.881944', '0.827586', '0.891459', '0.849782', '0.899480', '0.870027', '0.811582', '0.889571']
         : correct/total = [(866, 1140), (968, 1158), (984, 1127), (1012, 1158), (953, 1134), (956, 1145), (983, 1145), (1004, 1127), (974, 1136), (977, 1128), (1014, 1144), (971, 1125), (1016, 1152), (960, 1160), (1002, 1124), (973, 1145), (1038, 1154), (984, 1131), (939, 1157), (1015, 1141)]
         : compromised: 0.8529, honest: 0.8603
Round 006: test acc mean=0.8694 ± 0.0189 | min=0.8211 max=0.8913
         : test loss mean=0.3015 ± 0.0360
         : individual accs = ['0.875439', '0.885147', '0.842059', '0.859240', '0.876543', '0.880349', '0.866376', '0.881988', '0.881162', '0.883865', '0.890734', '0.881778', '0.859375', '0.847414', '0.853203', '0.844541', '0.881282', '0.885942', '0.821089', '0.891323']
         : correct/total = [(998, 1140), (1025, 1158), (949, 1127), (995, 1158), (994, 1134), (1008, 1145), (992, 1145), (994, 1127), (1001, 1136), (997, 1128), (1019, 1144), (992, 1125), (990, 1152), (983, 1160), (959, 1124), (967, 1145), (1017, 1154), (1002, 1131), (950, 1157), (1017, 1141)]
         : compromised: 0.8579, honest: 0.8744
Round 007: test acc mean=0.8861 ± 0.0101 | min=0.8574 max=0.9015
         : test loss mean=0.2760 ± 0.0190
         : individual accs = ['0.871053', '0.892055', '0.880213', '0.892055', '0.888007', '0.885590', '0.888210', '0.901508', '0.880282', '0.896277', '0.895979', '0.897778', '0.883681', '0.883621', '0.880783', '0.876856', '0.892548', '0.883289', '0.857390', '0.895706']
         : correct/total = [(993, 1140), (1033, 1158), (992, 1127), (1033, 1158), (1007, 1134), (1014, 1145), (1017, 1145), (1016, 1127), (1000, 1136), (1011, 1128), (1025, 1144), (1010, 1125), (1018, 1152), (1025, 1160), (990, 1124), (1004, 1145), (1030, 1154), (999, 1131), (992, 1157), (1022, 1141)]
         : compromised: 0.8791, honest: 0.8892
Round 008: test acc mean=0.8893 ± 0.0089 | min=0.8707 max=0.9086
         : test loss mean=0.2631 ± 0.0187
         : individual accs = ['0.892982', '0.891192', '0.878438', '0.893782', '0.902116', '0.896943', '0.882096', '0.908607', '0.883803', '0.890071', '0.896853', '0.896000', '0.886285', '0.883621', '0.895018', '0.870742', '0.887348', '0.886826', '0.874676', '0.889571']
         : correct/total = [(1018, 1140), (1032, 1158), (990, 1127), (1035, 1158), (1023, 1134), (1027, 1145), (1010, 1145), (1024, 1127), (1004, 1136), (1004, 1128), (1026, 1144), (1008, 1125), (1021, 1152), (1025, 1160), (1006, 1124), (997, 1145), (1024, 1154), (1003, 1131), (1012, 1157), (1015, 1141)]
         : compromised: 0.8872, honest: 0.8903
Round 009: test acc mean=0.8924 ± 0.0088 | min=0.8715 max=0.9113
         : test loss mean=0.2609 ± 0.0195
         : individual accs = ['0.897368', '0.892055', '0.880213', '0.899827', '0.899471', '0.897817', '0.895197', '0.911269', '0.871479', '0.893617', '0.893357', '0.896889', '0.894965', '0.887931', '0.891459', '0.882969', '0.896880', '0.888594', '0.878133', '0.899211']
         : correct/total = [(1023, 1140), (1033, 1158), (992, 1127), (1042, 1158), (1020, 1134), (1028, 1145), (1025, 1145), (1027, 1127), (990, 1136), (1008, 1128), (1022, 1144), (1009, 1125), (1031, 1152), (1030, 1160), (1002, 1124), (1011, 1145), (1035, 1154), (1005, 1131), (1016, 1157), (1026, 1141)]
         : compromised: 0.8898, honest: 0.8936
Round 010: test acc mean=0.8958 ± 0.0088 | min=0.8747 max=0.9099
         : test loss mean=0.2556 ± 0.0182
         : individual accs = ['0.900877', '0.898100', '0.883762', '0.904145', '0.893298', '0.902183', '0.896943', '0.906832', '0.882923', '0.896277', '0.892483', '0.899556', '0.892361', '0.906034', '0.901246', '0.884716', '0.909879', '0.891247', '0.874676', '0.899211']
         : correct/total = [(1027, 1140), (1040, 1158), (996, 1127), (1047, 1158), (1013, 1134), (1033, 1145), (1027, 1145), (1022, 1127), (1003, 1136), (1011, 1128), (1021, 1144), (1012, 1125), (1028, 1152), (1051, 1160), (1013, 1124), (1013, 1145), (1050, 1154), (1008, 1131), (1012, 1157), (1026, 1141)]
         : compromised: 0.8946, honest: 0.8964

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 30.0% compromised
Final accuracy - Compromised: 0.8946, Honest: 0.8964
Overall test accuracy: mean=0.8958 ± 0.0088
