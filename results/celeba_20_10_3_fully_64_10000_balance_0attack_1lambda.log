Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
BALANCE algorithm:
  - Model dimension: 30,758 parameters
  - Complexity: O(N×d) = O(20×30,758)
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.8318 ± 0.0777
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 002: test acc mean=0.5164 ± 0.0149 | min=0.4911 max=0.5625
         : test loss mean=0.7558 ± 0.0584
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.505768', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (570, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
Round 003: test acc mean=0.5195 ± 0.0166 | min=0.4911 max=0.5625
         : test loss mean=0.6991 ± 0.0615
         : individual accs = ['0.541228', '0.509499', '0.493345', '0.528497', '0.522046', '0.526638', '0.531004', '0.503993', '0.562500', '0.491135', '0.525350', '0.499556', '0.536458', '0.506897', '0.517794', '0.517031', '0.519931', '0.508400', '0.522904', '0.525855']
         : correct/total = [(617, 1140), (590, 1158), (556, 1127), (612, 1158), (592, 1134), (603, 1145), (608, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (562, 1125), (618, 1152), (588, 1160), (582, 1124), (592, 1145), (600, 1154), (575, 1131), (605, 1157), (600, 1141)]
Round 004: test acc mean=0.5240 ± 0.0220 | min=0.4911 max=0.5893
         : test loss mean=0.6851 ± 0.0494
         : individual accs = ['0.529825', '0.508636', '0.497782', '0.531952', '0.522046', '0.514410', '0.523144', '0.503993', '0.562500', '0.491135', '0.525350', '0.589333', '0.550347', '0.506897', '0.519573', '0.517904', '0.530329', '0.508400', '0.523768', '0.522349']
         : correct/total = [(604, 1140), (589, 1158), (561, 1127), (616, 1158), (592, 1134), (589, 1145), (599, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (663, 1125), (634, 1152), (588, 1160), (584, 1124), (593, 1145), (612, 1154), (575, 1131), (606, 1157), (596, 1141)]
Round 005: test acc mean=0.5343 ± 0.0326 | min=0.4911 max=0.6319
         : test loss mean=0.6508 ± 0.0378
         : individual accs = ['0.529825', '0.508636', '0.493345', '0.537997', '0.528219', '0.528384', '0.562445', '0.507542', '0.568662', '0.491135', '0.528846', '0.532444', '0.631944', '0.520690', '0.526690', '0.517031', '0.592721', '0.511936', '0.543647', '0.524102']
         : correct/total = [(604, 1140), (589, 1158), (556, 1127), (623, 1158), (599, 1134), (605, 1145), (644, 1145), (572, 1127), (646, 1136), (554, 1128), (605, 1144), (599, 1125), (728, 1152), (604, 1160), (592, 1124), (592, 1145), (684, 1154), (579, 1131), (629, 1157), (598, 1141)]
Round 006: test acc mean=0.6294 ± 0.0622 | min=0.5279 max=0.7326
         : test loss mean=0.5817 ± 0.0286
         : individual accs = ['0.728070', '0.552677', '0.644188', '0.672712', '0.562610', '0.659389', '0.593886', '0.678793', '0.630282', '0.542553', '0.639860', '0.572444', '0.732639', '0.624138', '0.549822', '0.625328', '0.636049', '0.527851', '0.706137', '0.709027']
         : correct/total = [(830, 1140), (640, 1158), (726, 1127), (779, 1158), (638, 1134), (755, 1145), (680, 1145), (765, 1127), (716, 1136), (612, 1128), (732, 1144), (644, 1125), (844, 1152), (724, 1160), (618, 1124), (716, 1145), (734, 1154), (597, 1131), (817, 1157), (809, 1141)]
Round 007: test acc mean=0.7006 ± 0.0657 | min=0.5505 max=0.7973
         : test loss mean=0.5517 ± 0.0326
         : individual accs = ['0.753509', '0.631261', '0.628217', '0.725389', '0.713404', '0.722271', '0.688210', '0.762201', '0.758803', '0.550532', '0.646853', '0.797333', '0.794271', '0.729310', '0.600534', '0.631441', '0.748700', '0.700265', '0.675886', '0.753725']
         : correct/total = [(859, 1140), (731, 1158), (708, 1127), (840, 1158), (809, 1134), (827, 1145), (788, 1145), (859, 1127), (862, 1136), (621, 1128), (740, 1144), (897, 1125), (915, 1152), (846, 1160), (675, 1124), (723, 1145), (864, 1154), (792, 1131), (782, 1157), (860, 1141)]
Round 008: test acc mean=0.7429 ± 0.0523 | min=0.6218 max=0.8187
         : test loss mean=0.5222 ± 0.0282
         : individual accs = ['0.778947', '0.621762', '0.729370', '0.755613', '0.754850', '0.792140', '0.798253', '0.773736', '0.727993', '0.656915', '0.763986', '0.760000', '0.769965', '0.768966', '0.700178', '0.682969', '0.787695', '0.818744', '0.764909', '0.651183']
         : correct/total = [(888, 1140), (720, 1158), (822, 1127), (875, 1158), (856, 1134), (907, 1145), (914, 1145), (872, 1127), (827, 1136), (741, 1128), (874, 1144), (855, 1125), (887, 1152), (892, 1160), (787, 1124), (782, 1145), (909, 1154), (926, 1131), (885, 1157), (743, 1141)]
Round 009: test acc mean=0.7873 ± 0.0442 | min=0.6788 max=0.8420
         : test loss mean=0.4950 ± 0.0237
         : individual accs = ['0.807018', '0.678756', '0.734694', '0.824698', '0.768078', '0.831441', '0.829694', '0.831411', '0.760563', '0.744681', '0.813811', '0.831111', '0.842014', '0.805172', '0.756228', '0.718777', '0.801560', '0.755968', '0.784788', '0.824715']
         : correct/total = [(920, 1140), (786, 1158), (828, 1127), (955, 1158), (871, 1134), (952, 1145), (950, 1145), (937, 1127), (864, 1136), (840, 1128), (931, 1144), (935, 1125), (970, 1152), (934, 1160), (850, 1124), (823, 1145), (925, 1154), (855, 1131), (908, 1157), (941, 1141)]
Round 010: test acc mean=0.8273 ± 0.0256 | min=0.7759 max=0.8837
         : test loss mean=0.4595 ± 0.0213
         : individual accs = ['0.850000', '0.797927', '0.816327', '0.816062', '0.799824', '0.824454', '0.840175', '0.849157', '0.823063', '0.817376', '0.852273', '0.819556', '0.883681', '0.775862', '0.804270', '0.794760', '0.863951', '0.847922', '0.835782', '0.833479']
         : correct/total = [(969, 1140), (924, 1158), (920, 1127), (945, 1158), (907, 1134), (944, 1145), (962, 1145), (957, 1127), (935, 1136), (922, 1128), (975, 1144), (922, 1125), (1018, 1152), (900, 1160), (904, 1124), (910, 1145), (997, 1154), (959, 1131), (967, 1157), (951, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: fully, Aggregation: balance
Overall test accuracy: mean=0.8273 ± 0.0256

=== BALANCE SUMMARY ===
Node 0: acceptance=1.000
Node 1: acceptance=1.000
Node 2: acceptance=1.000
Node 3: acceptance=1.000
Node 4: acceptance=1.000
Node 5: acceptance=1.000
Node 6: acceptance=1.000
Node 7: acceptance=1.000
Node 8: acceptance=1.000
Node 9: acceptance=1.000
Node 10: acceptance=1.000
Node 11: acceptance=1.000
Node 12: acceptance=1.000
Node 13: acceptance=1.000
Node 14: acceptance=1.000
Node 15: acceptance=1.000
Node 16: acceptance=1.000
Node 17: acceptance=1.000
Node 18: acceptance=1.000
Node 19: acceptance=1.000

Performance Summary:
  - Distance computation time: 2.958s (44.1%)
  - Filtering time: 3.102s (46.2%)
  - Aggregation time: 0.655s (9.7%)
  - Total time: 6.715s
  - Mean acceptance rate: 1.000

BALANCE Algorithm Properties:
  - Model dimension: 30,758
  - No compression: Full parameter comparison
  - Theoretical complexity: O(deg(i)×d)
  - Approach: Full parameter filtering + averaging
