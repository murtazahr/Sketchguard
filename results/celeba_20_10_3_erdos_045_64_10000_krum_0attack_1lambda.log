Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.8765 ± 0.0209 | min=0.8351 max=0.9180
         : test loss mean=0.3058 ± 0.0485
         : individual accs = ['0.835088', '0.858377', '0.885537', '0.868739', '0.917989', '0.851528', '0.901310', '0.892635', '0.881162', '0.884752', '0.860140', '0.903111', '0.875868', '0.854310', '0.857651', '0.883843', '0.884749', '0.900088', '0.850475', '0.882559']
         : correct/total = [(952, 1140), (994, 1158), (998, 1127), (1006, 1158), (1041, 1134), (975, 1145), (1032, 1145), (1006, 1127), (1001, 1136), (998, 1128), (984, 1144), (1016, 1125), (1009, 1152), (991, 1160), (964, 1124), (1012, 1145), (1021, 1154), (1018, 1131), (984, 1157), (1007, 1141)]
Round 002: test acc mean=0.8971 ± 0.0157 | min=0.8583 max=0.9185
         : test loss mean=0.2695 ± 0.0476
         : individual accs = ['0.918421', '0.886874', '0.895297', '0.905872', '0.869489', '0.899563', '0.910044', '0.902396', '0.895246', '0.896277', '0.905594', '0.905778', '0.896701', '0.905172', '0.865658', '0.905677', '0.905546', '0.894783', '0.858254', '0.918493']
         : correct/total = [(1047, 1140), (1027, 1158), (1009, 1127), (1049, 1158), (986, 1134), (1030, 1145), (1042, 1145), (1017, 1127), (1017, 1136), (1011, 1128), (1036, 1144), (1019, 1125), (1033, 1152), (1050, 1160), (973, 1124), (1037, 1145), (1045, 1154), (1012, 1131), (993, 1157), (1048, 1141)]
Round 003: test acc mean=0.9027 ± 0.0123 | min=0.8712 max=0.9244
         : test loss mean=0.2493 ± 0.0292
         : individual accs = ['0.903509', '0.916235', '0.897072', '0.894646', '0.915344', '0.903930', '0.912664', '0.909494', '0.888204', '0.904255', '0.894231', '0.924444', '0.902778', '0.881034', '0.907473', '0.898690', '0.912478', '0.908046', '0.871219', '0.908852']
         : correct/total = [(1030, 1140), (1061, 1158), (1011, 1127), (1036, 1158), (1038, 1134), (1035, 1145), (1045, 1145), (1025, 1127), (1009, 1136), (1020, 1128), (1023, 1144), (1040, 1125), (1040, 1152), (1022, 1160), (1020, 1124), (1029, 1145), (1053, 1154), (1027, 1131), (1008, 1157), (1037, 1141)]
Round 004: test acc mean=0.9059 ± 0.0113 | min=0.8816 max=0.9214
         : test loss mean=0.2379 ± 0.0215
         : individual accs = ['0.921053', '0.890328', '0.905058', '0.898100', '0.906526', '0.921397', '0.921397', '0.914818', '0.901408', '0.914007', '0.890734', '0.912000', '0.913194', '0.903448', '0.911032', '0.902183', '0.903813', '0.888594', '0.881590', '0.916740']
         : correct/total = [(1050, 1140), (1031, 1158), (1020, 1127), (1040, 1158), (1028, 1134), (1055, 1145), (1055, 1145), (1031, 1127), (1024, 1136), (1031, 1128), (1019, 1144), (1026, 1125), (1052, 1152), (1048, 1160), (1024, 1124), (1033, 1145), (1043, 1154), (1005, 1131), (1020, 1157), (1046, 1141)]
Round 005: test acc mean=0.9067 ± 0.0091 | min=0.8917 max=0.9214
         : test loss mean=0.2378 ± 0.0223
         : individual accs = ['0.918421', '0.905872', '0.891748', '0.894646', '0.912698', '0.921397', '0.918777', '0.910382', '0.907570', '0.903369', '0.907343', '0.910222', '0.912326', '0.901724', '0.901246', '0.900437', '0.914211', '0.892131', '0.891962', '0.917616']
         : correct/total = [(1047, 1140), (1049, 1158), (1005, 1127), (1036, 1158), (1035, 1134), (1055, 1145), (1052, 1145), (1026, 1127), (1031, 1136), (1019, 1128), (1038, 1144), (1024, 1125), (1051, 1152), (1046, 1160), (1013, 1124), (1031, 1145), (1055, 1154), (1009, 1131), (1032, 1157), (1047, 1141)]
Round 006: test acc mean=0.9107 ± 0.0074 | min=0.8971 max=0.9224
         : test loss mean=0.2331 ± 0.0244
         : individual accs = ['0.912281', '0.907599', '0.897959', '0.905872', '0.922399', '0.913537', '0.920524', '0.918367', '0.901408', '0.908688', '0.902098', '0.919111', '0.919271', '0.911207', '0.912811', '0.910044', '0.909879', '0.904509', '0.897148', '0.919369']
         : correct/total = [(1040, 1140), (1051, 1158), (1012, 1127), (1049, 1158), (1046, 1134), (1046, 1145), (1054, 1145), (1035, 1127), (1024, 1136), (1025, 1128), (1032, 1144), (1034, 1125), (1059, 1152), (1057, 1160), (1026, 1124), (1042, 1145), (1050, 1154), (1023, 1131), (1038, 1157), (1049, 1141)]
Round 007: test acc mean=0.9102 ± 0.0088 | min=0.8944 max=0.9240
         : test loss mean=0.2320 ± 0.0211
         : individual accs = ['0.920175', '0.899827', '0.904170', '0.905009', '0.919753', '0.899563', '0.924017', '0.921917', '0.894366', '0.912234', '0.911713', '0.922667', '0.910590', '0.909483', '0.901246', '0.912664', '0.914211', '0.908046', '0.896283', '0.915863']
         : correct/total = [(1049, 1140), (1042, 1158), (1019, 1127), (1048, 1158), (1043, 1134), (1030, 1145), (1058, 1145), (1039, 1127), (1016, 1136), (1029, 1128), (1043, 1144), (1038, 1125), (1049, 1152), (1055, 1160), (1013, 1124), (1045, 1145), (1055, 1154), (1027, 1131), (1037, 1157), (1045, 1141)]
Round 008: test acc mean=0.9120 ± 0.0104 | min=0.8894 max=0.9272
         : test loss mean=0.2375 ± 0.0289
         : individual accs = ['0.924561', '0.918826', '0.891748', '0.915371', '0.920635', '0.902183', '0.919651', '0.927240', '0.905810', '0.905142', '0.910839', '0.920000', '0.924479', '0.912931', '0.897687', '0.913537', '0.914211', '0.908930', '0.889369', '0.917616']
         : correct/total = [(1054, 1140), (1064, 1158), (1005, 1127), (1060, 1158), (1044, 1134), (1033, 1145), (1053, 1145), (1045, 1127), (1029, 1136), (1021, 1128), (1042, 1144), (1035, 1125), (1065, 1152), (1059, 1160), (1009, 1124), (1046, 1145), (1055, 1154), (1028, 1131), (1029, 1157), (1047, 1141)]
Round 009: test acc mean=0.9103 ± 0.0092 | min=0.8926 max=0.9289
         : test loss mean=0.2398 ± 0.0316
         : individual accs = ['0.928947', '0.913644', '0.903283', '0.905009', '0.908289', '0.911790', '0.901310', '0.919255', '0.892606', '0.913121', '0.911713', '0.922667', '0.914931', '0.899138', '0.911032', '0.912664', '0.917678', '0.904509', '0.893691', '0.920245']
         : correct/total = [(1059, 1140), (1058, 1158), (1018, 1127), (1048, 1158), (1030, 1134), (1044, 1145), (1032, 1145), (1036, 1127), (1014, 1136), (1030, 1128), (1043, 1144), (1038, 1125), (1054, 1152), (1043, 1160), (1024, 1124), (1045, 1145), (1059, 1154), (1023, 1131), (1034, 1157), (1050, 1141)]
Round 010: test acc mean=0.9113 ± 0.0092 | min=0.8935 max=0.9262
         : test loss mean=0.2394 ± 0.0264
         : individual accs = ['0.918421', '0.914508', '0.898846', '0.906736', '0.915344', '0.920524', '0.923144', '0.920142', '0.893486', '0.909574', '0.908217', '0.926222', '0.901042', '0.912069', '0.909253', '0.913537', '0.909879', '0.900088', '0.898876', '0.925504']
         : correct/total = [(1047, 1140), (1059, 1158), (1013, 1127), (1050, 1158), (1038, 1134), (1054, 1145), (1057, 1145), (1037, 1127), (1015, 1136), (1026, 1128), (1039, 1144), (1042, 1125), (1038, 1152), (1058, 1160), (1022, 1124), (1046, 1145), (1050, 1154), (1018, 1131), (1040, 1157), (1056, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: krum
Overall test accuracy: mean=0.9113 ± 0.0092
