Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 8/20 nodes: [1, 5, 11, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.4903 ± 0.1554 | min=0.0039 max=0.5712
         : test loss mean=1699827.0502 ± 5133970.1731
         : individual accs = ['0.533672', '0.533191', '0.571184', '0.514193', '0.531899', '0.564497', '0.546387', '0.544033', '0.540682', '0.526070', '0.003862', '0.540663', '0.534816', '0.553252', '0.532083', '0.524696', '0.569468', '0.049725', '0.535994', '0.556444']
         : correct/total = [(2203, 4128), (2241, 4203), (2331, 4081), (2228, 4333), (2176, 4091), (2420, 4287), (2291, 4193), (2366, 4349), (2266, 4191), (2250, 4277), (16, 4143), (2267, 4193), (2189, 4093), (2322, 4197), (2156, 4052), (2114, 4029), (2365, 4153), (208, 4183), (2189, 4084), (2297, 4128)]
         : compromised: 0.4805, honest: 0.4969
Round 002: test acc mean=0.6561 ± 0.2027 | min=0.0480 max=0.7509
         : test loss mean=nan ± nan
         : individual accs = ['0.713178', '0.730906', '0.727518', '0.702285', '0.721095', '0.750875', '0.723348', '0.719476', '0.712956', '0.720599', '0.048033', '0.724541', '0.738089', '0.717894', '0.721125', '0.731447', '0.722129', '0.049486', '0.733105', '0.714632']
         : correct/total = [(2944, 4128), (3072, 4203), (2969, 4081), (3043, 4333), (2950, 4091), (3219, 4287), (3033, 4193), (3129, 4349), (2988, 4191), (3082, 4277), (199, 4143), (3038, 4193), (3021, 4093), (3013, 4197), (2922, 4052), (2947, 4029), (2999, 4153), (207, 4183), (2994, 4084), (2950, 4128)]
         : compromised: 0.6458, honest: 0.6631
Round 003: test acc mean=0.7047 ± 0.2188 | min=0.0480 max=0.7898
         : test loss mean=nan ± nan
         : individual accs = ['0.772045', '0.782774', '0.789757', '0.765751', '0.780249', '0.776534', '0.765323', '0.788227', '0.784777', '0.787000', '0.048033', '0.783449', '0.784266', '0.780081', '0.771471', '0.760735', '0.777510', '0.049486', '0.786729', '0.759448']
         : correct/total = [(3187, 4128), (3290, 4203), (3223, 4081), (3318, 4333), (3192, 4091), (3329, 4287), (3209, 4193), (3428, 4349), (3289, 4191), (3366, 4277), (199, 4143), (3285, 4193), (3210, 4093), (3274, 4197), (3126, 4052), (3065, 4029), (3229, 4153), (207, 4183), (3213, 4084), (3135, 4128)]
         : compromised: 0.6893, honest: 0.7149
Round 004: test acc mean=0.6854 ± 0.2738 | min=0.0047 max=0.8158
         : test loss mean=nan ± nan
         : individual accs = ['0.804021', '0.810611', '0.806175', '0.807293', '0.807382', '0.004665', '0.782733', '0.795125', '0.795037', '0.808744', '0.048033', '0.790603', '0.797703', '0.798904', '0.794916', '0.797220', '0.815796', '0.049486', '0.806317', '0.786337']
         : correct/total = [(3319, 4128), (3407, 4203), (3290, 4081), (3498, 4333), (3303, 4091), (20, 4287), (3282, 4193), (3458, 4349), (3332, 4191), (3459, 4277), (199, 4143), (3315, 4193), (3265, 4093), (3353, 4197), (3221, 4052), (3212, 4029), (3388, 4153), (207, 4183), (3293, 4084), (3246, 4128)]
         : compromised: 0.6067, honest: 0.7378
Round 005: test acc mean=0.7338 ± 0.2285 | min=0.0480 max=0.8221
         : test loss mean=nan ± nan
         : individual accs = ['0.817103', '0.813467', '0.820877', '0.790445', '0.812271', '0.814322', '0.796804', '0.809611', '0.809115', '0.819266', '0.048033', '0.800859', '0.822135', '0.801525', '0.808490', '0.804914', '0.818204', '0.049486', '0.818071', '0.800388']
         : correct/total = [(3373, 4128), (3419, 4203), (3350, 4081), (3425, 4333), (3323, 4091), (3491, 4287), (3341, 4193), (3521, 4349), (3391, 4191), (3504, 4277), (199, 4143), (3358, 4193), (3365, 4093), (3364, 4197), (3276, 4052), (3243, 4029), (3398, 4153), (207, 4183), (3341, 4084), (3304, 4128)]
         : compromised: 0.7160, honest: 0.7456
Round 006: test acc mean=0.7416 ± 0.2311 | min=0.0480 max=0.8321
         : test loss mean=nan ± nan
         : individual accs = ['0.826793', '0.818463', '0.820632', '0.824371', '0.822782', '0.823886', '0.803244', '0.831456', '0.813887', '0.832125', '0.048033', '0.804674', '0.825067', '0.802716', '0.825518', '0.820551', '0.814833', '0.049486', '0.816601', '0.806444']
         : correct/total = [(3413, 4128), (3440, 4203), (3349, 4081), (3572, 4333), (3366, 4091), (3532, 4287), (3368, 4193), (3616, 4349), (3411, 4191), (3559, 4277), (199, 4143), (3374, 4193), (3377, 4093), (3369, 4197), (3345, 4052), (3306, 4029), (3384, 4153), (207, 4183), (3335, 4084), (3329, 4128)]
         : compromised: 0.7208, honest: 0.7554
Round 007: test acc mean=0.7030 ± 0.2803 | min=0.0114 max=0.8475
         : test loss mean=nan ± nan
         : individual accs = ['0.820979', '0.828218', '0.819652', '0.816986', '0.847470', '0.011430', '0.814930', '0.832835', '0.809592', '0.843114', '0.048033', '0.814930', '0.818226', '0.807958', '0.803307', '0.807148', '0.827835', '0.049486', '0.819295', '0.818072']
         : correct/total = [(3389, 4128), (3481, 4203), (3345, 4081), (3540, 4333), (3467, 4091), (49, 4287), (3417, 4193), (3622, 4349), (3393, 4191), (3606, 4277), (199, 4143), (3417, 4193), (3349, 4093), (3391, 4197), (3255, 4052), (3252, 4029), (3438, 4153), (207, 4183), (3346, 4084), (3377, 4128)]
         : compromised: 0.6191, honest: 0.7589
Round 008: test acc mean=0.7548 ± 0.2355 | min=0.0480 max=0.8469
         : test loss mean=nan ± nan
         : individual accs = ['0.828246', '0.836069', '0.846851', '0.828987', '0.840870', '0.832983', '0.829716', '0.841113', '0.838702', '0.839373', '0.048033', '0.820653', '0.831419', '0.828687', '0.826999', '0.824274', '0.841079', '0.049486', '0.842801', '0.819041']
         : correct/total = [(3419, 4128), (3514, 4203), (3456, 4081), (3592, 4333), (3440, 4091), (3571, 4287), (3479, 4193), (3658, 4349), (3515, 4191), (3590, 4277), (199, 4143), (3441, 4193), (3403, 4093), (3478, 4197), (3351, 4052), (3321, 4029), (3493, 4153), (207, 4183), (3442, 4084), (3381, 4128)]
         : compromised: 0.7336, honest: 0.7689
Round 009: test acc mean=0.7515 ± 0.2344 | min=0.0480 max=0.8431
         : test loss mean=nan ± nan
         : individual accs = ['0.820010', '0.833452', '0.834599', '0.826448', '0.839648', '0.831817', '0.824946', '0.840193', '0.830828', '0.841244', '0.048033', '0.829955', '0.843147', '0.825590', '0.819842', '0.813105', '0.824223', '0.049486', '0.834231', '0.820010']
         : correct/total = [(3385, 4128), (3503, 4203), (3406, 4081), (3581, 4333), (3435, 4091), (3566, 4287), (3459, 4193), (3654, 4349), (3482, 4191), (3598, 4277), (199, 4143), (3480, 4193), (3451, 4093), (3465, 4197), (3322, 4052), (3276, 4029), (3423, 4153), (207, 4183), (3407, 4084), (3385, 4128)]
         : compromised: 0.7334, honest: 0.7636
Round 010: test acc mean=0.7559 ± 0.2359 | min=0.0480 max=0.8506
         : test loss mean=nan ± nan
         : individual accs = ['0.825097', '0.835118', '0.837540', '0.843526', '0.850648', '0.846513', '0.816599', '0.842263', '0.832260', '0.834463', '0.048033', '0.833294', '0.839482', '0.829164', '0.833662', '0.819310', '0.836745', '0.049486', '0.843781', '0.820736']
         : correct/total = [(3406, 4128), (3510, 4203), (3418, 4081), (3655, 4333), (3480, 4091), (3629, 4287), (3424, 4193), (3663, 4349), (3488, 4191), (3569, 4277), (199, 4143), (3494, 4193), (3436, 4093), (3480, 4197), (3378, 4052), (3301, 4029), (3475, 4153), (207, 4183), (3446, 4084), (3388, 4128)]
         : compromised: 0.7388, honest: 0.7673

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 40.0% compromised
Final accuracy - Compromised: 0.7388, Honest: 0.7673
Overall test accuracy: mean=0.7559 ± 0.2359
