Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: krum, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0754 ± 0.0577 | min=0.0039 max=0.2435
         : test loss mean=225.3199 ± 361.2332
         : individual accs = ['0.089147', '0.053533', '0.081843', '0.003923', '0.065510', '0.005365', '0.086334', '0.076569', '0.149129', '0.173954', '0.114893', '0.051514', '0.045932', '0.022873', '0.044669', '0.045669', '0.067662', '0.007650', '0.077865', '0.243459']
         : correct/total = [(368, 4128), (225, 4203), (334, 4081), (17, 4333), (268, 4091), (23, 4287), (362, 4193), (333, 4349), (625, 4191), (744, 4277), (476, 4143), (216, 4193), (188, 4093), (96, 4197), (181, 4052), (184, 4029), (281, 4153), (32, 4183), (318, 4084), (1005, 4128)]
         : compromised: 0.0141, honest: 0.0822
Round 002: test acc mean=0.1097 ± 0.1807 | min=0.0430 max=0.6590
         : test loss mean=2284008.8588 ± 6425875.8549
         : individual accs = ['0.049419', '0.048775', '0.061505', '0.049619', '0.046199', '0.046186', '0.045314', '0.046907', '0.659031', '0.043488', '0.042964', '0.050799', '0.052040', '0.049083', '0.049112', '0.046910', '0.050566', '0.051159', '0.060235', '0.644138']
         : correct/total = [(204, 4128), (205, 4203), (251, 4081), (215, 4333), (189, 4091), (198, 4287), (190, 4193), (204, 4349), (2762, 4191), (186, 4277), (178, 4143), (213, 4193), (213, 4093), (206, 4197), (199, 4052), (189, 4029), (210, 4153), (214, 4183), (246, 4084), (2659, 4128)]
         : compromised: 0.0476, honest: 0.1166
Round 003: test acc mean=0.0504 ± 0.0078 | min=0.0342 max=0.0623
         : test loss mean=1670.8836 ± 5426.4149
         : individual accs = ['0.034157', '0.052819', '0.061505', '0.037618', '0.052066', '0.052018', '0.053422', '0.045758', '0.051300', '0.048632', '0.051895', '0.034343', '0.062301', '0.049083', '0.055281', '0.061554', '0.048158', '0.057853', '0.051910', '0.046512']
         : correct/total = [(141, 4128), (222, 4203), (251, 4081), (163, 4333), (213, 4091), (223, 4287), (224, 4193), (199, 4349), (215, 4191), (208, 4277), (215, 4143), (144, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (200, 4153), (242, 4183), (212, 4084), (192, 4128)]
         : compromised: 0.0506, honest: 0.0504
Round 004: test acc mean=0.0535 ± 0.0046 | min=0.0438 max=0.0616
         : test loss mean=1175.7378 ± 4981.9513
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.043850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.048131', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (190, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (197, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0506, honest: 0.0539
Round 005: test acc mean=0.0544 ± 0.0045 | min=0.0483 max=0.0623
         : test loss mean=6.7434 ± 8.9884
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.048274', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (200, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0506, honest: 0.0548
Round 006: test acc mean=0.0527 ± 0.0044 | min=0.0446 max=0.0615
         : test loss mean=5.1942 ± 5.8056
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.048004', '0.052066', '0.051318', '0.053422', '0.044608', '0.057266', '0.048632', '0.051895', '0.054853', '0.047642', '0.046938', '0.055281', '0.051874', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (208, 4333), (213, 4091), (220, 4287), (224, 4193), (194, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (195, 4093), (197, 4197), (224, 4052), (209, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0491, honest: 0.0531
Round 007: test acc mean=0.0539 ± 0.0052 | min=0.0425 max=0.0623
         : test loss mean=3.8861 ± 0.5518
         : individual accs = ['0.050630', '0.052819', '0.061505', '0.049850', '0.052066', '0.042454', '0.052707', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.045509', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(209, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (182, 4287), (221, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (191, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0440, honest: 0.0550
Round 008: test acc mean=0.0542 ± 0.0048 | min=0.0438 max=0.0623
         : test loss mean=3.9700 ± 1.0748
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.043850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (190, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0506, honest: 0.0547
Round 009: test acc mean=0.0544 ± 0.0043 | min=0.0491 max=0.0623
         : test loss mean=3.8156 ± 0.4878
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.050035', '0.051895', '0.054853', '0.062301', '0.049083', '0.050592', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (214, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (205, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0506, honest: 0.0548
Round 010: test acc mean=0.0523 ± 0.0044 | min=0.0438 max=0.0615
         : test loss mean=3.8018 ± 0.4342
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.043850', '0.052066', '0.052484', '0.053422', '0.050586', '0.057266', '0.048632', '0.051895', '0.054853', '0.047642', '0.049083', '0.050099', '0.054604', '0.050566', '0.046378', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (190, 4333), (213, 4091), (225, 4287), (224, 4193), (220, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (195, 4093), (206, 4197), (203, 4052), (220, 4029), (210, 4153), (194, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0508, honest: 0.0524

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: krum, 10.0% compromised
Final accuracy - Compromised: 0.0508, Honest: 0.0524
Overall test accuracy: mean=0.0523 ± 0.0044
