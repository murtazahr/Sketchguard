Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 16/20 nodes: [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 4
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Backdoor attack: Created poisoned datasets for 16 compromised nodes
Round 001: test acc mean=0.0232 ± 0.0180 | min=0.0033 max=0.0550
         : test loss mean=151276.9172 ± 125569.8963
         : individual accs = ['0.005329', '0.017369', '0.003676', '0.046619', '0.011489', '0.019827', '0.003339', '0.005748', '0.015987', '0.038578', '0.033551', '0.050083', '0.013193', '0.020014', '0.004689', '0.045172', '0.014929', '0.006216', '0.054114', '0.054990']
         : correct/total = [(22, 4128), (73, 4203), (15, 4081), (202, 4333), (47, 4091), (85, 4287), (14, 4193), (25, 4349), (67, 4191), (165, 4277), (139, 4143), (210, 4193), (54, 4093), (84, 4197), (19, 4052), (182, 4029), (62, 4153), (26, 4183), (221, 4084), (227, 4128)]
         : compromised: 0.0267, honest: 0.0094
Round 002: test acc mean=0.0491 ± 0.0046 | min=0.0368 max=0.0597
         : test loss mean=nan ± nan
         : individual accs = ['0.049419', '0.048299', '0.049743', '0.046619', '0.047910', '0.052951', '0.041498', '0.036790', '0.051062', '0.050736', '0.048274', '0.048891', '0.047398', '0.047653', '0.052320', '0.046910', '0.047436', '0.052833', '0.059745', '0.054990']
         : correct/total = [(204, 4128), (203, 4203), (203, 4081), (202, 4333), (196, 4091), (227, 4287), (174, 4193), (160, 4349), (214, 4191), (217, 4277), (200, 4143), (205, 4193), (194, 4093), (200, 4197), (212, 4052), (189, 4029), (197, 4153), (221, 4183), (244, 4084), (227, 4128)]
         : compromised: 0.0500, honest: 0.0454
Round 003: test acc mean=0.0509 ± 0.0039 | min=0.0464 max=0.0615
         : test loss mean=nan ± nan
         : individual accs = ['0.049661', '0.048299', '0.061505', '0.046619', '0.047910', '0.052951', '0.053422', '0.046447', '0.057266', '0.048632', '0.048274', '0.048891', '0.052040', '0.047653', '0.055281', '0.046910', '0.050566', '0.052833', '0.048482', '0.054990']
         : correct/total = [(205, 4128), (203, 4203), (251, 4081), (202, 4333), (196, 4091), (227, 4287), (224, 4193), (202, 4349), (240, 4191), (208, 4277), (200, 4143), (205, 4193), (213, 4093), (200, 4197), (224, 4052), (189, 4029), (210, 4153), (221, 4183), (198, 4084), (227, 4128)]
         : compromised: 0.0515, honest: 0.0486
Round 004: test acc mean=0.0509 ± 0.0055 | min=0.0389 max=0.0615
         : test loss mean=nan ± nan
         : individual accs = ['0.049661', '0.058292', '0.061505', '0.046619', '0.045466', '0.058782', '0.053422', '0.046907', '0.057266', '0.048632', '0.053102', '0.048891', '0.047642', '0.047653', '0.055281', '0.043435', '0.050566', '0.051159', '0.038932', '0.054990']
         : correct/total = [(205, 4128), (245, 4203), (251, 4081), (202, 4333), (186, 4091), (252, 4287), (224, 4193), (204, 4349), (240, 4191), (208, 4277), (220, 4143), (205, 4193), (195, 4093), (200, 4197), (224, 4052), (175, 4029), (210, 4153), (214, 4183), (159, 4084), (227, 4128)]
         : compromised: 0.0516, honest: 0.0481
Round 005: test acc mean=0.0528 ± 0.0045 | min=0.0464 max=0.0621
         : test loss mean=nan ± nan
         : individual accs = ['0.049661', '0.051392', '0.061505', '0.046619', '0.052066', '0.052251', '0.053422', '0.052886', '0.057266', '0.048632', '0.051895', '0.048891', '0.052284', '0.047653', '0.055281', '0.062050', '0.050566', '0.046378', '0.060480', '0.054990']
         : correct/total = [(205, 4128), (216, 4203), (251, 4081), (202, 4333), (213, 4091), (224, 4287), (224, 4193), (230, 4349), (240, 4191), (208, 4277), (215, 4143), (205, 4193), (214, 4093), (200, 4197), (224, 4052), (250, 4029), (210, 4153), (194, 4183), (247, 4084), (227, 4128)]
         : compromised: 0.0532, honest: 0.0513
Round 006: test acc mean=0.0526 ± 0.0045 | min=0.0466 max=0.0623
         : test loss mean=nan ± nan
         : individual accs = ['0.049419', '0.052819', '0.049253', '0.046619', '0.052066', '0.052018', '0.051753', '0.052656', '0.052732', '0.050269', '0.051895', '0.048891', '0.062301', '0.047653', '0.050099', '0.061554', '0.047436', '0.057853', '0.060235', '0.054990']
         : correct/total = [(204, 4128), (222, 4203), (201, 4081), (202, 4333), (213, 4091), (223, 4287), (217, 4193), (229, 4349), (221, 4191), (215, 4277), (215, 4143), (205, 4193), (255, 4093), (200, 4197), (203, 4052), (248, 4029), (197, 4153), (242, 4183), (246, 4084), (227, 4128)]
         : compromised: 0.0532, honest: 0.0504
Round 007: test acc mean=0.0494 ± 0.0035 | min=0.0415 max=0.0550
         : test loss mean=nan ± nan
         : individual accs = ['0.049419', '0.046395', '0.049743', '0.046619', '0.045710', '0.052484', '0.041498', '0.049897', '0.051062', '0.050736', '0.048033', '0.048891', '0.048375', '0.047653', '0.054788', '0.054604', '0.047436', '0.045422', '0.054358', '0.054990']
         : correct/total = [(204, 4128), (195, 4203), (203, 4081), (202, 4333), (187, 4091), (225, 4287), (174, 4193), (217, 4349), (214, 4191), (217, 4277), (199, 4143), (205, 4193), (198, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (190, 4183), (222, 4084), (227, 4128)]
         : compromised: 0.0497, honest: 0.0481
Round 008: test acc mean=0.0430 ± 0.0088 | min=0.0299 max=0.0583
         : test loss mean=nan ± nan
         : individual accs = ['0.034157', '0.058292', '0.035040', '0.046619', '0.032755', '0.052484', '0.038874', '0.036790', '0.035791', '0.033201', '0.048033', '0.048891', '0.047642', '0.047653', '0.031096', '0.054604', '0.041416', '0.051159', '0.029873', '0.054990']
         : correct/total = [(141, 4128), (245, 4203), (143, 4081), (202, 4333), (134, 4091), (225, 4287), (163, 4193), (160, 4349), (150, 4191), (142, 4277), (199, 4143), (205, 4193), (195, 4093), (200, 4197), (126, 4052), (220, 4029), (172, 4153), (214, 4183), (122, 4084), (227, 4128)]
         : compromised: 0.0446, honest: 0.0363
Round 009: test acc mean=0.0525 ± 0.0060 | min=0.0427 max=0.0623
         : test loss mean=nan ± nan
         : individual accs = ['0.049903', '0.052819', '0.061505', '0.046619', '0.052066', '0.052018', '0.053422', '0.052656', '0.042711', '0.043488', '0.051895', '0.048891', '0.062301', '0.047653', '0.055281', '0.061554', '0.042861', '0.057853', '0.060235', '0.054990']
         : correct/total = [(206, 4128), (222, 4203), (251, 4081), (202, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (179, 4191), (186, 4277), (215, 4143), (205, 4193), (255, 4093), (200, 4197), (224, 4052), (248, 4029), (178, 4153), (242, 4183), (246, 4084), (227, 4128)]
         : compromised: 0.0533, honest: 0.0494
Round 010: test acc mean=0.0517 ± 0.0038 | min=0.0464 max=0.0615
         : test loss mean=nan ± nan
         : individual accs = ['0.049661', '0.051392', '0.061505', '0.046619', '0.053043', '0.048519', '0.053422', '0.050126', '0.057266', '0.048632', '0.051412', '0.048891', '0.052284', '0.047653', '0.055281', '0.055845', '0.050566', '0.046378', '0.050196', '0.054990']
         : correct/total = [(205, 4128), (216, 4203), (251, 4081), (202, 4333), (217, 4091), (208, 4287), (224, 4193), (218, 4349), (240, 4191), (208, 4277), (213, 4143), (205, 4193), (214, 4093), (200, 4197), (224, 4052), (225, 4029), (210, 4153), (194, 4183), (205, 4084), (227, 4128)]
         : compromised: 0.0519, honest: 0.0508

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: backdoor, 80.0% compromised
Final accuracy - Compromised: 0.0519, Honest: 0.0508
Overall test accuracy: mean=0.0517 ± 0.0038

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 4x4
Overall ASR: 0.2000 ± 0.4000
Honest nodes ASR: 0.0000 ± 0.0000
Compromised nodes ASR: 0.2500 ± 0.4330
Note: Higher ASR indicates more successful backdoor attack
