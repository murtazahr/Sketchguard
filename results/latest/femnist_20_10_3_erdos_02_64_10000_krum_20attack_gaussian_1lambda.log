Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5539 ± 0.0227 | min=0.5088 max=0.6076
         : test loss mean=1.6597 ± 0.0772
         : individual accs = ['0.542878', '0.555556', '0.546190', '0.534964', '0.553899', '0.577560', '0.543763', '0.556450', '0.586018', '0.541501', '0.508810', '0.546148', '0.553872', '0.584227', '0.607601', '0.554480', '0.533590', '0.540521', '0.581538', '0.527616']
         : correct/total = [(2241, 4128), (2335, 4203), (2229, 4081), (2318, 4333), (2266, 4091), (2476, 4287), (2280, 4193), (2420, 4349), (2456, 4191), (2316, 4277), (2108, 4143), (2290, 4193), (2267, 4093), (2452, 4197), (2462, 4052), (2234, 4029), (2216, 4153), (2261, 4183), (2375, 4084), (2178, 4128)]
         : compromised: 0.5640, honest: 0.5513
Round 002: test acc mean=0.7378 ± 0.0116 | min=0.7118 max=0.7591
         : test loss mean=0.8669 ± 0.0422
         : individual accs = ['0.742248', '0.743517', '0.734624', '0.745442', '0.711806', '0.728248', '0.754591', '0.734882', '0.731806', '0.737667', '0.741974', '0.754829', '0.740288', '0.724565', '0.759131', '0.720526', '0.727185', '0.744203', '0.745103', '0.733527']
         : correct/total = [(3064, 4128), (3125, 4203), (2998, 4081), (3230, 4333), (2912, 4091), (3122, 4287), (3164, 4193), (3196, 4349), (3067, 4191), (3155, 4277), (3074, 4143), (3165, 4193), (3030, 4093), (3041, 4197), (3076, 4052), (2903, 4029), (3020, 4153), (3113, 4183), (3043, 4084), (3028, 4128)]
         : compromised: 0.7343, honest: 0.7387
Round 003: test acc mean=0.7790 ± 0.0109 | min=0.7622 max=0.7935
         : test loss mean=0.7048 ± 0.0332
         : individual accs = ['0.774225', '0.793481', '0.777015', '0.792292', '0.764605', '0.766503', '0.791319', '0.790756', '0.789549', '0.790274', '0.772146', '0.788695', '0.773271', '0.762449', '0.774186', '0.790767', '0.776547', '0.783409', '0.762243', '0.765746']
         : correct/total = [(3196, 4128), (3335, 4203), (3171, 4081), (3433, 4333), (3128, 4091), (3286, 4287), (3318, 4193), (3439, 4349), (3309, 4191), (3380, 4277), (3199, 4143), (3307, 4193), (3165, 4093), (3200, 4197), (3137, 4052), (3186, 4029), (3225, 4153), (3277, 4183), (3113, 4084), (3161, 4128)]
         : compromised: 0.7714, honest: 0.7809
Round 004: test acc mean=0.8007 ± 0.0078 | min=0.7890 max=0.8146
         : test loss mean=0.6254 ± 0.0261
         : individual accs = ['0.793362', '0.794195', '0.799069', '0.802446', '0.789049', '0.801959', '0.811591', '0.810531', '0.814603', '0.808978', '0.797248', '0.793942', '0.791595', '0.809149', '0.789733', '0.802432', '0.799663', '0.791537', '0.804848', '0.808866']
         : correct/total = [(3275, 4128), (3338, 4203), (3261, 4081), (3477, 4333), (3228, 4091), (3438, 4287), (3403, 4193), (3525, 4349), (3414, 4191), (3460, 4277), (3303, 4143), (3329, 4193), (3240, 4093), (3396, 4197), (3200, 4052), (3233, 4029), (3321, 4153), (3311, 4183), (3287, 4084), (3339, 4128)]
         : compromised: 0.7986, honest: 0.8013
Round 005: test acc mean=0.8128 ± 0.0075 | min=0.7952 max=0.8320
         : test loss mean=0.5797 ± 0.0264
         : individual accs = ['0.808866', '0.813467', '0.812056', '0.814216', '0.807382', '0.808258', '0.817076', '0.825937', '0.832021', '0.810381', '0.816799', '0.804913', '0.808453', '0.811770', '0.810711', '0.795235', '0.811702', '0.811140', '0.821499', '0.813711']
         : correct/total = [(3339, 4128), (3419, 4203), (3314, 4081), (3528, 4333), (3303, 4091), (3465, 4287), (3426, 4193), (3592, 4349), (3487, 4191), (3466, 4277), (3384, 4143), (3375, 4193), (3309, 4093), (3407, 4197), (3285, 4052), (3204, 4029), (3371, 4153), (3393, 4183), (3355, 4084), (3359, 4128)]
         : compromised: 0.8099, honest: 0.8135
Round 006: test acc mean=0.8249 ± 0.0079 | min=0.8137 max=0.8406
         : test loss mean=0.5453 ± 0.0218
         : individual accs = ['0.815649', '0.825839', '0.826268', '0.827833', '0.814471', '0.820387', '0.830432', '0.825477', '0.839895', '0.836801', '0.813662', '0.819461', '0.822624', '0.824398', '0.822804', '0.827252', '0.840597', '0.831700', '0.817336', '0.814438']
         : correct/total = [(3367, 4128), (3471, 4203), (3372, 4081), (3587, 4333), (3332, 4091), (3517, 4287), (3482, 4193), (3590, 4349), (3520, 4191), (3579, 4277), (3371, 4143), (3436, 4193), (3367, 4093), (3460, 4197), (3334, 4052), (3333, 4029), (3491, 4153), (3479, 4183), (3338, 4084), (3362, 4128)]
         : compromised: 0.8248, honest: 0.8249
Round 007: test acc mean=0.8279 ± 0.0077 | min=0.8107 max=0.8458
         : test loss mean=0.5251 ± 0.0273
         : individual accs = ['0.829942', '0.845824', '0.823818', '0.836141', '0.821315', '0.826219', '0.827570', '0.833065', '0.835361', '0.830489', '0.825006', '0.832817', '0.812851', '0.831785', '0.810711', '0.828990', '0.827113', '0.825006', '0.832272', '0.822674']
         : correct/total = [(3426, 4128), (3555, 4203), (3362, 4081), (3623, 4333), (3360, 4091), (3542, 4287), (3470, 4193), (3623, 4349), (3501, 4191), (3552, 4277), (3418, 4143), (3492, 4193), (3327, 4093), (3491, 4197), (3285, 4052), (3340, 4029), (3435, 4153), (3451, 4183), (3399, 4084), (3396, 4128)]
         : compromised: 0.8240, honest: 0.8289
Round 008: test acc mean=0.8267 ± 0.0110 | min=0.7955 max=0.8413
         : test loss mean=0.5191 ± 0.0296
         : individual accs = ['0.817829', '0.824887', '0.829209', '0.841219', '0.818137', '0.835083', '0.823992', '0.834215', '0.841327', '0.841010', '0.827420', '0.813737', '0.827755', '0.833452', '0.814413', '0.833457', '0.819408', '0.833373', '0.829334', '0.795543']
         : correct/total = [(3376, 4128), (3467, 4203), (3384, 4081), (3645, 4333), (3347, 4091), (3580, 4287), (3455, 4193), (3628, 4349), (3526, 4191), (3597, 4277), (3428, 4143), (3412, 4193), (3388, 4093), (3498, 4197), (3300, 4052), (3358, 4029), (3403, 4153), (3486, 4183), (3387, 4084), (3284, 4128)]
         : compromised: 0.8324, honest: 0.8253
Round 009: test acc mean=0.8340 ± 0.0060 | min=0.8233 max=0.8482
         : test loss mean=0.5034 ± 0.0249
         : individual accs = ['0.828004', '0.824173', '0.831904', '0.835218', '0.833537', '0.829251', '0.838063', '0.845482', '0.848246', '0.831658', '0.835144', '0.828285', '0.839238', '0.833452', '0.823297', '0.836684', '0.836504', '0.835286', '0.835211', '0.831880']
         : correct/total = [(3418, 4128), (3464, 4203), (3395, 4081), (3619, 4333), (3410, 4091), (3555, 4287), (3514, 4193), (3677, 4349), (3555, 4191), (3557, 4277), (3460, 4143), (3473, 4193), (3435, 4093), (3498, 4197), (3336, 4052), (3371, 4029), (3474, 4153), (3494, 4183), (3411, 4084), (3434, 4128)]
         : compromised: 0.8343, honest: 0.8340
Round 010: test acc mean=0.8374 ± 0.0083 | min=0.8186 max=0.8493
         : test loss mean=0.4898 ± 0.0212
         : individual accs = ['0.818556', '0.844397', '0.842441', '0.842603', '0.823515', '0.842314', '0.840687', '0.838354', '0.846815', '0.837737', '0.828868', '0.835679', '0.839238', '0.845604', '0.839585', '0.849342', '0.842042', '0.838872', '0.826641', '0.824128']
         : correct/total = [(3379, 4128), (3549, 4203), (3438, 4081), (3651, 4333), (3369, 4091), (3611, 4287), (3525, 4193), (3646, 4349), (3549, 4191), (3583, 4277), (3434, 4143), (3504, 4193), (3435, 4093), (3549, 4197), (3402, 4052), (3422, 4029), (3497, 4153), (3509, 4183), (3376, 4084), (3402, 4128)]
         : compromised: 0.8415, honest: 0.8363

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 20.0% compromised
Final accuracy - Compromised: 0.8415, Honest: 0.8363
Overall test accuracy: mean=0.8374 ± 0.0083
