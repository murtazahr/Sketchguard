Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.7
  - Stage 1: Distance-based filtering (select 70% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 6 compromised nodes
Round 001: test acc mean=0.6085 ± 0.0757 | min=0.5069 max=0.7158
         : test loss mean=1183.3546 ± 1823.0111
         : individual accs = ['0.589474', '0.667530', '0.608696', '0.639033', '0.587302', '0.514410', '0.697817', '0.623780', '0.690141', '0.708333', '0.530594', '0.635556', '0.522569', '0.506897', '0.517794', '0.694323', '0.715771', '0.508400', '0.522040', '0.689746']
         : correct/total = [(672, 1140), (773, 1158), (686, 1127), (740, 1158), (666, 1134), (589, 1145), (799, 1145), (703, 1127), (784, 1136), (799, 1128), (607, 1144), (715, 1125), (602, 1152), (588, 1160), (582, 1124), (795, 1145), (826, 1154), (575, 1131), (604, 1157), (787, 1141)]
         : compromised: 0.5154, honest: 0.6484
         : ubar stats = ['Node 0: s1=0.684, s2=0.077', 'Node 1: s1=0.684, s2=0.615', 'Node 2: s1=0.684, s2=0.077']...
Round 002: test acc mean=0.6236 ± 0.0932 | min=0.5052 max=0.7692
         : test loss mean=83.5183 ± 169.6218
         : individual accs = ['0.739474', '0.664076', '0.702751', '0.685665', '0.522046', '0.510917', '0.605240', '0.642413', '0.606514', '0.650709', '0.769231', '0.612444', '0.519097', '0.505172', '0.516014', '0.753712', '0.767764', '0.506631', '0.515990', '0.676599']
         : correct/total = [(843, 1140), (769, 1158), (792, 1127), (794, 1158), (592, 1134), (585, 1145), (693, 1145), (724, 1127), (689, 1136), (734, 1128), (880, 1144), (689, 1125), (598, 1152), (586, 1160), (580, 1124), (863, 1145), (886, 1154), (573, 1131), (597, 1157), (772, 1141)]
         : compromised: 0.5123, honest: 0.6713
         : ubar stats = ['Node 0: s1=0.684, s2=0.192', 'Node 1: s1=0.684, s2=0.654', 'Node 2: s1=0.684, s2=0.077']...
Round 003: test acc mean=0.6559 ± 0.1255 | min=0.4774 max=0.8488
         : test loss mean=418498657047.8423 ± 1343425212997.2607
         : individual accs = ['0.821930', '0.685665', '0.811003', '0.713299', '0.577601', '0.485590', '0.679476', '0.657498', '0.709507', '0.718972', '0.848776', '0.686222', '0.477431', '0.504310', '0.497331', '0.828821', '0.745234', '0.491600', '0.477960', '0.700263']
         : correct/total = [(937, 1140), (794, 1158), (914, 1127), (826, 1158), (655, 1134), (556, 1145), (778, 1145), (741, 1127), (806, 1136), (811, 1128), (971, 1144), (772, 1125), (550, 1152), (585, 1160), (559, 1124), (949, 1145), (860, 1154), (556, 1131), (553, 1157), (799, 1141)]
         : compromised: 0.4890, honest: 0.7274
         : ubar stats = ['Node 0: s1=0.684, s2=0.154', 'Node 1: s1=0.684, s2=0.744', 'Node 2: s1=0.684, s2=0.077']...
Round 004: test acc mean=0.7265 ± 0.1422 | min=0.5069 max=0.8741
         : test loss mean=nan ± nan
         : individual accs = ['0.865789', '0.770294', '0.850932', '0.807427', '0.742504', '0.514410', '0.822707', '0.747116', '0.815141', '0.844858', '0.874126', '0.841778', '0.522569', '0.506897', '0.517794', '0.841048', '0.792894', '0.508400', '0.522040', '0.821209']
         : correct/total = [(987, 1140), (892, 1158), (959, 1127), (935, 1158), (842, 1134), (589, 1145), (942, 1145), (842, 1127), (926, 1136), (953, 1128), (1000, 1144), (947, 1125), (602, 1152), (588, 1160), (582, 1124), (963, 1145), (915, 1154), (575, 1131), (604, 1157), (937, 1141)]
         : compromised: 0.5154, honest: 0.8170
         : ubar stats = ['Node 0: s1=0.684, s2=0.135', 'Node 1: s1=0.684, s2=0.769', 'Node 2: s1=0.684, s2=0.115']...
Round 005: test acc mean=0.7580 ± 0.1591 | min=0.5069 max=0.8811
         : test loss mean=nan ± nan
         : individual accs = ['0.850877', '0.872193', '0.858917', '0.875648', '0.835979', '0.514410', '0.868122', '0.857143', '0.857394', '0.867021', '0.881119', '0.859556', '0.522569', '0.506897', '0.517794', '0.855022', '0.857019', '0.508400', '0.522040', '0.871166']
         : correct/total = [(970, 1140), (1010, 1158), (968, 1127), (1014, 1158), (948, 1134), (589, 1145), (994, 1145), (966, 1127), (974, 1136), (978, 1128), (1008, 1144), (967, 1125), (602, 1152), (588, 1160), (582, 1124), (979, 1145), (989, 1154), (575, 1131), (604, 1157), (994, 1141)]
         : compromised: 0.5154, honest: 0.8619
         : ubar stats = ['Node 0: s1=0.684, s2=0.123', 'Node 1: s1=0.684, s2=0.785', 'Node 2: s1=0.684, s2=0.108']...
Round 006: test acc mean=0.7672 ± 0.1654 | min=0.5069 max=0.8921
         : test loss mean=nan ± nan
         : individual accs = ['0.892105', '0.870466', '0.865129', '0.883420', '0.860670', '0.514410', '0.881223', '0.871340', '0.885563', '0.869681', '0.890734', '0.881778', '0.522569', '0.506897', '0.517794', '0.834061', '0.888215', '0.508400', '0.522040', '0.878177']
         : correct/total = [(1017, 1140), (1008, 1158), (975, 1127), (1023, 1158), (976, 1134), (589, 1145), (1009, 1145), (982, 1127), (1006, 1136), (981, 1128), (1019, 1144), (992, 1125), (602, 1152), (588, 1160), (582, 1124), (955, 1145), (1025, 1154), (575, 1131), (604, 1157), (1002, 1141)]
         : compromised: 0.5154, honest: 0.8752
         : ubar stats = ['Node 0: s1=0.684, s2=0.115', 'Node 1: s1=0.684, s2=0.769', 'Node 2: s1=0.684, s2=0.218']...
Round 007: test acc mean=0.7766 ± 0.1712 | min=0.5069 max=0.8995
         : test loss mean=nan ± nan
         : individual accs = ['0.885965', '0.886010', '0.881100', '0.889465', '0.879189', '0.514410', '0.893450', '0.889086', '0.891725', '0.898936', '0.899476', '0.893333', '0.522569', '0.506897', '0.517794', '0.867249', '0.891681', '0.508400', '0.522040', '0.893076']
         : correct/total = [(1010, 1140), (1026, 1158), (993, 1127), (1030, 1158), (997, 1134), (589, 1145), (1023, 1145), (1002, 1127), (1013, 1136), (1014, 1128), (1029, 1144), (1005, 1125), (602, 1152), (588, 1160), (582, 1124), (993, 1145), (1029, 1154), (575, 1131), (604, 1157), (1019, 1141)]
         : compromised: 0.5154, honest: 0.8886
         : ubar stats = ['Node 0: s1=0.684, s2=0.110', 'Node 1: s1=0.684, s2=0.681', 'Node 2: s1=0.684, s2=0.231']...
Round 008: test acc mean=0.7776 ± 0.1719 | min=0.5069 max=0.9049
         : test loss mean=nan ± nan
         : individual accs = ['0.899123', '0.893782', '0.882875', '0.889465', '0.891534', '0.514410', '0.889956', '0.890861', '0.874120', '0.896277', '0.894231', '0.904889', '0.522569', '0.506897', '0.517794', '0.875109', '0.890815', '0.508400', '0.522040', '0.887818']
         : correct/total = [(1025, 1140), (1035, 1158), (995, 1127), (1030, 1158), (1011, 1134), (589, 1145), (1019, 1145), (1004, 1127), (993, 1136), (1011, 1128), (1023, 1144), (1018, 1125), (602, 1152), (588, 1160), (582, 1124), (1002, 1145), (1028, 1154), (575, 1131), (604, 1157), (1013, 1141)]
         : compromised: 0.5154, honest: 0.8901
         : ubar stats = ['Node 0: s1=0.684, s2=0.106', 'Node 1: s1=0.684, s2=0.683', 'Node 2: s1=0.684, s2=0.212']...
Round 009: test acc mean=0.7786 ± 0.1725 | min=0.5069 max=0.9009
         : test loss mean=nan ± nan
         : individual accs = ['0.900877', '0.884283', '0.875776', '0.898964', '0.891534', '0.514410', '0.898690', '0.892635', '0.890845', '0.890071', '0.897727', '0.897778', '0.522569', '0.506897', '0.517794', '0.875983', '0.888215', '0.508400', '0.522040', '0.895706']
         : correct/total = [(1027, 1140), (1024, 1158), (987, 1127), (1041, 1158), (1011, 1134), (589, 1145), (1029, 1145), (1006, 1127), (1012, 1136), (1004, 1128), (1027, 1144), (1010, 1125), (602, 1152), (588, 1160), (582, 1124), (1003, 1145), (1025, 1154), (575, 1131), (604, 1157), (1022, 1141)]
         : compromised: 0.5154, honest: 0.8914
         : ubar stats = ['Node 0: s1=0.684, s2=0.103', 'Node 1: s1=0.684, s2=0.615', 'Node 2: s1=0.684, s2=0.197']...
Round 010: test acc mean=0.7833 ± 0.1755 | min=0.5069 max=0.9070
         : test loss mean=nan ± nan
         : individual accs = ['0.907018', '0.899827', '0.878438', '0.898964', '0.898589', '0.514410', '0.897817', '0.901508', '0.897887', '0.901596', '0.898601', '0.906667', '0.522569', '0.506897', '0.517794', '0.885590', '0.901213', '0.508400', '0.522040', '0.899211']
         : correct/total = [(1034, 1140), (1042, 1158), (990, 1127), (1041, 1158), (1019, 1134), (589, 1145), (1028, 1145), (1016, 1127), (1020, 1136), (1017, 1128), (1028, 1144), (1020, 1125), (602, 1152), (588, 1160), (582, 1124), (1014, 1145), (1040, 1154), (575, 1131), (604, 1157), (1026, 1141)]
         : compromised: 0.5154, honest: 0.8981
         : ubar stats = ['Node 0: s1=0.684, s2=0.100', 'Node 1: s1=0.684, s2=0.608', 'Node 2: s1=0.684, s2=0.185']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: fully, Aggregation: ubar
Attack: backdoor, 30.0% compromised
Final accuracy - Compromised: 0.5154, Honest: 0.8981
Overall test accuracy: mean=0.7833 ± 0.1755

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.6781 ± 0.2118
Honest nodes ASR: 0.5401 ± 0.0257
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== UBAR SUMMARY ===
Node 0: stage1=0.684, stage2=0.100, overall=0.068
Node 1: stage1=0.684, stage2=0.608, overall=0.416
Node 2: stage1=0.684, stage2=0.185, overall=0.126
Node 3: stage1=0.684, stage2=0.331, overall=0.226
Node 4: stage1=0.684, stage2=0.569, overall=0.389
Node 5: stage1=0.684, stage2=0.354, overall=0.242
Node 6: stage1=0.684, stage2=0.338, overall=0.232
Node 7: stage1=0.684, stage2=0.454, overall=0.311
Node 8: stage1=0.684, stage2=0.369, overall=0.253
Node 9: stage1=0.684, stage2=0.408, overall=0.279
Node 10: stage1=0.684, stage2=0.108, overall=0.074
Node 11: stage1=0.684, stage2=0.223, overall=0.153
Node 12: stage1=0.684, stage2=0.354, overall=0.242
Node 13: stage1=0.684, stage2=0.354, overall=0.242
Node 14: stage1=0.684, stage2=0.354, overall=0.242
Node 15: stage1=0.684, stage2=0.115, overall=0.079
Node 16: stage1=0.684, stage2=0.500, overall=0.342
Node 17: stage1=0.684, stage2=0.354, overall=0.242
Node 18: stage1=0.684, stage2=0.354, overall=0.242
Node 19: stage1=0.684, stage2=0.462, overall=0.316

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.051s (17.7%)
    - Loss computation: 0.229s (79.1%)
    - Aggregation: 0.009s (3.2%)
  TOTALS:
    - Total computation: 0.290s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.290s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.048s
  - Loss computation: 0.202s
  - Aggregation: 0.006s
  - Model transfer: 0.000s
  - Total per node: 0.256s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.950s
  - Total loss computation: 4.049s
  - Total aggregation: 0.113s
  - Total model transfer: 0.000s
  - Grand total: 5.113s
  - Mean Stage 1 acceptance rate: 0.684
  - Mean Stage 2 acceptance rate: 0.345
  - Overall acceptance rate: 0.236

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.7
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 70% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
