Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: krum, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5268 ± 0.1203 | min=0.0055 max=0.5776
         : test loss mean=25224.8398 ± 109945.2634
         : individual accs = ['0.553779', '0.564121', '0.546190', '0.555504', '0.553899', '0.577560', '0.552111', '0.566337', '0.005488', '0.540566', '0.535602', '0.548056', '0.553872', '0.568978', '0.566140', '0.554480', '0.533590', '0.558929', '0.573213', '0.527616']
         : correct/total = [(2286, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2266, 4091), (2476, 4287), (2315, 4193), (2463, 4349), (23, 4191), (2312, 4277), (2219, 4143), (2298, 4193), (2267, 4093), (2388, 4197), (2294, 4052), (2234, 4029), (2216, 4153), (2338, 4183), (2341, 4084), (2178, 4128)]
         : compromised: 0.5664, honest: 0.5098
Round 002: test acc mean=0.5303 ± 0.3137 | min=0.0474 max=0.7610
         : test loss mean=nan ± nan
         : individual accs = ['0.712694', '0.743517', '0.722127', '0.734364', '0.735273', '0.052484', '0.761030', '0.752127', '0.051062', '0.733926', '0.732561', '0.739327', '0.047398', '0.047653', '0.054788', '0.735666', '0.722369', '0.739182', '0.054358', '0.733527']
         : correct/total = [(2942, 4128), (3125, 4203), (2947, 4081), (3182, 4333), (3008, 4091), (225, 4287), (3191, 4193), (3271, 4349), (214, 4191), (3139, 4277), (3035, 4143), (3100, 4193), (194, 4093), (200, 4197), (222, 4052), (2964, 4029), (3000, 4153), (3092, 4183), (222, 4084), (3028, 4128)]
         : compromised: 0.1660, honest: 0.6864
Round 003: test acc mean=0.5596 ± 0.3328 | min=0.0474 max=0.7928
         : test loss mean=nan ± nan
         : individual accs = ['0.773014', '0.788246', '0.788042', '0.780291', '0.771450', '0.052484', '0.783926', '0.778340', '0.051062', '0.774375', '0.773594', '0.763892', '0.047398', '0.047653', '0.054788', '0.792753', '0.773417', '0.777193', '0.054358', '0.765746']
         : correct/total = [(3191, 4128), (3313, 4203), (3216, 4081), (3381, 4333), (3156, 4091), (225, 4287), (3287, 4193), (3385, 4349), (214, 4191), (3312, 4277), (3205, 4143), (3203, 4193), (194, 4093), (200, 4197), (222, 4052), (3194, 4029), (3212, 4153), (3251, 4183), (222, 4084), (3161, 4128)]
         : compromised: 0.1723, honest: 0.7256
Round 004: test acc mean=0.5713 ± 0.3405 | min=0.0474 max=0.8089
         : test loss mean=nan ± nan
         : individual accs = ['0.800145', '0.787771', '0.780201', '0.798523', '0.788316', '0.052484', '0.805151', '0.790756', '0.051062', '0.804068', '0.783490', '0.789172', '0.047398', '0.047653', '0.054788', '0.802929', '0.802552', '0.775998', '0.054358', '0.808866']
         : correct/total = [(3303, 4128), (3311, 4203), (3184, 4081), (3460, 4333), (3225, 4091), (225, 4287), (3376, 4193), (3439, 4349), (214, 4191), (3439, 4277), (3246, 4143), (3309, 4193), (194, 4093), (200, 4197), (222, 4052), (3235, 4029), (3333, 4153), (3246, 4183), (222, 4084), (3339, 4128)]
         : compromised: 0.1721, honest: 0.7424
Round 005: test acc mean=0.5851 ± 0.3495 | min=0.0474 max=0.8211
         : test loss mean=nan ± nan
         : individual accs = ['0.810804', '0.817749', '0.814016', '0.819755', '0.813493', '0.052484', '0.818746', '0.815590', '0.051062', '0.821136', '0.815110', '0.808967', '0.047398', '0.047653', '0.054788', '0.816332', '0.794366', '0.814009', '0.054358', '0.813711']
         : correct/total = [(3347, 4128), (3437, 4203), (3322, 4081), (3552, 4333), (3328, 4091), (225, 4287), (3433, 4193), (3547, 4349), (214, 4191), (3512, 4277), (3377, 4143), (3392, 4193), (194, 4093), (200, 4197), (222, 4052), (3289, 4029), (3299, 4153), (3405, 4183), (222, 4084), (3359, 4128)]
         : compromised: 0.1784, honest: 0.7593
Round 006: test acc mean=0.5854 ± 0.3497 | min=0.0474 max=0.8330
         : test loss mean=nan ± nan
         : individual accs = ['0.809835', '0.808708', '0.795148', '0.826910', '0.814960', '0.052484', '0.824708', '0.817889', '0.051062', '0.819500', '0.812213', '0.799905', '0.047398', '0.047653', '0.054788', '0.832961', '0.818926', '0.803729', '0.054358', '0.814438']
         : correct/total = [(3343, 4128), (3399, 4203), (3245, 4081), (3583, 4333), (3334, 4091), (225, 4287), (3458, 4193), (3557, 4349), (214, 4191), (3505, 4277), (3365, 4143), (3354, 4193), (194, 4093), (200, 4197), (222, 4052), (3356, 4029), (3401, 4153), (3362, 4183), (222, 4084), (3362, 4128)]
         : compromised: 0.1767, honest: 0.7605
Round 007: test acc mean=0.5927 ± 0.3545 | min=0.0474 max=0.8362
         : test loss mean=nan ± nan
         : individual accs = ['0.830184', '0.832976', '0.833129', '0.821832', '0.824004', '0.052484', '0.836155', '0.820878', '0.051062', '0.827215', '0.812696', '0.815407', '0.047398', '0.047653', '0.054788', '0.820303', '0.825427', '0.822615', '0.054358', '0.822674']
         : correct/total = [(3427, 4128), (3501, 4203), (3400, 4081), (3561, 4333), (3371, 4091), (225, 4287), (3506, 4193), (3570, 4349), (214, 4191), (3538, 4277), (3367, 4143), (3419, 4193), (194, 4093), (200, 4197), (222, 4052), (3305, 4029), (3428, 4153), (3441, 4183), (222, 4084), (3396, 4128)]
         : compromised: 0.1799, honest: 0.7696
Round 008: test acc mean=0.5951 ± 0.3562 | min=0.0474 max=0.8412
         : test loss mean=nan ± nan
         : individual accs = ['0.824855', '0.840114', '0.834599', '0.841219', '0.831826', '0.052484', '0.836155', '0.838354', '0.051062', '0.836801', '0.823799', '0.831863', '0.047398', '0.047653', '0.054788', '0.819806', '0.810980', '0.829309', '0.054358', '0.795543']
         : correct/total = [(3405, 4128), (3531, 4203), (3406, 4081), (3645, 4333), (3403, 4091), (225, 4287), (3506, 4193), (3646, 4349), (214, 4191), (3579, 4277), (3413, 4143), (3488, 4193), (194, 4093), (200, 4197), (222, 4052), (3303, 4029), (3368, 4153), (3469, 4183), (222, 4084), (3284, 4128)]
         : compromised: 0.1810, honest: 0.7726
Round 009: test acc mean=0.5979 ± 0.3579 | min=0.0474 max=0.8506
         : test loss mean=nan ± nan
         : individual accs = ['0.822917', '0.835594', '0.833864', '0.838911', '0.820337', '0.052484', '0.848796', '0.837434', '0.051062', '0.850596', '0.812937', '0.826377', '0.047398', '0.047653', '0.054788', '0.834202', '0.825427', '0.830504', '0.054358', '0.831880']
         : correct/total = [(3397, 4128), (3512, 4203), (3403, 4081), (3635, 4333), (3356, 4091), (225, 4287), (3559, 4193), (3642, 4349), (214, 4191), (3638, 4277), (3368, 4143), (3465, 4193), (194, 4093), (200, 4197), (222, 4052), (3361, 4029), (3428, 4153), (3474, 4183), (222, 4084), (3434, 4128)]
         : compromised: 0.1812, honest: 0.7765
Round 010: test acc mean=0.5990 ± 0.3586 | min=0.0474 max=0.8455
         : test loss mean=nan ± nan
         : individual accs = ['0.830911', '0.835832', '0.829454', '0.838911', '0.837448', '0.052484', '0.845457', '0.838814', '0.051062', '0.835632', '0.813662', '0.831147', '0.047398', '0.047653', '0.054788', '0.834698', '0.842523', '0.833134', '0.054358', '0.824128']
         : correct/total = [(3430, 4128), (3513, 4203), (3385, 4081), (3635, 4333), (3426, 4091), (225, 4287), (3545, 4193), (3648, 4349), (214, 4191), (3574, 4277), (3371, 4143), (3485, 4193), (194, 4093), (200, 4197), (222, 4052), (3363, 4029), (3499, 4153), (3485, 4183), (222, 4084), (3402, 4128)]
         : compromised: 0.1816, honest: 0.7778

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: krum, 30.0% compromised
Final accuracy - Compromised: 0.1816, Honest: 0.7778
Overall test accuracy: mean=0.5990 ± 0.3586
