Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 2 compromised nodes
Round 001: test acc mean=0.4979 ± 0.0223 | min=0.4515 max=0.5634
         : test loss mean=11.5530 ± 18.9103
         : individual accs = ['0.482456', '0.479275', '0.503993', '0.495682', '0.500882', '0.494323', '0.451528', '0.487134', '0.563380', '0.492908', '0.490385', '0.477333', '0.503472', '0.513793', '0.488434', '0.510917', '0.476603', '0.502210', '0.527226', '0.516214']
         : correct/total = [(550, 1140), (555, 1158), (568, 1127), (574, 1158), (568, 1134), (566, 1145), (517, 1145), (549, 1127), (640, 1136), (556, 1128), (561, 1144), (537, 1125), (580, 1152), (596, 1160), (549, 1124), (585, 1145), (550, 1154), (568, 1131), (610, 1157), (589, 1141)]
         : compromised: 0.5041, honest: 0.4972
Round 002: test acc mean=0.5152 ± 0.0154 | min=0.4920 max=0.5634
         : test loss mean=19.5705 ± 19.7641
         : individual accs = ['0.528070', '0.508636', '0.493345', '0.530225', '0.522928', '0.512664', '0.520524', '0.503106', '0.563380', '0.492021', '0.525350', '0.497778', '0.522569', '0.505172', '0.517794', '0.506550', '0.513865', '0.506631', '0.520311', '0.512708']
         : correct/total = [(602, 1140), (589, 1158), (556, 1127), (614, 1158), (593, 1134), (587, 1145), (596, 1145), (567, 1127), (640, 1136), (555, 1128), (601, 1144), (560, 1125), (602, 1152), (586, 1160), (582, 1124), (580, 1145), (593, 1154), (573, 1131), (602, 1157), (585, 1141)]
         : compromised: 0.5089, honest: 0.5159
Round 003: test acc mean=0.5096 ± 0.0271 | min=0.4629 max=0.5581
         : test loss mean=0.7009 ± 0.0174
         : individual accs = ['0.476316', '0.533679', '0.468500', '0.504318', '0.518519', '0.462882', '0.500437', '0.553682', '0.536972', '0.513298', '0.527098', '0.479111', '0.541667', '0.487069', '0.488434', '0.526638', '0.558059', '0.494253', '0.520311', '0.501315']
         : correct/total = [(543, 1140), (618, 1158), (528, 1127), (584, 1158), (588, 1134), (530, 1145), (573, 1145), (624, 1127), (610, 1136), (579, 1128), (603, 1144), (539, 1125), (624, 1152), (565, 1160), (549, 1124), (603, 1145), (644, 1154), (559, 1131), (602, 1157), (572, 1141)]
         : compromised: 0.4750, honest: 0.5135
Round 004: test acc mean=0.5408 ± 0.0219 | min=0.4960 max=0.5845
         : test loss mean=3.0263 ± 2.3742
         : individual accs = ['0.535965', '0.531952', '0.496007', '0.541451', '0.555556', '0.519651', '0.536245', '0.580302', '0.584507', '0.553191', '0.543706', '0.515556', '0.564236', '0.518103', '0.534698', '0.550218', '0.569324', '0.520778', '0.531547', '0.533742']
         : correct/total = [(611, 1140), (616, 1158), (559, 1127), (627, 1158), (630, 1134), (595, 1145), (614, 1145), (654, 1127), (664, 1136), (624, 1128), (622, 1144), (580, 1125), (650, 1152), (601, 1160), (601, 1124), (630, 1145), (657, 1154), (589, 1131), (615, 1157), (609, 1141)]
         : compromised: 0.5189, honest: 0.5433
Round 005: test acc mean=0.6406 ± 0.0620 | min=0.5324 max=0.7293
         : test loss mean=0.6704 ± 0.2101
         : individual accs = ['0.599123', '0.718480', '0.532387', '0.648532', '0.729277', '0.591266', '0.610480', '0.716060', '0.541373', '0.718085', '0.695804', '0.569778', '0.678819', '0.578448', '0.584520', '0.707424', '0.690641', '0.656057', '0.615385', '0.631025']
         : correct/total = [(683, 1140), (832, 1158), (600, 1127), (751, 1158), (827, 1134), (677, 1145), (699, 1145), (807, 1127), (615, 1136), (810, 1128), (796, 1144), (641, 1125), (782, 1152), (671, 1160), (657, 1124), (810, 1145), (797, 1154), (742, 1131), (712, 1157), (720, 1141)]
         : compromised: 0.5849, honest: 0.6468
Round 006: test acc mean=0.7588 ± 0.0653 | min=0.5942 max=0.8282
         : test loss mean=1.0655 ± 1.3740
         : individual accs = ['0.766667', '0.828152', '0.614020', '0.785838', '0.805996', '0.763319', '0.717904', '0.806566', '0.594190', '0.825355', '0.797203', '0.719111', '0.806424', '0.666379', '0.753559', '0.804367', '0.825823', '0.773652', '0.748487', '0.773883']
         : correct/total = [(874, 1140), (959, 1158), (692, 1127), (910, 1158), (914, 1134), (874, 1145), (822, 1145), (909, 1127), (675, 1136), (931, 1128), (912, 1144), (809, 1125), (929, 1152), (773, 1160), (847, 1124), (921, 1145), (953, 1154), (875, 1131), (866, 1157), (883, 1141)]
         : compromised: 0.7148, honest: 0.7637
Round 007: test acc mean=0.7761 ± 0.0718 | min=0.5669 max=0.8395
         : test loss mean=0.5020 ± 0.2416
         : individual accs = ['0.748246', '0.835924', '0.614907', '0.828152', '0.839506', '0.772052', '0.731878', '0.823425', '0.566901', '0.832447', '0.833916', '0.767111', '0.829861', '0.750862', '0.758007', '0.826201', '0.829289', '0.803714', '0.739844', '0.789658']
         : correct/total = [(853, 1140), (968, 1158), (693, 1127), (959, 1158), (952, 1134), (884, 1145), (838, 1145), (928, 1127), (644, 1136), (939, 1128), (954, 1144), (863, 1125), (956, 1152), (871, 1160), (852, 1124), (946, 1145), (957, 1154), (909, 1131), (856, 1157), (901, 1141)]
         : compromised: 0.7615, honest: 0.7777
Round 008: test acc mean=0.8029 ± 0.0652 | min=0.5951 max=0.8480
         : test loss mean=0.6207 ± 0.6960
         : individual accs = ['0.845614', '0.841105', '0.642413', '0.848014', '0.826279', '0.830568', '0.777293', '0.837622', '0.595070', '0.836879', '0.833916', '0.791111', '0.835069', '0.769828', '0.819395', '0.836681', '0.830156', '0.819629', '0.816768', '0.823839']
         : correct/total = [(964, 1140), (974, 1158), (724, 1127), (982, 1158), (937, 1134), (951, 1145), (890, 1145), (944, 1127), (676, 1136), (944, 1128), (954, 1144), (890, 1125), (962, 1152), (893, 1160), (921, 1124), (958, 1145), (958, 1154), (927, 1131), (945, 1157), (940, 1141)]
         : compromised: 0.8002, honest: 0.8032
Round 009: test acc mean=0.8315 ± 0.0581 | min=0.6285 max=0.8722
         : test loss mean=0.4050 ± 0.1895
         : individual accs = ['0.846491', '0.870466', '0.712511', '0.872193', '0.864198', '0.856769', '0.811354', '0.853594', '0.628521', '0.854610', '0.868881', '0.828444', '0.861111', '0.813793', '0.838968', '0.849782', '0.866551', '0.854111', '0.820225', '0.858019']
         : correct/total = [(965, 1140), (1008, 1158), (803, 1127), (1010, 1158), (980, 1134), (981, 1145), (929, 1145), (962, 1127), (714, 1136), (964, 1128), (994, 1144), (932, 1125), (992, 1152), (944, 1160), (943, 1124), (973, 1145), (1000, 1154), (966, 1131), (949, 1157), (979, 1141)]
         : compromised: 0.8353, honest: 0.8311
Round 010: test acc mean=0.8214 ± 0.0701 | min=0.5889 max=0.8661
         : test loss mean=0.5508 ± 0.6031
         : individual accs = ['0.859649', '0.861831', '0.654836', '0.866149', '0.849206', '0.839301', '0.808734', '0.862467', '0.588908', '0.866135', '0.847902', '0.806222', '0.856771', '0.794828', '0.839858', '0.853275', '0.852686', '0.840849', '0.829732', '0.849255']
         : correct/total = [(980, 1140), (998, 1158), (738, 1127), (1003, 1158), (963, 1134), (961, 1145), (926, 1145), (972, 1127), (669, 1136), (977, 1128), (970, 1144), (907, 1125), (987, 1152), (922, 1160), (944, 1124), (977, 1145), (984, 1154), (951, 1131), (960, 1157), (969, 1141)]
         : compromised: 0.8171, honest: 0.8219

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: backdoor, 10.0% compromised
Final accuracy - Compromised: 0.8171, Honest: 0.8219
Overall test accuracy: mean=0.8214 ± 0.0701

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.5676 ± 0.0978
Honest nodes ASR: 0.5652 ± 0.1021
Compromised nodes ASR: 0.5894 ± 0.0356
Note: Higher ASR indicates more successful backdoor attack
