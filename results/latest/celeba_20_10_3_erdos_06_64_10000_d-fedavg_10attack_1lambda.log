Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.4979 ± 0.0223 | min=0.4515 max=0.5634
         : test loss mean=11.5530 ± 18.9103
         : individual accs = ['0.482456', '0.479275', '0.503993', '0.495682', '0.500882', '0.494323', '0.451528', '0.487134', '0.563380', '0.492908', '0.490385', '0.477333', '0.503472', '0.513793', '0.488434', '0.510917', '0.476603', '0.502210', '0.527226', '0.516214']
         : correct/total = [(550, 1140), (555, 1158), (568, 1127), (574, 1158), (568, 1134), (566, 1145), (517, 1145), (549, 1127), (640, 1136), (556, 1128), (561, 1144), (537, 1125), (580, 1152), (596, 1160), (549, 1124), (585, 1145), (550, 1154), (568, 1131), (610, 1157), (589, 1141)]
         : compromised: 0.5041, honest: 0.4972
Round 002: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=30.6469 ± 32.4588
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5107, honest: 0.5170
Round 003: test acc mean=0.5083 ± 0.0153 | min=0.4705 max=0.5289
         : test loss mean=0.6969 ± 0.0127
         : individual accs = ['0.528947', '0.503454', '0.494232', '0.528497', '0.500000', '0.514410', '0.517904', '0.487134', '0.512324', '0.504433', '0.524476', '0.480889', '0.470486', '0.514655', '0.517794', '0.501310', '0.516464', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (583, 1158), (557, 1127), (612, 1158), (567, 1134), (589, 1145), (593, 1145), (549, 1127), (582, 1136), (569, 1128), (600, 1144), (541, 1125), (542, 1152), (597, 1160), (582, 1124), (574, 1145), (596, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5145, honest: 0.5076
Round 004: test acc mean=0.6314 ± 0.0320 | min=0.5634 max=0.6675
         : test loss mean=1.0586 ± 1.1194
         : individual accs = ['0.661404', '0.652850', '0.563443', '0.667530', '0.658730', '0.656769', '0.589520', '0.615794', '0.595070', '0.617908', '0.664336', '0.609778', '0.583333', '0.612931', '0.652135', '0.654148', '0.599653', '0.663130', '0.658600', '0.651183']
         : correct/total = [(754, 1140), (756, 1158), (635, 1127), (773, 1158), (747, 1134), (752, 1145), (675, 1145), (694, 1127), (676, 1136), (697, 1128), (760, 1144), (686, 1125), (672, 1152), (711, 1160), (733, 1124), (749, 1145), (692, 1154), (750, 1131), (762, 1157), (743, 1141)]
         : compromised: 0.6348, honest: 0.6310
Round 005: test acc mean=0.5498 ± 0.0434 | min=0.5040 max=0.6557
         : test loss mean=0.6910 ± 0.0099
         : individual accs = ['0.528947', '0.569085', '0.503993', '0.521589', '0.591711', '0.515284', '0.517904', '0.655723', '0.548415', '0.622340', '0.527972', '0.518222', '0.584201', '0.510345', '0.520463', '0.581659', '0.618718', '0.519894', '0.522904', '0.517090']
         : correct/total = [(603, 1140), (659, 1158), (568, 1127), (604, 1158), (671, 1134), (590, 1145), (593, 1145), (739, 1127), (623, 1136), (702, 1128), (604, 1144), (583, 1125), (673, 1152), (592, 1160), (585, 1124), (666, 1145), (714, 1154), (588, 1131), (605, 1157), (590, 1141)]
         : compromised: 0.5128, honest: 0.5539
Round 006: test acc mean=0.7810 ± 0.0316 | min=0.6805 max=0.8094
         : test loss mean=0.8160 ± 0.9482
         : individual accs = ['0.801754', '0.791883', '0.711624', '0.805699', '0.800705', '0.808734', '0.767686', '0.766637', '0.680458', '0.796986', '0.809441', '0.794667', '0.789062', '0.758621', '0.794484', '0.785153', '0.785962', '0.790451', '0.785653', '0.794040']
         : correct/total = [(914, 1140), (917, 1158), (802, 1127), (933, 1158), (908, 1134), (926, 1145), (879, 1145), (864, 1127), (773, 1136), (899, 1128), (926, 1144), (894, 1125), (909, 1152), (880, 1160), (893, 1124), (899, 1145), (907, 1154), (894, 1131), (909, 1157), (906, 1141)]
         : compromised: 0.7837, honest: 0.7807
Round 007: test acc mean=0.6745 ± 0.0519 | min=0.5739 max=0.7507
         : test loss mean=0.6577 ± 0.0265
         : individual accs = ['0.657895', '0.712435', '0.574091', '0.674439', '0.731041', '0.681223', '0.606114', '0.750665', '0.573944', '0.724291', '0.696678', '0.628444', '0.731771', '0.618966', '0.658363', '0.718777', '0.739168', '0.682582', '0.662057', '0.666082']
         : correct/total = [(750, 1140), (825, 1158), (647, 1127), (781, 1158), (829, 1134), (780, 1145), (694, 1145), (846, 1127), (652, 1136), (817, 1128), (797, 1144), (707, 1125), (843, 1152), (718, 1160), (740, 1124), (823, 1145), (853, 1154), (772, 1131), (766, 1157), (760, 1141)]
         : compromised: 0.6501, honest: 0.6772
Round 008: test acc mean=0.8271 ± 0.0252 | min=0.7430 max=0.8575
         : test loss mean=0.7627 ± 0.8338
         : individual accs = ['0.826316', '0.857513', '0.777285', '0.842832', '0.824515', '0.846288', '0.820087', '0.826974', '0.742958', '0.835106', '0.852273', '0.830222', '0.829861', '0.821552', '0.829181', '0.833188', '0.831889', '0.824934', '0.835782', '0.852761']
         : correct/total = [(942, 1140), (993, 1158), (876, 1127), (976, 1158), (935, 1134), (969, 1145), (939, 1145), (932, 1127), (844, 1136), (942, 1128), (975, 1144), (934, 1125), (956, 1152), (953, 1160), (932, 1124), (954, 1145), (960, 1154), (933, 1131), (967, 1157), (973, 1141)]
         : compromised: 0.8339, honest: 0.8263
Round 009: test acc mean=0.7592 ± 0.0563 | min=0.6171 max=0.8204
         : test loss mean=0.5755 ± 0.0554
         : individual accs = ['0.756140', '0.820380', '0.626442', '0.773748', '0.792769', '0.786026', '0.712664', '0.804791', '0.617077', '0.795213', '0.811189', '0.711111', '0.797743', '0.712931', '0.746441', '0.800000', '0.806759', '0.793988', '0.745895', '0.773006']
         : correct/total = [(862, 1140), (950, 1158), (706, 1127), (896, 1158), (899, 1134), (900, 1145), (816, 1145), (907, 1127), (701, 1136), (897, 1128), (928, 1144), (800, 1125), (919, 1152), (827, 1160), (839, 1124), (916, 1145), (931, 1154), (898, 1131), (863, 1157), (882, 1141)]
         : compromised: 0.7495, honest: 0.7603
Round 010: test acc mean=0.8416 ± 0.0235 | min=0.7570 max=0.8748
         : test loss mean=0.7255 ± 0.7616
         : individual accs = ['0.854386', '0.874784', '0.803017', '0.859240', '0.843915', '0.851528', '0.834934', '0.841171', '0.757042', '0.843972', '0.855769', '0.845333', '0.848090', '0.841379', '0.843416', '0.848908', '0.845754', '0.839080', '0.840104', '0.859772']
         : correct/total = [(974, 1140), (1013, 1158), (905, 1127), (995, 1158), (957, 1134), (975, 1145), (956, 1145), (948, 1127), (860, 1136), (952, 1128), (979, 1144), (951, 1125), (977, 1152), (976, 1160), (948, 1124), (972, 1145), (976, 1154), (949, 1131), (972, 1157), (981, 1141)]
         : compromised: 0.8465, honest: 0.8410

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: directed_deviation, 10.0% compromised
Final accuracy - Compromised: 0.8465, Honest: 0.8410
Overall test accuracy: mean=0.8416 ± 0.0235
