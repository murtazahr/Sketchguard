Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.7
  - Stage 1: Distance-based filtering (select 70% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 6 compromised nodes
Round 001: test acc mean=0.5825 ± 0.0652 | min=0.5069 max=0.7158
         : test loss mean=1276.8752 ± 2043.5248
         : individual accs = ['0.625439', '0.649396', '0.563443', '0.684801', '0.537919', '0.515284', '0.655022', '0.580302', '0.636444', '0.655142', '0.530594', '0.614222', '0.522569', '0.506897', '0.517794', '0.586900', '0.715771', '0.508400', '0.522040', '0.521472']
         : correct/total = [(713, 1140), (752, 1158), (635, 1127), (793, 1158), (610, 1134), (590, 1145), (750, 1145), (654, 1127), (723, 1136), (739, 1128), (607, 1144), (691, 1125), (602, 1152), (588, 1160), (582, 1124), (672, 1145), (826, 1154), (575, 1131), (604, 1157), (595, 1141)]
         : compromised: 0.5155, honest: 0.6112
         : ubar stats = ['Node 0: s1=0.667, s2=0.250', 'Node 1: s1=0.667, s2=0.750', 'Node 2: s1=0.600, s2=0.333']...
Round 002: test acc mean=0.6615 ± 0.1057 | min=0.4991 max=0.7787
         : test loss mean=182.7590 ± 461.8433
         : individual accs = ['0.731579', '0.707254', '0.688554', '0.745250', '0.585538', '0.514410', '0.743231', '0.658385', '0.757923', '0.757979', '0.771853', '0.778667', '0.522569', '0.499138', '0.518683', '0.725764', '0.734835', '0.508400', '0.516854', '0.762489']
         : correct/total = [(834, 1140), (819, 1158), (776, 1127), (863, 1158), (664, 1134), (589, 1145), (851, 1145), (742, 1127), (861, 1136), (855, 1128), (883, 1144), (876, 1125), (602, 1152), (579, 1160), (583, 1124), (831, 1145), (848, 1154), (575, 1131), (598, 1157), (870, 1141)]
         : compromised: 0.5133, honest: 0.7250
         : ubar stats = ['Node 0: s1=0.667, s2=0.250', 'Node 1: s1=0.667, s2=0.625', 'Node 2: s1=0.600, s2=0.333']...
Round 003: test acc mean=0.7071 ± 0.1500 | min=0.4774 max=0.8593
         : test loss mean=146364176795215.0625 ± 632713087894524.2500
         : individual accs = ['0.833333', '0.793610', '0.816327', '0.846287', '0.683422', '0.503057', '0.792140', '0.703638', '0.840669', '0.835106', '0.859266', '0.824000', '0.477431', '0.493103', '0.483096', '0.775546', '0.767764', '0.491600', '0.477960', '0.844873']
         : correct/total = [(950, 1140), (919, 1158), (920, 1127), (980, 1158), (775, 1134), (576, 1145), (907, 1145), (793, 1127), (955, 1136), (942, 1128), (983, 1144), (927, 1125), (550, 1152), (572, 1160), (543, 1124), (888, 1145), (886, 1154), (556, 1131), (553, 1157), (964, 1141)]
         : compromised: 0.4877, honest: 0.8011
         : ubar stats = ['Node 0: s1=0.667, s2=0.250', 'Node 1: s1=0.667, s2=0.500', 'Node 2: s1=0.600, s2=0.444']...
Round 004: test acc mean=0.7413 ± 0.1532 | min=0.5069 max=0.8865
         : test loss mean=nan ± nan
         : individual accs = ['0.864035', '0.867012', '0.834073', '0.867012', '0.803351', '0.514410', '0.808734', '0.814552', '0.878521', '0.886525', '0.886364', '0.701333', '0.522569', '0.506897', '0.517794', '0.822707', '0.827556', '0.508400', '0.522040', '0.872918']
         : correct/total = [(985, 1140), (1004, 1158), (940, 1127), (1004, 1158), (911, 1134), (589, 1145), (926, 1145), (918, 1127), (998, 1136), (1000, 1128), (1014, 1144), (789, 1125), (602, 1152), (588, 1160), (582, 1124), (942, 1145), (955, 1154), (575, 1131), (604, 1157), (996, 1141)]
         : compromised: 0.5154, honest: 0.8382
         : ubar stats = ['Node 0: s1=0.667, s2=0.250', 'Node 1: s1=0.667, s2=0.438', 'Node 2: s1=0.600, s2=0.417']...
Round 005: test acc mean=0.7618 ± 0.1619 | min=0.5069 max=0.8899
         : test loss mean=nan ± nan
         : individual accs = ['0.861404', '0.868739', '0.834073', '0.888601', '0.854497', '0.514410', '0.868122', '0.853594', '0.884683', '0.883865', '0.889860', '0.865778', '0.522569', '0.506897', '0.517794', '0.848035', '0.864818', '0.508400', '0.522040', '0.877301']
         : correct/total = [(982, 1140), (1006, 1158), (940, 1127), (1029, 1158), (969, 1134), (589, 1145), (994, 1145), (962, 1127), (1005, 1136), (997, 1128), (1018, 1144), (974, 1125), (602, 1152), (588, 1160), (582, 1124), (971, 1145), (998, 1154), (575, 1131), (604, 1157), (1001, 1141)]
         : compromised: 0.5154, honest: 0.8674
         : ubar stats = ['Node 0: s1=0.667, s2=0.400', 'Node 1: s1=0.667, s2=0.400', 'Node 2: s1=0.600, s2=0.467']...
Round 006: test acc mean=0.7623 ± 0.1624 | min=0.5069 max=0.8925
         : test loss mean=nan ± nan
         : individual accs = ['0.857018', '0.879965', '0.836735', '0.875648', '0.855379', '0.514410', '0.840175', '0.856256', '0.889085', '0.875887', '0.892483', '0.885333', '0.522569', '0.506897', '0.517794', '0.848035', '0.876083', '0.508400', '0.522040', '0.885188']
         : correct/total = [(977, 1140), (1019, 1158), (943, 1127), (1014, 1158), (970, 1134), (589, 1145), (962, 1145), (965, 1127), (1010, 1136), (988, 1128), (1021, 1144), (996, 1125), (602, 1152), (588, 1160), (582, 1124), (971, 1145), (1011, 1154), (575, 1131), (604, 1157), (1010, 1141)]
         : compromised: 0.5154, honest: 0.8681
         : ubar stats = ['Node 0: s1=0.667, s2=0.375', 'Node 1: s1=0.667, s2=0.375', 'Node 2: s1=0.600, s2=0.500']...
Round 007: test acc mean=0.7715 ± 0.1682 | min=0.5069 max=0.8989
         : test loss mean=nan ± nan
         : individual accs = ['0.881579', '0.893782', '0.884650', '0.887737', '0.861552', '0.514410', '0.840175', '0.877551', '0.883803', '0.898936', '0.897727', '0.886222', '0.522569', '0.506897', '0.517794', '0.873362', '0.879549', '0.508400', '0.522040', '0.892200']
         : correct/total = [(1005, 1140), (1035, 1158), (997, 1127), (1028, 1158), (977, 1134), (589, 1145), (962, 1145), (989, 1127), (1004, 1136), (1014, 1128), (1027, 1144), (997, 1125), (602, 1152), (588, 1160), (582, 1124), (1000, 1145), (1015, 1154), (575, 1131), (604, 1157), (1018, 1141)]
         : compromised: 0.5154, honest: 0.8813
         : ubar stats = ['Node 0: s1=0.667, s2=0.357', 'Node 1: s1=0.667, s2=0.357', 'Node 2: s1=0.600, s2=0.476']...
Round 008: test acc mean=0.7544 ± 0.1618 | min=0.5069 max=0.8955
         : test loss mean=nan ± nan
         : individual accs = ['0.863158', '0.881693', '0.771961', '0.895509', '0.886243', '0.514410', '0.869869', '0.787045', '0.883803', '0.884752', '0.886364', '0.739556', '0.522569', '0.506897', '0.517794', '0.871616', '0.888215', '0.508400', '0.522040', '0.886065']
         : correct/total = [(984, 1140), (1021, 1158), (870, 1127), (1037, 1158), (1005, 1134), (589, 1145), (996, 1145), (887, 1127), (1004, 1136), (998, 1128), (1014, 1144), (832, 1125), (602, 1152), (588, 1160), (582, 1124), (998, 1145), (1025, 1154), (575, 1131), (604, 1157), (1011, 1141)]
         : compromised: 0.5154, honest: 0.8568
         : ubar stats = ['Node 0: s1=0.667, s2=0.344', 'Node 1: s1=0.667, s2=0.344', 'Node 2: s1=0.600, s2=0.458']...
Round 009: test acc mean=0.7743 ± 0.1702 | min=0.5069 max=0.9048
         : test loss mean=nan ± nan
         : individual accs = ['0.894737', '0.890328', '0.841171', '0.901554', '0.904762', '0.514410', '0.896943', '0.867791', '0.884683', '0.899823', '0.896853', '0.867556', '0.522569', '0.506897', '0.517794', '0.875983', '0.879549', '0.508400', '0.522040', '0.893076']
         : correct/total = [(1020, 1140), (1031, 1158), (948, 1127), (1044, 1158), (1026, 1134), (589, 1145), (1027, 1145), (978, 1127), (1005, 1136), (1015, 1128), (1026, 1144), (976, 1125), (602, 1152), (588, 1160), (582, 1124), (1003, 1145), (1015, 1154), (575, 1131), (604, 1157), (1019, 1141)]
         : compromised: 0.5154, honest: 0.8853
         : ubar stats = ['Node 0: s1=0.667, s2=0.417', 'Node 1: s1=0.667, s2=0.333', 'Node 2: s1=0.600, s2=0.481']...
Round 010: test acc mean=0.7754 ± 0.1708 | min=0.5069 max=0.9059
         : test loss mean=nan ± nan
         : individual accs = ['0.876316', '0.899827', '0.864241', '0.905872', '0.904762', '0.514410', '0.883843', '0.849157', '0.894366', '0.902482', '0.882867', '0.886222', '0.522569', '0.506897', '0.517794', '0.882096', '0.894281', '0.508400', '0.522040', '0.889571']
         : correct/total = [(999, 1140), (1042, 1158), (974, 1127), (1049, 1158), (1026, 1134), (589, 1145), (1012, 1145), (957, 1127), (1016, 1136), (1018, 1128), (1010, 1144), (997, 1125), (602, 1152), (588, 1160), (582, 1124), (1010, 1145), (1032, 1154), (575, 1131), (604, 1157), (1015, 1141)]
         : compromised: 0.5154, honest: 0.8869
         : ubar stats = ['Node 0: s1=0.667, s2=0.400', 'Node 1: s1=0.667, s2=0.400', 'Node 2: s1=0.600, s2=0.467']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: ubar
Attack: backdoor, 30.0% compromised
Final accuracy - Compromised: 0.5154, Honest: 0.8869
Overall test accuracy: mean=0.7754 ± 0.1708

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.6986 ± 0.1996
Honest nodes ASR: 0.5694 ± 0.0356
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== UBAR SUMMARY ===
Node 0: stage1=0.667, stage2=0.400, overall=0.267
Node 1: stage1=0.667, stage2=0.400, overall=0.267
Node 2: stage1=0.600, stage2=0.467, overall=0.280
Node 3: stage1=0.500, stage2=0.500, overall=0.250
Node 4: stage1=0.500, stage2=0.650, overall=0.325
Node 5: stage1=0.600, stage2=0.500, overall=0.300
Node 6: stage1=0.600, stage2=0.633, overall=0.380
Node 7: stage1=0.600, stage2=0.600, overall=0.360
Node 8: stage1=0.500, stage2=1.000, overall=0.500
Node 9: stage1=0.667, stage2=0.550, overall=0.367
Node 10: stage1=0.500, stage2=0.500, overall=0.250
Node 11: stage1=0.571, stage2=0.425, overall=0.243
Node 12: stage1=0.571, stage2=0.475, overall=0.271
Node 13: stage1=0.500, stage2=0.650, overall=0.325
Node 14: stage1=0.571, stage2=0.450, overall=0.257
Node 15: stage1=0.667, stage2=0.275, overall=0.183
Node 16: stage1=0.600, stage2=0.467, overall=0.280
Node 17: stage1=0.600, stage2=0.533, overall=0.320
Node 18: stage1=0.500, stage2=0.650, overall=0.325
Node 19: stage1=0.500, stage2=1.000, overall=0.500

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.020s (9.8%)
    - Loss computation: 0.177s (88.1%)
    - Aggregation: 0.004s (2.1%)
  TOTALS:
    - Total computation: 0.201s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.201s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.013s
  - Loss computation: 0.131s
  - Aggregation: 0.003s
  - Model transfer: 0.000s
  - Total per node: 0.147s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.255s
  - Total loss computation: 2.617s
  - Total aggregation: 0.060s
  - Total model transfer: 0.000s
  - Grand total: 2.932s
  - Mean Stage 1 acceptance rate: 0.574
  - Mean Stage 2 acceptance rate: 0.556
  - Overall acceptance rate: 0.319

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.7
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 70% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
