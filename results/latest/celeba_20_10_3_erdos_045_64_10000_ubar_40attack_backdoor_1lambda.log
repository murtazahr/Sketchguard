Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 8/20 nodes: [1, 5, 11, 12, 13, 14, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.6
  - Stage 1: Distance-based filtering (select 60% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 8 compromised nodes
Round 001: test acc mean=0.5787 ± 0.0649 | min=0.5040 max=0.7074
         : test loss mean=1665.0071 ± 2055.8102
         : individual accs = ['0.625439', '0.508636', '0.637977', '0.639896', '0.524691', '0.514410', '0.655895', '0.585626', '0.573063', '0.648936', '0.579545', '0.504000', '0.522569', '0.506897', '0.517794', '0.707424', '0.630849', '0.508400', '0.522040', '0.660824']
         : correct/total = [(713, 1140), (589, 1158), (719, 1127), (741, 1158), (595, 1134), (589, 1145), (751, 1145), (660, 1127), (651, 1136), (732, 1128), (663, 1144), (567, 1125), (602, 1152), (588, 1160), (582, 1124), (810, 1145), (728, 1154), (575, 1131), (604, 1157), (754, 1141)]
         : compromised: 0.5131, honest: 0.6225
         : ubar stats = ['Node 0: s1=0.583, s2=0.143', 'Node 1: s1=0.600, s2=1.000', 'Node 2: s1=0.500, s2=0.250']...
Round 002: test acc mean=0.6171 ± 0.1035 | min=0.4987 max=0.7764
         : test loss mean=174.0889 ± 326.7322
         : individual accs = ['0.691228', '0.509499', '0.582076', '0.739206', '0.526455', '0.517031', '0.613100', '0.692103', '0.742958', '0.716312', '0.765734', '0.498667', '0.520833', '0.505172', '0.514235', '0.736245', '0.776430', '0.510168', '0.519447', '0.666082']
         : correct/total = [(788, 1140), (590, 1158), (656, 1127), (856, 1158), (597, 1134), (592, 1145), (702, 1145), (780, 1127), (844, 1136), (808, 1128), (876, 1144), (561, 1125), (600, 1152), (586, 1160), (578, 1124), (843, 1145), (896, 1154), (577, 1131), (601, 1157), (760, 1141)]
         : compromised: 0.5119, honest: 0.6873
         : ubar stats = ['Node 0: s1=0.583, s2=0.143', 'Node 1: s1=0.600, s2=1.000', 'Node 2: s1=0.500, s2=0.250']...
Round 003: test acc mean=0.6561 ± 0.1450 | min=0.4773 max=0.8432
         : test loss mean=1076375895943.1487 ± 1824112046815.2671
         : individual accs = ['0.723684', '0.491364', '0.771961', '0.788428', '0.694885', '0.483843', '0.733624', '0.748891', '0.795775', '0.813830', '0.824301', '0.477333', '0.477431', '0.493103', '0.482206', '0.807860', '0.843154', '0.491600', '0.477960', '0.700263']
         : correct/total = [(825, 1140), (569, 1158), (870, 1127), (913, 1158), (788, 1134), (554, 1145), (840, 1145), (844, 1127), (904, 1136), (918, 1128), (943, 1144), (537, 1125), (550, 1152), (572, 1160), (542, 1124), (925, 1145), (973, 1154), (556, 1131), (553, 1157), (799, 1141)]
         : compromised: 0.4844, honest: 0.7706
         : ubar stats = ['Node 0: s1=0.583, s2=0.333', 'Node 1: s1=0.600, s2=1.000', 'Node 2: s1=0.500, s2=0.250']...
Round 004: test acc mean=0.6959 ± 0.1519 | min=0.4987 max=0.8520
         : test loss mean=nan ± nan
         : individual accs = ['0.813158', '0.508636', '0.838509', '0.839378', '0.793651', '0.514410', '0.735371', '0.804791', '0.844190', '0.851950', '0.824301', '0.498667', '0.522569', '0.506897', '0.517794', '0.829694', '0.850087', '0.508400', '0.522040', '0.794040']
         : correct/total = [(927, 1140), (589, 1158), (945, 1127), (972, 1158), (900, 1134), (589, 1145), (842, 1145), (907, 1127), (959, 1136), (961, 1128), (943, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (950, 1145), (981, 1154), (575, 1131), (604, 1157), (906, 1141)]
         : compromised: 0.5124, honest: 0.8183
         : ubar stats = ['Node 0: s1=0.583, s2=0.357', 'Node 1: s1=0.600, s2=0.792', 'Node 2: s1=0.500, s2=0.250']...
Round 005: test acc mean=0.7095 ± 0.1628 | min=0.4987 max=0.8683
         : test loss mean=nan ± nan
         : individual accs = ['0.842105', '0.508636', '0.837622', '0.855786', '0.828924', '0.514410', '0.816594', '0.834073', '0.863556', '0.862589', '0.868007', '0.498667', '0.522569', '0.506897', '0.517794', '0.861135', '0.868284', '0.508400', '0.522040', '0.751972']
         : correct/total = [(960, 1140), (589, 1158), (944, 1127), (991, 1158), (940, 1134), (589, 1145), (935, 1145), (940, 1127), (981, 1136), (973, 1128), (993, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (986, 1145), (1002, 1154), (575, 1131), (604, 1157), (858, 1141)]
         : compromised: 0.5124, honest: 0.8409
         : ubar stats = ['Node 0: s1=0.583, s2=0.400', 'Node 1: s1=0.600, s2=0.667', 'Node 2: s1=0.500, s2=0.250']...
Round 006: test acc mean=0.7152 ± 0.1725 | min=0.4987 max=0.8907
         : test loss mean=nan ± nan
         : individual accs = ['0.878070', '0.508636', '0.864241', '0.648532', '0.858025', '0.514410', '0.868122', '0.850932', '0.879401', '0.854610', '0.890734', '0.498667', '0.522569', '0.506897', '0.517794', '0.866376', '0.887348', '0.508400', '0.522040', '0.858896']
         : correct/total = [(1001, 1140), (589, 1158), (974, 1127), (751, 1158), (973, 1134), (589, 1145), (994, 1145), (959, 1127), (999, 1136), (964, 1128), (1019, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (992, 1145), (1024, 1154), (575, 1131), (604, 1157), (980, 1141)]
         : compromised: 0.5124, honest: 0.8504
         : ubar stats = ['Node 0: s1=0.583, s2=0.381', 'Node 1: s1=0.600, s2=0.583', 'Node 2: s1=0.500, s2=0.292']...
Round 007: test acc mean=0.7311 ± 0.1788 | min=0.4987 max=0.8910
         : test loss mean=nan ± nan
         : individual accs = ['0.883333', '0.508636', '0.878438', '0.879965', '0.880952', '0.514410', '0.870742', '0.858030', '0.874120', '0.890957', '0.879371', '0.498667', '0.522569', '0.506897', '0.517794', '0.857642', '0.890815', '0.508400', '0.522040', '0.878177']
         : correct/total = [(1007, 1140), (589, 1158), (990, 1127), (1019, 1158), (999, 1134), (589, 1145), (997, 1145), (967, 1127), (993, 1136), (1005, 1128), (1006, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (982, 1145), (1028, 1154), (575, 1131), (604, 1157), (1002, 1141)]
         : compromised: 0.5124, honest: 0.8769
         : ubar stats = ['Node 0: s1=0.583, s2=0.347', 'Node 1: s1=0.600, s2=0.524', 'Node 2: s1=0.500, s2=0.286']...
Round 008: test acc mean=0.7333 ± 0.1806 | min=0.4987 max=0.8960
         : test loss mean=nan ± nan
         : individual accs = ['0.894737', '0.508636', '0.878438', '0.867012', '0.890653', '0.514410', '0.882969', '0.878438', '0.862676', '0.888298', '0.874126', '0.498667', '0.522569', '0.506897', '0.517794', '0.878603', '0.896014', '0.508400', '0.522040', '0.874671']
         : correct/total = [(1020, 1140), (589, 1158), (990, 1127), (1004, 1158), (1010, 1134), (589, 1145), (1011, 1145), (990, 1127), (980, 1136), (1002, 1128), (1000, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (1006, 1145), (1034, 1154), (575, 1131), (604, 1157), (998, 1141)]
         : compromised: 0.5124, honest: 0.8806
         : ubar stats = ['Node 0: s1=0.583, s2=0.321', 'Node 1: s1=0.600, s2=0.479', 'Node 2: s1=0.500, s2=0.281']...
Round 009: test acc mean=0.7402 ± 0.1862 | min=0.4987 max=0.9030
         : test loss mean=nan ± nan
         : individual accs = ['0.901754', '0.508636', '0.880213', '0.894646', '0.892416', '0.514410', '0.889083', '0.896185', '0.899648', '0.887411', '0.902972', '0.498667', '0.522569', '0.506897', '0.517794', '0.876856', '0.894281', '0.508400', '0.522040', '0.889571']
         : correct/total = [(1028, 1140), (589, 1158), (992, 1127), (1036, 1158), (1012, 1134), (589, 1145), (1018, 1145), (1010, 1127), (1022, 1136), (1001, 1128), (1033, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (1004, 1145), (1032, 1154), (575, 1131), (604, 1157), (1015, 1141)]
         : compromised: 0.5124, honest: 0.8921
         : ubar stats = ['Node 0: s1=0.583, s2=0.302', 'Node 1: s1=0.600, s2=0.444', 'Node 2: s1=0.500, s2=0.306']...
Round 010: test acc mean=0.7416 ± 0.1874 | min=0.4987 max=0.9070
         : test loss mean=nan ± nan
         : individual accs = ['0.907018', '0.508636', '0.863354', '0.896373', '0.902116', '0.514410', '0.890830', '0.897072', '0.900528', '0.902482', '0.892483', '0.498667', '0.522569', '0.506897', '0.517794', '0.882096', '0.896880', '0.508400', '0.522040', '0.900964']
         : correct/total = [(1034, 1140), (589, 1158), (973, 1127), (1038, 1158), (1023, 1134), (589, 1145), (1020, 1145), (1011, 1127), (1023, 1136), (1018, 1128), (1021, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (1010, 1145), (1035, 1154), (575, 1131), (604, 1157), (1028, 1141)]
         : compromised: 0.5124, honest: 0.8943
         : ubar stats = ['Node 0: s1=0.583, s2=0.286', 'Node 1: s1=0.600, s2=0.417', 'Node 2: s1=0.500, s2=0.300']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: ubar
Attack: backdoor, 40.0% compromised
Final accuracy - Compromised: 0.5124, Honest: 0.8943
Overall test accuracy: mean=0.7416 ± 0.1874

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.7297 ± 0.2220
Honest nodes ASR: 0.5496 ± 0.0313
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== UBAR SUMMARY ===
Node 0: stage1=0.583, stage2=0.286, overall=0.167
Node 1: stage1=0.600, stage2=0.417, overall=0.250
Node 2: stage1=0.500, stage2=0.300, overall=0.150
Node 3: stage1=0.571, stage2=0.425, overall=0.243
Node 4: stage1=0.556, stage2=0.480, overall=0.267
Node 5: stage1=0.600, stage2=0.400, overall=0.240
Node 6: stage1=0.583, stage2=0.457, overall=0.267
Node 7: stage1=0.545, stage2=0.533, overall=0.291
Node 8: stage1=0.571, stage2=0.275, overall=0.157
Node 9: stage1=0.545, stage2=0.317, overall=0.173
Node 10: stage1=0.500, stage2=0.350, overall=0.175
Node 11: stage1=0.583, stage2=0.386, overall=0.225
Node 12: stage1=0.583, stage2=0.400, overall=0.233
Node 13: stage1=0.556, stage2=0.440, overall=0.244
Node 14: stage1=0.571, stage2=0.450, overall=0.257
Node 15: stage1=0.556, stage2=0.200, overall=0.111
Node 16: stage1=0.571, stage2=0.300, overall=0.171
Node 17: stage1=0.500, stage2=0.475, overall=0.237
Node 18: stage1=0.583, stage2=0.400, overall=0.233
Node 19: stage1=0.600, stage2=0.433, overall=0.260

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.038s (15.6%)
    - Loss computation: 0.200s (82.4%)
    - Aggregation: 0.005s (2.0%)
  TOTALS:
    - Total computation: 0.242s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.242s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.025s
  - Loss computation: 0.166s
  - Aggregation: 0.003s
  - Model transfer: 0.000s
  - Total per node: 0.194s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.500s
  - Total loss computation: 3.320s
  - Total aggregation: 0.070s
  - Total model transfer: 0.000s
  - Grand total: 3.890s
  - Mean Stage 1 acceptance rate: 0.563
  - Mean Stage 2 acceptance rate: 0.386
  - Overall acceptance rate: 0.217

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.6
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 60% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
