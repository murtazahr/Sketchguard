Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.8
  - Stage 1: Distance-based filtering (select 80% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 4 compromised nodes
Round 001: test acc mean=0.5986 ± 0.0660 | min=0.5069 max=0.7158
         : test loss mean=762.7269 ± 1538.6006
         : individual accs = ['0.670175', '0.649396', '0.563443', '0.684801', '0.567901', '0.514410', '0.696070', '0.580302', '0.636444', '0.655142', '0.606643', '0.551111', '0.522569', '0.506897', '0.641459', '0.620961', '0.715771', '0.508400', '0.559205', '0.521472']
         : correct/total = [(764, 1140), (752, 1158), (635, 1127), (793, 1158), (644, 1134), (589, 1145), (797, 1145), (654, 1127), (723, 1136), (739, 1128), (694, 1144), (620, 1125), (602, 1152), (588, 1160), (721, 1124), (711, 1145), (826, 1154), (575, 1131), (647, 1157), (595, 1141)]
         : compromised: 0.5131, honest: 0.6200
         : ubar stats = ['Node 0: s1=0.667, s2=0.500', 'Node 1: s1=0.667, s2=0.750', 'Node 2: s1=0.800, s2=0.250']...
Round 002: test acc mean=0.6721 ± 0.0970 | min=0.5026 max=0.7991
         : test loss mean=38.1027 ± 100.1248
         : individual accs = ['0.695614', '0.674439', '0.688554', '0.729706', '0.524691', '0.513537', '0.799127', '0.662822', '0.734155', '0.757979', '0.701049', '0.728000', '0.524306', '0.502586', '0.672598', '0.767686', '0.751300', '0.508400', '0.764045', '0.740578']
         : correct/total = [(793, 1140), (781, 1158), (776, 1127), (845, 1158), (595, 1134), (588, 1145), (915, 1145), (747, 1127), (834, 1136), (855, 1128), (802, 1144), (819, 1125), (604, 1152), (583, 1160), (756, 1124), (879, 1145), (867, 1154), (575, 1131), (884, 1157), (845, 1141)]
         : compromised: 0.5122, honest: 0.7120
         : ubar stats = ['Node 0: s1=0.667, s2=0.750', 'Node 1: s1=0.667, s2=0.750', 'Node 2: s1=0.800, s2=0.250']...
Round 003: test acc mean=0.7219 ± 0.1316 | min=0.4774 max=0.8379
         : test loss mean=41393385657.4478 ± 121240447637.7965
         : individual accs = ['0.811404', '0.765112', '0.815439', '0.786701', '0.564374', '0.485590', '0.774672', '0.779059', '0.830986', '0.831560', '0.801573', '0.810667', '0.477431', '0.508621', '0.751779', '0.827948', '0.826690', '0.491600', '0.658600', '0.837862']
         : correct/total = [(925, 1140), (886, 1158), (919, 1127), (911, 1158), (640, 1134), (556, 1145), (887, 1145), (878, 1127), (944, 1136), (938, 1128), (917, 1144), (912, 1125), (550, 1152), (590, 1160), (845, 1124), (948, 1145), (954, 1154), (556, 1131), (762, 1157), (956, 1141)]
         : compromised: 0.4908, honest: 0.7797
         : ubar stats = ['Node 0: s1=0.667, s2=0.750', 'Node 1: s1=0.667, s2=0.750', 'Node 2: s1=0.800, s2=0.250']...
Round 004: test acc mean=0.7566 ± 0.1314 | min=0.5069 max=0.8679
         : test loss mean=nan ± nan
         : individual accs = ['0.851754', '0.859240', '0.857143', '0.844560', '0.698413', '0.514410', '0.781659', '0.716060', '0.867077', '0.867908', '0.841783', '0.846222', '0.522569', '0.506897', '0.782028', '0.734498', '0.841421', '0.508400', '0.825411', '0.865031']
         : correct/total = [(971, 1140), (995, 1158), (966, 1127), (978, 1158), (792, 1134), (589, 1145), (895, 1145), (807, 1127), (985, 1136), (979, 1128), (963, 1144), (952, 1125), (602, 1152), (588, 1160), (879, 1124), (841, 1145), (971, 1154), (575, 1131), (955, 1157), (987, 1141)]
         : compromised: 0.5131, honest: 0.8175
         : ubar stats = ['Node 0: s1=0.667, s2=0.625', 'Node 1: s1=0.667, s2=0.625', 'Node 2: s1=0.800, s2=0.250']...
Round 005: test acc mean=0.7732 ± 0.1464 | min=0.5069 max=0.8916
         : test loss mean=nan ± nan
         : individual accs = ['0.831579', '0.862694', '0.565217', '0.876511', '0.826279', '0.514410', '0.870742', '0.855368', '0.882923', '0.875887', '0.891608', '0.872889', '0.522569', '0.506897', '0.801601', '0.853275', '0.807626', '0.508400', '0.855661', '0.881683']
         : correct/total = [(948, 1140), (999, 1158), (637, 1127), (1015, 1158), (937, 1134), (589, 1145), (997, 1145), (964, 1127), (1003, 1136), (988, 1128), (1020, 1144), (982, 1125), (602, 1152), (588, 1160), (901, 1124), (977, 1145), (932, 1154), (575, 1131), (990, 1157), (1006, 1141)]
         : compromised: 0.5131, honest: 0.8382
         : ubar stats = ['Node 0: s1=0.667, s2=0.550', 'Node 1: s1=0.667, s2=0.600', 'Node 2: s1=0.800, s2=0.250']...
Round 006: test acc mean=0.7940 ± 0.1412 | min=0.5069 max=0.8899
         : test loss mean=nan ± nan
         : individual accs = ['0.858772', '0.871330', '0.832298', '0.867012', '0.860670', '0.514410', '0.842795', '0.869565', '0.889085', '0.860816', '0.889860', '0.879111', '0.522569', '0.506897', '0.845196', '0.851528', '0.869151', '0.508400', '0.856525', '0.883436']
         : correct/total = [(979, 1140), (1009, 1158), (938, 1127), (1004, 1158), (976, 1134), (589, 1145), (965, 1145), (980, 1127), (1010, 1136), (971, 1128), (1018, 1144), (989, 1125), (602, 1152), (588, 1160), (950, 1124), (975, 1145), (1003, 1154), (575, 1131), (991, 1157), (1008, 1141)]
         : compromised: 0.5131, honest: 0.8642
         : ubar stats = ['Node 0: s1=0.667, s2=0.500', 'Node 1: s1=0.667, s2=0.625', 'Node 2: s1=0.800, s2=0.375']...
Round 007: test acc mean=0.7831 ± 0.1409 | min=0.5069 max=0.8886
         : test loss mean=nan ± nan
         : individual accs = ['0.880702', '0.888601', '0.865129', '0.822107', '0.803351', '0.514410', '0.884716', '0.738243', '0.871479', '0.888298', '0.766608', '0.885333', '0.522569', '0.506897', '0.864769', '0.853275', '0.886482', '0.508400', '0.826275', '0.883436']
         : correct/total = [(1004, 1140), (1029, 1158), (975, 1127), (952, 1158), (911, 1134), (589, 1145), (1013, 1145), (832, 1127), (990, 1136), (1002, 1128), (877, 1144), (996, 1125), (602, 1152), (588, 1160), (972, 1124), (977, 1145), (1023, 1154), (575, 1131), (956, 1157), (1008, 1141)]
         : compromised: 0.5131, honest: 0.8506
         : ubar stats = ['Node 0: s1=0.667, s2=0.464', 'Node 1: s1=0.667, s2=0.571', 'Node 2: s1=0.800, s2=0.357']...
Round 008: test acc mean=0.8020 ± 0.1451 | min=0.5069 max=0.8924
         : test loss mean=nan ± nan
         : individual accs = ['0.875439', '0.886010', '0.858917', '0.827288', '0.876543', '0.514410', '0.875109', '0.877551', '0.874120', '0.868794', '0.868881', '0.892444', '0.522569', '0.506897', '0.892349', '0.871616', '0.888215', '0.508400', '0.873812', '0.880806']
         : correct/total = [(998, 1140), (1026, 1158), (968, 1127), (958, 1158), (994, 1134), (589, 1145), (1002, 1145), (989, 1127), (993, 1136), (980, 1128), (994, 1144), (1004, 1125), (602, 1152), (588, 1160), (1003, 1124), (998, 1145), (1025, 1154), (575, 1131), (1011, 1157), (1005, 1141)]
         : compromised: 0.5131, honest: 0.8742
         : ubar stats = ['Node 0: s1=0.667, s2=0.438', 'Node 1: s1=0.667, s2=0.562', 'Node 2: s1=0.800, s2=0.344']...
Round 009: test acc mean=0.8066 ± 0.1472 | min=0.5069 max=0.8986
         : test loss mean=nan ± nan
         : individual accs = ['0.888596', '0.896373', '0.859805', '0.883420', '0.864198', '0.514410', '0.866376', '0.881100', '0.889085', '0.890071', '0.898601', '0.878222', '0.522569', '0.506897', '0.872776', '0.875983', '0.888215', '0.508400', '0.856525', '0.889571']
         : correct/total = [(1013, 1140), (1038, 1158), (969, 1127), (1023, 1158), (980, 1134), (589, 1145), (992, 1145), (993, 1127), (1010, 1136), (1004, 1128), (1028, 1144), (988, 1125), (602, 1152), (588, 1160), (981, 1124), (1003, 1145), (1025, 1154), (575, 1131), (991, 1157), (1015, 1141)]
         : compromised: 0.5131, honest: 0.8799
         : ubar stats = ['Node 0: s1=0.667, s2=0.417', 'Node 1: s1=0.667, s2=0.611', 'Node 2: s1=0.800, s2=0.333']...
Round 010: test acc mean=0.8139 ± 0.1507 | min=0.5069 max=0.9041
         : test loss mean=nan ± nan
         : individual accs = ['0.894737', '0.904145', '0.873114', '0.898964', '0.890653', '0.514410', '0.878603', '0.887311', '0.891725', '0.892730', '0.902972', '0.896889', '0.522569', '0.506897', '0.896797', '0.875109', '0.876950', '0.508400', '0.869490', '0.894829']
         : correct/total = [(1020, 1140), (1047, 1158), (984, 1127), (1041, 1158), (1010, 1134), (589, 1145), (1006, 1145), (1000, 1127), (1013, 1136), (1007, 1128), (1033, 1144), (1009, 1125), (602, 1152), (588, 1160), (1008, 1124), (1002, 1145), (1012, 1154), (575, 1131), (1006, 1157), (1021, 1141)]
         : compromised: 0.5131, honest: 0.8891
         : ubar stats = ['Node 0: s1=0.667, s2=0.400', 'Node 1: s1=0.667, s2=0.575', 'Node 2: s1=0.800, s2=0.325']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: ubar
Attack: backdoor, 20.0% compromised
Final accuracy - Compromised: 0.5131, Honest: 0.8891
Overall test accuracy: mean=0.8139 ± 0.1507

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.6441 ± 0.1796
Honest nodes ASR: 0.5551 ± 0.0270
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== UBAR SUMMARY ===
Node 0: stage1=0.667, stage2=0.400, overall=0.267
Node 1: stage1=0.667, stage2=0.575, overall=0.383
Node 2: stage1=0.800, stage2=0.325, overall=0.260
Node 3: stage1=0.750, stage2=0.567, overall=0.425
Node 4: stage1=0.750, stage2=0.667, overall=0.500
Node 5: stage1=0.800, stage2=0.425, overall=0.340
Node 6: stage1=0.800, stage2=0.475, overall=0.380
Node 7: stage1=0.800, stage2=0.375, overall=0.300
Node 8: stage1=0.500, stage2=1.000, overall=0.500
Node 9: stage1=0.667, stage2=0.500, overall=0.333
Node 10: stage1=0.750, stage2=0.500, overall=0.375
Node 11: stage1=0.714, stage2=0.400, overall=0.286
Node 12: stage1=0.714, stage2=0.440, overall=0.314
Node 13: stage1=0.750, stage2=0.533, overall=0.400
Node 14: stage1=0.714, stage2=0.500, overall=0.357
Node 15: stage1=0.667, stage2=0.325, overall=0.217
Node 16: stage1=0.800, stage2=0.325, overall=0.260
Node 17: stage1=0.800, stage2=0.475, overall=0.380
Node 18: stage1=0.750, stage2=0.500, overall=0.375
Node 19: stage1=0.500, stage2=1.000, overall=0.500

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.018s (9.0%)
    - Loss computation: 0.178s (86.8%)
    - Aggregation: 0.009s (4.3%)
  TOTALS:
    - Total computation: 0.206s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.206s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.013s
  - Loss computation: 0.135s
  - Aggregation: 0.004s
  - Model transfer: 0.000s
  - Total per node: 0.152s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.258s
  - Total loss computation: 2.707s
  - Total aggregation: 0.074s
  - Total model transfer: 0.000s
  - Grand total: 3.039s
  - Mean Stage 1 acceptance rate: 0.718
  - Mean Stage 2 acceptance rate: 0.515
  - Overall acceptance rate: 0.370

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.8
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 80% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
