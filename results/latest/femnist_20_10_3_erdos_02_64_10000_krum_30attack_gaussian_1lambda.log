Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5352 ± 0.0853 | min=0.1740 max=0.5949
         : test loss mean=1.7798 ± 0.5228
         : individual accs = ['0.542878', '0.555556', '0.546190', '0.534964', '0.553899', '0.577560', '0.543763', '0.556450', '0.586018', '0.173954', '0.508810', '0.546148', '0.553872', '0.594949', '0.576012', '0.554480', '0.533590', '0.566818', '0.569540', '0.527616']
         : correct/total = [(2241, 4128), (2335, 4203), (2229, 4081), (2318, 4333), (2266, 4091), (2476, 4287), (2280, 4193), (2420, 4349), (2456, 4191), (744, 4277), (2108, 4143), (2290, 4193), (2267, 4093), (2497, 4197), (2334, 4052), (2234, 4029), (2216, 4153), (2371, 4183), (2326, 4084), (2178, 4128)]
         : compromised: 0.5731, honest: 0.5189
Round 002: test acc mean=0.7371 ± 0.0187 | min=0.6878 max=0.7639
         : test loss mean=0.9678 ± 0.4568
         : individual accs = ['0.742248', '0.743517', '0.734624', '0.757443', '0.711806', '0.763937', '0.754591', '0.734882', '0.731806', '0.696049', '0.741974', '0.687813', '0.740288', '0.751489', '0.754195', '0.735666', '0.735131', '0.746115', '0.745103', '0.733527']
         : correct/total = [(3064, 4128), (3125, 4203), (2998, 4081), (3282, 4333), (2912, 4091), (3275, 4287), (3164, 4193), (3196, 4349), (3067, 4191), (2977, 4277), (3074, 4143), (2884, 4193), (3030, 4093), (3154, 4197), (3056, 4052), (2964, 4029), (3053, 4153), (3121, 4183), (3043, 4084), (3028, 4128)]
         : compromised: 0.7502, honest: 0.7315
Round 003: test acc mean=0.7709 ± 0.0154 | min=0.7225 max=0.7935
         : test loss mean=0.8301 ± 0.4954
         : individual accs = ['0.774225', '0.793481', '0.777015', '0.785137', '0.764605', '0.769769', '0.786072', '0.776040', '0.786447', '0.722469', '0.772146', '0.750775', '0.773271', '0.759828', '0.772952', '0.790271', '0.758488', '0.773368', '0.766405', '0.765746']
         : correct/total = [(3196, 4128), (3335, 4203), (3171, 4081), (3402, 4333), (3128, 4091), (3300, 4287), (3296, 4193), (3375, 4349), (3296, 4191), (3090, 4277), (3199, 4143), (3148, 4193), (3165, 4093), (3189, 4197), (3132, 4052), (3184, 4029), (3150, 4153), (3235, 4183), (3130, 4084), (3161, 4128)]
         : compromised: 0.7693, honest: 0.7716
Round 004: test acc mean=0.7990 ± 0.0090 | min=0.7825 max=0.8172
         : test loss mean=0.6630 ± 0.1156
         : individual accs = ['0.799661', '0.798001', '0.799069', '0.799215', '0.793693', '0.788197', '0.806105', '0.810991', '0.817227', '0.803367', '0.797248', '0.782495', '0.789152', '0.805814', '0.787266', '0.812857', '0.793884', '0.794406', '0.792116', '0.808866']
         : correct/total = [(3301, 4128), (3354, 4203), (3261, 4081), (3463, 4333), (3247, 4091), (3379, 4287), (3380, 4193), (3527, 4349), (3425, 4191), (3436, 4277), (3303, 4143), (3281, 4193), (3230, 4093), (3382, 4197), (3190, 4052), (3275, 4029), (3297, 4153), (3323, 4183), (3235, 4084), (3339, 4128)]
         : compromised: 0.7928, honest: 0.8016
Round 005: test acc mean=0.8076 ± 0.0106 | min=0.7887 max=0.8270
         : test loss mean=0.5902 ± 0.0351
         : individual accs = ['0.792636', '0.804901', '0.801274', '0.813293', '0.808849', '0.793795', '0.808490', '0.821108', '0.827010', '0.826280', '0.816799', '0.800859', '0.800880', '0.798666', '0.811451', '0.797468', '0.809535', '0.815922', '0.788688', '0.813711']
         : correct/total = [(3272, 4128), (3383, 4203), (3270, 4081), (3524, 4333), (3309, 4091), (3403, 4287), (3390, 4193), (3571, 4349), (3466, 4191), (3534, 4277), (3384, 4143), (3358, 4193), (3278, 4093), (3352, 4197), (3288, 4052), (3213, 4029), (3362, 4153), (3413, 4183), (3221, 4084), (3359, 4128)]
         : compromised: 0.8016, honest: 0.8102
Round 006: test acc mean=0.8204 ± 0.0081 | min=0.8107 max=0.8417
         : test loss mean=0.5538 ± 0.0291
         : individual accs = ['0.819525', '0.828456', '0.816222', '0.828294', '0.820093', '0.811523', '0.826616', '0.826167', '0.831544', '0.841711', '0.813662', '0.814930', '0.814561', '0.812962', '0.828727', '0.818814', '0.813147', '0.815922', '0.810725', '0.814438']
         : correct/total = [(3383, 4128), (3482, 4203), (3331, 4081), (3589, 4333), (3355, 4091), (3479, 4287), (3466, 4193), (3593, 4349), (3485, 4191), (3600, 4277), (3371, 4143), (3417, 4193), (3334, 4093), (3412, 4197), (3358, 4052), (3299, 4029), (3377, 4153), (3413, 4183), (3311, 4084), (3362, 4128)]
         : compromised: 0.8157, honest: 0.8224
Round 007: test acc mean=0.8284 ± 0.0091 | min=0.8122 max=0.8548
         : test loss mean=0.5281 ± 0.0297
         : individual accs = ['0.822674', '0.834166', '0.832394', '0.826448', '0.819360', '0.815722', '0.830432', '0.832375', '0.841804', '0.854805', '0.825006', '0.830909', '0.825312', '0.828925', '0.812192', '0.834947', '0.821575', '0.827636', '0.828355', '0.822674']
         : correct/total = [(3396, 4128), (3506, 4203), (3397, 4081), (3581, 4333), (3352, 4091), (3497, 4287), (3482, 4193), (3620, 4349), (3528, 4191), (3656, 4277), (3418, 4143), (3484, 4193), (3378, 4093), (3479, 4197), (3291, 4052), (3364, 4029), (3412, 4153), (3462, 4183), (3383, 4084), (3396, 4128)]
         : compromised: 0.8230, honest: 0.8307
Round 008: test acc mean=0.8304 ± 0.0125 | min=0.7955 max=0.8553
         : test loss mean=0.5125 ± 0.0319
         : individual accs = ['0.828004', '0.829645', '0.835334', '0.842834', '0.815449', '0.839282', '0.835917', '0.834675', '0.840849', '0.855272', '0.827420', '0.839494', '0.823601', '0.839409', '0.816634', '0.817573', '0.824223', '0.832656', '0.833986', '0.795543']
         : correct/total = [(3418, 4128), (3487, 4203), (3409, 4081), (3652, 4333), (3336, 4091), (3598, 4287), (3505, 4193), (3630, 4349), (3524, 4191), (3658, 4277), (3428, 4143), (3520, 4193), (3371, 4093), (3523, 4197), (3309, 4052), (3294, 4029), (3423, 4153), (3483, 4183), (3406, 4084), (3284, 4128)]
         : compromised: 0.8309, honest: 0.8302
Round 009: test acc mean=0.8343 ± 0.0111 | min=0.8154 max=0.8567
         : test loss mean=0.5032 ± 0.0335
         : individual accs = ['0.815407', '0.849393', '0.844156', '0.839603', '0.837937', '0.825986', '0.839971', '0.843872', '0.846099', '0.856675', '0.835144', '0.826616', '0.823357', '0.816297', '0.837364', '0.840407', '0.819889', '0.833612', '0.823213', '0.831880']
         : correct/total = [(3366, 4128), (3570, 4203), (3445, 4081), (3638, 4333), (3428, 4091), (3541, 4287), (3522, 4193), (3670, 4349), (3546, 4191), (3664, 4277), (3460, 4143), (3466, 4193), (3370, 4093), (3426, 4197), (3393, 4052), (3386, 4029), (3405, 4153), (3487, 4183), (3362, 4084), (3434, 4128)]
         : compromised: 0.8266, honest: 0.8376
Round 010: test acc mean=0.8362 ± 0.0094 | min=0.8189 max=0.8623
         : test loss mean=0.5001 ± 0.0310
         : individual accs = ['0.834302', '0.832739', '0.835825', '0.840526', '0.818871', '0.825286', '0.840687', '0.838584', '0.842520', '0.862287', '0.828868', '0.831863', '0.834351', '0.836550', '0.837611', '0.852569', '0.842764', '0.832656', '0.831048', '0.824128']
         : correct/total = [(3444, 4128), (3500, 4203), (3411, 4081), (3642, 4333), (3350, 4091), (3538, 4287), (3525, 4193), (3647, 4349), (3531, 4191), (3688, 4277), (3434, 4143), (3488, 4193), (3415, 4093), (3511, 4197), (3394, 4052), (3435, 4029), (3500, 4153), (3483, 4183), (3394, 4084), (3402, 4128)]
         : compromised: 0.8329, honest: 0.8376

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 30.0% compromised
Final accuracy - Compromised: 0.8329, Honest: 0.8376
Overall test accuracy: mean=0.8362 ± 0.0094
