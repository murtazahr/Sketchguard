Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 8/20 nodes: [1, 5, 11, 12, 13, 14, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 4
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Backdoor attack: Created poisoned datasets for 8 compromised nodes
Round 001: test acc mean=0.3075 ± 0.2684 | min=0.0020 max=0.5732
         : test loss mean=40232.0001 ± 81859.8483
         : individual accs = ['0.562742', '0.564121', '0.531977', '0.007847', '0.004155', '0.004899', '0.534701', '0.005748', '0.030780', '0.540566', '0.535602', '0.025757', '0.553872', '0.003812', '0.566140', '0.001986', '0.014929', '0.558929', '0.573213', '0.527616']
         : correct/total = [(2323, 4128), (2371, 4203), (2171, 4081), (34, 4333), (17, 4091), (21, 4287), (2242, 4193), (25, 4349), (129, 4191), (2312, 4277), (2219, 4143), (108, 4193), (2267, 4093), (16, 4197), (2294, 4052), (8, 4029), (62, 4153), (2338, 4183), (2341, 4084), (2178, 4128)]
         : compromised: 0.3563, honest: 0.2749
Round 002: test acc mean=0.2541 ± 0.3134 | min=0.0383 max=0.7491
         : test loss mean=nan ± nan
         : individual accs = ['0.717297', '0.048775', '0.738054', '0.049619', '0.047910', '0.052484', '0.749106', '0.050126', '0.038893', '0.734627', '0.732561', '0.050560', '0.047398', '0.054801', '0.054788', '0.054604', '0.047436', '0.049247', '0.724535', '0.038275']
         : correct/total = [(2961, 4128), (205, 4203), (3012, 4081), (215, 4333), (196, 4091), (225, 4287), (3141, 4193), (218, 4349), (163, 4191), (3142, 4277), (3035, 4143), (212, 4193), (194, 4093), (230, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (2959, 4084), (158, 4128)]
         : compromised: 0.1353, honest: 0.3332
Round 003: test acc mean=0.1951 ± 0.2928 | min=0.0351 max=0.7861
         : test loss mean=nan ± nan
         : individual accs = ['0.773498', '0.048775', '0.784612', '0.039926', '0.047910', '0.052018', '0.786072', '0.046907', '0.057266', '0.777882', '0.048274', '0.035058', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.047965']
         : correct/total = [(3193, 4128), (205, 4203), (3202, 4081), (173, 4333), (196, 4091), (223, 4287), (3296, 4193), (204, 4349), (240, 4191), (3327, 4277), (200, 4143), (147, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (198, 4128)]
         : compromised: 0.0487, honest: 0.2927
Round 004: test acc mean=0.1648 ± 0.2704 | min=0.0474 max=0.8145
         : test loss mean=nan ± nan
         : individual accs = ['0.802810', '0.048775', '0.049988', '0.047542', '0.047910', '0.052018', '0.814453', '0.052656', '0.057266', '0.808043', '0.051895', '0.049845', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.057413']
         : correct/total = [(3314, 4128), (205, 4203), (204, 4081), (206, 4333), (196, 4091), (223, 4287), (3415, 4193), (229, 4349), (240, 4191), (3456, 4277), (215, 4143), (209, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (237, 4128)]
         : compromised: 0.0505, honest: 0.2410
Round 005: test acc mean=0.1651 ± 0.2730 | min=0.0465 max=0.8237
         : test loss mean=nan ± nan
         : individual accs = ['0.813469', '0.048775', '0.049988', '0.047542', '0.047910', '0.052018', '0.807775', '0.046907', '0.057266', '0.823708', '0.052860', '0.051514', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.046512']
         : correct/total = [(3358, 4128), (205, 4203), (204, 4081), (206, 4333), (196, 4091), (223, 4287), (3387, 4193), (204, 4349), (240, 4191), (3523, 4277), (219, 4143), (216, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (192, 4128)]
         : compromised: 0.0507, honest: 0.2413
Round 006: test acc mean=0.1672 ± 0.2747 | min=0.0469 max=0.8289
         : test loss mean=nan ± nan
         : individual accs = ['0.817345', '0.048775', '0.061505', '0.047542', '0.047910', '0.052018', '0.816838', '0.046907', '0.057266', '0.828852', '0.051171', '0.054853', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.057413']
         : correct/total = [(3374, 4128), (205, 4203), (251, 4081), (206, 4333), (196, 4091), (223, 4287), (3425, 4193), (204, 4349), (240, 4191), (3545, 4277), (212, 4143), (230, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (237, 4128)]
         : compromised: 0.0511, honest: 0.2446
Round 007: test acc mean=0.1681 ± 0.2769 | min=0.0446 max=0.8285
         : test loss mean=nan ± nan
         : individual accs = ['0.828488', '0.048775', '0.061505', '0.047542', '0.052066', '0.052018', '0.824708', '0.044608', '0.057266', '0.828151', '0.051895', '0.051514', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.057413']
         : correct/total = [(3420, 4128), (205, 4203), (251, 4081), (206, 4333), (213, 4091), (223, 4287), (3458, 4193), (194, 4349), (240, 4191), (3542, 4277), (215, 4143), (216, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (237, 4128)]
         : compromised: 0.0507, honest: 0.2463
Round 008: test acc mean=0.1297 ± 0.2331 | min=0.0474 max=0.8335
         : test loss mean=nan ± nan
         : individual accs = ['0.824128', '0.048775', '0.061505', '0.049850', '0.052066', '0.052018', '0.833532', '0.052656', '0.057266', '0.048632', '0.051895', '0.051514', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.054990']
         : correct/total = [(3402, 4128), (205, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (3495, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (216, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (227, 4128)]
         : compromised: 0.0507, honest: 0.1824
Round 009: test acc mean=0.1294 ± 0.2335 | min=0.0469 max=0.8300
         : test loss mean=nan ± nan
         : individual accs = ['0.829457', '0.048775', '0.061505', '0.048004', '0.052066', '0.052018', '0.829955', '0.046907', '0.057266', '0.048632', '0.051895', '0.051514', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.054990']
         : correct/total = [(3424, 4128), (205, 4203), (251, 4081), (208, 4333), (213, 4091), (223, 4287), (3480, 4193), (204, 4349), (240, 4191), (208, 4277), (215, 4143), (216, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (227, 4128)]
         : compromised: 0.0507, honest: 0.1819
Round 010: test acc mean=0.1296 ± 0.2371 | min=0.0469 max=0.8464
         : test loss mean=nan ± nan
         : individual accs = ['0.835029', '0.048775', '0.049988', '0.047542', '0.052066', '0.052018', '0.846411', '0.046907', '0.051062', '0.048632', '0.051895', '0.050560', '0.047398', '0.047653', '0.054788', '0.054604', '0.047436', '0.049247', '0.054358', '0.054990']
         : correct/total = [(3447, 4128), (205, 4203), (204, 4081), (206, 4333), (213, 4091), (223, 4287), (3549, 4193), (204, 4349), (214, 4191), (208, 4277), (215, 4143), (212, 4193), (194, 4093), (200, 4197), (222, 4052), (220, 4029), (197, 4153), (206, 4183), (222, 4084), (227, 4128)]
         : compromised: 0.0506, honest: 0.1822

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: backdoor, 40.0% compromised
Final accuracy - Compromised: 0.0506, Honest: 0.1822
Overall test accuracy: mean=0.1296 ± 0.2371

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 4x4
Overall ASR: 0.5051 ± 0.4951
Honest nodes ASR: 0.3418 ± 0.4658
Compromised nodes ASR: 0.7500 ± 0.4330
Note: Higher ASR indicates more successful backdoor attack
