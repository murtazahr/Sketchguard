Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: krum, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.5185 ± 0.0123 | min=0.4916 max=0.5408
         : test loss mean=1.8287 ± 0.0398
         : individual accs = ['0.521802', '0.514632', '0.540799', '0.491576', '0.525055', '0.528341', '0.496542', '0.525868', '0.506323', '0.513444', '0.514603', '0.518722', '0.533594', '0.517513', '0.527887', '0.527674', '0.519624', '0.511834', '0.532076', '0.502422']
         : correct/total = [(2154, 4128), (2163, 4203), (2207, 4081), (2130, 4333), (2148, 4091), (2265, 4287), (2082, 4193), (2287, 4349), (2122, 4191), (2196, 4277), (2132, 4143), (2175, 4193), (2184, 4093), (2172, 4197), (2139, 4052), (2126, 4029), (2158, 4153), (2141, 4183), (2173, 4084), (2074, 4128)]
         : compromised: 0.5229, honest: 0.5180
Round 002: test acc mean=0.7114 ± 0.0077 | min=0.6984 max=0.7320
         : test loss mean=0.9402 ± 0.0224
         : individual accs = ['0.710514', '0.715917', '0.712570', '0.706208', '0.704718', '0.731980', '0.708800', '0.717176', '0.718206', '0.709142', '0.704803', '0.703554', '0.715368', '0.701215', '0.711994', '0.704393', '0.713942', '0.718862', '0.719393', '0.698401']
         : correct/total = [(2933, 4128), (3009, 4203), (2908, 4081), (3060, 4333), (2883, 4091), (3138, 4287), (2972, 4193), (3119, 4349), (3010, 4191), (3033, 4277), (2920, 4143), (2950, 4193), (2928, 4093), (2943, 4197), (2885, 4052), (2838, 4029), (2965, 4153), (3007, 4183), (2938, 4084), (2883, 4128)]
         : compromised: 0.7166, honest: 0.7108
Round 003: test acc mean=0.7784 ± 0.0079 | min=0.7616 max=0.7924
         : test loss mean=0.7123 ± 0.0243
         : individual accs = ['0.776405', '0.778729', '0.784367', '0.769213', '0.780494', '0.791463', '0.766039', '0.782249', '0.786447', '0.783025', '0.774077', '0.772955', '0.787686', '0.777937', '0.775173', '0.771407', '0.780641', '0.775759', '0.792360', '0.761628']
         : correct/total = [(3205, 4128), (3273, 4203), (3201, 4081), (3333, 4333), (3193, 4091), (3393, 4287), (3212, 4193), (3402, 4349), (3296, 4191), (3349, 4277), (3207, 4143), (3241, 4193), (3224, 4093), (3265, 4197), (3141, 4052), (3108, 4029), (3242, 4153), (3245, 4183), (3236, 4084), (3144, 4128)]
         : compromised: 0.7847, honest: 0.7777
Round 004: test acc mean=0.7907 ± 0.0068 | min=0.7811 max=0.8010
         : test loss mean=0.6506 ± 0.0235
         : individual accs = ['0.792151', '0.790626', '0.796864', '0.783291', '0.797849', '0.799394', '0.783926', '0.797885', '0.796230', '0.801029', '0.781077', '0.784880', '0.794527', '0.782940', '0.790721', '0.783817', '0.800867', '0.782692', '0.789667', '0.782946']
         : correct/total = [(3270, 4128), (3323, 4203), (3252, 4081), (3394, 4333), (3264, 4091), (3427, 4287), (3287, 4193), (3470, 4349), (3337, 4191), (3426, 4277), (3236, 4143), (3291, 4193), (3252, 4093), (3286, 4197), (3204, 4052), (3158, 4029), (3326, 4153), (3274, 4183), (3225, 4084), (3232, 4128)]
         : compromised: 0.7912, honest: 0.7906
Round 005: test acc mean=0.8011 ± 0.0071 | min=0.7865 max=0.8119
         : test loss mean=0.6201 ± 0.0263
         : individual accs = ['0.801114', '0.798477', '0.809115', '0.797831', '0.804693', '0.806158', '0.804913', '0.806622', '0.805536', '0.808511', '0.790249', '0.787264', '0.803323', '0.802240', '0.799605', '0.799206', '0.806405', '0.786517', '0.811949', '0.791424']
         : correct/total = [(3307, 4128), (3356, 4203), (3302, 4081), (3457, 4333), (3292, 4091), (3456, 4287), (3375, 4193), (3508, 4349), (3376, 4191), (3458, 4277), (3274, 4143), (3301, 4193), (3288, 4093), (3367, 4197), (3240, 4052), (3220, 4029), (3349, 4153), (3290, 4183), (3316, 4084), (3267, 4128)]
         : compromised: 0.8042, honest: 0.8007
Round 006: test acc mean=0.8067 ± 0.0072 | min=0.7924 max=0.8174
         : test loss mean=0.6009 ± 0.0240
         : individual accs = ['0.805233', '0.808708', '0.814016', '0.795523', '0.810804', '0.815722', '0.803959', '0.814440', '0.813648', '0.817395', '0.792421', '0.801574', '0.808698', '0.801287', '0.805775', '0.802432', '0.813869', '0.798709', '0.812439', '0.797238']
         : correct/total = [(3324, 4128), (3399, 4203), (3322, 4081), (3447, 4333), (3317, 4091), (3497, 4287), (3371, 4193), (3542, 4349), (3410, 4191), (3496, 4277), (3283, 4143), (3361, 4193), (3310, 4093), (3363, 4197), (3265, 4052), (3233, 4029), (3380, 4153), (3341, 4183), (3318, 4084), (3291, 4128)]
         : compromised: 0.8085, honest: 0.8065
Round 007: test acc mean=0.8259 ± 0.0078 | min=0.8057 max=0.8367
         : test loss mean=0.5467 ± 0.0258
         : individual accs = ['0.823401', '0.831073', '0.833619', '0.822986', '0.830359', '0.836716', '0.820892', '0.833985', '0.834884', '0.835866', '0.819455', '0.814930', '0.825067', '0.822969', '0.820582', '0.824026', '0.829762', '0.819508', '0.833007', '0.805717']
         : correct/total = [(3399, 4128), (3493, 4203), (3402, 4081), (3566, 4333), (3397, 4091), (3587, 4287), (3442, 4193), (3627, 4349), (3499, 4191), (3575, 4277), (3395, 4143), (3417, 4193), (3377, 4093), (3454, 4197), (3325, 4052), (3320, 4029), (3446, 4153), (3428, 4183), (3402, 4084), (3326, 4128)]
         : compromised: 0.8298, honest: 0.8255
Round 008: test acc mean=0.8237 ± 0.0067 | min=0.8122 max=0.8367
         : test loss mean=0.5465 ± 0.0274
         : individual accs = ['0.817103', '0.823935', '0.829209', '0.822986', '0.829382', '0.831117', '0.819461', '0.836744', '0.833930', '0.828618', '0.812213', '0.813499', '0.826289', '0.821777', '0.818608', '0.820055', '0.828798', '0.820703', '0.826396', '0.813711']
         : correct/total = [(3373, 4128), (3463, 4203), (3384, 4081), (3566, 4333), (3393, 4091), (3563, 4287), (3436, 4193), (3639, 4349), (3495, 4191), (3544, 4277), (3365, 4143), (3411, 4193), (3382, 4093), (3449, 4197), (3317, 4052), (3304, 4029), (3442, 4153), (3433, 4183), (3375, 4084), (3359, 4128)]
         : compromised: 0.8264, honest: 0.8234
Round 009: test acc mean=0.8196 ± 0.0083 | min=0.8011 max=0.8401
         : test loss mean=0.5441 ± 0.0264
         : individual accs = ['0.810804', '0.825125', '0.823818', '0.811909', '0.824248', '0.828318', '0.812306', '0.819499', '0.840134', '0.825345', '0.816799', '0.809683', '0.818471', '0.816297', '0.820582', '0.816828', '0.826391', '0.816639', '0.828355', '0.801114']
         : correct/total = [(3347, 4128), (3468, 4203), (3362, 4081), (3518, 4333), (3372, 4091), (3551, 4287), (3406, 4193), (3564, 4349), (3521, 4191), (3530, 4277), (3384, 4143), (3395, 4193), (3350, 4093), (3426, 4197), (3325, 4052), (3291, 4029), (3432, 4153), (3416, 4183), (3383, 4084), (3307, 4128)]
         : compromised: 0.8223, honest: 0.8193
Round 010: test acc mean=0.8161 ± 0.0071 | min=0.8061 max=0.8315
         : test loss mean=0.5581 ± 0.0285
         : individual accs = ['0.808140', '0.814894', '0.818182', '0.811216', '0.828404', '0.822020', '0.813022', '0.819729', '0.831544', '0.824877', '0.807869', '0.806105', '0.814317', '0.815344', '0.815153', '0.812112', '0.818204', '0.807554', '0.825171', '0.808624']
         : correct/total = [(3336, 4128), (3425, 4203), (3339, 4081), (3515, 4333), (3389, 4091), (3524, 4287), (3409, 4193), (3565, 4349), (3485, 4191), (3528, 4277), (3347, 4143), (3380, 4193), (3333, 4093), (3422, 4197), (3303, 4052), (3272, 4029), (3398, 4153), (3378, 4183), (3370, 4084), (3338, 4128)]
         : compromised: 0.8187, honest: 0.8158

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: krum
Attack: krum, 10.0% compromised
Final accuracy - Compromised: 0.8187, Honest: 0.8158
Overall test accuracy: mean=0.8161 ± 0.0071
