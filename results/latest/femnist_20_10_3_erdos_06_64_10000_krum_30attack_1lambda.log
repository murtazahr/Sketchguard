Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.5366 ± 0.0147 | min=0.5121 max=0.5695
         : test loss mean=1.7454 ± 0.0497
         : individual accs = ['0.533672', '0.533191', '0.563587', '0.514193', '0.531899', '0.553067', '0.533270', '0.544033', '0.548318', '0.526070', '0.522085', '0.540663', '0.534816', '0.553252', '0.532083', '0.524696', '0.569468', '0.525221', '0.535994', '0.512112']
         : correct/total = [(2203, 4128), (2241, 4203), (2300, 4081), (2228, 4333), (2176, 4091), (2371, 4287), (2236, 4193), (2366, 4349), (2298, 4191), (2250, 4277), (2163, 4143), (2267, 4193), (2189, 4093), (2322, 4197), (2156, 4052), (2114, 4029), (2365, 4153), (2197, 4183), (2189, 4084), (2114, 4128)]
         : compromised: 0.5391, honest: 0.5355
Round 002: test acc mean=0.7288 ± 0.0107 | min=0.7019 max=0.7480
         : test loss mean=0.8967 ± 0.0360
         : individual accs = ['0.741764', '0.730906', '0.727518', '0.736210', '0.721095', '0.739212', '0.727403', '0.744309', '0.721546', '0.720599', '0.731595', '0.701884', '0.738089', '0.717894', '0.717177', '0.731447', '0.722129', '0.748028', '0.733105', '0.724806']
         : correct/total = [(3062, 4128), (3072, 4203), (2969, 4081), (3190, 4333), (2950, 4091), (3169, 4287), (3050, 4193), (3237, 4349), (3024, 4191), (3082, 4277), (3031, 4143), (2943, 4193), (3021, 4093), (3013, 4197), (2906, 4052), (2947, 4029), (2999, 4153), (3129, 4183), (2994, 4084), (2992, 4128)]
         : compromised: 0.7323, honest: 0.7274
Round 003: test acc mean=0.7818 ± 0.0101 | min=0.7617 max=0.7951
         : test loss mean=0.7076 ± 0.0271
         : individual accs = ['0.792636', '0.795146', '0.790738', '0.773829', '0.792716', '0.789130', '0.761746', '0.791676', '0.781675', '0.787000', '0.770698', '0.771524', '0.781823', '0.773648', '0.781589', '0.782080', '0.794125', '0.770022', '0.788443', '0.764777']
         : correct/total = [(3272, 4128), (3342, 4203), (3227, 4081), (3353, 4333), (3243, 4091), (3383, 4287), (3194, 4193), (3443, 4349), (3276, 4191), (3366, 4277), (3193, 4143), (3235, 4193), (3200, 4093), (3247, 4197), (3167, 4052), (3151, 4029), (3298, 4153), (3221, 4183), (3220, 4084), (3157, 4128)]
         : compromised: 0.7808, honest: 0.7822
Round 004: test acc mean=0.7940 ± 0.0097 | min=0.7707 max=0.8120
         : test loss mean=0.6492 ± 0.0283
         : individual accs = ['0.802326', '0.812039', '0.793188', '0.793676', '0.808360', '0.794728', '0.787980', '0.798115', '0.793367', '0.807108', '0.770698', '0.784641', '0.800391', '0.781749', '0.798124', '0.796972', '0.791717', '0.784604', '0.796768', '0.784157']
         : correct/total = [(3312, 4128), (3413, 4203), (3237, 4081), (3439, 4333), (3307, 4091), (3407, 4287), (3304, 4193), (3471, 4349), (3325, 4191), (3452, 4277), (3193, 4143), (3290, 4193), (3276, 4093), (3281, 4197), (3234, 4052), (3211, 4029), (3288, 4153), (3282, 4183), (3254, 4084), (3237, 4128)]
         : compromised: 0.7927, honest: 0.7946
Round 005: test acc mean=0.8082 ± 0.0120 | min=0.7897 max=0.8290
         : test loss mean=0.5954 ± 0.0303
         : individual accs = ['0.800145', '0.825839', '0.821122', '0.792061', '0.806160', '0.811523', '0.800143', '0.799264', '0.802911', '0.821370', '0.794111', '0.792750', '0.825556', '0.814391', '0.802567', '0.806900', '0.829039', '0.808033', '0.820274', '0.789729']
         : correct/total = [(3303, 4128), (3471, 4203), (3351, 4081), (3432, 4333), (3298, 4091), (3479, 4287), (3355, 4193), (3476, 4349), (3365, 4191), (3513, 4277), (3290, 4143), (3324, 4193), (3379, 4093), (3418, 4197), (3252, 4052), (3251, 4029), (3443, 4153), (3380, 4183), (3350, 4084), (3260, 4128)]
         : compromised: 0.8137, honest: 0.8058
Round 006: test acc mean=0.8213 ± 0.0095 | min=0.8034 max=0.8377
         : test loss mean=0.5536 ± 0.0316
         : individual accs = ['0.828973', '0.832976', '0.834599', '0.813293', '0.821560', '0.824586', '0.820176', '0.828696', '0.823193', '0.823241', '0.807145', '0.821846', '0.824823', '0.815344', '0.822804', '0.803425', '0.837708', '0.809228', '0.827130', '0.804506']
         : correct/total = [(3422, 4128), (3501, 4203), (3406, 4081), (3524, 4333), (3361, 4091), (3535, 4287), (3439, 4193), (3604, 4349), (3450, 4191), (3521, 4277), (3344, 4143), (3446, 4193), (3376, 4093), (3422, 4197), (3334, 4052), (3237, 4029), (3479, 4153), (3385, 4183), (3378, 4084), (3321, 4128)]
         : compromised: 0.8207, honest: 0.8215
Round 007: test acc mean=0.8205 ± 0.0094 | min=0.8021 max=0.8360
         : test loss mean=0.5444 ± 0.0344
         : individual accs = ['0.821221', '0.835118', '0.823083', '0.820679', '0.835737', '0.836016', '0.817315', '0.822718', '0.814841', '0.833996', '0.813903', '0.814691', '0.820914', '0.813915', '0.805775', '0.810127', '0.826631', '0.816161', '0.825171', '0.802083']
         : correct/total = [(3390, 4128), (3510, 4203), (3359, 4081), (3556, 4333), (3419, 4091), (3584, 4287), (3427, 4193), (3578, 4349), (3415, 4191), (3567, 4277), (3372, 4143), (3416, 4193), (3360, 4093), (3416, 4197), (3265, 4052), (3264, 4029), (3433, 4153), (3414, 4183), (3370, 4084), (3311, 4128)]
         : compromised: 0.8197, honest: 0.8209
Round 008: test acc mean=0.8281 ± 0.0066 | min=0.8159 max=0.8418
         : test loss mean=0.5190 ± 0.0281
         : individual accs = ['0.835514', '0.832025', '0.827983', '0.826217', '0.841848', '0.827385', '0.827570', '0.824097', '0.828919', '0.835165', '0.819213', '0.821369', '0.829221', '0.826305', '0.815893', '0.822288', '0.838430', '0.826918', '0.835700', '0.820736']
         : correct/total = [(3449, 4128), (3497, 4203), (3379, 4081), (3580, 4333), (3444, 4091), (3547, 4287), (3470, 4193), (3584, 4349), (3474, 4191), (3572, 4277), (3394, 4143), (3444, 4193), (3394, 4093), (3468, 4197), (3306, 4052), (3313, 4029), (3482, 4153), (3459, 4183), (3413, 4084), (3388, 4128)]
         : compromised: 0.8269, honest: 0.8287
Round 009: test acc mean=0.8305 ± 0.0081 | min=0.8098 max=0.8464
         : test loss mean=0.5099 ± 0.0293
         : individual accs = ['0.830911', '0.840114', '0.834844', '0.831526', '0.831582', '0.837182', '0.828047', '0.830766', '0.836555', '0.846388', '0.831282', '0.833055', '0.820669', '0.829878', '0.819348', '0.825515', '0.820852', '0.832656', '0.839618', '0.809835']
         : correct/total = [(3430, 4128), (3531, 4203), (3407, 4081), (3603, 4333), (3402, 4091), (3589, 4287), (3472, 4193), (3613, 4349), (3506, 4191), (3620, 4277), (3444, 4143), (3493, 4193), (3359, 4093), (3483, 4197), (3320, 4052), (3326, 4029), (3409, 4153), (3483, 4183), (3429, 4084), (3343, 4128)]
         : compromised: 0.8299, honest: 0.8308
Round 010: test acc mean=0.8352 ± 0.0068 | min=0.8258 max=0.8473
         : test loss mean=0.5013 ± 0.0285
         : individual accs = ['0.836483', '0.842493', '0.838765', '0.829679', '0.841604', '0.833683', '0.827570', '0.847321', '0.831067', '0.846621', '0.830316', '0.834009', '0.842903', '0.826305', '0.828233', '0.825763', '0.834818', '0.834808', '0.843536', '0.827762']
         : correct/total = [(3453, 4128), (3541, 4203), (3423, 4081), (3595, 4333), (3443, 4091), (3574, 4287), (3470, 4193), (3685, 4349), (3483, 4191), (3621, 4277), (3440, 4143), (3497, 4193), (3450, 4093), (3468, 4197), (3356, 4052), (3327, 4029), (3467, 4153), (3492, 4183), (3445, 4084), (3417, 4128)]
         : compromised: 0.8349, honest: 0.8353

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: directed_deviation, 30.0% compromised
Final accuracy - Compromised: 0.8349, Honest: 0.8353
Overall test accuracy: mean=0.8352 ± 0.0068
