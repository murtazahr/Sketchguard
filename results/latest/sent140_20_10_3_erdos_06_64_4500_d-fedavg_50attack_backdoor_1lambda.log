Device: cuda
Seed: 987654321
Loading 1 LEAF Sent140 train files...
LEAF Sent140 train: 254555 users, 908652 samples
Building vocabulary (max_size=10000)...
Vocabulary size: 10000
Loading 1 LEAF Sent140 test files...
LEAF Sent140 test: 254555 users, 286281 samples
Found 254555 train users, 254555 test users, 254555 common users
User sample counts range: 494 (max) to 1 (min)
Distributed ALL 254555 users across 20 clients
Users per client: 12727 (with 15 clients getting +1 user)
Train partition sizes: [44353, 44290, 44657, 44907, 44696, 45843, 45801, 45619, 45069, 45639, 45821, 45311, 45779, 46056, 45625, 45984, 46428, 44737, 45540, 46497]
Test partition sizes: [14232, 14235, 14266, 14217, 14238, 14373, 14346, 14334, 14294, 14373, 14344, 14302, 14354, 14362, 14320, 14395, 14389, 14257, 14251, 14399]
  Client 0: 44353 train samples, 2 unique classes
  Client 1: 44290 train samples, 2 unique classes
  Client 2: 44657 train samples, 2 unique classes
  Client 3: 44907 train samples, 2 unique classes
  Client 4: 44696 train samples, 2 unique classes
  Client 5: 45843 train samples, 2 unique classes
  Client 6: 45801 train samples, 2 unique classes
  Client 7: 45619 train samples, 2 unique classes
  Client 8: 45069 train samples, 2 unique classes
  Client 9: 45639 train samples, 2 unique classes
  Client 10: 45821 train samples, 2 unique classes
  Client 11: 45311 train samples, 2 unique classes
  Client 12: 45779 train samples, 2 unique classes
  Client 13: 46056 train samples, 2 unique classes
  Client 14: 45625 train samples, 2 unique classes
  Client 15: 45984 train samples, 2 unique classes
  Client 16: 46428 train samples, 2 unique classes
  Client 17: 44737 train samples, 2 unique classes
  Client 18: 45540 train samples, 2 unique classes
  Client 19: 46497 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 10/20 nodes: [1, 2, 5, 11, 12, 13, 14, 15, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 1, trigger size: 3
Model variant: baseline
Model parameters: 1,174,986
Initial test acc across nodes: mean=0.4953 ± 0.0174
Backdoor attack: Created poisoned datasets for 10 compromised nodes
Round 001: test acc mean=0.5040 ± 0.0075 | min=0.4902 max=0.5188
         : test loss mean=5.9440 ± 3.7153
         : individual accs = ['0.509345', '0.490200', '0.513318', '0.514384', '0.498033', '0.501218', '0.500488', '0.502302', '0.496362', '0.508662', '0.509133', '0.506153', '0.504389', '0.509887', '0.506774', '0.495728', '0.503788', '0.490426', '0.518771', '0.500035']
         : correct/total = [(7249, 14232), (6978, 14235), (7323, 14266), (7313, 14217), (7091, 14238), (7204, 14373), (7180, 14346), (7200, 14334), (7095, 14294), (7311, 14373), (7303, 14344), (7239, 14302), (7240, 14354), (7323, 14362), (7257, 14320), (7136, 14395), (7249, 14389), (6992, 14257), (7393, 14251), (7200, 14399)]
         : compromised: 0.5037, honest: 0.5043
Round 002: test acc mean=0.5038 ± 0.0057 | min=0.4944 max=0.5154
         : test loss mean=8.7227 ± 2.5822
         : individual accs = ['0.501335', '0.515420', '0.511145', '0.511571', '0.502177', '0.502331', '0.496515', '0.501256', '0.504967', '0.506505', '0.501743', '0.497133', '0.506200', '0.494430', '0.504818', '0.496909', '0.505942', '0.513642', '0.500035', '0.501146']
         : correct/total = [(7135, 14232), (7337, 14235), (7292, 14266), (7273, 14217), (7150, 14238), (7220, 14373), (7123, 14346), (7185, 14334), (7218, 14294), (7280, 14373), (7197, 14344), (7110, 14302), (7266, 14354), (7101, 14362), (7229, 14320), (7153, 14395), (7280, 14389), (7323, 14257), (7126, 14251), (7216, 14399)]
         : compromised: 0.5042, honest: 0.5033
Round 003: test acc mean=0.5051 ± 0.0054 | min=0.4932 max=0.5170
         : test loss mean=8.9825 ± 1.5924
         : individual accs = ['0.507378', '0.516965', '0.512968', '0.515017', '0.505478', '0.504279', '0.500976', '0.506697', '0.501749', '0.504766', '0.501603', '0.504475', '0.497144', '0.493176', '0.507472', '0.502813', '0.507471', '0.504664', '0.504386', '0.501979']
         : correct/total = [(7221, 14232), (7359, 14235), (7318, 14266), (7322, 14217), (7197, 14238), (7248, 14373), (7187, 14346), (7263, 14334), (7172, 14294), (7255, 14373), (7195, 14344), (7215, 14302), (7136, 14354), (7083, 14362), (7267, 14320), (7238, 14395), (7302, 14389), (7195, 14257), (7188, 14251), (7228, 14399)]
         : compromised: 0.5048, honest: 0.5053
Round 004: test acc mean=0.4952 ± 0.0053 | min=0.4840 max=0.5070
         : test loss mean=10.2119 ± 3.5832
         : individual accs = ['0.492974', '0.484018', '0.487453', '0.485053', '0.494873', '0.495652', '0.498815', '0.492954', '0.498321', '0.496278', '0.498745', '0.494057', '0.502508', '0.506963', '0.492668', '0.497534', '0.492529', '0.498211', '0.495965', '0.498160']
         : correct/total = [(7016, 14232), (6890, 14235), (6954, 14266), (6896, 14217), (7046, 14238), (7124, 14373), (7156, 14346), (7066, 14334), (7123, 14294), (7133, 14373), (7154, 14344), (7066, 14302), (7213, 14354), (7281, 14362), (7055, 14320), (7162, 14395), (7087, 14389), (7103, 14257), (7068, 14251), (7173, 14399)]
         : compromised: 0.4955, honest: 0.4949
Round 005: test acc mean=0.4948 ± 0.0055 | min=0.4823 max=0.5061
         : test loss mean=6.3501 ± 1.5523
         : individual accs = ['0.491639', '0.482262', '0.487032', '0.484912', '0.494803', '0.495791', '0.499721', '0.492884', '0.498181', '0.495234', '0.498397', '0.493777', '0.502926', '0.506127', '0.492458', '0.497881', '0.492529', '0.495336', '0.495614', '0.497673']
         : correct/total = [(6997, 14232), (6865, 14235), (6948, 14266), (6894, 14217), (7045, 14238), (7126, 14373), (7169, 14346), (7065, 14334), (7121, 14294), (7118, 14373), (7149, 14344), (7062, 14302), (7219, 14354), (7269, 14362), (7052, 14320), (7167, 14395), (7087, 14389), (7062, 14257), (7063, 14251), (7166, 14399)]
         : compromised: 0.4949, honest: 0.4946
Round 006: test acc mean=0.4977 ± 0.0069 | min=0.4862 max=0.5139
         : test loss mean=1.8520 ± 0.6129
         : individual accs = ['0.495433', '0.488514', '0.511636', '0.486249', '0.489886', '0.496904', '0.498327', '0.506279', '0.497901', '0.499896', '0.513873', '0.505454', '0.493382', '0.492550', '0.497137', '0.498159', '0.499896', '0.495125', '0.494702', '0.493229']
         : correct/total = [(7051, 14232), (6954, 14235), (7299, 14266), (6913, 14217), (6975, 14238), (7142, 14373), (7149, 14346), (7257, 14334), (7117, 14294), (7185, 14373), (7371, 14344), (7229, 14302), (7082, 14354), (7074, 14362), (7119, 14320), (7171, 14395), (7193, 14389), (7059, 14257), (7050, 14251), (7102, 14399)]
         : compromised: 0.4974, honest: 0.4981
Round 007: test acc mean=0.4987 ± 0.0063 | min=0.4835 max=0.5079
         : test loss mean=2.0000 ± 0.1013
         : individual accs = ['0.498173', '0.490832', '0.483527', '0.507772', '0.504284', '0.495930', '0.497560', '0.489745', '0.496222', '0.501287', '0.499233', '0.491959', '0.507245', '0.507938', '0.496718', '0.502466', '0.495378', '0.503332', '0.498912', '0.504827']
         : correct/total = [(7090, 14232), (6987, 14235), (6898, 14266), (7219, 14217), (7180, 14238), (7128, 14373), (7138, 14346), (7020, 14334), (7093, 14294), (7205, 14373), (7161, 14344), (7036, 14302), (7281, 14354), (7295, 14362), (7113, 14320), (7233, 14395), (7128, 14389), (7176, 14257), (7110, 14251), (7269, 14399)]
         : compromised: 0.4979, honest: 0.4994
Round 008: test acc mean=0.5022 ± 0.0058 | min=0.4897 max=0.5158
         : test loss mean=1.6414 ± 0.3558
         : individual accs = ['0.507518', '0.515841', '0.509673', '0.509320', '0.501264', '0.498574', '0.496445', '0.504814', '0.495453', '0.503514', '0.500000', '0.503566', '0.495263', '0.489695', '0.506844', '0.499271', '0.503649', '0.503191', '0.501158', '0.498646']
         : correct/total = [(7223, 14232), (7343, 14235), (7271, 14266), (7241, 14217), (7137, 14238), (7166, 14373), (7122, 14346), (7236, 14334), (7082, 14294), (7237, 14373), (7172, 14344), (7202, 14302), (7109, 14354), (7033, 14362), (7258, 14320), (7187, 14395), (7247, 14389), (7174, 14257), (7142, 14251), (7180, 14399)]
         : compromised: 0.5023, honest: 0.5021
Round 009: test acc mean=0.5052 ± 0.0056 | min=0.4932 max=0.5170
         : test loss mean=0.9880 ± 0.1609
         : individual accs = ['0.507307', '0.517035', '0.513178', '0.516283', '0.505478', '0.504140', '0.500209', '0.507325', '0.501819', '0.504557', '0.501255', '0.506153', '0.497004', '0.493176', '0.507472', '0.502258', '0.507610', '0.505506', '0.504386', '0.501910']
         : correct/total = [(7220, 14232), (7360, 14235), (7321, 14266), (7340, 14217), (7197, 14238), (7246, 14373), (7176, 14346), (7272, 14334), (7173, 14294), (7252, 14373), (7190, 14344), (7239, 14302), (7134, 14354), (7083, 14362), (7267, 14320), (7230, 14395), (7304, 14389), (7207, 14257), (7188, 14251), (7227, 14399)]
         : compromised: 0.5050, honest: 0.5054
Round 010: test acc mean=0.5032 ± 0.0057 | min=0.4935 max=0.5168
         : test loss mean=0.8933 ± 0.3414
         : individual accs = ['0.506535', '0.516825', '0.502664', '0.515088', '0.505057', '0.497878', '0.495121', '0.507325', '0.498811', '0.504627', '0.501673', '0.507272', '0.497004', '0.493525', '0.501885', '0.502327', '0.499618', '0.504945', '0.504807', '0.500938']
         : correct/total = [(7209, 14232), (7357, 14235), (7171, 14266), (7323, 14217), (7191, 14238), (7156, 14373), (7103, 14346), (7272, 14334), (7130, 14294), (7253, 14373), (7196, 14344), (7255, 14302), (7134, 14354), (7088, 14362), (7187, 14320), (7231, 14395), (7189, 14389), (7199, 14257), (7194, 14251), (7213, 14399)]
         : compromised: 0.5029, honest: 0.5035

=== FINAL RESULTS ===
Dataset: sent140, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: backdoor, 50.0% compromised
Final accuracy - Compromised: 0.5029, Honest: 0.5035
Overall test accuracy: mean=0.5032 ± 0.0057

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 1
Trigger size: 3x3
Overall ASR: 0.4522 ± 0.4314
Honest nodes ASR: 0.4215 ± 0.4292
Compromised nodes ASR: 0.4829 ± 0.4314
Note: Higher ASR indicates more successful backdoor attack
