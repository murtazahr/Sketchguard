Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.4257 ± 0.2213 | min=0.0026 max=0.5949
         : test loss mean=58065.8302 ± 117987.7360
         : individual accs = ['0.542878', '0.555556', '0.546190', '0.534964', '0.553899', '0.025659', '0.543763', '0.556450', '0.586018', '0.173954', '0.508810', '0.546148', '0.553872', '0.594949', '0.016041', '0.554480', '0.019986', '0.002630', '0.569540', '0.527616']
         : correct/total = [(2241, 4128), (2335, 4203), (2229, 4081), (2318, 4333), (2266, 4091), (110, 4287), (2280, 4193), (2420, 4349), (2456, 4191), (744, 4277), (2108, 4143), (2290, 4193), (2267, 4093), (2497, 4197), (65, 4052), (2234, 4029), (83, 4153), (11, 4183), (2326, 4084), (2178, 4128)]
         : compromised: 0.2938, honest: 0.4822
Round 002: test acc mean=0.5614 ± 0.2985 | min=0.0275 max=0.7574
         : test loss mean=nan ± nan
         : individual accs = ['0.742248', '0.743517', '0.734624', '0.757443', '0.711806', '0.027525', '0.754591', '0.734882', '0.731806', '0.696049', '0.741974', '0.687813', '0.047398', '0.751489', '0.054788', '0.735666', '0.047436', '0.049247', '0.745103', '0.733527']
         : correct/total = [(3064, 4128), (3125, 4203), (2998, 4081), (3282, 4333), (2912, 4091), (118, 4287), (3164, 4193), (3196, 4349), (3067, 4191), (2977, 4277), (3074, 4143), (2884, 4193), (194, 4093), (3154, 4197), (222, 4052), (2964, 4029), (197, 4153), (206, 4183), (3043, 4084), (3028, 4128)]
         : compromised: 0.2793, honest: 0.6824
Round 003: test acc mean=0.5899 ± 0.3148 | min=0.0275 max=0.7935
         : test loss mean=nan ± nan
         : individual accs = ['0.774225', '0.793481', '0.777015', '0.785137', '0.764605', '0.027525', '0.786072', '0.776040', '0.786447', '0.722469', '0.772146', '0.750775', '0.047398', '0.759828', '0.054788', '0.790271', '0.047436', '0.049247', '0.766405', '0.765746']
         : correct/total = [(3196, 4128), (3335, 4203), (3171, 4081), (3402, 4333), (3128, 4091), (118, 4287), (3296, 4193), (3375, 4349), (3296, 4191), (3090, 4277), (3199, 4143), (3148, 4193), (194, 4093), (3189, 4197), (222, 4052), (3184, 4029), (197, 4153), (206, 4183), (3130, 4084), (3161, 4128)]
         : compromised: 0.2842, honest: 0.7208
Round 004: test acc mean=0.6132 ± 0.3290 | min=0.0191 max=0.8175
         : test loss mean=nan ± nan
         : individual accs = ['0.799661', '0.817511', '0.799069', '0.799215', '0.793693', '0.019128', '0.806105', '0.810991', '0.817227', '0.803367', '0.797248', '0.782495', '0.047398', '0.805814', '0.054788', '0.812857', '0.047436', '0.049247', '0.792116', '0.808866']
         : correct/total = [(3301, 4128), (3436, 4203), (3261, 4081), (3463, 4333), (3247, 4091), (82, 4287), (3380, 4193), (3527, 4349), (3425, 4191), (3436, 4277), (3303, 4143), (3281, 4193), (194, 4093), (3382, 4197), (222, 4052), (3275, 4029), (197, 4153), (206, 4183), (3235, 4084), (3339, 4128)]
         : compromised: 0.2947, honest: 0.7497
Round 005: test acc mean=0.6176 ± 0.3316 | min=0.0191 max=0.8270
         : test loss mean=nan ± nan
         : individual accs = ['0.797481', '0.804901', '0.810831', '0.813293', '0.808849', '0.019128', '0.808490', '0.821108', '0.827010', '0.826280', '0.816799', '0.800859', '0.047398', '0.798666', '0.054788', '0.797468', '0.047436', '0.049247', '0.788688', '0.813711']
         : correct/total = [(3292, 4128), (3383, 4203), (3309, 4081), (3524, 4333), (3309, 4091), (82, 4287), (3390, 4193), (3571, 4349), (3466, 4191), (3534, 4277), (3384, 4143), (3358, 4193), (194, 4093), (3352, 4197), (222, 4052), (3213, 4029), (197, 4153), (206, 4183), (3221, 4084), (3359, 4128)]
         : compromised: 0.2930, honest: 0.7568
Round 006: test acc mean=0.6257 ± 0.3382 | min=0.0026 max=0.8415
         : test loss mean=nan ± nan
         : individual accs = ['0.813953', '0.828456', '0.810096', '0.828294', '0.820093', '0.002566', '0.826616', '0.826167', '0.831544', '0.841478', '0.813662', '0.814930', '0.047398', '0.812962', '0.054788', '0.818814', '0.047436', '0.049247', '0.810725', '0.814438']
         : correct/total = [(3360, 4128), (3482, 4203), (3306, 4081), (3589, 4333), (3355, 4091), (11, 4287), (3466, 4193), (3593, 4349), (3485, 4191), (3599, 4277), (3371, 4143), (3417, 4193), (194, 4093), (3412, 4197), (222, 4052), (3299, 4029), (197, 4153), (206, 4183), (3311, 4084), (3362, 4128)]
         : compromised: 0.2963, honest: 0.7669
Round 007: test acc mean=0.6335 ± 0.3427 | min=0.0026 max=0.8536
         : test loss mean=nan ± nan
         : individual accs = ['0.828731', '0.834166', '0.832394', '0.825063', '0.819360', '0.002566', '0.830432', '0.832375', '0.841804', '0.853636', '0.825006', '0.830909', '0.047398', '0.828925', '0.054788', '0.834947', '0.047436', '0.049247', '0.828355', '0.822674']
         : correct/total = [(3421, 4128), (3506, 4203), (3397, 4081), (3575, 4333), (3352, 4091), (11, 4287), (3482, 4193), (3620, 4349), (3528, 4191), (3651, 4277), (3418, 4143), (3484, 4193), (194, 4093), (3479, 4197), (222, 4052), (3364, 4029), (197, 4153), (206, 4183), (3383, 4084), (3396, 4128)]
         : compromised: 0.3019, honest: 0.7756
Round 008: test acc mean=0.6335 ± 0.3428 | min=0.0026 max=0.8546
         : test loss mean=nan ± nan
         : individual accs = ['0.827035', '0.829645', '0.831659', '0.844680', '0.815449', '0.002566', '0.835917', '0.834675', '0.840849', '0.854571', '0.827420', '0.839494', '0.047398', '0.839409', '0.054788', '0.817573', '0.047436', '0.049247', '0.833986', '0.795543']
         : correct/total = [(3414, 4128), (3487, 4203), (3394, 4081), (3660, 4333), (3336, 4091), (11, 4287), (3505, 4193), (3630, 4349), (3524, 4191), (3655, 4277), (3428, 4143), (3520, 4193), (194, 4093), (3523, 4197), (222, 4052), (3294, 4029), (197, 4153), (206, 4183), (3406, 4084), (3284, 4128)]
         : compromised: 0.3046, honest: 0.7744
Round 009: test acc mean=0.6389 ± 0.3431 | min=0.0257 max=0.8557
         : test loss mean=nan ± nan
         : individual accs = ['0.825097', '0.849393', '0.839500', '0.838449', '0.837937', '0.025659', '0.844264', '0.843872', '0.846099', '0.855740', '0.835144', '0.826616', '0.047398', '0.815344', '0.054788', '0.840407', '0.047436', '0.049247', '0.823213', '0.831880']
         : correct/total = [(3406, 4128), (3570, 4203), (3426, 4081), (3633, 4333), (3428, 4091), (110, 4287), (3540, 4193), (3670, 4349), (3546, 4191), (3660, 4277), (3460, 4143), (3466, 4193), (194, 4093), (3422, 4197), (222, 4052), (3386, 4029), (197, 4153), (206, 4183), (3362, 4084), (3434, 4128)]
         : compromised: 0.3026, honest: 0.7830
Round 010: test acc mean=0.6371 ± 0.3448 | min=0.0026 max=0.8614
         : test loss mean=nan ± nan
         : individual accs = ['0.831153', '0.840114', '0.833864', '0.841911', '0.818871', '0.002566', '0.845457', '0.838584', '0.842520', '0.861351', '0.828868', '0.833294', '0.047398', '0.837026', '0.054788', '0.832216', '0.047436', '0.049247', '0.831048', '0.824128']
         : correct/total = [(3431, 4128), (3531, 4203), (3403, 4081), (3648, 4333), (3350, 4091), (11, 4287), (3545, 4193), (3647, 4349), (3531, 4191), (3684, 4277), (3434, 4143), (3494, 4193), (194, 4093), (3513, 4197), (222, 4052), (3353, 4029), (197, 4153), (206, 4183), (3394, 4084), (3402, 4128)]
         : compromised: 0.3037, honest: 0.7800

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: directed_deviation, 30.0% compromised
Final accuracy - Compromised: 0.3037, Honest: 0.7800
Overall test accuracy: mean=0.6371 ± 0.3448
