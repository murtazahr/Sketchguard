Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.1688 ± 0.1215 | min=0.0020 max=0.4123
         : test loss mean=44972699.1964 ± 72499181.4561
         : individual accs = ['0.247335', '0.256959', '0.262191', '0.164782', '0.001956', '0.017961', '0.005247', '0.412279', '0.130756', '0.104045', '0.183442', '0.282375', '0.015392', '0.021444', '0.005923', '0.275751', '0.274982', '0.301458', '0.239226', '0.171512']
         : correct/total = [(1021, 4128), (1080, 4203), (1070, 4081), (714, 4333), (8, 4091), (77, 4287), (22, 4193), (1793, 4349), (548, 4191), (445, 4277), (760, 4143), (1184, 4193), (63, 4093), (90, 4197), (24, 4052), (1111, 4029), (1142, 4153), (1261, 4183), (977, 4084), (708, 4128)]
         : compromised: 0.0197, honest: 0.1853
Round 002: test acc mean=0.3728 ± 0.3241 | min=0.0430 max=0.7167
         : test loss mean=nan ± nan
         : individual accs = ['0.715601', '0.691173', '0.698358', '0.048234', '0.043021', '0.045253', '0.050799', '0.045068', '0.707230', '0.699556', '0.695873', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.671563', '0.683720', '0.716699', '0.688469']
         : correct/total = [(2954, 4128), (2905, 4203), (2850, 4081), (209, 4333), (176, 4091), (194, 4287), (213, 4193), (196, 4349), (2964, 4191), (2992, 4277), (2883, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (2789, 4153), (2860, 4183), (2927, 4084), (2842, 4128)]
         : compromised: 0.0472, honest: 0.4090
Round 003: test acc mean=0.2666 ± 0.3323 | min=0.0430 max=0.7834
         : test loss mean=nan ± nan
         : individual accs = ['0.783430', '0.781347', '0.048272', '0.048234', '0.043021', '0.045253', '0.050799', '0.045068', '0.049630', '0.778583', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.766436', '0.774731', '0.760417']
         : correct/total = [(3234, 4128), (3284, 4203), (197, 4081), (209, 4333), (176, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (3330, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (3206, 4183), (3164, 4084), (3139, 4128)]
         : compromised: 0.0472, honest: 0.2910
Round 004: test acc mean=0.1613 ± 0.2675 | min=0.0430 max=0.8057
         : test loss mean=nan ± nan
         : individual accs = ['0.805717', '0.046158', '0.055134', '0.046619', '0.043021', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.797258', '0.791182']
         : correct/total = [(3326, 4128), (194, 4203), (225, 4081), (202, 4333), (176, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (3256, 4084), (3266, 4128)]
         : compromised: 0.0472, honest: 0.1739
Round 005: test acc mean=0.0856 ± 0.1651 | min=0.0270 max=0.8047
         : test loss mean=nan ± nan
         : individual accs = ['0.050145', '0.047109', '0.026954', '0.047773', '0.043021', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.052889', '0.804748']
         : correct/total = [(207, 4128), (198, 4203), (110, 4081), (207, 4333), (176, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (216, 4084), (3322, 4128)]
         : compromised: 0.0472, honest: 0.0899
Round 006: test acc mean=0.0488 ± 0.0090 | min=0.0132 max=0.0596
         : test loss mean=nan ± nan
         : individual accs = ['0.059593', '0.050202', '0.057584', '0.013155', '0.048643', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.052889', '0.054506']
         : correct/total = [(246, 4128), (211, 4203), (235, 4081), (57, 4333), (199, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0472, honest: 0.0490
Round 007: test acc mean=0.0501 ± 0.0033 | min=0.0435 max=0.0576
         : test loss mean=nan ± nan
         : individual accs = ['0.050145', '0.050202', '0.057584', '0.048465', '0.048643', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.052889', '0.054506']
         : correct/total = [(207, 4128), (211, 4203), (235, 4081), (210, 4333), (199, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0472, honest: 0.0505
Round 008: test acc mean=0.0496 ± 0.0029 | min=0.0435 max=0.0545
         : test loss mean=nan ± nan
         : individual accs = ['0.050145', '0.048775', '0.050723', '0.046619', '0.048643', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.052889', '0.054506']
         : correct/total = [(207, 4128), (205, 4203), (207, 4081), (202, 4333), (199, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0472, honest: 0.0499
Round 009: test acc mean=0.0498 ± 0.0030 | min=0.0435 max=0.0545
         : test loss mean=nan ± nan
         : individual accs = ['0.050145', '0.048775', '0.053418', '0.046619', '0.048643', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.052889', '0.054506']
         : correct/total = [(207, 4128), (205, 4203), (218, 4081), (202, 4333), (199, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0472, honest: 0.0500
Round 010: test acc mean=0.0474 ± 0.0103 | min=0.0049 max=0.0545
         : test loss mean=nan ± nan
         : individual accs = ['0.050145', '0.048775', '0.053418', '0.043157', '0.004889', '0.045253', '0.050799', '0.045068', '0.049630', '0.043488', '0.048033', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.052011', '0.049486', '0.052889', '0.054506']
         : correct/total = [(207, 4128), (205, 4203), (218, 4081), (187, 4333), (20, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (186, 4277), (199, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (216, 4153), (207, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0472, honest: 0.0474

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: ring, Aggregation: d-fedavg
Attack: gaussian, 10.0% compromised
Final accuracy - Compromised: 0.0472, Honest: 0.0474
Overall test accuracy: mean=0.0474 ± 0.0103
