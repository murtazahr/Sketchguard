Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5540 ± 0.0154 | min=0.5276 max=0.5776
         : test loss mean=1.6644 ± 0.0532
         : individual accs = ['0.553779', '0.564121', '0.546190', '0.555504', '0.553899', '0.577560', '0.576675', '0.537365', '0.570985', '0.540566', '0.535602', '0.531123', '0.553872', '0.568978', '0.566140', '0.554480', '0.533590', '0.558929', '0.573213', '0.527616']
         : correct/total = [(2286, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2266, 4091), (2476, 4287), (2418, 4193), (2337, 4349), (2393, 4191), (2312, 4277), (2219, 4143), (2227, 4193), (2267, 4093), (2388, 4197), (2294, 4052), (2234, 4029), (2216, 4153), (2338, 4183), (2341, 4084), (2178, 4128)]
         : compromised: 0.5664, honest: 0.5487
Round 002: test acc mean=0.7307 ± 0.0098 | min=0.7075 max=0.7542
         : test loss mean=0.8932 ± 0.0274
         : individual accs = ['0.726986', '0.743517', '0.722127', '0.734364', '0.735273', '0.736646', '0.737181', '0.732352', '0.707468', '0.733926', '0.732561', '0.721440', '0.720254', '0.724565', '0.754195', '0.735666', '0.722369', '0.739182', '0.729432', '0.724806']
         : correct/total = [(3001, 4128), (3125, 4203), (2947, 4081), (3182, 4333), (3008, 4091), (3158, 4287), (3091, 4193), (3185, 4349), (2965, 4191), (3139, 4277), (3035, 4143), (3025, 4193), (2948, 4093), (3041, 4197), (3056, 4052), (2964, 4029), (3000, 4153), (3092, 4183), (2979, 4084), (2992, 4128)]
         : compromised: 0.7340, honest: 0.7293
Round 003: test acc mean=0.7759 ± 0.0067 | min=0.7608 max=0.7882
         : test loss mean=0.7091 ± 0.0212
         : individual accs = ['0.771076', '0.788246', '0.764028', '0.781906', '0.771450', '0.778167', '0.769855', '0.776270', '0.786209', '0.776011', '0.770215', '0.779633', '0.760811', '0.778890', '0.781836', '0.778605', '0.780159', '0.775520', '0.777669', '0.770591']
         : correct/total = [(3183, 4128), (3313, 4203), (3118, 4081), (3388, 4333), (3156, 4091), (3336, 4287), (3228, 4193), (3376, 4349), (3295, 4191), (3319, 4277), (3191, 4143), (3269, 4193), (3114, 4093), (3269, 4197), (3168, 4052), (3137, 4029), (3240, 4153), (3244, 4183), (3176, 4084), (3181, 4128)]
         : compromised: 0.7755, honest: 0.7760
Round 004: test acc mean=0.8020 ± 0.0085 | min=0.7873 max=0.8196
         : test loss mean=0.6210 ± 0.0272
         : individual accs = ['0.791909', '0.812991', '0.804460', '0.809139', '0.787338', '0.805925', '0.813022', '0.788227', '0.819613', '0.812485', '0.800145', '0.797043', '0.798925', '0.803908', '0.798618', '0.801191', '0.790994', '0.805403', '0.802889', '0.796269']
         : correct/total = [(3269, 4128), (3417, 4203), (3283, 4081), (3506, 4333), (3221, 4091), (3455, 4287), (3409, 4193), (3428, 4349), (3435, 4191), (3475, 4277), (3315, 4143), (3342, 4193), (3270, 4093), (3374, 4197), (3236, 4052), (3228, 4029), (3285, 4153), (3369, 4183), (3279, 4084), (3287, 4128)]
         : compromised: 0.8026, honest: 0.8018
Round 005: test acc mean=0.8109 ± 0.0083 | min=0.7951 max=0.8301
         : test loss mean=0.5875 ± 0.0271
         : individual accs = ['0.804506', '0.817035', '0.816957', '0.809601', '0.796138', '0.813623', '0.813737', '0.817889', '0.830112', '0.821136', '0.795076', '0.808967', '0.809919', '0.804146', '0.806269', '0.808637', '0.807850', '0.812814', '0.821009', '0.803537']
         : correct/total = [(3321, 4128), (3434, 4203), (3334, 4081), (3508, 4333), (3257, 4091), (3488, 4287), (3412, 4193), (3557, 4349), (3479, 4191), (3512, 4277), (3294, 4143), (3392, 4193), (3315, 4093), (3375, 4197), (3267, 4052), (3258, 4029), (3355, 4153), (3400, 4183), (3353, 4084), (3317, 4128)]
         : compromised: 0.8113, honest: 0.8108
Round 006: test acc mean=0.8132 ± 0.0065 | min=0.8008 max=0.8235
         : test loss mean=0.5672 ± 0.0225
         : individual accs = ['0.815649', '0.811801', '0.800784', '0.821602', '0.810315', '0.817588', '0.820415', '0.820189', '0.812455', '0.823474', '0.805455', '0.808252', '0.810897', '0.811532', '0.822557', '0.809382', '0.807850', '0.814009', '0.802155', '0.818314']
         : correct/total = [(3367, 4128), (3412, 4203), (3268, 4081), (3560, 4333), (3315, 4091), (3505, 4287), (3440, 4193), (3567, 4349), (3405, 4191), (3522, 4277), (3337, 4143), (3389, 4193), (3319, 4093), (3406, 4197), (3333, 4052), (3261, 4029), (3355, 4153), (3405, 4183), (3276, 4084), (3378, 4128)]
         : compromised: 0.8131, honest: 0.8133
Round 007: test acc mean=0.8289 ± 0.0062 | min=0.8157 max=0.8406
         : test loss mean=0.5250 ± 0.0234
         : individual accs = ['0.825824', '0.826077', '0.823573', '0.833833', '0.815693', '0.836016', '0.832340', '0.827317', '0.840611', '0.835632', '0.822110', '0.818269', '0.835084', '0.831546', '0.830948', '0.826756', '0.827354', '0.835286', '0.830803', '0.823886']
         : correct/total = [(3409, 4128), (3472, 4203), (3361, 4081), (3613, 4333), (3337, 4091), (3584, 4287), (3490, 4193), (3598, 4349), (3523, 4191), (3574, 4277), (3406, 4143), (3431, 4193), (3418, 4093), (3490, 4197), (3367, 4052), (3331, 4029), (3436, 4153), (3494, 4183), (3393, 4084), (3401, 4128)]
         : compromised: 0.8333, honest: 0.8271
Round 008: test acc mean=0.8273 ± 0.0085 | min=0.8106 max=0.8416
         : test loss mean=0.5204 ± 0.0215
         : individual accs = ['0.828246', '0.832976', '0.829944', '0.835910', '0.812515', '0.828085', '0.841641', '0.834445', '0.832975', '0.838438', '0.816799', '0.810637', '0.831419', '0.830832', '0.818115', '0.833457', '0.815073', '0.825723', '0.824682', '0.823886']
         : correct/total = [(3419, 4128), (3501, 4203), (3387, 4081), (3622, 4333), (3324, 4091), (3550, 4287), (3529, 4193), (3629, 4349), (3491, 4191), (3586, 4277), (3384, 4143), (3399, 4193), (3403, 4093), (3487, 4197), (3315, 4052), (3358, 4029), (3385, 4153), (3454, 4183), (3368, 4084), (3401, 4128)]
         : compromised: 0.8265, honest: 0.8276
Round 009: test acc mean=0.8351 ± 0.0061 | min=0.8242 max=0.8482
         : test loss mean=0.5013 ± 0.0241
         : individual accs = ['0.832364', '0.848204', '0.835334', '0.838680', '0.824248', '0.832750', '0.827570', '0.839733', '0.844190', '0.843816', '0.839971', '0.835679', '0.831419', '0.833929', '0.832182', '0.831968', '0.830243', '0.838393', '0.836925', '0.825097']
         : correct/total = [(3436, 4128), (3565, 4203), (3409, 4081), (3634, 4333), (3372, 4091), (3570, 4287), (3470, 4193), (3652, 4349), (3538, 4191), (3609, 4277), (3480, 4143), (3504, 4193), (3403, 4093), (3500, 4197), (3372, 4052), (3352, 4029), (3448, 4153), (3507, 4183), (3418, 4084), (3406, 4128)]
         : compromised: 0.8343, honest: 0.8355
Round 010: test acc mean=0.8353 ± 0.0063 | min=0.8223 max=0.8452
         : test loss mean=0.4982 ± 0.0237
         : individual accs = ['0.837694', '0.838687', '0.828963', '0.843757', '0.822293', '0.835783', '0.841879', '0.836284', '0.835839', '0.845219', '0.829109', '0.834963', '0.825312', '0.840600', '0.839339', '0.835443', '0.838671', '0.841262', '0.827620', '0.827035']
         : correct/total = [(3458, 4128), (3525, 4203), (3383, 4081), (3656, 4333), (3364, 4091), (3583, 4287), (3530, 4193), (3637, 4349), (3503, 4191), (3615, 4277), (3435, 4143), (3501, 4193), (3378, 4093), (3528, 4197), (3401, 4052), (3366, 4029), (3483, 4153), (3519, 4183), (3380, 4084), (3414, 4128)]
         : compromised: 0.8350, honest: 0.8354

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 30.0% compromised
Final accuracy - Compromised: 0.8350, Honest: 0.8354
Overall test accuracy: mean=0.8353 ± 0.0063
