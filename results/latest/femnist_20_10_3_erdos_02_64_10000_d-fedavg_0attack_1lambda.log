/home/student.unimelb.edu.au/mrangwala/miniconda3/envs/edgedrift/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:282: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0925 ± 0.0478 | min=0.0399 max=0.2435
         : test loss mean=4.0762 ± 0.0353
         : individual accs = ['0.089147', '0.053533', '0.081843', '0.039926', '0.065510', '0.102169', '0.086334', '0.081628', '0.149129', '0.173954', '0.114893', '0.054853', '0.062301', '0.049797', '0.063672', '0.070985', '0.067662', '0.121205', '0.077865', '0.243459']
         : correct/total = [(368, 4128), (225, 4203), (334, 4081), (173, 4333), (268, 4091), (438, 4287), (362, 4193), (355, 4349), (625, 4191), (744, 4277), (476, 4143), (230, 4193), (255, 4093), (209, 4197), (258, 4052), (286, 4029), (281, 4153), (507, 4183), (318, 4084), (1005, 4128)]
Round 002: test acc mean=0.5829 ± 0.0420 | min=0.5155 max=0.6590
         : test loss mean=3.0508 ± 0.2223
         : individual accs = ['0.633963', '0.591958', '0.547170', '0.635818', '0.587876', '0.607185', '0.527069', '0.538285', '0.659031', '0.621931', '0.576394', '0.595755', '0.587100', '0.541577', '0.534057', '0.531149', '0.515531', '0.583792', '0.597943', '0.644138']
         : correct/total = [(2617, 4128), (2488, 4203), (2233, 4081), (2755, 4333), (2405, 4091), (2603, 4287), (2210, 4193), (2341, 4349), (2762, 4191), (2660, 4277), (2388, 4143), (2498, 4193), (2403, 4093), (2273, 4197), (2164, 4052), (2140, 4029), (2141, 4153), (2442, 4183), (2442, 4084), (2659, 4128)]
Round 003: test acc mean=0.7238 ± 0.0238 | min=0.6685 max=0.7573
         : test loss mean=1.4961 ± 0.2891
         : individual accs = ['0.710998', '0.687842', '0.675815', '0.753520', '0.719384', '0.744343', '0.746721', '0.719476', '0.757337', '0.733224', '0.705045', '0.668495', '0.742731', '0.735764', '0.724580', '0.746091', '0.722129', '0.722209', '0.726004', '0.734012']
         : correct/total = [(2935, 4128), (2891, 4203), (2758, 4081), (3265, 4333), (2943, 4091), (3191, 4287), (3131, 4193), (3129, 4349), (3174, 4191), (3136, 4277), (2921, 4143), (2803, 4193), (3040, 4093), (3088, 4197), (2936, 4052), (3006, 4029), (2999, 4153), (3021, 4183), (2965, 4084), (3030, 4128)]
Round 004: test acc mean=0.7831 ± 0.0093 | min=0.7596 max=0.7957
         : test loss mean=0.8332 ± 0.0990
         : individual accs = ['0.779797', '0.785391', '0.764519', '0.788368', '0.776583', '0.789130', '0.794181', '0.790756', '0.783584', '0.784896', '0.759594', '0.780825', '0.790374', '0.787229', '0.795656', '0.791512', '0.785938', '0.784604', '0.780607', '0.769380']
         : correct/total = [(3219, 4128), (3301, 4203), (3120, 4081), (3416, 4333), (3177, 4091), (3383, 4287), (3330, 4193), (3439, 4349), (3284, 4191), (3357, 4277), (3147, 4143), (3274, 4193), (3235, 4093), (3304, 4197), (3224, 4052), (3189, 4029), (3264, 4153), (3282, 4183), (3188, 4084), (3176, 4128)]
Round 005: test acc mean=0.8067 ± 0.0077 | min=0.7857 max=0.8159
         : test loss mean=0.6446 ± 0.0382
         : individual accs = ['0.798692', '0.810849', '0.800784', '0.806601', '0.799560', '0.815022', '0.813737', '0.810991', '0.815557', '0.805237', '0.785663', '0.803005', '0.809919', '0.806290', '0.815893', '0.810871', '0.814592', '0.811618', '0.804358', '0.794816']
         : correct/total = [(3297, 4128), (3408, 4203), (3268, 4081), (3495, 4333), (3271, 4091), (3494, 4287), (3412, 4193), (3527, 4349), (3418, 4191), (3444, 4277), (3255, 4143), (3367, 4193), (3315, 4093), (3384, 4197), (3306, 4052), (3267, 4029), (3383, 4153), (3395, 4183), (3285, 4084), (3281, 4128)]
Round 006: test acc mean=0.8225 ± 0.0056 | min=0.8103 max=0.8298
         : test loss mean=0.5633 ± 0.0214
         : individual accs = ['0.815165', '0.823697', '0.822593', '0.823448', '0.811538', '0.825519', '0.826377', '0.828236', '0.827010', '0.823241', '0.810282', '0.820415', '0.820669', '0.825590', '0.828480', '0.828245', '0.825668', '0.829787', '0.819540', '0.814438']
         : correct/total = [(3365, 4128), (3462, 4203), (3357, 4081), (3568, 4333), (3320, 4091), (3539, 4287), (3465, 4193), (3602, 4349), (3466, 4191), (3521, 4277), (3357, 4143), (3440, 4193), (3359, 4093), (3465, 4197), (3357, 4052), (3337, 4029), (3429, 4153), (3471, 4183), (3347, 4084), (3362, 4128)]
Round 007: test acc mean=0.8321 ± 0.0069 | min=0.8149 max=0.8413
         : test loss mean=0.5222 ± 0.0221
         : individual accs = ['0.823401', '0.841304', '0.831414', '0.832679', '0.824004', '0.835083', '0.836632', '0.834675', '0.837032', '0.835399', '0.817041', '0.829716', '0.831908', '0.839409', '0.837364', '0.835195', '0.836745', '0.836959', '0.830803', '0.814922']
         : correct/total = [(3399, 4128), (3536, 4203), (3393, 4081), (3608, 4333), (3371, 4091), (3580, 4287), (3508, 4193), (3630, 4349), (3508, 4191), (3573, 4277), (3385, 4143), (3479, 4193), (3405, 4093), (3523, 4197), (3393, 4052), (3365, 4029), (3475, 4153), (3501, 4183), (3393, 4084), (3364, 4128)]
Round 008: test acc mean=0.8384 ± 0.0070 | min=0.8207 max=0.8466
         : test loss mean=0.4937 ± 0.0208
         : individual accs = ['0.827762', '0.844397', '0.838275', '0.842834', '0.831826', '0.842547', '0.844980', '0.840883', '0.834407', '0.843348', '0.825489', '0.835917', '0.841192', '0.842030', '0.839092', '0.846364', '0.846617', '0.842458', '0.837659', '0.820736']
         : correct/total = [(3417, 4128), (3549, 4203), (3421, 4081), (3652, 4333), (3403, 4091), (3612, 4287), (3543, 4193), (3657, 4349), (3497, 4191), (3607, 4277), (3420, 4143), (3505, 4193), (3443, 4093), (3534, 4197), (3400, 4052), (3410, 4029), (3516, 4153), (3524, 4183), (3421, 4084), (3388, 4128)]
Round 009: test acc mean=0.8449 ± 0.0055 | min=0.8318 max=0.8513
         : test loss mean=0.4736 ± 0.0191
         : individual accs = ['0.835756', '0.851059', '0.846116', '0.847450', '0.837937', '0.847912', '0.849750', '0.847551', '0.850155', '0.851298', '0.831764', '0.841402', '0.844368', '0.847510', '0.845755', '0.850583', '0.845172', '0.848434', '0.841332', '0.836240']
         : correct/total = [(3450, 4128), (3577, 4203), (3453, 4081), (3672, 4333), (3428, 4091), (3635, 4287), (3563, 4193), (3686, 4349), (3563, 4191), (3641, 4277), (3446, 4143), (3528, 4193), (3456, 4093), (3557, 4197), (3427, 4052), (3427, 4029), (3510, 4153), (3549, 4183), (3436, 4084), (3452, 4128)]
Round 010: test acc mean=0.8485 ± 0.0055 | min=0.8394 max=0.8611
         : test loss mean=0.4594 ± 0.0190
         : individual accs = ['0.839390', '0.856293', '0.848321', '0.848835', '0.846003', '0.845580', '0.851658', '0.851000', '0.853973', '0.861118', '0.840212', '0.843787', '0.848033', '0.852752', '0.848717', '0.853065', '0.850710', '0.849151', '0.842067', '0.839874']
         : correct/total = [(3465, 4128), (3599, 4203), (3462, 4081), (3678, 4333), (3461, 4091), (3625, 4287), (3571, 4193), (3701, 4349), (3579, 4191), (3683, 4277), (3481, 4143), (3538, 4193), (3471, 4093), (3579, 4197), (3439, 4052), (3437, 4029), (3533, 4153), (3552, 4183), (3439, 4084), (3467, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Overall test accuracy: mean=0.8485 ± 0.0055
