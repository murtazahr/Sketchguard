Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.5422 ± 0.0219 | min=0.5121 max=0.5969
         : test loss mean=1.7235 ± 0.0821
         : individual accs = ['0.533672', '0.533191', '0.563587', '0.514193', '0.531899', '0.596921', '0.555688', '0.544033', '0.540682', '0.526070', '0.522085', '0.540663', '0.534816', '0.553252', '0.584896', '0.524696', '0.569468', '0.525221', '0.535994', '0.512112']
         : correct/total = [(2203, 4128), (2241, 4203), (2300, 4081), (2228, 4333), (2176, 4091), (2559, 4287), (2330, 4193), (2366, 4349), (2266, 4191), (2250, 4277), (2163, 4143), (2267, 4193), (2189, 4093), (2322, 4197), (2370, 4052), (2114, 4029), (2365, 4153), (2197, 4183), (2189, 4084), (2114, 4128)]
         : compromised: 0.5552, honest: 0.5366
Round 002: test acc mean=0.7284 ± 0.0107 | min=0.7019 max=0.7480
         : test loss mean=0.9006 ± 0.0366
         : individual accs = ['0.741764', '0.730906', '0.727518', '0.736210', '0.721095', '0.722883', '0.730265', '0.744309', '0.712956', '0.720599', '0.731595', '0.701884', '0.738089', '0.717894', '0.730257', '0.731447', '0.722129', '0.748028', '0.733105', '0.724806']
         : correct/total = [(3062, 4128), (3072, 4203), (2969, 4081), (3190, 4333), (2950, 4091), (3099, 4287), (3062, 4193), (3237, 4349), (2988, 4191), (3082, 4277), (3031, 4143), (2943, 4193), (3021, 4093), (3013, 4197), (2959, 4052), (2947, 4029), (2999, 4153), (3129, 4183), (2994, 4084), (2992, 4128)]
         : compromised: 0.7317, honest: 0.7270
Round 003: test acc mean=0.7813 ± 0.0093 | min=0.7648 max=0.7951
         : test loss mean=0.7098 ± 0.0267
         : individual accs = ['0.792636', '0.795146', '0.790738', '0.772675', '0.792716', '0.789130', '0.777009', '0.791676', '0.784300', '0.787000', '0.770698', '0.771524', '0.784266', '0.780081', '0.766041', '0.782080', '0.777510', '0.770022', '0.786729', '0.764777']
         : correct/total = [(3272, 4128), (3342, 4203), (3227, 4081), (3348, 4333), (3243, 4091), (3383, 4287), (3258, 4193), (3443, 4349), (3287, 4191), (3366, 4277), (3193, 4143), (3235, 4193), (3210, 4093), (3274, 4197), (3104, 4052), (3151, 4029), (3229, 4153), (3221, 4183), (3213, 4084), (3157, 4128)]
         : compromised: 0.7794, honest: 0.7822
Round 004: test acc mean=0.7943 ± 0.0098 | min=0.7707 max=0.8120
         : test loss mean=0.6456 ± 0.0283
         : individual accs = ['0.802326', '0.812039', '0.793188', '0.793676', '0.808360', '0.803359', '0.790842', '0.798115', '0.790981', '0.807108', '0.770698', '0.784641', '0.800391', '0.781749', '0.797384', '0.793745', '0.791717', '0.784604', '0.796768', '0.784157']
         : correct/total = [(3312, 4128), (3413, 4203), (3237, 4081), (3439, 4333), (3307, 4091), (3444, 4287), (3316, 4193), (3471, 4349), (3315, 4191), (3452, 4277), (3193, 4143), (3290, 4193), (3276, 4093), (3281, 4197), (3231, 4052), (3198, 4029), (3288, 4153), (3282, 4183), (3254, 4084), (3237, 4128)]
         : compromised: 0.7940, honest: 0.7944
Round 005: test acc mean=0.8025 ± 0.0088 | min=0.7897 max=0.8172
         : test loss mean=0.5978 ± 0.0287
         : individual accs = ['0.800145', '0.814418', '0.798824', '0.791138', '0.806160', '0.810590', '0.792750', '0.799264', '0.813887', '0.817162', '0.794111', '0.792750', '0.808698', '0.790565', '0.800346', '0.801936', '0.815555', '0.808033', '0.804358', '0.789729']
         : correct/total = [(3303, 4128), (3423, 4203), (3260, 4081), (3428, 4333), (3298, 4091), (3475, 4287), (3324, 4193), (3476, 4349), (3411, 4191), (3495, 4277), (3290, 4143), (3324, 4193), (3310, 4093), (3318, 4197), (3243, 4052), (3231, 4029), (3387, 4153), (3380, 4183), (3285, 4084), (3260, 4128)]
         : compromised: 0.8038, honest: 0.8020
Round 006: test acc mean=0.8196 ± 0.0085 | min=0.8071 max=0.8319
         : test loss mean=0.5671 ± 0.0257
         : individual accs = ['0.823643', '0.821080', '0.829944', '0.813986', '0.825959', '0.808491', '0.809444', '0.831915', '0.811262', '0.822773', '0.807145', '0.808013', '0.831908', '0.830355', '0.812932', '0.819310', '0.826391', '0.817117', '0.828599', '0.812258']
         : correct/total = [(3400, 4128), (3451, 4203), (3387, 4081), (3527, 4333), (3379, 4091), (3466, 4287), (3394, 4193), (3618, 4349), (3400, 4191), (3519, 4277), (3344, 4143), (3388, 4193), (3405, 4093), (3485, 4197), (3294, 4052), (3301, 4029), (3432, 4153), (3418, 4183), (3384, 4084), (3353, 4128)]
         : compromised: 0.8216, honest: 0.8188
Round 007: test acc mean=0.8262 ± 0.0089 | min=0.8085 max=0.8382
         : test loss mean=0.5373 ± 0.0309
         : individual accs = ['0.838178', '0.833928', '0.834599', '0.822294', '0.832070', '0.831351', '0.820176', '0.836284', '0.815319', '0.836100', '0.811731', '0.822800', '0.826533', '0.825351', '0.808490', '0.819310', '0.835781', '0.819747', '0.835455', '0.818314']
         : correct/total = [(3460, 4128), (3505, 4203), (3406, 4081), (3563, 4333), (3404, 4091), (3564, 4287), (3439, 4193), (3637, 4349), (3417, 4191), (3576, 4277), (3363, 4143), (3450, 4193), (3383, 4093), (3464, 4197), (3276, 4052), (3301, 4029), (3471, 4153), (3429, 4183), (3412, 4084), (3378, 4128)]
         : compromised: 0.8245, honest: 0.8269
Round 008: test acc mean=0.8290 ± 0.0083 | min=0.8152 max=0.8437
         : test loss mean=0.5168 ± 0.0277
         : individual accs = ['0.831153', '0.828456', '0.841215', '0.817909', '0.836715', '0.833217', '0.815168', '0.837204', '0.838463', '0.828151', '0.820420', '0.832340', '0.828732', '0.820348', '0.816634', '0.825019', '0.843727', '0.824289', '0.837414', '0.824128']
         : correct/total = [(3431, 4128), (3482, 4203), (3433, 4081), (3544, 4333), (3423, 4091), (3572, 4287), (3418, 4193), (3641, 4349), (3514, 4191), (3542, 4277), (3399, 4143), (3490, 4193), (3392, 4093), (3443, 4197), (3309, 4052), (3324, 4029), (3504, 4153), (3448, 4183), (3420, 4084), (3402, 4128)]
         : compromised: 0.8268, honest: 0.8300
Round 009: test acc mean=0.8353 ± 0.0092 | min=0.8207 max=0.8487
         : test loss mean=0.5047 ± 0.0277
         : individual accs = ['0.837936', '0.847252', '0.848567', '0.825987', '0.842337', '0.832983', '0.826854', '0.835594', '0.833691', '0.848726', '0.821385', '0.820892', '0.837039', '0.836312', '0.827493', '0.838173', '0.848062', '0.830504', '0.845984', '0.820736']
         : correct/total = [(3459, 4128), (3561, 4203), (3463, 4081), (3579, 4333), (3446, 4091), (3571, 4287), (3467, 4193), (3634, 4349), (3494, 4191), (3630, 4277), (3403, 4143), (3442, 4193), (3426, 4093), (3510, 4197), (3353, 4052), (3377, 4029), (3522, 4153), (3474, 4183), (3455, 4084), (3388, 4128)]
         : compromised: 0.8351, honest: 0.8354
Round 010: test acc mean=0.8321 ± 0.0094 | min=0.8140 max=0.8511
         : test loss mean=0.5029 ± 0.0273
         : individual accs = ['0.829700', '0.840828', '0.838275', '0.835449', '0.836470', '0.849312', '0.828524', '0.846172', '0.829158', '0.851064', '0.832971', '0.829239', '0.822380', '0.822969', '0.824284', '0.820551', '0.830002', '0.828831', '0.831783', '0.813953']
         : correct/total = [(3425, 4128), (3534, 4203), (3421, 4081), (3620, 4333), (3422, 4091), (3641, 4287), (3474, 4193), (3680, 4349), (3475, 4191), (3640, 4277), (3451, 4143), (3477, 4193), (3366, 4093), (3454, 4197), (3340, 4052), (3306, 4029), (3447, 4153), (3467, 4183), (3397, 4084), (3360, 4128)]
         : compromised: 0.8299, honest: 0.8330

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 30.0% compromised
Final accuracy - Compromised: 0.8299, Honest: 0.8330
Overall test accuracy: mean=0.8321 ± 0.0094
