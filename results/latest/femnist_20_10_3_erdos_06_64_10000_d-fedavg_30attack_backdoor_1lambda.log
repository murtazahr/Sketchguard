Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 4
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Backdoor attack: Created poisoned datasets for 6 compromised nodes
Round 001: test acc mean=0.0125 ± 0.0115 | min=0.0029 max=0.0459
         : test loss mean=3974.1927 ± 3404.8796
         : individual accs = ['0.003391', '0.006662', '0.010537', '0.014078', '0.002933', '0.003266', '0.004293', '0.005519', '0.007874', '0.009820', '0.004586', '0.027188', '0.008551', '0.002859', '0.004689', '0.009183', '0.021430', '0.045900', '0.023751', '0.033430']
         : correct/total = [(14, 4128), (28, 4203), (43, 4081), (61, 4333), (12, 4091), (14, 4287), (18, 4193), (24, 4349), (33, 4191), (42, 4277), (19, 4143), (114, 4193), (35, 4093), (12, 4197), (19, 4052), (37, 4029), (89, 4153), (192, 4183), (97, 4084), (138, 4128)]
         : compromised: 0.0148, honest: 0.0115
Round 002: test acc mean=0.0447 ± 0.0060 | min=0.0355 max=0.0561
         : test loss mean=60511997649262224.0000 ± 194125455548558336.0000
         : individual accs = ['0.048934', '0.048775', '0.056114', '0.043157', '0.048643', '0.048519', '0.035535', '0.035640', '0.044619', '0.043488', '0.039585', '0.036728', '0.048620', '0.049559', '0.047878', '0.041698', '0.047195', '0.039445', '0.054358', '0.035853']
         : correct/total = [(202, 4128), (205, 4203), (229, 4081), (187, 4333), (199, 4091), (208, 4287), (149, 4193), (155, 4349), (187, 4191), (186, 4277), (164, 4143), (154, 4193), (199, 4093), (208, 4197), (194, 4052), (168, 4029), (196, 4153), (165, 4183), (222, 4084), (148, 4128)]
         : compromised: 0.0481, honest: 0.0433
Round 003: test acc mean=0.0488 ± 0.0094 | min=0.0198 max=0.0618
         : test loss mean=3.9144 ± 0.0361
         : individual accs = ['0.051599', '0.051630', '0.050723', '0.048465', '0.051088', '0.048052', '0.019795', '0.051276', '0.025292', '0.053075', '0.050447', '0.061770', '0.053750', '0.046938', '0.048124', '0.056342', '0.055141', '0.050203', '0.052889', '0.048450']
         : correct/total = [(213, 4128), (217, 4203), (207, 4081), (210, 4333), (209, 4091), (206, 4287), (83, 4193), (223, 4349), (106, 4191), (227, 4277), (209, 4143), (259, 4193), (220, 4093), (197, 4197), (195, 4052), (227, 4029), (229, 4153), (210, 4183), (216, 4084), (200, 4128)]
         : compromised: 0.0500, honest: 0.0482
Round 004: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.7153 ± 0.0191
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0566, honest: 0.0559
Round 005: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.7278 ± 0.0266
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0566, honest: 0.0559
Round 006: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.7425 ± 0.0288
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0566, honest: 0.0559
Round 007: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.7726 ± 0.0333
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0566, honest: 0.0559
Round 008: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.7616 ± 0.0290
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0566, honest: 0.0559
Round 009: test acc mean=0.0547 ± 0.0074 | min=0.0253 max=0.0624
         : test loss mean=3.7331 ± 0.0229
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.025292', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (106, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0566, honest: 0.0539
Round 010: test acc mean=0.0488 ± 0.0032 | min=0.0434 max=0.0549
         : test loss mean=5.0456 ± 4.0339
         : individual accs = ['0.050145', '0.049726', '0.052683', '0.043388', '0.052554', '0.043387', '0.044598', '0.049207', '0.054880', '0.048398', '0.045619', '0.046983', '0.050574', '0.047177', '0.050346', '0.050633', '0.051288', '0.048291', '0.051665', '0.045058']
         : correct/total = [(207, 4128), (209, 4203), (215, 4081), (188, 4333), (215, 4091), (186, 4287), (187, 4193), (214, 4349), (230, 4191), (207, 4277), (189, 4143), (197, 4193), (207, 4093), (198, 4197), (204, 4052), (204, 4029), (213, 4153), (202, 4183), (211, 4084), (186, 4128)]
         : compromised: 0.0486, honest: 0.0489

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: backdoor, 30.0% compromised
Final accuracy - Compromised: 0.0486, Honest: 0.0489
Overall test accuracy: mean=0.0488 ± 0.0032

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 4x4
Overall ASR: 0.0000 ± 0.0000
Honest nodes ASR: 0.0000 ± 0.0000
Compromised nodes ASR: 0.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack
