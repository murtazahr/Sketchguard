Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 14/20 nodes: [1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 17, 18, 19]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.30000000000000004
  - Stage 1: Distance-based filtering (select 30% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.6310 ± 0.0615 | min=0.5205 max=0.7172
         : test loss mean=0.6761 ± 0.0075
         : individual accs = ['0.683333', '0.601900', '0.608696', '0.620035', '0.611993', '0.621834', '0.581659', '0.582964', '0.563380', '0.699468', '0.702797', '0.614222', '0.700521', '0.717241', '0.530249', '0.520524', '0.715771', '0.687887', '0.685393', '0.570552']
         : correct/total = [(779, 1140), (697, 1158), (686, 1127), (718, 1158), (694, 1134), (712, 1145), (666, 1145), (657, 1127), (640, 1136), (789, 1128), (804, 1144), (691, 1125), (807, 1152), (832, 1160), (596, 1124), (596, 1145), (826, 1154), (778, 1131), (793, 1157), (651, 1141)]
         : compromised: 0.6160, honest: 0.6661
         : ubar stats = ['Node 0: s1=0.263, s2=0.200', 'Node 1: s1=0.263, s2=0.800', 'Node 2: s1=0.263, s2=0.200']...
Round 002: test acc mean=0.7016 ± 0.0553 | min=0.5374 max=0.7686
         : test loss mean=0.6127 ± 0.0511
         : individual accs = ['0.735965', '0.693437', '0.754215', '0.696028', '0.618166', '0.703930', '0.730131', '0.657498', '0.707746', '0.727837', '0.727273', '0.755556', '0.708333', '0.618103', '0.537367', '0.679476', '0.768631', '0.743590', '0.744166', '0.723926']
         : correct/total = [(839, 1140), (803, 1158), (850, 1127), (806, 1158), (701, 1134), (806, 1145), (836, 1145), (741, 1127), (804, 1136), (821, 1128), (832, 1144), (850, 1125), (816, 1152), (717, 1160), (604, 1124), (778, 1145), (887, 1154), (841, 1131), (861, 1157), (826, 1141)]
         : compromised: 0.6997, honest: 0.7059
         : ubar stats = ['Node 0: s1=0.263, s2=0.200', 'Node 1: s1=0.263, s2=0.600', 'Node 2: s1=0.263, s2=0.200']...
Round 003: test acc mean=0.7927 ± 0.0370 | min=0.7260 max=0.8437
         : test loss mean=0.4861 ± 0.0650
         : individual accs = ['0.842105', '0.798791', '0.814552', '0.816062', '0.753968', '0.843668', '0.804367', '0.786158', '0.800176', '0.834220', '0.815559', '0.811556', '0.730035', '0.775000', '0.733986', '0.779913', '0.840555', '0.745358', '0.726016', '0.801928']
         : correct/total = [(960, 1140), (925, 1158), (918, 1127), (945, 1158), (855, 1134), (966, 1145), (921, 1145), (886, 1127), (909, 1136), (941, 1128), (933, 1144), (913, 1125), (841, 1152), (899, 1160), (825, 1124), (893, 1145), (970, 1154), (843, 1131), (840, 1157), (915, 1141)]
         : compromised: 0.7844, honest: 0.8121
         : ubar stats = ['Node 0: s1=0.263, s2=0.200', 'Node 1: s1=0.263, s2=0.467', 'Node 2: s1=0.263, s2=0.200']...
Round 004: test acc mean=0.8538 ± 0.0159 | min=0.8273 max=0.8811
         : test loss mean=0.3521 ± 0.0303
         : individual accs = ['0.866667', '0.868739', '0.855368', '0.867012', '0.849206', '0.878603', '0.866376', '0.838509', '0.847711', '0.869681', '0.881119', '0.857778', '0.827257', '0.835345', '0.835409', '0.835808', '0.851820', '0.841733', '0.834918', '0.866784']
         : correct/total = [(988, 1140), (1006, 1158), (964, 1127), (1004, 1158), (963, 1134), (1006, 1145), (992, 1145), (945, 1127), (963, 1136), (981, 1128), (1008, 1144), (965, 1125), (953, 1152), (969, 1160), (939, 1124), (957, 1145), (983, 1154), (952, 1131), (966, 1157), (989, 1141)]
         : compromised: 0.8513, honest: 0.8595
         : ubar stats = ['Node 0: s1=0.263, s2=0.200', 'Node 1: s1=0.263, s2=0.450', 'Node 2: s1=0.263, s2=0.200']...
Round 005: test acc mean=0.8673 ± 0.0160 | min=0.8245 max=0.8895
         : test loss mean=0.3072 ± 0.0252
         : individual accs = ['0.846491', '0.874784', '0.857143', '0.889465', '0.870370', '0.856769', '0.883843', '0.853594', '0.870599', '0.889184', '0.888112', '0.875556', '0.870660', '0.868966', '0.861210', '0.857642', '0.879549', '0.850575', '0.824546', '0.876424']
         : correct/total = [(965, 1140), (1013, 1158), (966, 1127), (1030, 1158), (987, 1134), (981, 1145), (1012, 1145), (962, 1127), (989, 1136), (1003, 1128), (1016, 1144), (985, 1125), (1003, 1152), (1008, 1160), (968, 1124), (982, 1145), (1015, 1154), (962, 1131), (954, 1157), (1000, 1141)]
         : compromised: 0.8656, honest: 0.8712
         : ubar stats = ['Node 0: s1=0.263, s2=0.360', 'Node 1: s1=0.263, s2=0.400', 'Node 2: s1=0.263, s2=0.240']...
Round 006: test acc mean=0.8874 ± 0.0095 | min=0.8678 max=0.9004
         : test loss mean=0.2711 ± 0.0164
         : individual accs = ['0.892982', '0.884283', '0.881988', '0.894646', '0.879189', '0.900437', '0.895197', '0.891748', '0.897887', '0.882979', '0.895105', '0.896889', '0.877604', '0.891379', '0.882562', '0.869869', '0.897747', '0.876216', '0.867761', '0.891323']
         : correct/total = [(1018, 1140), (1024, 1158), (994, 1127), (1036, 1158), (997, 1134), (1031, 1145), (1025, 1145), (1005, 1127), (1020, 1136), (996, 1128), (1024, 1144), (1009, 1125), (1011, 1152), (1034, 1160), (992, 1124), (996, 1145), (1036, 1154), (991, 1131), (1004, 1157), (1017, 1141)]
         : compromised: 0.8863, honest: 0.8900
         : ubar stats = ['Node 0: s1=0.263, s2=0.333', 'Node 1: s1=0.263, s2=0.367', 'Node 2: s1=0.263, s2=0.233']...
Round 007: test acc mean=0.8940 ± 0.0083 | min=0.8764 max=0.9079
         : test loss mean=0.2582 ± 0.0139
         : individual accs = ['0.907895', '0.895509', '0.889086', '0.904145', '0.887125', '0.899563', '0.892576', '0.899734', '0.902289', '0.901596', '0.900350', '0.883556', '0.888889', '0.891379', '0.896797', '0.884716', '0.902080', '0.881521', '0.876404', '0.893953']
         : correct/total = [(1035, 1140), (1037, 1158), (1002, 1127), (1047, 1158), (1006, 1134), (1030, 1145), (1022, 1145), (1014, 1127), (1025, 1136), (1017, 1128), (1030, 1144), (994, 1125), (1024, 1152), (1034, 1160), (1008, 1124), (1013, 1145), (1041, 1154), (997, 1131), (1014, 1157), (1020, 1141)]
         : compromised: 0.8915, honest: 0.8998
         : ubar stats = ['Node 0: s1=0.263, s2=0.314', 'Node 1: s1=0.263, s2=0.400', 'Node 2: s1=0.263, s2=0.229']...
Round 008: test acc mean=0.8962 ± 0.0081 | min=0.8786 max=0.9093
         : test loss mean=0.2499 ± 0.0144
         : individual accs = ['0.904386', '0.896373', '0.886424', '0.902418', '0.894180', '0.896943', '0.897817', '0.898846', '0.890845', '0.900709', '0.903846', '0.909333', '0.899306', '0.900862', '0.907473', '0.878603', '0.897747', '0.888594', '0.880726', '0.888694']
         : correct/total = [(1031, 1140), (1038, 1158), (999, 1127), (1045, 1158), (1014, 1134), (1027, 1145), (1028, 1145), (1013, 1127), (1012, 1136), (1016, 1128), (1034, 1144), (1023, 1125), (1036, 1152), (1045, 1160), (1020, 1124), (1006, 1145), (1036, 1154), (1005, 1131), (1019, 1157), (1014, 1141)]
         : compromised: 0.8946, honest: 0.9000
         : ubar stats = ['Node 0: s1=0.263, s2=0.300', 'Node 1: s1=0.263, s2=0.375', 'Node 2: s1=0.263, s2=0.275']...
Round 009: test acc mean=0.8999 ± 0.0112 | min=0.8660 max=0.9138
         : test loss mean=0.2461 ± 0.0178
         : individual accs = ['0.913158', '0.895509', '0.892635', '0.911917', '0.902998', '0.906550', '0.907424', '0.901508', '0.900528', '0.890957', '0.904720', '0.913778', '0.904514', '0.902586', '0.911032', '0.884716', '0.900347', '0.886826', '0.866033', '0.900088']
         : correct/total = [(1041, 1140), (1037, 1158), (1006, 1127), (1056, 1158), (1024, 1134), (1038, 1145), (1039, 1145), (1016, 1127), (1023, 1136), (1005, 1128), (1035, 1144), (1028, 1125), (1042, 1152), (1047, 1160), (1024, 1124), (1013, 1145), (1039, 1154), (1003, 1131), (1002, 1157), (1027, 1141)]
         : compromised: 0.8989, honest: 0.9023
         : ubar stats = ['Node 0: s1=0.263, s2=0.289', 'Node 1: s1=0.263, s2=0.422', 'Node 2: s1=0.263, s2=0.289']...
Round 010: test acc mean=0.9017 ± 0.0074 | min=0.8850 max=0.9132
         : test loss mean=0.2391 ± 0.0154
         : individual accs = ['0.913158', '0.901554', '0.897072', '0.906736', '0.900353', '0.901310', '0.903057', '0.907720', '0.901408', '0.903369', '0.906469', '0.909333', '0.902778', '0.905172', '0.912811', '0.889956', '0.904679', '0.888594', '0.885048', '0.893953']
         : correct/total = [(1041, 1140), (1044, 1158), (1011, 1127), (1050, 1158), (1021, 1134), (1032, 1145), (1034, 1145), (1023, 1127), (1024, 1136), (1019, 1128), (1037, 1144), (1023, 1125), (1040, 1152), (1050, 1160), (1026, 1124), (1019, 1145), (1044, 1154), (1005, 1131), (1024, 1157), (1020, 1141)]
         : compromised: 0.8999, honest: 0.9060
         : ubar stats = ['Node 0: s1=0.263, s2=0.300', 'Node 1: s1=0.263, s2=0.400', 'Node 2: s1=0.263, s2=0.320']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: fully, Aggregation: ubar
Attack: directed_deviation, 70.0% compromised
Final accuracy - Compromised: 0.8999, Honest: 0.9060
Overall test accuracy: mean=0.9017 ± 0.0074

=== UBAR SUMMARY ===
Node 0: stage1=0.263, stage2=0.300, overall=0.079
Node 1: stage1=0.263, stage2=0.400, overall=0.105
Node 2: stage1=0.263, stage2=0.320, overall=0.084
Node 3: stage1=0.263, stage2=0.420, overall=0.111
Node 4: stage1=0.263, stage2=0.520, overall=0.137
Node 5: stage1=0.263, stage2=0.380, overall=0.100
Node 6: stage1=0.263, stage2=0.340, overall=0.089
Node 7: stage1=0.263, stage2=0.520, overall=0.137
Node 8: stage1=0.263, stage2=0.460, overall=0.121
Node 9: stage1=0.263, stage2=0.420, overall=0.111
Node 10: stage1=0.263, stage2=0.300, overall=0.079
Node 11: stage1=0.263, stage2=0.260, overall=0.068
Node 12: stage1=0.263, stage2=0.520, overall=0.137
Node 13: stage1=0.263, stage2=0.560, overall=0.147
Node 14: stage1=0.263, stage2=0.560, overall=0.147
Node 15: stage1=0.263, stage2=0.240, overall=0.063
Node 16: stage1=0.263, stage2=0.360, overall=0.095
Node 17: stage1=0.263, stage2=0.280, overall=0.074
Node 18: stage1=0.263, stage2=0.440, overall=0.116
Node 19: stage1=0.263, stage2=0.420, overall=0.111

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.053s (21.3%)
    - Loss computation: 0.193s (77.1%)
    - Aggregation: 0.004s (1.6%)
  TOTALS:
    - Total computation: 0.250s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.250s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.047s
  - Loss computation: 0.168s
  - Aggregation: 0.003s
  - Model transfer: 0.000s
  - Total per node: 0.219s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.945s
  - Total loss computation: 3.367s
  - Total aggregation: 0.068s
  - Total model transfer: 0.000s
  - Grand total: 4.379s
  - Mean Stage 1 acceptance rate: 0.263
  - Mean Stage 2 acceptance rate: 0.401
  - Overall acceptance rate: 0.106

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.30000000000000004
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 30% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
