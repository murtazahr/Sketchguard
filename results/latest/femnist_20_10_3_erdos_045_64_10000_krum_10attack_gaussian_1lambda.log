Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5472 ± 0.0136 | min=0.5257 max=0.5716
         : test loss mean=1.7190 ± 0.0552
         : individual accs = ['0.538275', '0.564121', '0.546190', '0.555504', '0.559032', '0.554934', '0.539232', '0.539204', '0.540205', '0.540566', '0.525706', '0.547579', '0.549230', '0.571599', '0.565400', '0.531646', '0.526848', '0.558929', '0.563173', '0.527616']
         : correct/total = [(2222, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2287, 4091), (2379, 4287), (2261, 4193), (2345, 4349), (2264, 4191), (2312, 4277), (2178, 4143), (2296, 4193), (2248, 4093), (2399, 4197), (2291, 4052), (2142, 4029), (2188, 4153), (2338, 4183), (2300, 4084), (2178, 4128)]
         : compromised: 0.5633, honest: 0.5455
Round 002: test acc mean=0.7338 ± 0.0070 | min=0.7190 max=0.7441
         : test loss mean=0.8945 ± 0.0281
         : individual accs = ['0.727713', '0.732810', '0.721882', '0.733903', '0.730384', '0.744110', '0.737420', '0.739020', '0.739919', '0.742810', '0.734733', '0.731696', '0.741510', '0.729807', '0.743583', '0.736163', '0.724296', '0.728186', '0.736778', '0.718992']
         : correct/total = [(3004, 4128), (3080, 4203), (2946, 4081), (3180, 4333), (2988, 4091), (3190, 4287), (3092, 4193), (3214, 4349), (3101, 4191), (3177, 4277), (3044, 4143), (3068, 4193), (3035, 4093), (3063, 4197), (3013, 4052), (2966, 4029), (3008, 4153), (3046, 4183), (3009, 4084), (2968, 4128)]
         : compromised: 0.7370, honest: 0.7334
Round 003: test acc mean=0.7654 ± 0.0118 | min=0.7434 max=0.7919
         : test loss mean=0.7429 ± 0.0442
         : individual accs = ['0.750000', '0.778967', '0.743445', '0.766213', '0.752872', '0.773035', '0.768662', '0.754886', '0.791935', '0.785364', '0.761525', '0.752445', '0.762766', '0.761496', '0.764067', '0.759990', '0.776065', '0.774803', '0.764202', '0.765262']
         : correct/total = [(3096, 4128), (3274, 4203), (3034, 4081), (3320, 4333), (3080, 4091), (3314, 4287), (3223, 4193), (3283, 4349), (3319, 4191), (3359, 4277), (3155, 4143), (3155, 4193), (3122, 4093), (3196, 4197), (3096, 4052), (3062, 4029), (3223, 4153), (3241, 4183), (3121, 4084), (3159, 4128)]
         : compromised: 0.7673, honest: 0.7652
Round 004: test acc mean=0.7972 ± 0.0091 | min=0.7829 max=0.8158
         : test loss mean=0.6367 ± 0.0316
         : individual accs = ['0.789729', '0.812515', '0.789267', '0.792753', '0.782938', '0.790763', '0.796566', '0.809381', '0.815796', '0.802198', '0.788559', '0.792034', '0.795993', '0.795092', '0.794916', '0.808637', '0.793884', '0.804686', '0.803869', '0.784884']
         : correct/total = [(3260, 4128), (3415, 4203), (3221, 4081), (3435, 4333), (3203, 4091), (3390, 4287), (3340, 4193), (3520, 4349), (3419, 4191), (3431, 4277), (3267, 4143), (3321, 4193), (3258, 4093), (3337, 4197), (3221, 4052), (3258, 4029), (3297, 4153), (3366, 4183), (3283, 4084), (3240, 4128)]
         : compromised: 0.7929, honest: 0.7977
Round 005: test acc mean=0.8076 ± 0.0072 | min=0.7955 max=0.8268
         : test loss mean=0.5982 ± 0.0244
         : individual accs = ['0.795543', '0.817273', '0.809360', '0.810524', '0.797849', '0.801959', '0.817076', '0.808232', '0.803627', '0.805237', '0.798697', '0.804436', '0.812118', '0.826781', '0.807502', '0.810127', '0.806164', '0.811140', '0.808031', '0.800630']
         : correct/total = [(3284, 4128), (3435, 4203), (3303, 4081), (3512, 4333), (3264, 4091), (3438, 4287), (3426, 4193), (3515, 4349), (3368, 4191), (3444, 4277), (3309, 4143), (3373, 4193), (3324, 4093), (3470, 4197), (3272, 4052), (3264, 4029), (3348, 4153), (3393, 4183), (3300, 4084), (3305, 4128)]
         : compromised: 0.8144, honest: 0.8069
Round 006: test acc mean=0.8099 ± 0.0093 | min=0.7939 max=0.8332
         : test loss mean=0.5781 ± 0.0308
         : individual accs = ['0.803052', '0.820604', '0.812056', '0.810985', '0.793938', '0.818288', '0.805390', '0.809152', '0.833214', '0.821370', '0.797248', '0.803482', '0.809919', '0.808911', '0.809724', '0.801440', '0.805442', '0.816161', '0.819050', '0.798692']
         : correct/total = [(3315, 4128), (3449, 4203), (3314, 4081), (3514, 4333), (3248, 4091), (3508, 4287), (3377, 4193), (3519, 4349), (3492, 4191), (3513, 4277), (3303, 4143), (3369, 4193), (3315, 4093), (3395, 4197), (3281, 4052), (3229, 4029), (3345, 4153), (3414, 4183), (3345, 4084), (3297, 4128)]
         : compromised: 0.8136, honest: 0.8095
Round 007: test acc mean=0.8235 ± 0.0058 | min=0.8144 max=0.8335
         : test loss mean=0.5398 ± 0.0258
         : individual accs = ['0.826550', '0.831549', '0.817692', '0.826910', '0.818137', '0.819687', '0.828524', '0.829846', '0.821761', '0.826280', '0.815110', '0.833532', '0.823357', '0.823445', '0.827739', '0.814594', '0.824223', '0.817356', '0.829579', '0.814438']
         : correct/total = [(3412, 4128), (3495, 4203), (3337, 4081), (3583, 4333), (3347, 4091), (3514, 4287), (3474, 4193), (3609, 4349), (3444, 4191), (3534, 4277), (3377, 4143), (3495, 4193), (3370, 4093), (3456, 4197), (3354, 4052), (3282, 4029), (3423, 4153), (3419, 4183), (3388, 4084), (3362, 4128)]
         : compromised: 0.8216, honest: 0.8237
Round 008: test acc mean=0.8233 ± 0.0091 | min=0.8076 max=0.8405
         : test loss mean=0.5356 ± 0.0299
         : individual accs = ['0.810320', '0.835832', '0.831414', '0.840526', '0.807626', '0.832750', '0.829001', '0.824097', '0.825817', '0.814590', '0.819937', '0.817315', '0.821158', '0.832976', '0.819595', '0.819062', '0.818926', '0.817117', '0.835211', '0.811773']
         : correct/total = [(3345, 4128), (3513, 4203), (3393, 4081), (3642, 4333), (3304, 4091), (3570, 4287), (3476, 4193), (3584, 4349), (3461, 4191), (3484, 4277), (3397, 4143), (3427, 4193), (3361, 4093), (3496, 4197), (3321, 4052), (3300, 4029), (3401, 4153), (3418, 4183), (3411, 4084), (3351, 4128)]
         : compromised: 0.8329, honest: 0.8222
Round 009: test acc mean=0.8268 ± 0.0099 | min=0.8117 max=0.8494
         : test loss mean=0.5251 ± 0.0313
         : individual accs = ['0.816376', '0.838449', '0.830189', '0.835449', '0.834515', '0.819454', '0.824946', '0.842722', '0.849439', '0.832593', '0.816558', '0.829001', '0.824823', '0.826305', '0.824038', '0.815587', '0.811702', '0.827158', '0.823947', '0.811773']
         : correct/total = [(3370, 4128), (3524, 4203), (3388, 4081), (3620, 4333), (3414, 4091), (3513, 4287), (3459, 4193), (3665, 4349), (3560, 4191), (3561, 4277), (3383, 4143), (3476, 4193), (3376, 4093), (3468, 4197), (3339, 4052), (3286, 4029), (3371, 4153), (3460, 4183), (3365, 4084), (3351, 4128)]
         : compromised: 0.8229, honest: 0.8272
Round 010: test acc mean=0.8248 ± 0.0101 | min=0.8086 max=0.8435
         : test loss mean=0.5128 ± 0.0252
         : individual accs = ['0.808624', '0.838687', '0.813281', '0.840757', '0.829382', '0.834383', '0.814214', '0.823638', '0.843474', '0.840309', '0.822351', '0.818984', '0.816760', '0.816059', '0.821570', '0.812112', '0.828317', '0.823333', '0.824682', '0.824128']
         : correct/total = [(3338, 4128), (3525, 4203), (3319, 4081), (3643, 4333), (3393, 4091), (3577, 4287), (3414, 4193), (3582, 4349), (3535, 4191), (3594, 4277), (3407, 4143), (3434, 4193), (3343, 4093), (3425, 4197), (3329, 4052), (3272, 4029), (3440, 4153), (3444, 4183), (3368, 4084), (3402, 4128)]
         : compromised: 0.8252, honest: 0.8247

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 10.0% compromised
Final accuracy - Compromised: 0.8252, Honest: 0.8247
Overall test accuracy: mean=0.8248 ± 0.0101
