Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Degree statistics: avg=4.80, min=2, max=7
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5487 ± 0.0209 | min=0.5088 max=0.5876
         : test loss mean=1.6889 ± 0.0799
         : individual accs = ['0.538275', '0.555556', '0.546190', '0.534964', '0.553899', '0.554934', '0.539232', '0.539204', '0.586018', '0.541501', '0.508810', '0.546148', '0.549230', '0.584227', '0.587611', '0.531646', '0.526848', '0.540521', '0.581538', '0.527616']
         : correct/total = [(2222, 4128), (2335, 4203), (2229, 4081), (2318, 4333), (2266, 4091), (2379, 4287), (2261, 4193), (2345, 4349), (2456, 4191), (2316, 4277), (2108, 4143), (2290, 4193), (2248, 4093), (2452, 4197), (2381, 4052), (2142, 4029), (2188, 4153), (2261, 4183), (2375, 4084), (2178, 4128)]
         : compromised: 0.5696, honest: 0.5464
Round 002: test acc mean=0.7341 ± 0.0097 | min=0.7111 max=0.7460
         : test loss mean=0.8776 ± 0.0325
         : individual accs = ['0.727713', '0.743517', '0.734624', '0.745442', '0.711073', '0.735946', '0.731219', '0.745459', '0.731806', '0.737667', '0.741974', '0.746005', '0.742976', '0.728377', '0.719645', '0.729213', '0.717794', '0.733206', '0.745103', '0.733527']
         : correct/total = [(3004, 4128), (3125, 4203), (2998, 4081), (3230, 4333), (2909, 4091), (3155, 4287), (3066, 4193), (3242, 4349), (3067, 4191), (3155, 4277), (3074, 4143), (3128, 4193), (3041, 4093), (3057, 4197), (2916, 4052), (2938, 4029), (2981, 4153), (3067, 4183), (3043, 4084), (3028, 4128)]
         : compromised: 0.7322, honest: 0.7343
Round 003: test acc mean=0.7793 ± 0.0095 | min=0.7577 max=0.7999
         : test loss mean=0.7019 ± 0.0364
         : individual accs = ['0.775436', '0.783726', '0.785837', '0.792061', '0.768027', '0.774668', '0.776055', '0.785008', '0.779766', '0.799860', '0.757664', '0.787264', '0.783289', '0.782225', '0.769250', '0.788037', '0.779196', '0.776954', '0.775220', '0.765746']
         : correct/total = [(3201, 4128), (3294, 4203), (3207, 4081), (3432, 4333), (3142, 4091), (3321, 4287), (3254, 4193), (3414, 4349), (3268, 4191), (3421, 4277), (3139, 4143), (3301, 4193), (3206, 4093), (3283, 4197), (3117, 4052), (3175, 4029), (3236, 4153), (3250, 4183), (3166, 4084), (3161, 4128)]
         : compromised: 0.7784, honest: 0.7794
Round 004: test acc mean=0.8015 ± 0.0096 | min=0.7881 max=0.8189
         : test loss mean=0.6268 ± 0.0279
         : individual accs = ['0.797723', '0.818939', '0.801764', '0.808447', '0.788805', '0.798227', '0.799666', '0.814670', '0.816034', '0.806406', '0.788076', '0.796327', '0.816516', '0.792947', '0.801333', '0.805907', '0.792921', '0.790103', '0.806072', '0.789729']
         : correct/total = [(3293, 4128), (3442, 4203), (3272, 4081), (3503, 4333), (3227, 4091), (3422, 4287), (3353, 4193), (3543, 4349), (3420, 4191), (3449, 4277), (3265, 4143), (3339, 4193), (3342, 4093), (3328, 4197), (3247, 4052), (3247, 4029), (3293, 4153), (3305, 4183), (3292, 4084), (3260, 4128)]
         : compromised: 0.7956, honest: 0.8022
Round 005: test acc mean=0.8099 ± 0.0097 | min=0.7921 max=0.8307
         : test loss mean=0.5904 ± 0.0256
         : individual accs = ['0.793847', '0.821318', '0.813036', '0.792061', '0.817160', '0.807791', '0.809444', '0.818349', '0.822954', '0.830722', '0.804490', '0.804674', '0.801368', '0.807243', '0.812685', '0.810127', '0.807609', '0.809228', '0.795544', '0.818556']
         : correct/total = [(3277, 4128), (3452, 4203), (3318, 4081), (3432, 4333), (3343, 4091), (3463, 4287), (3394, 4193), (3559, 4349), (3449, 4191), (3553, 4277), (3333, 4143), (3374, 4193), (3280, 4093), (3388, 4197), (3293, 4052), (3264, 4029), (3354, 4153), (3385, 4183), (3249, 4084), (3379, 4128)]
         : compromised: 0.8075, honest: 0.8102
Round 006: test acc mean=0.8181 ± 0.0071 | min=0.8047 max=0.8310
         : test loss mean=0.5588 ± 0.0265
         : individual accs = ['0.813469', '0.823935', '0.811076', '0.827602', '0.814960', '0.826685', '0.813976', '0.824097', '0.811024', '0.817863', '0.804731', '0.820653', '0.805033', '0.816059', '0.821570', '0.812112', '0.824464', '0.830983', '0.820029', '0.822190']
         : correct/total = [(3358, 4128), (3463, 4203), (3310, 4081), (3586, 4333), (3334, 4091), (3544, 4287), (3413, 4193), (3584, 4349), (3399, 4191), (3498, 4277), (3334, 4143), (3441, 4193), (3295, 4093), (3425, 4197), (3329, 4052), (3272, 4029), (3424, 4153), (3476, 4183), (3349, 4084), (3394, 4128)]
         : compromised: 0.8214, honest: 0.8178
Round 007: test acc mean=0.8268 ± 0.0088 | min=0.8028 max=0.8368
         : test loss mean=0.5301 ± 0.0267
         : individual accs = ['0.819767', '0.831549', '0.828473', '0.824602', '0.822537', '0.826919', '0.830432', '0.834905', '0.836077', '0.835399', '0.802800', '0.827093', '0.836795', '0.833214', '0.825271', '0.832216', '0.830966', '0.817834', '0.830558', '0.808140']
         : correct/total = [(3384, 4128), (3495, 4203), (3381, 4081), (3573, 4333), (3365, 4091), (3545, 4287), (3482, 4193), (3631, 4349), (3504, 4191), (3573, 4277), (3326, 4143), (3468, 4193), (3425, 4093), (3497, 4197), (3344, 4052), (3353, 4029), (3451, 4153), (3421, 4183), (3392, 4084), (3336, 4128)]
         : compromised: 0.8301, honest: 0.8264
Round 008: test acc mean=0.8249 ± 0.0122 | min=0.7980 max=0.8405
         : test loss mean=0.5225 ± 0.0337
         : individual accs = ['0.824612', '0.834404', '0.808625', '0.836603', '0.828893', '0.820854', '0.829716', '0.839503', '0.838463', '0.840542', '0.820661', '0.821369', '0.828976', '0.831308', '0.802567', '0.811864', '0.832651', '0.813053', '0.834721', '0.797965']
         : correct/total = [(3404, 4128), (3507, 4203), (3300, 4081), (3625, 4333), (3391, 4091), (3519, 4287), (3479, 4193), (3651, 4349), (3514, 4191), (3595, 4277), (3400, 4143), (3444, 4193), (3393, 4093), (3489, 4197), (3252, 4052), (3271, 4029), (3458, 4153), (3401, 4183), (3409, 4084), (3294, 4128)]
         : compromised: 0.8261, honest: 0.8247
Round 009: test acc mean=0.8323 ± 0.0080 | min=0.8182 max=0.8516
         : test loss mean=0.5051 ± 0.0204
         : individual accs = ['0.819525', '0.842731', '0.840235', '0.832449', '0.835248', '0.834383', '0.832817', '0.833295', '0.851587', '0.821604', '0.818248', '0.823992', '0.828976', '0.829402', '0.826259', '0.833209', '0.831206', '0.841023', '0.837904', '0.832364']
         : correct/total = [(3383, 4128), (3542, 4203), (3429, 4081), (3607, 4333), (3417, 4091), (3577, 4287), (3492, 4193), (3624, 4349), (3569, 4191), (3514, 4277), (3390, 4143), (3455, 4193), (3393, 4093), (3481, 4197), (3348, 4052), (3357, 4029), (3452, 4153), (3518, 4183), (3422, 4084), (3436, 4128)]
         : compromised: 0.8319, honest: 0.8324
Round 010: test acc mean=0.8368 ± 0.0099 | min=0.8108 max=0.8534
         : test loss mean=0.4931 ± 0.0287
         : individual accs = ['0.836967', '0.853438', '0.810831', '0.846527', '0.834759', '0.828085', '0.847365', '0.840193', '0.840611', '0.846154', '0.830316', '0.840448', '0.842903', '0.844413', '0.823791', '0.839166', '0.840597', '0.838154', '0.821254', '0.830911']
         : correct/total = [(3455, 4128), (3587, 4203), (3309, 4081), (3668, 4333), (3415, 4091), (3550, 4287), (3553, 4193), (3654, 4349), (3523, 4191), (3619, 4277), (3440, 4143), (3524, 4193), (3450, 4093), (3544, 4197), (3338, 4052), (3381, 4029), (3491, 4153), (3506, 4183), (3354, 4084), (3430, 4128)]
         : compromised: 0.8362, honest: 0.8369

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: directed_deviation, 10.0% compromised
Final accuracy - Compromised: 0.8362, Honest: 0.8369
Overall test accuracy: mean=0.8368 ± 0.0099
