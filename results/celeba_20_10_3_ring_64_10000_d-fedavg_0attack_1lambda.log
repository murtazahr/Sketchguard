Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.6029 ± 0.0503 | min=0.5075 max=0.6693
         : test loss mean=0.6870 ± 0.0026
         : individual accs = ['0.565789', '0.642487', '0.596273', '0.613990', '0.645503', '0.514410', '0.521397', '0.507542', '0.637324', '0.610816', '0.661713', '0.598222', '0.669271', '0.595690', '0.627224', '0.590393', '0.521664', '0.650752', '0.648228', '0.638913']
         : correct/total = [(645, 1140), (744, 1158), (672, 1127), (711, 1158), (732, 1134), (589, 1145), (597, 1145), (572, 1127), (724, 1136), (689, 1128), (757, 1144), (673, 1125), (771, 1152), (691, 1160), (705, 1124), (676, 1145), (602, 1154), (736, 1131), (750, 1157), (729, 1141)]
Round 002: test acc mean=0.6734 ± 0.0232 | min=0.6279 max=0.7173
         : test loss mean=0.6552 ± 0.0155
         : individual accs = ['0.653509', '0.654577', '0.671695', '0.668394', '0.648148', '0.627948', '0.674236', '0.637977', '0.706866', '0.641844', '0.680944', '0.717333', '0.704861', '0.680172', '0.685053', '0.681223', '0.684575', '0.679929', '0.695765', '0.672217']
         : correct/total = [(745, 1140), (758, 1158), (757, 1127), (774, 1158), (735, 1134), (719, 1145), (772, 1145), (719, 1127), (803, 1136), (724, 1128), (779, 1144), (807, 1125), (812, 1152), (789, 1160), (770, 1124), (780, 1145), (790, 1154), (769, 1131), (805, 1157), (767, 1141)]
Round 003: test acc mean=0.7360 ± 0.0282 | min=0.6861 max=0.7893
         : test loss mean=0.5794 ± 0.0326
         : individual accs = ['0.714035', '0.712435', '0.708962', '0.704663', '0.686067', '0.699563', '0.705677', '0.710736', '0.757923', '0.743794', '0.789336', '0.774222', '0.729167', '0.749138', '0.758007', '0.751965', '0.764298', '0.759505', '0.738980', '0.761613']
         : correct/total = [(814, 1140), (825, 1158), (799, 1127), (816, 1158), (778, 1134), (801, 1145), (808, 1145), (801, 1127), (861, 1136), (839, 1128), (903, 1144), (871, 1125), (840, 1152), (869, 1160), (852, 1124), (861, 1145), (882, 1154), (859, 1131), (855, 1157), (869, 1141)]
Round 004: test acc mean=0.8069 ± 0.0256 | min=0.7522 max=0.8453
         : test loss mean=0.4647 ± 0.0454
         : individual accs = ['0.791228', '0.777202', '0.770186', '0.752159', '0.771605', '0.797380', '0.790393', '0.801242', '0.825704', '0.840426', '0.845280', '0.842667', '0.808160', '0.820690', '0.822064', '0.801747', '0.837955', '0.818744', '0.802939', '0.819457']
         : correct/total = [(902, 1140), (900, 1158), (868, 1127), (871, 1158), (875, 1134), (913, 1145), (905, 1145), (903, 1127), (938, 1136), (948, 1128), (967, 1144), (948, 1125), (931, 1152), (952, 1160), (924, 1124), (918, 1145), (967, 1154), (926, 1131), (929, 1157), (935, 1141)]
Round 005: test acc mean=0.8362 ± 0.0246 | min=0.7813 max=0.8794
         : test loss mean=0.3896 ± 0.0419
         : individual accs = ['0.825439', '0.846287', '0.799468', '0.801382', '0.781305', '0.810480', '0.834061', '0.833185', '0.849472', '0.841312', '0.879371', '0.872000', '0.838542', '0.855172', '0.861210', '0.844541', '0.858752', '0.845270', '0.811582', '0.834356']
         : correct/total = [(941, 1140), (980, 1158), (901, 1127), (928, 1158), (886, 1134), (928, 1145), (955, 1145), (939, 1127), (965, 1136), (949, 1128), (1006, 1144), (981, 1125), (966, 1152), (992, 1160), (968, 1124), (967, 1145), (991, 1154), (956, 1131), (939, 1157), (952, 1141)]
Round 006: test acc mean=0.8601 ± 0.0149 | min=0.8307 max=0.8890
         : test loss mean=0.3378 ± 0.0292
         : individual accs = ['0.860526', '0.857513', '0.839397', '0.848014', '0.830688', '0.841921', '0.854148', '0.869565', '0.882923', '0.869681', '0.888986', '0.871111', '0.861111', '0.868966', '0.848754', '0.851528', '0.877816', '0.864721', '0.845290', '0.870289']
         : correct/total = [(981, 1140), (993, 1158), (946, 1127), (982, 1158), (942, 1134), (964, 1145), (978, 1145), (980, 1127), (1003, 1136), (981, 1128), (1017, 1144), (980, 1125), (992, 1152), (1008, 1160), (954, 1124), (975, 1145), (1013, 1154), (978, 1131), (978, 1157), (993, 1141)]
Round 007: test acc mean=0.8751 ± 0.0118 | min=0.8527 max=0.9003
         : test loss mean=0.3083 ± 0.0213
         : individual accs = ['0.877193', '0.883420', '0.852706', '0.860104', '0.857143', '0.882969', '0.877729', '0.874889', '0.877641', '0.887411', '0.900350', '0.887111', '0.877604', '0.877586', '0.874555', '0.855895', '0.883882', '0.870027', '0.863440', '0.879930']
         : correct/total = [(1000, 1140), (1023, 1158), (961, 1127), (996, 1158), (972, 1134), (1011, 1145), (1005, 1145), (986, 1127), (997, 1136), (1001, 1128), (1030, 1144), (998, 1125), (1011, 1152), (1018, 1160), (983, 1124), (980, 1145), (1020, 1154), (984, 1131), (999, 1157), (1004, 1141)]
Round 008: test acc mean=0.8762 ± 0.0120 | min=0.8563 max=0.8943
         : test loss mean=0.2981 ± 0.0184
         : individual accs = ['0.883333', '0.888601', '0.858030', '0.860967', '0.856261', '0.894323', '0.881223', '0.871340', '0.870599', '0.860816', '0.893357', '0.889778', '0.880208', '0.883621', '0.889680', '0.862009', '0.878683', '0.875332', '0.865169', '0.879930']
         : correct/total = [(1007, 1140), (1029, 1158), (967, 1127), (997, 1158), (971, 1134), (1024, 1145), (1009, 1145), (982, 1127), (989, 1136), (971, 1128), (1022, 1144), (1001, 1125), (1014, 1152), (1025, 1160), (1000, 1124), (987, 1145), (1014, 1154), (990, 1131), (1001, 1157), (1004, 1141)]
Round 009: test acc mean=0.8819 ± 0.0143 | min=0.8444 max=0.9013
         : test loss mean=0.2861 ± 0.0236
         : individual accs = ['0.895614', '0.893782', '0.874889', '0.870466', '0.872134', '0.901310', '0.889083', '0.888199', '0.888204', '0.891844', '0.896853', '0.896000', '0.885417', '0.881897', '0.884342', '0.865502', '0.876950', '0.844385', '0.854797', '0.886065']
         : correct/total = [(1021, 1140), (1035, 1158), (986, 1127), (1008, 1158), (989, 1134), (1032, 1145), (1018, 1145), (1001, 1127), (1009, 1136), (1006, 1128), (1026, 1144), (1008, 1125), (1020, 1152), (1023, 1160), (994, 1124), (991, 1145), (1012, 1154), (955, 1131), (989, 1157), (1011, 1141)]
Round 010: test acc mean=0.8886 ± 0.0098 | min=0.8669 max=0.9022
         : test loss mean=0.2746 ± 0.0171
         : individual accs = ['0.892105', '0.894646', '0.866903', '0.889465', '0.876543', '0.896070', '0.873362', '0.890861', '0.896127', '0.896277', '0.901224', '0.902222', '0.890625', '0.893103', '0.897687', '0.874236', '0.886482', '0.884173', '0.877269', '0.893076']
         : correct/total = [(1017, 1140), (1036, 1158), (977, 1127), (1030, 1158), (994, 1134), (1026, 1145), (1000, 1145), (1004, 1127), (1018, 1136), (1011, 1128), (1031, 1144), (1015, 1125), (1026, 1152), (1036, 1160), (1009, 1124), (1001, 1145), (1023, 1154), (1000, 1131), (1015, 1157), (1019, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: ring, Aggregation: d-fedavg
Overall test accuracy: mean=0.8886 ± 0.0098
