Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: directed_deviation, lambda: 1.0
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5037 ± 0.0287 | min=0.4439 max=0.5555
         : test loss mean=2313.1585 ± 1745.7811
         : individual accs = ['0.528947', '0.508636', '0.466726', '0.528497', '0.471781', '0.482096', '0.499563', '0.485359', '0.555458', '0.536348', '0.517483', '0.493333', '0.465278', '0.477586', '0.517794', '0.540611', '0.515598', '0.443855', '0.522040', '0.517090']
         : correct/total = [(603, 1140), (589, 1158), (526, 1127), (612, 1158), (535, 1134), (552, 1145), (572, 1145), (547, 1127), (631, 1136), (605, 1128), (592, 1144), (555, 1125), (536, 1152), (554, 1160), (582, 1124), (619, 1145), (595, 1154), (502, 1131), (604, 1157), (590, 1141)]
         : compromised: 0.4848, honest: 0.5118
Round 002: test acc mean=0.5078 ± 0.0143 | min=0.4871 max=0.5519
         : test loss mean=1.1945 ± 0.0335
         : individual accs = ['0.513158', '0.488774', '0.493345', '0.505181', '0.514991', '0.501310', '0.516157', '0.505768', '0.551937', '0.492908', '0.526224', '0.499556', '0.519097', '0.487069', '0.508897', '0.509170', '0.506066', '0.496021', '0.515125', '0.504820']
         : correct/total = [(585, 1140), (566, 1158), (556, 1127), (585, 1158), (584, 1134), (574, 1145), (591, 1145), (570, 1127), (627, 1136), (556, 1128), (602, 1144), (562, 1125), (598, 1152), (565, 1160), (572, 1124), (583, 1145), (584, 1154), (561, 1131), (596, 1157), (576, 1141)]
         : compromised: 0.5046, honest: 0.5091
Round 003: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.7757 ± 0.0133
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5154, honest: 0.5168
Round 004: test acc mean=0.5279 ± 0.0132 | min=0.5058 max=0.5687
         : test loss mean=50.7555 ± 1.8718
         : individual accs = ['0.537719', '0.522453', '0.505768', '0.537133', '0.528219', '0.531004', '0.532751', '0.513753', '0.568662', '0.509752', '0.529720', '0.510222', '0.532118', '0.520690', '0.530249', '0.528384', '0.525130', '0.521662', '0.535869', '0.536372']
         : correct/total = [(613, 1140), (605, 1158), (570, 1127), (622, 1158), (599, 1134), (608, 1145), (610, 1145), (579, 1127), (646, 1136), (575, 1128), (606, 1144), (574, 1125), (613, 1152), (604, 1160), (596, 1124), (605, 1145), (606, 1154), (590, 1131), (620, 1157), (612, 1141)]
         : compromised: 0.5286, honest: 0.5276
Round 005: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.8961 ± 0.0208
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5154, honest: 0.5168
Round 006: test acc mean=0.5528 ± 0.0129 | min=0.5315 max=0.5933
         : test loss mean=29.9355 ± 1.0711
         : individual accs = ['0.557018', '0.544905', '0.531500', '0.567358', '0.544092', '0.549345', '0.552838', '0.548358', '0.593310', '0.535461', '0.562063', '0.543111', '0.558160', '0.555172', '0.563167', '0.556332', '0.545927', '0.541114', '0.557476', '0.549518']
         : correct/total = [(635, 1140), (631, 1158), (599, 1127), (657, 1158), (617, 1134), (629, 1145), (633, 1145), (618, 1127), (674, 1136), (604, 1128), (643, 1144), (611, 1125), (643, 1152), (644, 1160), (633, 1124), (637, 1145), (630, 1154), (612, 1131), (645, 1157), (627, 1141)]
         : compromised: 0.5541, honest: 0.5523
Round 007: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.9180 ± 0.0221
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5154, honest: 0.5168
Round 008: test acc mean=0.6024 ± 0.0115 | min=0.5837 max=0.6244
         : test loss mean=15.1574 ± 0.7060
         : individual accs = ['0.605263', '0.595855', '0.598935', '0.624352', '0.606702', '0.617467', '0.617467', '0.597161', '0.622359', '0.586879', '0.609266', '0.609778', '0.604167', '0.600862', '0.593416', '0.589520', '0.589255', '0.602122', '0.593777', '0.583699']
         : correct/total = [(690, 1140), (690, 1158), (675, 1127), (723, 1158), (688, 1134), (707, 1145), (707, 1145), (673, 1127), (707, 1136), (662, 1128), (697, 1144), (686, 1125), (696, 1152), (697, 1160), (667, 1124), (675, 1145), (680, 1154), (681, 1131), (687, 1157), (666, 1141)]
         : compromised: 0.6020, honest: 0.6026
Round 009: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=0.9512 ± 0.0240
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5154, honest: 0.5168
Round 010: test acc mean=0.6350 ± 0.0129 | min=0.6109 max=0.6505
         : test loss mean=10.5044 ± 0.5333
         : individual accs = ['0.628070', '0.625216', '0.639752', '0.649396', '0.634039', '0.649782', '0.648908', '0.631766', '0.650528', '0.624113', '0.648601', '0.647111', '0.641493', '0.640517', '0.637900', '0.612227', '0.610919', '0.642794', '0.612792', '0.624014']
         : correct/total = [(716, 1140), (724, 1158), (721, 1127), (752, 1158), (719, 1134), (744, 1145), (743, 1145), (712, 1127), (739, 1136), (704, 1128), (742, 1144), (728, 1125), (739, 1152), (743, 1160), (717, 1124), (701, 1145), (705, 1154), (727, 1131), (709, 1157), (712, 1141)]
         : compromised: 0.6375, honest: 0.6339

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: fully, Aggregation: d-fedavg
Attack: directed_deviation, 30.0% compromised
Final accuracy - Compromised: 0.6375, Honest: 0.6339
Overall test accuracy: mean=0.6350 ± 0.0129
