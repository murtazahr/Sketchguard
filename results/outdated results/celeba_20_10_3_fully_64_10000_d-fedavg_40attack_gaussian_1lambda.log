Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Attack: Compromised 8/20 nodes: [1, 5, 11, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5164 ± 0.0150 | min=0.4911 max=0.5625
         : test loss mean=nan ± nan
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.491135', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (554, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5124, honest: 0.5190
Round 002: test acc mean=0.5041 ± 0.0236 | min=0.4489 max=0.5402
         : test loss mean=199.6915 ± 138.4190
         : individual accs = ['0.526316', '0.476684', '0.519965', '0.528497', '0.522046', '0.448908', '0.478603', '0.501331', '0.462148', '0.506206', '0.525350', '0.501333', '0.523438', '0.505172', '0.488434', '0.516157', '0.515598', '0.514589', '0.540190', '0.482033']
         : correct/total = [(600, 1140), (552, 1158), (586, 1127), (612, 1158), (592, 1134), (514, 1145), (548, 1145), (565, 1127), (525, 1136), (571, 1128), (601, 1144), (564, 1125), (603, 1152), (586, 1160), (549, 1124), (591, 1145), (595, 1154), (582, 1131), (625, 1157), (550, 1141)]
         : compromised: 0.4998, honest: 0.5070
Round 003: test acc mean=0.4958 ± 0.0163 | min=0.4665 max=0.5267
         : test loss mean=262.4033 ± 169.3827
         : individual accs = ['0.474561', '0.493092', '0.507542', '0.471503', '0.504409', '0.491703', '0.478603', '0.502218', '0.466549', '0.491135', '0.495629', '0.508444', '0.477431', '0.506897', '0.514235', '0.482969', '0.514731', '0.492485', '0.515125', '0.526731']
         : correct/total = [(541, 1140), (571, 1158), (572, 1127), (546, 1158), (572, 1134), (563, 1145), (548, 1145), (566, 1127), (530, 1136), (554, 1128), (567, 1144), (572, 1125), (550, 1152), (588, 1160), (578, 1124), (553, 1145), (594, 1154), (557, 1131), (596, 1157), (601, 1141)]
         : compromised: 0.4999, honest: 0.4930
Round 004: test acc mean=0.5045 ± 0.0234 | min=0.4601 max=0.5625
         : test loss mean=202.4194 ± 151.2689
         : individual accs = ['0.510526', '0.512953', '0.487134', '0.528497', '0.522928', '0.512664', '0.479476', '0.501331', '0.562500', '0.485816', '0.474650', '0.507556', '0.519097', '0.503448', '0.478648', '0.517031', '0.486135', '0.534925', '0.504754', '0.460123']
         : correct/total = [(582, 1140), (594, 1158), (549, 1127), (612, 1158), (593, 1134), (587, 1145), (549, 1145), (565, 1127), (639, 1136), (548, 1128), (543, 1144), (571, 1125), (598, 1152), (584, 1160), (538, 1124), (592, 1145), (561, 1154), (605, 1131), (584, 1157), (525, 1141)]
         : compromised: 0.5093, honest: 0.5013
Round 005: test acc mean=0.5035 ± 0.0244 | min=0.4539 max=0.5616
         : test loss mean=204.6649 ± 189.5825
         : individual accs = ['0.498246', '0.491364', '0.538598', '0.538860', '0.522046', '0.515284', '0.477729', '0.476486', '0.561620', '0.453901', '0.514860', '0.499556', '0.489583', '0.496552', '0.487544', '0.510044', '0.515598', '0.509284', '0.479689', '0.492550']
         : correct/total = [(568, 1140), (569, 1158), (607, 1127), (624, 1158), (592, 1134), (590, 1145), (547, 1145), (537, 1127), (638, 1136), (512, 1128), (589, 1144), (562, 1125), (564, 1152), (576, 1160), (548, 1124), (584, 1145), (595, 1154), (576, 1131), (555, 1157), (562, 1141)]
         : compromised: 0.4961, honest: 0.5084
Round 006: test acc mean=0.4921 ± 0.0224 | min=0.4375 max=0.5226
         : test loss mean=261.7298 ± 212.8206
         : individual accs = ['0.471053', '0.495682', '0.493345', '0.471503', '0.479718', '0.513537', '0.517031', '0.502218', '0.437500', '0.508865', '0.471154', '0.501333', '0.522569', '0.498276', '0.485765', '0.517031', '0.515598', '0.508400', '0.454624', '0.477651']
         : correct/total = [(537, 1140), (574, 1158), (556, 1127), (546, 1158), (544, 1134), (588, 1145), (592, 1145), (566, 1127), (497, 1136), (574, 1128), (539, 1144), (564, 1125), (602, 1152), (578, 1160), (546, 1124), (592, 1145), (595, 1154), (575, 1131), (526, 1157), (545, 1141)]
         : compromised: 0.4975, honest: 0.4886
Round 007: test acc mean=0.5010 ± 0.0206 | min=0.4711 max=0.5563
         : test loss mean=376.6155 ± 348.6993
         : individual accs = ['0.471053', '0.488774', '0.493345', '0.471503', '0.477954', '0.514410', '0.521397', '0.500444', '0.556338', '0.491135', '0.525350', '0.492444', '0.477431', '0.493966', '0.516904', '0.514410', '0.484402', '0.508400', '0.508211', '0.511832']
         : correct/total = [(537, 1140), (566, 1158), (556, 1127), (546, 1158), (542, 1134), (589, 1145), (597, 1145), (564, 1127), (632, 1136), (554, 1128), (601, 1144), (554, 1125), (550, 1152), (573, 1160), (581, 1124), (589, 1145), (559, 1154), (575, 1131), (588, 1157), (584, 1141)]
         : compromised: 0.5001, honest: 0.5016
Round 008: test acc mean=0.5006 ± 0.0209 | min=0.4630 max=0.5616
         : test loss mean=199.5956 ± 149.9777
         : individual accs = ['0.519298', '0.510363', '0.488909', '0.501727', '0.462963', '0.489083', '0.521397', '0.496894', '0.561620', '0.490248', '0.488636', '0.496000', '0.483507', '0.493103', '0.503559', '0.471616', '0.503466', '0.521662', '0.487468', '0.519720']
         : correct/total = [(592, 1140), (591, 1158), (551, 1127), (581, 1158), (525, 1134), (560, 1145), (597, 1145), (560, 1127), (638, 1136), (553, 1128), (559, 1144), (558, 1125), (557, 1152), (572, 1160), (566, 1124), (540, 1145), (581, 1154), (590, 1131), (564, 1157), (593, 1141)]
         : compromised: 0.4981, honest: 0.5022
Round 009: test acc mean=0.5088 ± 0.0203 | min=0.4711 max=0.5599
         : test loss mean=236.0452 ± 252.3700
         : individual accs = ['0.520175', '0.493955', '0.494232', '0.528497', '0.495591', '0.509170', '0.529258', '0.503993', '0.559859', '0.478723', '0.525350', '0.471111', '0.496528', '0.506897', '0.508897', '0.517031', '0.516464', '0.508400', '0.530683', '0.482033']
         : correct/total = [(593, 1140), (572, 1158), (557, 1127), (612, 1158), (562, 1134), (583, 1145), (606, 1145), (568, 1127), (636, 1136), (540, 1128), (601, 1144), (530, 1125), (572, 1152), (588, 1160), (572, 1124), (592, 1145), (596, 1154), (575, 1131), (614, 1157), (550, 1141)]
         : compromised: 0.5032, honest: 0.5126
Round 010: test acc mean=0.5004 ± 0.0201 | min=0.4586 max=0.5364
         : test loss mean=288.0105 ± 227.6032
         : individual accs = ['0.509649', '0.508636', '0.506655', '0.483592', '0.522046', '0.490830', '0.517904', '0.503993', '0.458627', '0.508865', '0.491259', '0.498667', '0.522569', '0.506897', '0.517794', '0.483843', '0.463605', '0.508400', '0.468453', '0.536372']
         : correct/total = [(581, 1140), (589, 1158), (571, 1127), (560, 1158), (592, 1134), (562, 1145), (593, 1145), (568, 1127), (521, 1136), (574, 1128), (562, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (554, 1145), (535, 1154), (575, 1131), (542, 1157), (612, 1141)]
         : compromised: 0.5028, honest: 0.4989

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: fully, Aggregation: d-fedavg
Attack: gaussian, 40.0% compromised
Final accuracy - Compromised: 0.5028, Honest: 0.4989
Overall test accuracy: mean=0.5004 ± 0.0201
