/home/student.unimelb.edu.au/mrangwala/miniconda3/envs/edgedrift/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:282: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=4.1043 ± 0.0005
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
Round 002: test acc mean=0.2097 ± 0.0061 | min=0.1991 max=0.2184
         : test loss mean=3.4537 ± 0.0163
         : individual accs = ['0.213663', '0.216036', '0.213918', '0.199631', '0.215106', '0.205272', '0.210351', '0.205794', '0.208781', '0.204816', '0.199131', '0.209397', '0.214268', '0.203955', '0.218411', '0.215934', '0.199133', '0.214200', '0.217924', '0.208091']
         : correct/total = [(882, 4128), (908, 4203), (873, 4081), (865, 4333), (880, 4091), (880, 4287), (882, 4193), (895, 4349), (875, 4191), (876, 4277), (825, 4143), (878, 4193), (877, 4093), (856, 4197), (885, 4052), (870, 4029), (827, 4153), (896, 4183), (890, 4084), (859, 4128)]
Round 003: test acc mean=0.6604 ± 0.0096 | min=0.6367 max=0.6745
         : test loss mean=1.2162 ± 0.0337
         : individual accs = ['0.664002', '0.667143', '0.647635', '0.666744', '0.661941', '0.673431', '0.663487', '0.661072', '0.674541', '0.654431', '0.636737', '0.664918', '0.664794', '0.658804', '0.670533', '0.654257', '0.643872', '0.659814', '0.668707', '0.651890']
         : correct/total = [(2741, 4128), (2804, 4203), (2643, 4081), (2889, 4333), (2708, 4091), (2887, 4287), (2782, 4193), (2875, 4349), (2827, 4191), (2799, 4277), (2638, 4143), (2788, 4193), (2721, 4093), (2765, 4197), (2717, 4052), (2636, 4029), (2674, 4153), (2760, 4183), (2731, 4084), (2691, 4128)]
Round 004: test acc mean=0.7621 ± 0.0071 | min=0.7427 max=0.7721
         : test loss mean=0.7792 ± 0.0243
         : individual accs = ['0.758963', '0.765168', '0.759128', '0.763674', '0.754339', '0.768136', '0.768424', '0.764084', '0.772131', '0.767594', '0.742699', '0.757453', '0.771806', '0.759114', '0.763327', '0.760735', '0.751505', '0.768109', '0.767875', '0.757510']
         : correct/total = [(3133, 4128), (3216, 4203), (3098, 4081), (3309, 4333), (3086, 4091), (3293, 4287), (3222, 4193), (3323, 4349), (3236, 4191), (3283, 4277), (3077, 4143), (3176, 4193), (3159, 4093), (3186, 4197), (3093, 4052), (3065, 4029), (3121, 4153), (3213, 4183), (3136, 4084), (3127, 4128)]
Round 005: test acc mean=0.7992 ± 0.0067 | min=0.7820 max=0.8068
         : test loss mean=0.6400 ± 0.0211
         : individual accs = ['0.789486', '0.804187', '0.797109', '0.799677', '0.787582', '0.805692', '0.803959', '0.803173', '0.805058', '0.801964', '0.782042', '0.798712', '0.800147', '0.801287', '0.805528', '0.803673', '0.796051', '0.806837', '0.800930', '0.789971']
         : correct/total = [(3259, 4128), (3380, 4203), (3253, 4081), (3465, 4333), (3222, 4091), (3454, 4287), (3371, 4193), (3493, 4349), (3374, 4191), (3430, 4277), (3240, 4143), (3349, 4193), (3275, 4093), (3363, 4197), (3264, 4052), (3238, 4029), (3306, 4153), (3375, 4183), (3271, 4084), (3261, 4128)]
Round 006: test acc mean=0.8187 ± 0.0067 | min=0.8042 max=0.8275
         : test loss mean=0.5698 ± 0.0205
         : individual accs = ['0.807171', '0.821794', '0.813771', '0.820909', '0.807382', '0.823653', '0.823515', '0.825707', '0.827487', '0.821838', '0.804248', '0.820653', '0.816760', '0.823445', '0.824531', '0.823033', '0.817963', '0.824050', '0.816357', '0.809351']
         : correct/total = [(3332, 4128), (3454, 4203), (3321, 4081), (3557, 4333), (3303, 4091), (3531, 4287), (3453, 4193), (3591, 4349), (3468, 4191), (3515, 4277), (3332, 4143), (3441, 4193), (3343, 4093), (3456, 4197), (3341, 4052), (3316, 4029), (3397, 4153), (3447, 4183), (3334, 4084), (3341, 4128)]
Round 007: test acc mean=0.8303 ± 0.0064 | min=0.8161 max=0.8373
         : test loss mean=0.5268 ± 0.0202
         : individual accs = ['0.820010', '0.836307', '0.827248', '0.833372', '0.821315', '0.833683', '0.837109', '0.835594', '0.837270', '0.833996', '0.816075', '0.827570', '0.826777', '0.836788', '0.835390', '0.835939', '0.828317', '0.833851', '0.829089', '0.820736']
         : correct/total = [(3385, 4128), (3515, 4203), (3376, 4081), (3611, 4333), (3360, 4091), (3574, 4287), (3510, 4193), (3634, 4349), (3509, 4191), (3567, 4277), (3381, 4143), (3470, 4193), (3384, 4093), (3512, 4197), (3385, 4052), (3368, 4029), (3440, 4153), (3488, 4183), (3386, 4084), (3388, 4128)]
Round 008: test acc mean=0.8371 ± 0.0054 | min=0.8255 max=0.8437
         : test loss mean=0.4986 ± 0.0210
         : individual accs = ['0.827035', '0.840590', '0.836070', '0.840295', '0.828893', '0.838815', '0.842356', '0.842263', '0.843713', '0.841478', '0.825489', '0.834486', '0.835817', '0.841315', '0.839092', '0.841648', '0.838430', '0.839589', '0.836190', '0.827762']
         : correct/total = [(3414, 4128), (3533, 4203), (3412, 4081), (3641, 4333), (3391, 4091), (3596, 4287), (3532, 4193), (3663, 4349), (3536, 4191), (3599, 4277), (3420, 4143), (3499, 4193), (3421, 4093), (3531, 4197), (3400, 4052), (3391, 4029), (3482, 4153), (3512, 4183), (3415, 4084), (3417, 4128)]
Round 009: test acc mean=0.8438 ± 0.0056 | min=0.8307 max=0.8513
         : test loss mean=0.4763 ± 0.0204
         : individual accs = ['0.830669', '0.850345', '0.843666', '0.847911', '0.835493', '0.841847', '0.850227', '0.849621', '0.851348', '0.848258', '0.833213', '0.843310', '0.839482', '0.846319', '0.842300', '0.847357', '0.844450', '0.846522', '0.842556', '0.840116']
         : correct/total = [(3429, 4128), (3574, 4203), (3443, 4081), (3674, 4333), (3418, 4091), (3609, 4287), (3565, 4193), (3695, 4349), (3568, 4191), (3628, 4277), (3452, 4143), (3536, 4193), (3436, 4093), (3552, 4197), (3413, 4052), (3414, 4029), (3507, 4153), (3541, 4183), (3441, 4084), (3468, 4128)]
Round 010: test acc mean=0.8485 ± 0.0050 | min=0.8385 max=0.8546
         : test loss mean=0.4599 ± 0.0199
         : individual accs = ['0.838663', '0.853200', '0.850772', '0.850450', '0.839404', '0.846046', '0.853565', '0.853989', '0.851825', '0.854571', '0.838523', '0.848319', '0.844613', '0.849893', '0.849457', '0.853562', '0.848543', '0.851781', '0.848923', '0.843023']
         : correct/total = [(3462, 4128), (3586, 4203), (3472, 4081), (3685, 4333), (3434, 4091), (3627, 4287), (3579, 4193), (3714, 4349), (3570, 4191), (3655, 4277), (3474, 4143), (3557, 4193), (3457, 4093), (3567, 4197), (3442, 4052), (3439, 4029), (3524, 4153), (3563, 4183), (3467, 4084), (3480, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: d-fedavg
Overall test accuracy: mean=0.8485 ± 0.0050
