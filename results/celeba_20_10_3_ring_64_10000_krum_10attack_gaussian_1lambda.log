Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.7145 ± 0.0192 | min=0.6897 max=0.7678
         : test loss mean=0.5805 ± 0.0263
         : individual accs = ['0.702632', '0.693437', '0.700089', '0.699482', '0.693122', '0.705677', '0.724891', '0.709849', '0.749120', '0.720745', '0.705420', '0.728000', '0.723090', '0.712069', '0.719751', '0.702183', '0.767764', '0.689655', '0.734659', '0.708151']
         : correct/total = [(801, 1140), (803, 1158), (789, 1127), (810, 1158), (786, 1134), (808, 1145), (830, 1145), (800, 1127), (851, 1136), (813, 1128), (807, 1144), (819, 1125), (833, 1152), (826, 1160), (809, 1124), (804, 1145), (886, 1154), (780, 1131), (850, 1157), (808, 1141)]
         : compromised: 0.7089, honest: 0.7151
Round 002: test acc mean=0.8206 ± 0.0268 | min=0.7714 max=0.8671
         : test loss mean=0.4019 ± 0.0428
         : individual accs = ['0.774561', '0.835924', '0.782609', '0.821244', '0.820106', '0.834061', '0.854148', '0.821650', '0.786972', '0.856383', '0.867133', '0.857778', '0.822917', '0.803448', '0.771352', '0.818341', '0.822357', '0.802829', '0.837511', '0.821209']
         : correct/total = [(883, 1140), (968, 1158), (882, 1127), (951, 1158), (930, 1134), (955, 1145), (978, 1145), (926, 1127), (894, 1136), (966, 1128), (992, 1144), (965, 1125), (948, 1152), (932, 1160), (867, 1124), (937, 1145), (949, 1154), (908, 1131), (969, 1157), (937, 1141)]
         : compromised: 0.8188, honest: 0.8208
Round 003: test acc mean=0.8620 ± 0.0134 | min=0.8347 max=0.8895
         : test loss mean=0.3187 ± 0.0213
         : individual accs = ['0.842982', '0.889465', '0.856256', '0.855786', '0.843034', '0.862009', '0.873362', '0.858030', '0.875000', '0.873227', '0.881119', '0.834667', '0.866319', '0.850862', '0.871886', '0.859389', '0.870884', '0.864721', '0.848747', '0.862401']
         : correct/total = [(961, 1140), (1030, 1158), (965, 1127), (991, 1158), (956, 1134), (987, 1145), (1000, 1145), (967, 1127), (994, 1136), (985, 1128), (1008, 1144), (939, 1125), (998, 1152), (987, 1160), (980, 1124), (984, 1145), (1005, 1154), (978, 1131), (982, 1157), (984, 1141)]
         : compromised: 0.8564, honest: 0.8626
Round 004: test acc mean=0.8764 ± 0.0102 | min=0.8513 max=0.8924
         : test loss mean=0.2890 ± 0.0204
         : individual accs = ['0.885965', '0.885147', '0.874002', '0.872193', '0.875661', '0.870742', '0.885590', '0.880213', '0.874120', '0.890957', '0.877622', '0.892444', '0.878472', '0.874138', '0.876335', '0.852402', '0.871750', '0.876216', '0.851340', '0.882559']
         : correct/total = [(1010, 1140), (1025, 1158), (985, 1127), (1010, 1158), (993, 1134), (997, 1145), (1014, 1145), (992, 1127), (993, 1136), (1005, 1128), (1004, 1144), (1004, 1125), (1012, 1152), (1014, 1160), (985, 1124), (976, 1145), (1006, 1154), (991, 1131), (985, 1157), (1007, 1141)]
         : compromised: 0.8724, honest: 0.8768
Round 005: test acc mean=0.8763 ± 0.0185 | min=0.8332 max=0.8978
         : test loss mean=0.2909 ± 0.0344
         : individual accs = ['0.839474', '0.892919', '0.869565', '0.895509', '0.876543', '0.864629', '0.897817', '0.850932', '0.857394', '0.880319', '0.887238', '0.872000', '0.889757', '0.893103', '0.896797', '0.874236', '0.893414', '0.879752', '0.833189', '0.880806']
         : correct/total = [(957, 1140), (1034, 1158), (980, 1127), (1037, 1158), (994, 1134), (990, 1145), (1028, 1145), (959, 1127), (974, 1136), (993, 1128), (1015, 1144), (981, 1125), (1025, 1152), (1036, 1160), (1008, 1124), (1001, 1145), (1031, 1154), (995, 1131), (964, 1157), (1005, 1141)]
         : compromised: 0.8789, honest: 0.8760
Round 006: test acc mean=0.8858 ± 0.0137 | min=0.8515 max=0.9024
         : test loss mean=0.2758 ± 0.0279
         : individual accs = ['0.896491', '0.892919', '0.884650', '0.895509', '0.858025', '0.851528', '0.883843', '0.902396', '0.881162', '0.879433', '0.901224', '0.896000', '0.892361', '0.885345', '0.896797', '0.862882', '0.896014', '0.885942', '0.881590', '0.891323']
         : correct/total = [(1022, 1140), (1034, 1158), (997, 1127), (1037, 1158), (973, 1134), (975, 1145), (1012, 1145), (1017, 1127), (1001, 1136), (992, 1128), (1031, 1144), (1008, 1125), (1028, 1152), (1027, 1160), (1008, 1124), (988, 1145), (1034, 1154), (1002, 1131), (1020, 1157), (1017, 1141)]
         : compromised: 0.8684, honest: 0.8877
Round 007: test acc mean=0.8925 ± 0.0095 | min=0.8734 max=0.9125
         : test loss mean=0.2642 ± 0.0183
         : individual accs = ['0.898246', '0.890328', '0.888199', '0.904145', '0.886243', '0.899563', '0.896943', '0.907720', '0.880282', '0.890071', '0.898601', '0.889778', '0.893229', '0.888793', '0.892349', '0.873362', '0.912478', '0.885057', '0.877269', '0.897458']
         : correct/total = [(1024, 1140), (1031, 1158), (1001, 1127), (1047, 1158), (1005, 1134), (1030, 1145), (1027, 1145), (1023, 1127), (1000, 1136), (1004, 1128), (1028, 1144), (1001, 1125), (1029, 1152), (1031, 1160), (1003, 1124), (1000, 1145), (1053, 1154), (1001, 1131), (1015, 1157), (1024, 1141)]
         : compromised: 0.8942, honest: 0.8923
Round 008: test acc mean=0.8929 ± 0.0065 | min=0.8816 max=0.9022
         : test loss mean=0.2672 ± 0.0156
         : individual accs = ['0.900000', '0.897237', '0.886424', '0.898964', '0.891534', '0.902183', '0.889956', '0.889973', '0.883803', '0.899823', '0.890734', '0.900444', '0.898438', '0.894828', '0.889680', '0.885590', '0.902080', '0.883289', '0.881590', '0.891323']
         : correct/total = [(1026, 1140), (1039, 1158), (999, 1127), (1041, 1158), (1011, 1134), (1033, 1145), (1019, 1145), (1003, 1127), (1004, 1136), (1015, 1128), (1019, 1144), (1013, 1125), (1035, 1152), (1038, 1160), (1000, 1124), (1014, 1145), (1041, 1154), (999, 1131), (1020, 1157), (1017, 1141)]
         : compromised: 0.8985, honest: 0.8923
Round 009: test acc mean=0.8934 ± 0.0127 | min=0.8574 max=0.9142
         : test loss mean=0.2646 ± 0.0279
         : individual accs = ['0.886842', '0.896373', '0.897072', '0.902418', '0.897707', '0.892576', '0.911790', '0.895297', '0.871479', '0.895390', '0.895105', '0.897778', '0.894097', '0.895690', '0.903915', '0.879476', '0.914211', '0.882405', '0.857390', '0.900088']
         : correct/total = [(1011, 1140), (1038, 1158), (1011, 1127), (1045, 1158), (1018, 1134), (1022, 1145), (1044, 1145), (1009, 1127), (990, 1136), (1010, 1128), (1024, 1144), (1010, 1125), (1030, 1152), (1039, 1160), (1016, 1124), (1007, 1145), (1055, 1154), (998, 1131), (992, 1157), (1027, 1141)]
         : compromised: 0.8941, honest: 0.8933
Round 010: test acc mean=0.8929 ± 0.0110 | min=0.8634 max=0.9084
         : test loss mean=0.2660 ± 0.0273
         : individual accs = ['0.899123', '0.898100', '0.888199', '0.903282', '0.895062', '0.895197', '0.907424', '0.894410', '0.882923', '0.880319', '0.888112', '0.908444', '0.895833', '0.892241', '0.901246', '0.881223', '0.906412', '0.878868', '0.863440', '0.898335']
         : correct/total = [(1025, 1140), (1040, 1158), (1001, 1127), (1046, 1158), (1015, 1134), (1025, 1145), (1039, 1145), (1008, 1127), (1003, 1136), (993, 1128), (1016, 1144), (1022, 1125), (1032, 1152), (1035, 1160), (1013, 1124), (1009, 1145), (1046, 1154), (994, 1131), (999, 1157), (1025, 1141)]
         : compromised: 0.8937, honest: 0.8928

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: ring, Aggregation: krum
Attack: gaussian, 10.0% compromised
Final accuracy - Compromised: 0.8937, Honest: 0.8928
Overall test accuracy: mean=0.8929 ± 0.0110
