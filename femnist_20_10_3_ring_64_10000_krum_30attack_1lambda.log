Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0501 ± 0.0145 | min=0.0108 max=0.0747
         : test loss mean=81763.6366 ± 142167.8724
         : individual accs = ['0.051599', '0.051630', '0.048272', '0.048234', '0.057932', '0.050618', '0.057000', '0.074730', '0.053209', '0.053776', '0.050447', '0.072979', '0.025654', '0.024065', '0.051826', '0.050633', '0.058271', '0.010758', '0.055828', '0.054506']
         : correct/total = [(213, 4128), (217, 4203), (197, 4081), (209, 4333), (237, 4091), (217, 4287), (239, 4193), (325, 4349), (223, 4191), (230, 4277), (209, 4143), (306, 4193), (105, 4093), (101, 4197), (210, 4052), (204, 4029), (242, 4153), (45, 4183), (228, 4084), (225, 4128)]
         : compromised: 0.0365, honest: 0.0559
Round 002: test acc mean=0.0552 ± 0.0127 | min=0.0446 max=0.0953
         : test loss mean=3783718290165535.0000 ± 16492817315648388.0000
         : individual accs = ['0.044574', '0.051630', '0.095320', '0.052850', '0.057932', '0.050618', '0.051037', '0.058174', '0.051062', '0.083470', '0.045619', '0.045314', '0.049597', '0.055278', '0.046397', '0.067262', '0.054418', '0.045900', '0.048482', '0.048450']
         : correct/total = [(184, 4128), (217, 4203), (389, 4081), (229, 4333), (237, 4091), (217, 4287), (214, 4193), (253, 4349), (214, 4191), (357, 4277), (189, 4143), (190, 4193), (203, 4093), (232, 4197), (188, 4052), (271, 4029), (226, 4153), (192, 4183), (198, 4084), (200, 4128)]
         : compromised: 0.0494, honest: 0.0577
Round 003: test acc mean=0.0480 ± 0.0208 | min=0.0130 max=0.1052
         : test loss mean=1032519279658384943751683375104000.0000 ± 4500647197288311261392040154365952.0000
         : individual accs = ['0.063227', '0.052819', '0.050723', '0.048234', '0.057932', '0.050618', '0.044598', '0.051506', '0.057266', '0.065466', '0.055274', '0.049845', '0.014415', '0.047177', '0.015054', '0.056342', '0.105225', '0.016734', '0.012977', '0.044331']
         : correct/total = [(261, 4128), (222, 4203), (207, 4081), (209, 4333), (237, 4091), (217, 4287), (187, 4193), (224, 4349), (240, 4191), (280, 4277), (229, 4143), (209, 4193), (59, 4093), (198, 4197), (61, 4052), (227, 4029), (437, 4153), (70, 4183), (53, 4084), (183, 4128)]
         : compromised: 0.0262, honest: 0.0573
Round 004: test acc mean=0.0742 ± 0.0272 | min=0.0461 max=0.1440
         : test loss mean=nan ± nan
         : individual accs = ['0.059593', '0.101118', '0.074982', '0.074544', '0.082132', '0.076977', '0.144050', '0.083238', '0.113099', '0.064064', '0.046102', '0.126401', '0.049841', '0.049083', '0.061204', '0.054852', '0.074645', '0.046139', '0.052155', '0.048934']
         : correct/total = [(246, 4128), (425, 4203), (306, 4081), (323, 4333), (336, 4091), (330, 4287), (604, 4193), (362, 4349), (474, 4191), (274, 4277), (191, 4143), (530, 4193), (204, 4093), (206, 4197), (248, 4052), (221, 4029), (310, 4153), (193, 4183), (213, 4084), (202, 4128)]
         : compromised: 0.0559, honest: 0.0820
Round 005: test acc mean=0.0935 ± 0.0438 | min=0.0461 max=0.1770
         : test loss mean=nan ± nan
         : individual accs = ['0.091085', '0.052581', '0.106837', '0.177014', '0.132730', '0.126895', '0.122108', '0.047827', '0.164400', '0.068272', '0.057929', '0.150966', '0.049841', '0.049083', '0.061204', '0.055101', '0.108355', '0.046139', '0.052155', '0.149467']
         : correct/total = [(376, 4128), (221, 4203), (436, 4081), (767, 4333), (543, 4091), (544, 4287), (512, 4193), (208, 4349), (689, 4191), (292, 4277), (240, 4143), (633, 4193), (204, 4093), (206, 4197), (248, 4052), (222, 4029), (450, 4153), (193, 4183), (213, 4084), (617, 4128)]
         : compromised: 0.0642, honest: 0.1060
Round 006: test acc mean=0.1087 ± 0.0519 | min=0.0446 max=0.2002
         : test loss mean=nan ± nan
         : individual accs = ['0.044574', '0.155365', '0.177407', '0.114470', '0.142264', '0.132027', '0.109230', '0.124856', '0.200191', '0.094459', '0.061067', '0.189602', '0.049841', '0.049083', '0.061204', '0.116406', '0.183963', '0.046139', '0.055583', '0.066618']
         : correct/total = [(184, 4128), (653, 4203), (724, 4081), (496, 4333), (582, 4091), (566, 4287), (458, 4193), (543, 4349), (839, 4191), (404, 4277), (253, 4143), (795, 4193), (204, 4093), (206, 4197), (248, 4052), (469, 4029), (764, 4153), (193, 4183), (227, 4084), (275, 4128)]
         : compromised: 0.0656, honest: 0.1272
Round 007: test acc mean=0.1337 ± 0.0627 | min=0.0461 max=0.2528
         : test loss mean=nan ± nan
         : individual accs = ['0.242975', '0.165120', '0.210243', '0.148627', '0.119286', '0.119431', '0.125209', '0.092435', '0.183250', '0.145663', '0.124306', '0.252802', '0.049841', '0.049083', '0.061204', '0.211963', '0.158921', '0.046139', '0.055583', '0.111676']
         : correct/total = [(1003, 4128), (694, 4203), (858, 4081), (644, 4333), (488, 4091), (512, 4287), (525, 4193), (402, 4349), (768, 4191), (623, 4277), (515, 4143), (1060, 4193), (204, 4093), (206, 4197), (248, 4052), (854, 4029), (660, 4153), (193, 4183), (227, 4084), (461, 4128)]
         : compromised: 0.0635, honest: 0.1637
Round 008: test acc mean=0.1676 ± 0.0700 | min=0.0491 max=0.2597
         : test loss mean=nan ± nan
         : individual accs = ['0.200097', '0.178920', '0.259740', '0.155320', '0.225862', '0.224866', '0.227761', '0.196137', '0.221904', '0.174655', '0.165339', '0.225137', '0.058637', '0.049083', '0.061204', '0.225118', '0.228991', '0.050203', '0.055583', '0.168120']
         : correct/total = [(826, 4128), (752, 4203), (1060, 4081), (673, 4333), (924, 4091), (964, 4287), (955, 4193), (853, 4349), (930, 4191), (747, 4277), (685, 4143), (944, 4193), (240, 4093), (206, 4197), (248, 4052), (907, 4029), (951, 4153), (210, 4183), (227, 4084), (694, 4128)]
         : compromised: 0.0833, honest: 0.2038
Round 009: test acc mean=0.2205 ± 0.1060 | min=0.0491 max=0.3475
         : test loss mean=nan ± nan
         : individual accs = ['0.238130', '0.245539', '0.322470', '0.268405', '0.342459', '0.335899', '0.250656', '0.184870', '0.313768', '0.254150', '0.251026', '0.347484', '0.049841', '0.049083', '0.061204', '0.289154', '0.310619', '0.050203', '0.055583', '0.189438']
         : correct/total = [(983, 4128), (1032, 4203), (1316, 4081), (1163, 4333), (1401, 4091), (1440, 4287), (1051, 4193), (804, 4349), (1315, 4191), (1087, 4277), (1040, 4143), (1457, 4193), (204, 4093), (206, 4197), (248, 4052), (1165, 4029), (1290, 4153), (210, 4183), (227, 4084), (782, 4128)]
         : compromised: 0.1003, honest: 0.2720
Round 010: test acc mean=0.2707 ± 0.1280 | min=0.0491 max=0.3890
         : test loss mean=nan ± nan
         : individual accs = ['0.313227', '0.307875', '0.373193', '0.353104', '0.365436', '0.358759', '0.318626', '0.326972', '0.366500', '0.348609', '0.331885', '0.388982', '0.049841', '0.049083', '0.061204', '0.354430', '0.362870', '0.053311', '0.052889', '0.277374']
         : correct/total = [(1293, 4128), (1294, 4203), (1523, 4081), (1530, 4333), (1495, 4091), (1538, 4287), (1336, 4193), (1422, 4349), (1536, 4191), (1491, 4277), (1375, 4143), (1631, 4193), (204, 4093), (206, 4197), (248, 4052), (1428, 4029), (1507, 4153), (223, 4183), (216, 4084), (1145, 4128)]
         : compromised: 0.1042, honest: 0.3421

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: ring, Aggregation: krum
Attack: directed_deviation, 30.0% compromised
Final accuracy - Compromised: 0.1042, Honest: 0.3421
Overall test accuracy: mean=0.2707 ± 0.1280
