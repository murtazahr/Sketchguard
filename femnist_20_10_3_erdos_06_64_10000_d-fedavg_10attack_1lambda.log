Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0295 ± 0.0183 | min=0.0022 max=0.0566
         : test loss mean=90.2211 ± 149.8587
         : individual accs = ['0.013808', '0.051630', '0.045332', '0.018925', '0.020777', '0.047352', '0.044598', '0.047827', '0.012646', '0.012859', '0.055998', '0.006201', '0.034938', '0.013105', '0.006910', '0.056590', '0.051047', '0.022472', '0.002204', '0.024467']
         : correct/total = [(57, 4128), (217, 4203), (185, 4081), (82, 4333), (85, 4091), (203, 4287), (187, 4193), (208, 4349), (53, 4191), (55, 4277), (232, 4143), (26, 4193), (143, 4093), (55, 4197), (28, 4052), (228, 4029), (212, 4153), (94, 4183), (9, 4084), (101, 4128)]
         : compromised: 0.0302, honest: 0.0294
Round 002: test acc mean=0.0211 ± 0.0088 | min=0.0142 max=0.0512
         : test loss mean=692.9696 ± 1109.2077
         : individual accs = ['0.016231', '0.039496', '0.014212', '0.017771', '0.015644', '0.014696', '0.020749', '0.018165', '0.019089', '0.015431', '0.051171', '0.019556', '0.019057', '0.019061', '0.019743', '0.023579', '0.027450', '0.017213', '0.019344', '0.014535']
         : correct/total = [(67, 4128), (166, 4203), (58, 4081), (77, 4333), (64, 4091), (63, 4287), (87, 4193), (79, 4349), (80, 4191), (66, 4277), (212, 4143), (82, 4193), (78, 4093), (80, 4197), (80, 4052), (95, 4029), (114, 4153), (72, 4183), (79, 4084), (60, 4128)]
         : compromised: 0.0169, honest: 0.0216
Round 003: test acc mean=0.0477 ± 0.0055 | min=0.0355 max=0.0545
         : test loss mean=4.1238 ± 0.2818
         : individual accs = ['0.050145', '0.047109', '0.035531', '0.044773', '0.044977', '0.045253', '0.035535', '0.049207', '0.037700', '0.048398', '0.047309', '0.053184', '0.050574', '0.049083', '0.051826', '0.050633', '0.051288', '0.053311', '0.052889', '0.054506']
         : correct/total = [(207, 4128), (198, 4203), (145, 4081), (194, 4333), (184, 4091), (194, 4287), (149, 4193), (214, 4349), (158, 4191), (207, 4277), (196, 4143), (223, 4193), (207, 4093), (206, 4197), (210, 4052), (204, 4029), (213, 4153), (223, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0472, honest: 0.0477
Round 004: test acc mean=0.0541 ± 0.0099 | min=0.0129 max=0.0624
         : test loss mean=4.3186 ± 0.5430
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.012885', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (54, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0538
Round 005: test acc mean=0.0490 ± 0.0054 | min=0.0355 max=0.0578
         : test loss mean=3.9969 ± 0.1577
         : individual accs = ['0.049176', '0.047109', '0.035531', '0.047773', '0.044977', '0.057849', '0.050799', '0.043918', '0.037700', '0.047463', '0.055274', '0.049606', '0.049841', '0.045747', '0.051579', '0.054852', '0.054418', '0.053311', '0.052155', '0.050388']
         : correct/total = [(203, 4128), (198, 4203), (145, 4081), (207, 4333), (184, 4091), (248, 4287), (213, 4193), (191, 4349), (158, 4191), (203, 4277), (229, 4143), (208, 4193), (204, 4093), (192, 4197), (209, 4052), (221, 4029), (226, 4153), (223, 4183), (213, 4084), (208, 4128)]
         : compromised: 0.0518, honest: 0.0487
Round 006: test acc mean=0.0570 ± 0.0043 | min=0.0506 max=0.0702
         : test loss mean=4.1269 ± 0.3031
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.070150', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (294, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0570
Round 007: test acc mean=0.0492 ± 0.0055 | min=0.0355 max=0.0578
         : test loss mean=3.9340 ± 0.1129
         : individual accs = ['0.049176', '0.047109', '0.035531', '0.047773', '0.044977', '0.057849', '0.050799', '0.043918', '0.037700', '0.047463', '0.055274', '0.053184', '0.049841', '0.045747', '0.051579', '0.054852', '0.054418', '0.053311', '0.052155', '0.050388']
         : correct/total = [(203, 4128), (198, 4203), (145, 4081), (207, 4333), (184, 4091), (248, 4287), (213, 4193), (191, 4349), (158, 4191), (203, 4277), (229, 4143), (223, 4193), (204, 4093), (192, 4197), (209, 4052), (221, 4029), (226, 4153), (223, 4183), (213, 4084), (208, 4128)]
         : compromised: 0.0518, honest: 0.0489
Round 008: test acc mean=0.0573 ± 0.0055 | min=0.0506 max=0.0771
         : test loss mean=4.1321 ± 0.3213
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.077070', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (323, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0574
Round 009: test acc mean=0.0500 ± 0.0046 | min=0.0377 max=0.0578
         : test loss mean=3.8872 ± 0.0976
         : individual accs = ['0.049176', '0.047109', '0.055134', '0.047773', '0.044977', '0.057849', '0.050799', '0.043918', '0.037700', '0.047463', '0.055274', '0.049606', '0.049841', '0.045747', '0.051579', '0.054852', '0.054418', '0.053311', '0.052155', '0.050388']
         : correct/total = [(203, 4128), (198, 4203), (225, 4081), (207, 4333), (184, 4091), (248, 4287), (213, 4193), (191, 4349), (158, 4191), (203, 4277), (229, 4143), (208, 4193), (204, 4093), (192, 4197), (209, 4052), (221, 4029), (226, 4153), (223, 4183), (213, 4084), (208, 4128)]
         : compromised: 0.0518, honest: 0.0497
Round 010: test acc mean=0.0574 ± 0.0059 | min=0.0506 max=0.0795
         : test loss mean=4.1566 ± 0.3619
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.079456', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (333, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0575

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: directed_deviation, 10.0% compromised
Final accuracy - Compromised: 0.0565, Honest: 0.0575
Overall test accuracy: mean=0.0574 ± 0.0059
