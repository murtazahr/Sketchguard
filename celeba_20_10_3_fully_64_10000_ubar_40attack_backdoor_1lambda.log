Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 8/20 nodes: [1, 5, 11, 12, 13, 14, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.6
  - Stage 1: Distance-based filtering (select 60% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 8 compromised nodes
Round 001: test acc mean=0.5860 ± 0.0644 | min=0.5069 max=0.6897
         : test loss mean=1600.6231 ± 1994.7575
         : individual accs = ['0.630702', '0.508636', '0.622005', '0.651986', '0.589065', '0.514410', '0.680349', '0.636202', '0.583627', '0.687057', '0.628497', '0.520889', '0.522569', '0.506897', '0.517794', '0.613100', '0.585789', '0.508400', '0.522040', '0.689746']
         : correct/total = [(719, 1140), (589, 1158), (701, 1127), (755, 1158), (668, 1134), (589, 1145), (779, 1145), (717, 1127), (663, 1136), (775, 1128), (719, 1144), (586, 1125), (602, 1152), (588, 1160), (582, 1124), (702, 1145), (676, 1154), (575, 1131), (604, 1157), (787, 1141)]
         : compromised: 0.5152, honest: 0.6332
         : ubar stats = ['Node 0: s1=0.579, s2=0.182', 'Node 1: s1=0.579, s2=1.000', 'Node 2: s1=0.579, s2=0.273']...
Round 002: test acc mean=0.5884 ± 0.0765 | min=0.4978 max=0.7196
         : test loss mean=190.4850 ± 359.1199
         : individual accs = ['0.650877', '0.511226', '0.719610', '0.568221', '0.531746', '0.513537', '0.628821', '0.675244', '0.669894', '0.656915', '0.599650', '0.497778', '0.520833', '0.503448', '0.516904', '0.707424', '0.588388', '0.509284', '0.515125', '0.683611']
         : correct/total = [(742, 1140), (592, 1158), (811, 1127), (658, 1158), (603, 1134), (588, 1145), (720, 1145), (761, 1127), (761, 1136), (741, 1128), (686, 1144), (560, 1125), (600, 1152), (584, 1160), (581, 1124), (810, 1145), (679, 1154), (576, 1131), (596, 1157), (780, 1141)]
         : compromised: 0.5110, honest: 0.6400
         : ubar stats = ['Node 0: s1=0.579, s2=0.182', 'Node 1: s1=0.579, s2=1.000', 'Node 2: s1=0.579, s2=0.273']...
Round 003: test acc mean=0.6358 ± 0.1250 | min=0.4774 max=0.7886
         : test loss mean=nan ± nan
         : individual accs = ['0.759649', '0.491364', '0.759539', '0.747841', '0.644621', '0.485590', '0.735371', '0.685004', '0.735035', '0.719858', '0.745629', '0.498667', '0.477431', '0.493103', '0.482206', '0.788646', '0.779896', '0.491600', '0.477960', '0.717791']
         : correct/total = [(866, 1140), (569, 1158), (856, 1127), (866, 1158), (731, 1134), (556, 1145), (842, 1145), (772, 1127), (835, 1136), (812, 1128), (853, 1144), (561, 1125), (550, 1152), (572, 1160), (542, 1124), (903, 1145), (900, 1154), (556, 1131), (553, 1157), (819, 1141)]
         : compromised: 0.4872, honest: 0.7349
         : ubar stats = ['Node 0: s1=0.579, s2=0.242', 'Node 1: s1=0.579, s2=1.000', 'Node 2: s1=0.579, s2=0.242']...
Round 004: test acc mean=0.6944 ± 0.1496 | min=0.4987 max=0.8358
         : test loss mean=nan ± nan
         : individual accs = ['0.835088', '0.508636', '0.835847', '0.814335', '0.768959', '0.514410', '0.810480', '0.777285', '0.821303', '0.807624', '0.835664', '0.498667', '0.522569', '0.506897', '0.517794', '0.820087', '0.828423', '0.508400', '0.522040', '0.833479']
         : correct/total = [(952, 1140), (589, 1158), (942, 1127), (943, 1158), (872, 1134), (589, 1145), (928, 1145), (876, 1127), (933, 1136), (911, 1128), (956, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (939, 1145), (956, 1154), (575, 1131), (604, 1157), (951, 1141)]
         : compromised: 0.5124, honest: 0.8157
         : ubar stats = ['Node 0: s1=0.579, s2=0.205', 'Node 1: s1=0.579, s2=0.773', 'Node 2: s1=0.579, s2=0.205']...
Round 005: test acc mean=0.7158 ± 0.1664 | min=0.4987 max=0.8720
         : test loss mean=nan ± nan
         : individual accs = ['0.835088', '0.508636', '0.835847', '0.862694', '0.832451', '0.514410', '0.857642', '0.839397', '0.856514', '0.859929', '0.868881', '0.498667', '0.522569', '0.506897', '0.517794', '0.843668', '0.852686', '0.508400', '0.522040', '0.872042']
         : correct/total = [(952, 1140), (589, 1158), (942, 1127), (999, 1158), (944, 1134), (589, 1145), (982, 1145), (946, 1127), (973, 1136), (970, 1128), (994, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (966, 1145), (984, 1154), (575, 1131), (604, 1157), (995, 1141)]
         : compromised: 0.5124, honest: 0.8514
         : ubar stats = ['Node 0: s1=0.579, s2=0.309', 'Node 1: s1=0.579, s2=0.636', 'Node 2: s1=0.579, s2=0.255']...
Round 006: test acc mean=0.7257 ± 0.1744 | min=0.4987 max=0.8864
         : test loss mean=nan ± nan
         : individual accs = ['0.877193', '0.508636', '0.866016', '0.860967', '0.851852', '0.514410', '0.876856', '0.859805', '0.882042', '0.863475', '0.886364', '0.498667', '0.522569', '0.506897', '0.517794', '0.852402', '0.862218', '0.508400', '0.522040', '0.875548']
         : correct/total = [(1000, 1140), (589, 1158), (976, 1127), (997, 1158), (966, 1134), (589, 1145), (1004, 1145), (969, 1127), (1002, 1136), (974, 1128), (1014, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (976, 1145), (995, 1154), (575, 1131), (604, 1157), (999, 1141)]
         : compromised: 0.5124, honest: 0.8679
         : ubar stats = ['Node 0: s1=0.579, s2=0.273', 'Node 1: s1=0.579, s2=0.545', 'Node 2: s1=0.579, s2=0.318']...
Round 007: test acc mean=0.7339 ± 0.1810 | min=0.4987 max=0.8936
         : test loss mean=nan ± nan
         : individual accs = ['0.885965', '0.508636', '0.874002', '0.882556', '0.873016', '0.514410', '0.889956', '0.882875', '0.882042', '0.893617', '0.886364', '0.498667', '0.522569', '0.506897', '0.517794', '0.861135', '0.883016', '0.508400', '0.522040', '0.884312']
         : correct/total = [(1010, 1140), (589, 1158), (985, 1127), (1022, 1158), (990, 1134), (589, 1145), (1019, 1145), (995, 1127), (1002, 1136), (1008, 1128), (1014, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (986, 1145), (1019, 1154), (575, 1131), (604, 1157), (1009, 1141)]
         : compromised: 0.5124, honest: 0.8816
         : ubar stats = ['Node 0: s1=0.579, s2=0.273', 'Node 1: s1=0.579, s2=0.481', 'Node 2: s1=0.579, s2=0.338']...
Round 008: test acc mean=0.7348 ± 0.1817 | min=0.4987 max=0.8974
         : test loss mean=nan ± nan
         : individual accs = ['0.897368', '0.508636', '0.874889', '0.883420', '0.885362', '0.514410', '0.886463', '0.886424', '0.865317', '0.890071', '0.890734', '0.498667', '0.522569', '0.506897', '0.517794', '0.871616', '0.881282', '0.508400', '0.522040', '0.883436']
         : correct/total = [(1023, 1140), (589, 1158), (986, 1127), (1023, 1158), (1004, 1134), (589, 1145), (1015, 1145), (999, 1127), (983, 1136), (1004, 1128), (1019, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (998, 1145), (1017, 1154), (575, 1131), (604, 1157), (1008, 1141)]
         : compromised: 0.5124, honest: 0.8830
         : ubar stats = ['Node 0: s1=0.579, s2=0.250', 'Node 1: s1=0.579, s2=0.432', 'Node 2: s1=0.579, s2=0.341']...
Round 009: test acc mean=0.7398 ± 0.1859 | min=0.4987 max=0.9014
         : test loss mean=nan ± nan
         : individual accs = ['0.900877', '0.508636', '0.875776', '0.898100', '0.892416', '0.514410', '0.894323', '0.900621', '0.901408', '0.890071', '0.888986', '0.498667', '0.522569', '0.506897', '0.517794', '0.873362', '0.884749', '0.508400', '0.522040', '0.896582']
         : correct/total = [(1027, 1140), (589, 1158), (987, 1127), (1040, 1158), (1012, 1134), (589, 1145), (1024, 1145), (1015, 1127), (1024, 1136), (1004, 1128), (1017, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (1000, 1145), (1021, 1154), (575, 1131), (604, 1157), (1023, 1141)]
         : compromised: 0.5124, honest: 0.8914
         : ubar stats = ['Node 0: s1=0.579, s2=0.232', 'Node 1: s1=0.579, s2=0.394', 'Node 2: s1=0.579, s2=0.384']...
Round 010: test acc mean=0.7422 ± 0.1877 | min=0.4987 max=0.9038
         : test loss mean=nan ± nan
         : individual accs = ['0.900877', '0.508636', '0.885537', '0.896373', '0.898589', '0.514410', '0.893450', '0.893523', '0.896127', '0.902482', '0.903846', '0.498667', '0.522569', '0.506897', '0.517794', '0.878603', '0.897747', '0.508400', '0.522040', '0.896582']
         : correct/total = [(1027, 1140), (589, 1158), (998, 1127), (1038, 1158), (1019, 1134), (589, 1145), (1023, 1145), (1007, 1127), (1018, 1136), (1018, 1128), (1034, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (1006, 1145), (1036, 1154), (575, 1131), (604, 1157), (1023, 1141)]
         : compromised: 0.5124, honest: 0.8953
         : ubar stats = ['Node 0: s1=0.579, s2=0.218', 'Node 1: s1=0.579, s2=0.364', 'Node 2: s1=0.579, s2=0.355']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: fully, Aggregation: ubar
Attack: backdoor, 40.0% compromised
Final accuracy - Compromised: 0.5124, Honest: 0.8953
Overall test accuracy: mean=0.7422 ± 0.1877

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.7251 ± 0.2253
Honest nodes ASR: 0.5419 ± 0.0261
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== UBAR SUMMARY ===
Node 0: stage1=0.579, stage2=0.218, overall=0.126
Node 1: stage1=0.579, stage2=0.364, overall=0.211
Node 2: stage1=0.579, stage2=0.355, overall=0.205
Node 3: stage1=0.579, stage2=0.273, overall=0.158
Node 4: stage1=0.579, stage2=0.591, overall=0.342
Node 5: stage1=0.579, stage2=0.364, overall=0.211
Node 6: stage1=0.579, stage2=0.273, overall=0.158
Node 7: stage1=0.579, stage2=0.655, overall=0.379
Node 8: stage1=0.579, stage2=0.382, overall=0.221
Node 9: stage1=0.579, stage2=0.373, overall=0.216
Node 10: stage1=0.579, stage2=0.273, overall=0.158
Node 11: stage1=0.579, stage2=0.273, overall=0.158
Node 12: stage1=0.579, stage2=0.364, overall=0.211
Node 13: stage1=0.579, stage2=0.364, overall=0.211
Node 14: stage1=0.579, stage2=0.364, overall=0.211
Node 15: stage1=0.579, stage2=0.109, overall=0.063
Node 16: stage1=0.579, stage2=0.509, overall=0.295
Node 17: stage1=0.579, stage2=0.364, overall=0.211
Node 18: stage1=0.579, stage2=0.364, overall=0.211
Node 19: stage1=0.579, stage2=0.345, overall=0.200

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.051s (18.6%)
    - Loss computation: 0.213s (78.5%)
    - Aggregation: 0.008s (3.0%)
  TOTALS:
    - Total computation: 0.272s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.272s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.048s
  - Loss computation: 0.193s
  - Aggregation: 0.005s
  - Model transfer: 0.000s
  - Total per node: 0.245s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.951s
  - Total loss computation: 3.853s
  - Total aggregation: 0.102s
  - Total model transfer: 0.000s
  - Grand total: 4.906s
  - Mean Stage 1 acceptance rate: 0.579
  - Mean Stage 2 acceptance rate: 0.359
  - Overall acceptance rate: 0.208

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.6
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 60% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
