Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
UBAR ALGORITHM (Two-Stage Byzantine-resilient)
  - Model dimension: 2,219,692 parameters
  - Rho parameter: 0.8
  - Stage 1: Distance-based filtering (select 80% closest neighbors)
  - Stage 2: Performance-based selection (loss comparison)
  - Complexity: O(deg(i)×d + deg(i)×inference)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 4 compromised nodes
Round 001: test acc mean=0.6126 ± 0.0652 | min=0.5069 max=0.7132
         : test loss mean=764.1416 ± 1542.7557
         : individual accs = ['0.683333', '0.675302', '0.608696', '0.684801', '0.565256', '0.514410', '0.585153', '0.583851', '0.617077', '0.655142', '0.644231', '0.551111', '0.522569', '0.506897', '0.669039', '0.620961', '0.713172', '0.508400', '0.685393', '0.656442']
         : correct/total = [(779, 1140), (782, 1158), (686, 1127), (793, 1158), (641, 1134), (589, 1145), (670, 1145), (658, 1127), (701, 1136), (739, 1128), (737, 1144), (620, 1125), (602, 1152), (588, 1160), (752, 1124), (711, 1145), (823, 1154), (575, 1131), (793, 1157), (749, 1141)]
         : compromised: 0.5131, honest: 0.6374
         : ubar stats = ['Node 0: s1=0.750, s2=0.417', 'Node 1: s1=0.727, s2=0.875', 'Node 2: s1=0.750, s2=0.111']...
Round 002: test acc mean=0.6320 ± 0.0878 | min=0.5026 max=0.7597
         : test loss mean=63.9908 ± 143.4501
         : individual accs = ['0.654386', '0.669257', '0.708962', '0.745250', '0.529101', '0.510044', '0.627948', '0.637977', '0.663732', '0.704787', '0.687937', '0.728000', '0.521701', '0.502586', '0.552491', '0.536245', '0.745234', '0.507515', '0.759723', '0.646801']
         : correct/total = [(746, 1140), (775, 1158), (799, 1127), (863, 1158), (600, 1134), (584, 1145), (719, 1145), (719, 1127), (754, 1136), (795, 1128), (787, 1144), (819, 1125), (601, 1152), (583, 1160), (621, 1124), (614, 1145), (860, 1154), (574, 1131), (879, 1157), (738, 1141)]
         : compromised: 0.5105, honest: 0.6624
         : ubar stats = ['Node 0: s1=0.750, s2=0.583', 'Node 1: s1=0.727, s2=0.750', 'Node 2: s1=0.750, s2=0.111']...
Round 003: test acc mean=0.6958 ± 0.1232 | min=0.4733 max=0.8489
         : test loss mean=54098008541.5025 ± 160219229315.8999
         : individual accs = ['0.714912', '0.695164', '0.749778', '0.848877', '0.706349', '0.485590', '0.717904', '0.682343', '0.739437', '0.828901', '0.774476', '0.811556', '0.477431', '0.473276', '0.580961', '0.804367', '0.805026', '0.491600', '0.825411', '0.702892']
         : correct/total = [(815, 1140), (805, 1158), (845, 1127), (983, 1158), (801, 1134), (556, 1145), (822, 1145), (769, 1127), (840, 1136), (935, 1128), (886, 1144), (913, 1125), (550, 1152), (549, 1160), (653, 1124), (921, 1145), (929, 1154), (556, 1131), (955, 1157), (802, 1141)]
         : compromised: 0.4820, honest: 0.7493
         : ubar stats = ['Node 0: s1=0.750, s2=0.556', 'Node 1: s1=0.727, s2=0.708', 'Node 2: s1=0.750, s2=0.111']...
Round 004: test acc mean=0.7671 ± 0.1309 | min=0.5069 max=0.8785
         : test loss mean=nan ± nan
         : individual accs = ['0.840351', '0.753022', '0.769299', '0.866149', '0.798942', '0.514410', '0.827948', '0.821650', '0.857394', '0.878546', '0.868007', '0.861333', '0.522569', '0.506897', '0.798932', '0.852402', '0.837088', '0.508400', '0.847882', '0.809816']
         : correct/total = [(958, 1140), (872, 1158), (867, 1127), (1003, 1158), (906, 1134), (589, 1145), (948, 1145), (926, 1127), (974, 1136), (991, 1128), (993, 1144), (969, 1125), (602, 1152), (588, 1160), (898, 1124), (976, 1145), (966, 1154), (575, 1131), (981, 1157), (924, 1141)]
         : compromised: 0.5131, honest: 0.8305
         : ubar stats = ['Node 0: s1=0.750, s2=0.479', 'Node 1: s1=0.727, s2=0.750', 'Node 2: s1=0.750, s2=0.194']...
Round 005: test acc mean=0.7929 ± 0.1407 | min=0.5069 max=0.8872
         : test loss mean=nan ± nan
         : individual accs = ['0.821053', '0.872193', '0.846495', '0.873057', '0.856261', '0.514410', '0.866376', '0.862467', '0.860035', '0.885638', '0.887238', '0.856889', '0.522569', '0.506897', '0.868327', '0.855895', '0.883016', '0.508400', '0.842697', '0.867660']
         : correct/total = [(936, 1140), (1010, 1158), (954, 1127), (1011, 1158), (971, 1134), (589, 1145), (992, 1145), (972, 1127), (977, 1136), (999, 1128), (1015, 1144), (964, 1125), (602, 1152), (588, 1160), (976, 1124), (980, 1145), (1019, 1154), (575, 1131), (975, 1157), (990, 1141)]
         : compromised: 0.5131, honest: 0.8628
         : ubar stats = ['Node 0: s1=0.750, s2=0.500', 'Node 1: s1=0.727, s2=0.775', 'Node 2: s1=0.750, s2=0.222']...
Round 006: test acc mean=0.8054 ± 0.1464 | min=0.5069 max=0.8961
         : test loss mean=nan ± nan
         : individual accs = ['0.881579', '0.878238', '0.867791', '0.894646', '0.867725', '0.514410', '0.877729', '0.879326', '0.896127', '0.874113', '0.891608', '0.877333', '0.522569', '0.506897', '0.868327', '0.868996', '0.888215', '0.508400', '0.866897', '0.876424']
         : correct/total = [(1005, 1140), (1017, 1158), (978, 1127), (1036, 1158), (984, 1134), (589, 1145), (1005, 1145), (991, 1127), (1018, 1136), (986, 1128), (1020, 1144), (987, 1125), (602, 1152), (588, 1160), (976, 1124), (995, 1145), (1025, 1154), (575, 1131), (1003, 1157), (1000, 1141)]
         : compromised: 0.5131, honest: 0.8784
         : ubar stats = ['Node 0: s1=0.750, s2=0.444', 'Node 1: s1=0.727, s2=0.812', 'Node 2: s1=0.750, s2=0.333']...
Round 007: test acc mean=0.8147 ± 0.1510 | min=0.5069 max=0.9013
         : test loss mean=nan ± nan
         : individual accs = ['0.892105', '0.894646', '0.875776', '0.894646', '0.886243', '0.514410', '0.893450', '0.889973', '0.896127', '0.893617', '0.896853', '0.901333', '0.522569', '0.506897', '0.886121', '0.874236', '0.893414', '0.508400', '0.878133', '0.894829']
         : correct/total = [(1017, 1140), (1036, 1158), (987, 1127), (1036, 1158), (1005, 1134), (589, 1145), (1023, 1145), (1003, 1127), (1018, 1136), (1008, 1128), (1026, 1144), (1014, 1125), (602, 1152), (588, 1160), (996, 1124), (1001, 1145), (1031, 1154), (575, 1131), (1016, 1157), (1021, 1141)]
         : compromised: 0.5131, honest: 0.8901
         : ubar stats = ['Node 0: s1=0.750, s2=0.393', 'Node 1: s1=0.727, s2=0.732', 'Node 2: s1=0.750, s2=0.302']...
Round 008: test acc mean=0.8153 ± 0.1514 | min=0.5069 max=0.9058
         : test loss mean=nan ± nan
         : individual accs = ['0.894737', '0.896373', '0.875776', '0.896373', '0.899471', '0.514410', '0.889083', '0.895297', '0.873239', '0.889184', '0.899476', '0.905778', '0.522569', '0.506897', '0.901246', '0.879476', '0.896014', '0.508400', '0.877269', '0.884312']
         : correct/total = [(1020, 1140), (1038, 1158), (987, 1127), (1038, 1158), (1020, 1134), (589, 1145), (1018, 1145), (1009, 1127), (992, 1136), (1003, 1128), (1029, 1144), (1019, 1125), (602, 1152), (588, 1160), (1013, 1124), (1007, 1145), (1034, 1154), (575, 1131), (1015, 1157), (1009, 1141)]
         : compromised: 0.5131, honest: 0.8908
         : ubar stats = ['Node 0: s1=0.750, s2=0.354', 'Node 1: s1=0.727, s2=0.750', 'Node 2: s1=0.750, s2=0.278']...
Round 009: test acc mean=0.8177 ± 0.1527 | min=0.5069 max=0.9076
         : test loss mean=nan ± nan
         : individual accs = ['0.905263', '0.893782', '0.870453', '0.898100', '0.903880', '0.514410', '0.894323', '0.888199', '0.897887', '0.890957', '0.898601', '0.907556', '0.522569', '0.506897', '0.903915', '0.882096', '0.900347', '0.508400', '0.863440', '0.902717']
         : correct/total = [(1032, 1140), (1035, 1158), (981, 1127), (1040, 1158), (1025, 1134), (589, 1145), (1024, 1145), (1001, 1127), (1020, 1136), (1005, 1128), (1028, 1144), (1021, 1125), (602, 1152), (588, 1160), (1016, 1124), (1010, 1145), (1039, 1154), (575, 1131), (999, 1157), (1030, 1141)]
         : compromised: 0.5131, honest: 0.8938
         : ubar stats = ['Node 0: s1=0.750, s2=0.324', 'Node 1: s1=0.727, s2=0.778', 'Node 2: s1=0.750, s2=0.272']...
Round 010: test acc mean=0.8207 ± 0.1540 | min=0.5069 max=0.9083
         : test loss mean=nan ± nan
         : individual accs = ['0.907018', '0.897237', '0.884650', '0.905009', '0.908289', '0.514410', '0.898690', '0.901508', '0.897007', '0.898050', '0.901224', '0.890667', '0.522569', '0.506897', '0.902135', '0.884716', '0.902946', '0.508400', '0.884183', '0.897458']
         : correct/total = [(1034, 1140), (1039, 1158), (997, 1127), (1048, 1158), (1030, 1134), (589, 1145), (1029, 1145), (1016, 1127), (1019, 1136), (1013, 1128), (1031, 1144), (1002, 1125), (602, 1152), (588, 1160), (1014, 1124), (1013, 1145), (1042, 1154), (575, 1131), (1023, 1157), (1024, 1141)]
         : compromised: 0.5131, honest: 0.8975
         : ubar stats = ['Node 0: s1=0.750, s2=0.300', 'Node 1: s1=0.727, s2=0.713', 'Node 2: s1=0.750, s2=0.267']...

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: ubar
Attack: backdoor, 20.0% compromised
Final accuracy - Compromised: 0.5131, Honest: 0.8975
Overall test accuracy: mean=0.8207 ± 0.1540

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.6250 ± 0.1886
Honest nodes ASR: 0.5313 ± 0.0224
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== UBAR SUMMARY ===
Node 0: stage1=0.750, stage2=0.300, overall=0.225
Node 1: stage1=0.727, stage2=0.713, overall=0.518
Node 2: stage1=0.750, stage2=0.267, overall=0.200
Node 3: stage1=0.750, stage2=0.417, overall=0.312
Node 4: stage1=0.727, stage2=0.525, overall=0.382
Node 5: stage1=0.800, stage2=0.358, overall=0.287
Node 6: stage1=0.786, stage2=0.355, overall=0.279
Node 7: stage1=0.786, stage2=0.391, overall=0.307
Node 8: stage1=0.800, stage2=0.375, overall=0.300
Node 9: stage1=0.769, stage2=0.180, overall=0.138
Node 10: stage1=0.778, stage2=0.243, overall=0.189
Node 11: stage1=0.786, stage2=0.200, overall=0.157
Node 12: stage1=0.750, stage2=0.378, overall=0.283
Node 13: stage1=0.769, stage2=0.370, overall=0.285
Node 14: stage1=0.800, stage2=0.542, overall=0.433
Node 15: stage1=0.727, stage2=0.200, overall=0.145
Node 16: stage1=0.769, stage2=0.250, overall=0.192
Node 17: stage1=0.778, stage2=0.400, overall=0.311
Node 18: stage1=0.750, stage2=0.333, overall=0.250
Node 19: stage1=0.750, stage2=0.417, overall=0.312

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Distance computation: 0.040s (15.4%)
    - Loss computation: 0.214s (81.9%)
    - Aggregation: 0.007s (2.8%)
  TOTALS:
    - Total computation: 0.262s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.262s

=== PER-NODE AVERAGE TIME ===
  - Distance computation: 0.032s
  - Loss computation: 0.178s
  - Aggregation: 0.005s
  - Model transfer: 0.000s
  - Total per node: 0.214s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total distance computation: 0.635s
  - Total loss computation: 3.561s
  - Total aggregation: 0.093s
  - Total model transfer: 0.000s
  - Grand total: 4.290s
  - Mean Stage 1 acceptance rate: 0.765
  - Mean Stage 2 acceptance rate: 0.361
  - Overall acceptance rate: 0.276

UBAR Algorithm Properties:
  - Model dimension: 2,219,692
  - Rho parameter: 0.8
  - Two-stage approach: Distance filtering + loss evaluation
  - Stage 1 selects: 80% of neighbors
  - Stage 2 uses: Training sample loss comparison
  - Theoretical complexity: O(deg(i)×d + deg(i)×inference)
  - Approach: UBAR paper implementation
