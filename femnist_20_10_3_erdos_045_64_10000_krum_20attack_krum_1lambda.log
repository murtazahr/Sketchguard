Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: krum, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5542 ± 0.0135 | min=0.5276 max=0.5776
         : test loss mean=1.6705 ± 0.0411
         : individual accs = ['0.553779', '0.564121', '0.546190', '0.555504', '0.553899', '0.577560', '0.543763', '0.556450', '0.570031', '0.540566', '0.535602', '0.546148', '0.553872', '0.571599', '0.566140', '0.554480', '0.533590', '0.558929', '0.573213', '0.527616']
         : correct/total = [(2286, 4128), (2371, 4203), (2229, 4081), (2407, 4333), (2266, 4091), (2476, 4287), (2280, 4193), (2420, 4349), (2389, 4191), (2312, 4277), (2219, 4143), (2290, 4193), (2267, 4093), (2399, 4197), (2294, 4052), (2234, 4029), (2216, 4153), (2338, 4183), (2341, 4084), (2178, 4128)]
         : compromised: 0.5655, honest: 0.5513
Round 002: test acc mean=0.7375 ± 0.0099 | min=0.7118 max=0.7542
         : test loss mean=0.8923 ± 0.0251
         : individual accs = ['0.730620', '0.743517', '0.734869', '0.723748', '0.711806', '0.750175', '0.746005', '0.744309', '0.730136', '0.745850', '0.732561', '0.737896', '0.741510', '0.735764', '0.754195', '0.741871', '0.726944', '0.732967', '0.750000', '0.734981']
         : correct/total = [(3016, 4128), (3125, 4203), (2999, 4081), (3136, 4333), (2912, 4091), (3216, 4287), (3128, 4193), (3237, 4349), (3060, 4191), (3190, 4277), (3035, 4143), (3094, 4193), (3035, 4093), (3088, 4197), (3056, 4052), (2989, 4029), (3019, 4153), (3066, 4183), (3063, 4084), (3034, 4128)]
         : compromised: 0.7401, honest: 0.7368
Round 003: test acc mean=0.7706 ± 0.0089 | min=0.7558 max=0.7884
         : test loss mean=0.7303 ± 0.0296
         : individual accs = ['0.772529', '0.768499', '0.765499', '0.768290', '0.762161', '0.774668', '0.780110', '0.787077', '0.788356', '0.759177', '0.757664', '0.769616', '0.771317', '0.755778', '0.774926', '0.759742', '0.771009', '0.769543', '0.779138', '0.776890']
         : correct/total = [(3189, 4128), (3230, 4203), (3124, 4081), (3329, 4333), (3118, 4091), (3321, 4287), (3271, 4193), (3423, 4349), (3304, 4191), (3247, 4277), (3139, 4143), (3227, 4193), (3157, 4093), (3172, 4197), (3140, 4052), (3061, 4029), (3202, 4153), (3219, 4183), (3182, 4084), (3207, 4128)]
         : compromised: 0.7678, honest: 0.7713
Round 004: test acc mean=0.7995 ± 0.0074 | min=0.7849 max=0.8173
         : test loss mean=0.6281 ± 0.0232
         : individual accs = ['0.784884', '0.817273', '0.803725', '0.792523', '0.785627', '0.806625', '0.791080', '0.798344', '0.803865', '0.802899', '0.798214', '0.798474', '0.791840', '0.805575', '0.802073', '0.800695', '0.801348', '0.803968', '0.803134', '0.797965']
         : correct/total = [(3240, 4128), (3435, 4203), (3280, 4081), (3434, 4333), (3214, 4091), (3458, 4287), (3317, 4193), (3472, 4349), (3369, 4191), (3434, 4277), (3307, 4143), (3348, 4193), (3241, 4093), (3381, 4197), (3250, 4052), (3226, 4029), (3328, 4153), (3363, 4183), (3280, 4084), (3294, 4128)]
         : compromised: 0.8020, honest: 0.7989
Round 005: test acc mean=0.8040 ± 0.0099 | min=0.7866 max=0.8234
         : test loss mean=0.6014 ± 0.0233
         : individual accs = ['0.787064', '0.816322', '0.816712', '0.796907', '0.816915', '0.794262', '0.810398', '0.803863', '0.823431', '0.793313', '0.786628', '0.807775', '0.803323', '0.800572', '0.799605', '0.801440', '0.800144', '0.815443', '0.800930', '0.804264']
         : correct/total = [(3249, 4128), (3431, 4203), (3333, 4081), (3453, 4333), (3342, 4091), (3405, 4287), (3398, 4193), (3496, 4349), (3451, 4191), (3393, 4277), (3259, 4143), (3387, 4193), (3288, 4093), (3360, 4197), (3240, 4052), (3229, 4029), (3323, 4153), (3411, 4183), (3271, 4084), (3320, 4128)]
         : compromised: 0.8034, honest: 0.8041
Round 006: test acc mean=0.8202 ± 0.0088 | min=0.7978 max=0.8330
         : test loss mean=0.5527 ± 0.0285
         : individual accs = ['0.817103', '0.827504', '0.804950', '0.830372', '0.797849', '0.817355', '0.830909', '0.827547', '0.818898', '0.824643', '0.816075', '0.810160', '0.820425', '0.826305', '0.815400', '0.832961', '0.818444', '0.818790', '0.829824', '0.817829']
         : correct/total = [(3373, 4128), (3478, 4203), (3285, 4081), (3598, 4333), (3264, 4091), (3504, 4287), (3484, 4193), (3599, 4349), (3432, 4191), (3527, 4277), (3381, 4143), (3397, 4193), (3358, 4093), (3468, 4197), (3304, 4052), (3356, 4029), (3399, 4153), (3425, 4183), (3389, 4084), (3376, 4128)]
         : compromised: 0.8207, honest: 0.8200
Round 007: test acc mean=0.8270 ± 0.0075 | min=0.8127 max=0.8435
         : test loss mean=0.5294 ± 0.0255
         : individual accs = ['0.820736', '0.834166', '0.822347', '0.831987', '0.819360', '0.826219', '0.830909', '0.832375', '0.837032', '0.828618', '0.822834', '0.825900', '0.820425', '0.833929', '0.825518', '0.833209', '0.818204', '0.819029', '0.843536', '0.812742']
         : correct/total = [(3388, 4128), (3506, 4203), (3356, 4081), (3605, 4333), (3352, 4091), (3542, 4287), (3484, 4193), (3620, 4349), (3508, 4191), (3544, 4277), (3409, 4143), (3463, 4193), (3358, 4093), (3500, 4197), (3345, 4052), (3357, 4029), (3398, 4153), (3426, 4183), (3445, 4084), (3355, 4128)]
         : compromised: 0.8249, honest: 0.8275
Round 008: test acc mean=0.8295 ± 0.0084 | min=0.8094 max=0.8454
         : test loss mean=0.5173 ± 0.0280
         : individual accs = ['0.823886', '0.830121', '0.823328', '0.842603', '0.821315', '0.832983', '0.835202', '0.838814', '0.845383', '0.831658', '0.822351', '0.834725', '0.828732', '0.824875', '0.821570', '0.822040', '0.833614', '0.830265', '0.837414', '0.809351']
         : correct/total = [(3401, 4128), (3489, 4203), (3360, 4081), (3651, 4333), (3360, 4091), (3571, 4287), (3502, 4193), (3648, 4349), (3543, 4191), (3557, 4277), (3407, 4143), (3500, 4193), (3392, 4093), (3462, 4197), (3329, 4052), (3312, 4029), (3462, 4153), (3473, 4183), (3420, 4084), (3341, 4128)]
         : compromised: 0.8292, honest: 0.8296
Round 009: test acc mean=0.8267 ± 0.0101 | min=0.8094 max=0.8471
         : test loss mean=0.5230 ± 0.0316
         : individual accs = ['0.809351', '0.834880', '0.835825', '0.818371', '0.838426', '0.821320', '0.835679', '0.828236', '0.847053', '0.826514', '0.812696', '0.824708', '0.821158', '0.817489', '0.811945', '0.835195', '0.836504', '0.836003', '0.819785', '0.822917']
         : correct/total = [(3341, 4128), (3509, 4203), (3411, 4081), (3546, 4333), (3430, 4091), (3521, 4287), (3504, 4193), (3602, 4349), (3550, 4191), (3535, 4277), (3367, 4143), (3458, 4193), (3361, 4093), (3431, 4197), (3290, 4052), (3365, 4029), (3474, 4153), (3497, 4183), (3348, 4084), (3397, 4128)]
         : compromised: 0.8240, honest: 0.8274
Round 010: test acc mean=0.8293 ± 0.0106 | min=0.8110 max=0.8464
         : test loss mean=0.5001 ± 0.0274
         : individual accs = ['0.811047', '0.846062', '0.822593', '0.824140', '0.816915', '0.840681', '0.822800', '0.828236', '0.845860', '0.846388', '0.821868', '0.837348', '0.815539', '0.821063', '0.828480', '0.819062', '0.837226', '0.840545', '0.833252', '0.827762']
         : correct/total = [(3348, 4128), (3556, 4203), (3357, 4081), (3571, 4333), (3342, 4091), (3604, 4287), (3450, 4193), (3602, 4349), (3545, 4191), (3620, 4277), (3405, 4143), (3511, 4193), (3338, 4093), (3446, 4197), (3357, 4052), (3300, 4029), (3477, 4153), (3516, 4183), (3403, 4084), (3417, 4128)]
         : compromised: 0.8295, honest: 0.8293

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: krum, 20.0% compromised
Final accuracy - Compromised: 0.8295, Honest: 0.8293
Overall test accuracy: mean=0.8293 ± 0.0106
