Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0210 ± 0.0185 | min=0.0036 max=0.0615
         : test loss mean=1021.3282 ± 1294.2967
         : individual accs = ['0.005329', '0.058292', '0.061505', '0.024925', '0.019311', '0.042920', '0.005008', '0.008508', '0.004056', '0.048632', '0.013034', '0.006439', '0.018813', '0.003574', '0.004689', '0.009183', '0.007705', '0.020798', '0.015916', '0.040940']
         : correct/total = [(22, 4128), (245, 4203), (251, 4081), (108, 4333), (79, 4091), (184, 4287), (21, 4193), (37, 4349), (17, 4191), (208, 4277), (54, 4143), (27, 4193), (77, 4093), (15, 4197), (19, 4052), (37, 4029), (32, 4153), (87, 4183), (65, 4084), (169, 4128)]
         : compromised: 0.0215, honest: 0.0208
Round 002: test acc mean=0.0462 ± 0.0112 | min=0.0139 max=0.0602
         : test loss mean=62945334.4210 ± 246714616.1633
         : individual accs = ['0.048450', '0.048299', '0.049743', '0.048004', '0.045710', '0.051318', '0.052707', '0.046447', '0.044619', '0.050736', '0.053102', '0.049845', '0.013926', '0.014534', '0.052320', '0.048151', '0.045750', '0.052833', '0.060235', '0.046512']
         : correct/total = [(200, 4128), (203, 4203), (203, 4081), (208, 4333), (187, 4091), (220, 4287), (221, 4193), (202, 4349), (187, 4191), (217, 4277), (220, 4143), (209, 4193), (57, 4093), (61, 4197), (212, 4052), (194, 4029), (190, 4153), (221, 4183), (246, 4084), (192, 4128)]
         : compromised: 0.0332, honest: 0.0494
Round 003: test acc mean=0.0517 ± 0.0046 | min=0.0458 max=0.0616
         : test loss mean=1534040.1225 ± 2335588.7632
         : individual accs = ['0.049661', '0.048299', '0.061505', '0.047542', '0.048399', '0.052018', '0.053422', '0.046907', '0.052732', '0.048632', '0.050205', '0.048891', '0.052284', '0.049083', '0.054788', '0.061554', '0.045750', '0.052833', '0.060235', '0.049176']
         : correct/total = [(205, 4128), (203, 4203), (251, 4081), (206, 4333), (198, 4091), (223, 4287), (224, 4193), (204, 4349), (221, 4191), (208, 4277), (208, 4143), (205, 4193), (214, 4093), (206, 4197), (222, 4052), (248, 4029), (190, 4153), (221, 4183), (246, 4084), (203, 4128)]
         : compromised: 0.0516, honest: 0.0517
Round 004: test acc mean=0.0518 ± 0.0047 | min=0.0455 max=0.0623
         : test loss mean=111295.0776 ± 200926.9688
         : individual accs = ['0.049661', '0.051392', '0.061505', '0.049850', '0.052066', '0.045486', '0.053422', '0.052656', '0.052732', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.047384', '0.046662', '0.050566', '0.046378', '0.060235', '0.049903']
         : correct/total = [(205, 4128), (216, 4203), (251, 4081), (216, 4333), (213, 4091), (195, 4287), (224, 4193), (229, 4349), (221, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (192, 4052), (188, 4029), (210, 4153), (194, 4183), (246, 4084), (206, 4128)]
         : compromised: 0.0508, honest: 0.0521
Round 005: test acc mean=0.0542 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.7596 ± 0.0355
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.050630']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (209, 4128)]
         : compromised: 0.0553, honest: 0.0539
Round 006: test acc mean=0.0461 ± 0.0046 | min=0.0422 max=0.0615
         : test loss mean=3.7415 ± 0.0252
         : individual accs = ['0.049903', '0.045206', '0.061505', '0.042234', '0.044243', '0.042454', '0.044360', '0.043228', '0.042711', '0.048632', '0.042964', '0.042213', '0.045688', '0.049083', '0.044669', '0.050137', '0.042861', '0.044227', '0.052644', '0.043120']
         : correct/total = [(206, 4128), (190, 4203), (251, 4081), (183, 4333), (181, 4091), (182, 4287), (186, 4193), (188, 4349), (179, 4191), (208, 4277), (178, 4143), (177, 4193), (187, 4093), (206, 4197), (181, 4052), (202, 4029), (178, 4153), (185, 4183), (215, 4084), (178, 4128)]
         : compromised: 0.0454, honest: 0.0463
Round 007: test acc mean=0.0541 ± 0.0045 | min=0.0480 max=0.0623
         : test loss mean=3.9506 ± 1.0111
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.047965']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (198, 4128)]
         : compromised: 0.0553, honest: 0.0538
Round 008: test acc mean=0.0544 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.7045 ± 0.0168
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.054990']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (227, 4128)]
         : compromised: 0.0553, honest: 0.0542
Round 009: test acc mean=0.0544 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.7072 ± 0.0477
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.054990']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (227, 4128)]
         : compromised: 0.0553, honest: 0.0542
Round 010: test acc mean=0.0540 ± 0.0046 | min=0.0465 max=0.0623
         : test loss mean=3.6953 ± 0.0177
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.046512']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (192, 4128)]
         : compromised: 0.0553, honest: 0.0537

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: directed_deviation, 20.0% compromised
Final accuracy - Compromised: 0.0553, Honest: 0.0537
Overall test accuracy: mean=0.0540 ± 0.0046
