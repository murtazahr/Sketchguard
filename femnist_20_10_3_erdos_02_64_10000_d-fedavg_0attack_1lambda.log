/home/student.unimelb.edu.au/mrangwala/miniconda3/envs/edgedrift/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:282: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 48
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0946 ± 0.0514 | min=0.0307 max=0.2580
         : test loss mean=4.0754 ± 0.0362
         : individual accs = ['0.089874', '0.053057', '0.093114', '0.030695', '0.065999', '0.101703', '0.089196', '0.076569', '0.162252', '0.173018', '0.123582', '0.055330', '0.062301', '0.055278', '0.063672', '0.069000', '0.059234', '0.117141', '0.093536', '0.257994']
         : correct/total = [(371, 4128), (223, 4203), (380, 4081), (133, 4333), (270, 4091), (436, 4287), (374, 4193), (333, 4349), (680, 4191), (740, 4277), (512, 4143), (232, 4193), (255, 4093), (232, 4197), (258, 4052), (278, 4029), (246, 4153), (490, 4183), (382, 4084), (1065, 4128)]
Round 002: test acc mean=0.5821 ± 0.0427 | min=0.5061 max=0.6619
         : test loss mean=3.0488 ± 0.2202
         : individual accs = ['0.634932', '0.590768', '0.547660', '0.630279', '0.588120', '0.605552', '0.528500', '0.539894', '0.661895', '0.614216', '0.575911', '0.597424', '0.588566', '0.540863', '0.530355', '0.530901', '0.506140', '0.583792', '0.602106', '0.644622']
         : correct/total = [(2621, 4128), (2483, 4203), (2235, 4081), (2731, 4333), (2406, 4091), (2596, 4287), (2216, 4193), (2348, 4349), (2774, 4191), (2627, 4277), (2386, 4143), (2505, 4193), (2409, 4093), (2270, 4197), (2149, 4052), (2139, 4029), (2102, 4153), (2442, 4183), (2459, 4084), (2661, 4128)]
Round 003: test acc mean=0.7229 ± 0.0253 | min=0.6616 max=0.7552
         : test loss mean=1.4971 ± 0.2885
         : individual accs = ['0.714874', '0.688080', '0.669689', '0.753058', '0.717184', '0.743410', '0.751252', '0.719246', '0.755190', '0.733692', '0.701424', '0.661579', '0.743220', '0.732666', '0.725321', '0.747084', '0.721406', '0.721731', '0.726249', '0.730862']
         : correct/total = [(2951, 4128), (2892, 4203), (2733, 4081), (3263, 4333), (2934, 4091), (3187, 4287), (3150, 4193), (3128, 4349), (3165, 4191), (3138, 4277), (2906, 4143), (2774, 4193), (3042, 4093), (3075, 4197), (2939, 4052), (3010, 4029), (2996, 4153), (3019, 4183), (2966, 4084), (3017, 4128)]
Round 004: test acc mean=0.7831 ± 0.0083 | min=0.7622 max=0.7932
         : test loss mean=0.8335 ± 0.0995
         : individual accs = ['0.779797', '0.786819', '0.766724', '0.787214', '0.776583', '0.788663', '0.791080', '0.790986', '0.783822', '0.783961', '0.762250', '0.779871', '0.791595', '0.786991', '0.793189', '0.790767', '0.785938', '0.785082', '0.780607', '0.770591']
         : correct/total = [(3219, 4128), (3307, 4203), (3129, 4081), (3411, 4333), (3177, 4091), (3381, 4287), (3317, 4193), (3440, 4349), (3285, 4191), (3353, 4277), (3158, 4143), (3270, 4193), (3240, 4093), (3303, 4197), (3214, 4052), (3186, 4029), (3264, 4153), (3284, 4183), (3188, 4084), (3181, 4128)]
Round 005: test acc mean=0.8073 ± 0.0073 | min=0.7866 max=0.8158
         : test loss mean=0.6444 ± 0.0380
         : individual accs = ['0.799903', '0.812515', '0.801519', '0.807293', '0.799804', '0.813856', '0.814453', '0.810071', '0.815796', '0.807108', '0.786628', '0.803482', '0.810164', '0.805099', '0.815647', '0.813105', '0.814351', '0.812336', '0.805338', '0.798207']
         : correct/total = [(3302, 4128), (3415, 4203), (3271, 4081), (3498, 4333), (3272, 4091), (3489, 4287), (3415, 4193), (3523, 4349), (3419, 4191), (3452, 4277), (3259, 4143), (3369, 4193), (3316, 4093), (3379, 4197), (3305, 4052), (3276, 4029), (3382, 4153), (3398, 4183), (3289, 4084), (3295, 4128)]
Round 006: test acc mean=0.8223 ± 0.0062 | min=0.8086 max=0.8298
         : test loss mean=0.5638 ± 0.0216
         : individual accs = ['0.813711', '0.824887', '0.821857', '0.824140', '0.810071', '0.824353', '0.829001', '0.827317', '0.826056', '0.823708', '0.808593', '0.818984', '0.821402', '0.825351', '0.828973', '0.827997', '0.825909', '0.829787', '0.820029', '0.813227']
         : correct/total = [(3359, 4128), (3467, 4203), (3354, 4081), (3571, 4333), (3314, 4091), (3534, 4287), (3476, 4193), (3598, 4349), (3462, 4191), (3523, 4277), (3350, 4143), (3434, 4193), (3362, 4093), (3464, 4197), (3359, 4052), (3336, 4029), (3430, 4153), (3471, 4183), (3349, 4084), (3357, 4128)]
Round 007: test acc mean=0.8317 ± 0.0065 | min=0.8156 max=0.8394
         : test loss mean=0.5225 ± 0.0219
         : individual accs = ['0.823643', '0.839400', '0.831904', '0.832449', '0.823759', '0.835316', '0.836871', '0.833295', '0.835361', '0.834697', '0.817282', '0.830193', '0.830687', '0.839171', '0.835637', '0.834947', '0.836745', '0.836242', '0.830803', '0.815649']
         : correct/total = [(3400, 4128), (3528, 4203), (3395, 4081), (3607, 4333), (3370, 4091), (3581, 4287), (3509, 4193), (3624, 4349), (3501, 4191), (3570, 4277), (3386, 4143), (3481, 4193), (3400, 4093), (3522, 4197), (3386, 4052), (3364, 4029), (3475, 4153), (3498, 4183), (3393, 4084), (3367, 4128)]
Round 008: test acc mean=0.8383 ± 0.0071 | min=0.8198 max=0.8469
         : test loss mean=0.4945 ± 0.0209
         : individual accs = ['0.828246', '0.843921', '0.839500', '0.843065', '0.831093', '0.842081', '0.844264', '0.840193', '0.833214', '0.844517', '0.825489', '0.834725', '0.841681', '0.841792', '0.839585', '0.846860', '0.844691', '0.841740', '0.840353', '0.819767']
         : correct/total = [(3419, 4128), (3547, 4203), (3426, 4081), (3653, 4333), (3400, 4091), (3610, 4287), (3540, 4193), (3654, 4349), (3492, 4191), (3612, 4277), (3420, 4143), (3500, 4193), (3445, 4093), (3533, 4197), (3402, 4052), (3412, 4029), (3508, 4153), (3521, 4183), (3432, 4084), (3384, 4128)]
Round 009: test acc mean=0.8451 ± 0.0051 | min=0.8327 max=0.8506
         : test loss mean=0.4744 ± 0.0189
         : individual accs = ['0.836483', '0.850583', '0.846116', '0.846988', '0.838670', '0.848146', '0.850227', '0.848241', '0.849916', '0.849193', '0.832730', '0.841641', '0.843635', '0.847748', '0.847730', '0.849839', '0.843968', '0.849869', '0.842801', '0.837936']
         : correct/total = [(3453, 4128), (3575, 4203), (3453, 4081), (3670, 4333), (3431, 4091), (3636, 4287), (3565, 4193), (3689, 4349), (3562, 4191), (3632, 4277), (3450, 4143), (3529, 4193), (3453, 4093), (3558, 4197), (3435, 4052), (3424, 4029), (3505, 4153), (3555, 4183), (3442, 4084), (3459, 4128)]
Round 010: test acc mean=0.8487 ± 0.0053 | min=0.8405 max=0.8581
         : test loss mean=0.4599 ± 0.0189
         : individual accs = ['0.841085', '0.855817', '0.849302', '0.851142', '0.843803', '0.843480', '0.852373', '0.853070', '0.856359', '0.858078', '0.840454', '0.844503', '0.847789', '0.852752', '0.848717', '0.852817', '0.847821', '0.850825', '0.842067', '0.841085']
         : correct/total = [(3472, 4128), (3597, 4203), (3466, 4081), (3688, 4333), (3452, 4091), (3616, 4287), (3574, 4193), (3710, 4349), (3589, 4191), (3670, 4277), (3482, 4143), (3541, 4193), (3470, 4093), (3579, 4197), (3439, 4052), (3436, 4029), (3521, 4153), (3559, 4183), (3439, 4084), (3472, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Overall test accuracy: mean=0.8487 ± 0.0053
