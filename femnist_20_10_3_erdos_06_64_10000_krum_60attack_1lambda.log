Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Attack: Compromised 12/20 nodes: [1, 2, 3, 5, 8, 11, 12, 13, 14, 15, 17, 18]
Attack type: directed_deviation, lambda: 1.0
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0189 ± 0.0190 | min=0.0030 max=0.0610
         : test loss mean=39664.2074 ± 21186.0204
         : individual accs = ['0.005329', '0.050440', '0.061014', '0.021463', '0.003178', '0.003032', '0.012163', '0.007128', '0.006442', '0.003040', '0.010138', '0.004770', '0.004153', '0.048606', '0.015795', '0.050137', '0.006983', '0.022950', '0.038932', '0.003149']
         : correct/total = [(22, 4128), (212, 4203), (249, 4081), (93, 4333), (13, 4091), (13, 4287), (51, 4193), (31, 4349), (27, 4191), (13, 4277), (42, 4143), (20, 4193), (17, 4093), (204, 4197), (64, 4052), (202, 4029), (29, 4153), (96, 4183), (159, 4084), (13, 4128)]
         : compromised: 0.0273, honest: 0.0064
Round 002: test acc mean=0.0360 ± 0.0152 | min=0.0048 max=0.0537
         : test loss mean=2029454559377.9028 ± 7494569425416.3770
         : individual accs = ['0.020591', '0.045206', '0.023524', '0.042234', '0.018333', '0.052951', '0.051991', '0.036790', '0.053686', '0.020341', '0.051412', '0.034343', '0.047642', '0.049083', '0.015795', '0.051874', '0.027450', '0.004781', '0.020568', '0.050630']
         : correct/total = [(85, 4128), (190, 4203), (96, 4081), (183, 4333), (75, 4091), (227, 4287), (218, 4193), (160, 4349), (225, 4191), (87, 4277), (213, 4143), (144, 4193), (195, 4093), (206, 4197), (64, 4052), (209, 4029), (114, 4153), (20, 4183), (84, 4084), (209, 4128)]
         : compromised: 0.0368, honest: 0.0347
Round 003: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.7557 ± 0.0098
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520
Round 004: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.7068 ± 0.0126
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520
Round 005: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.6943 ± 0.0133
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520
Round 006: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.6894 ± 0.0137
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520
Round 007: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.6871 ± 0.0138
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520
Round 008: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.6860 ± 0.0139
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520
Round 009: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.6852 ± 0.0140
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520
Round 010: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=3.6849 ± 0.0141
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
         : compromised: 0.0562, honest: 0.0520

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: directed_deviation, 60.0% compromised
Final accuracy - Compromised: 0.0562, Honest: 0.0520
Overall test accuracy: mean=0.0545 ± 0.0043
