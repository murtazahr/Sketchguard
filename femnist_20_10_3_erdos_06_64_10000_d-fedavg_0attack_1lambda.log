Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.0545 ± 0.0043 | min=0.0486 max=0.0623
         : test loss mean=4.1026 ± 0.0013
         : individual accs = ['0.049661', '0.052819', '0.061505', '0.049850', '0.052066', '0.052018', '0.053422', '0.052656', '0.057266', '0.048632', '0.051895', '0.054853', '0.062301', '0.049083', '0.055281', '0.061554', '0.050566', '0.057853', '0.060235', '0.057413']
         : correct/total = [(205, 4128), (222, 4203), (251, 4081), (216, 4333), (213, 4091), (223, 4287), (224, 4193), (229, 4349), (240, 4191), (208, 4277), (215, 4143), (230, 4193), (255, 4093), (206, 4197), (224, 4052), (248, 4029), (210, 4153), (242, 4183), (246, 4084), (237, 4128)]
Round 002: test acc mean=0.4648 ± 0.0104 | min=0.4386 max=0.4772
         : test loss mean=2.6884 ± 0.0518
         : individual accs = ['0.464632', '0.474185', '0.464102', '0.457881', '0.468101', '0.474691', '0.462914', '0.449759', '0.476259', '0.438625', '0.447019', '0.468400', '0.455412', '0.474386', '0.471866', '0.470836', '0.477245', '0.462587', '0.475759', '0.461483']
         : correct/total = [(1918, 4128), (1993, 4203), (1894, 4081), (1984, 4333), (1915, 4091), (2035, 4287), (1941, 4193), (1956, 4349), (1996, 4191), (1876, 4277), (1852, 4143), (1964, 4193), (1864, 4093), (1991, 4197), (1912, 4052), (1897, 4029), (1982, 4153), (1935, 4183), (1943, 4084), (1905, 4128)]
Round 003: test acc mean=0.7150 ± 0.0071 | min=0.6980 max=0.7244
         : test loss mean=1.0016 ± 0.0262
         : individual accs = ['0.717539', '0.724007', '0.705464', '0.724440', '0.714984', '0.722883', '0.715717', '0.716946', '0.718921', '0.712415', '0.701183', '0.714047', '0.722697', '0.713843', '0.717917', '0.715314', '0.698050', '0.716950', '0.720127', '0.706395']
         : correct/total = [(2962, 4128), (3043, 4203), (2879, 4081), (3139, 4333), (2925, 4091), (3099, 4287), (3001, 4193), (3118, 4349), (3013, 4191), (3047, 4277), (2905, 4143), (2994, 4193), (2958, 4093), (2996, 4197), (2909, 4052), (2882, 4029), (2899, 4153), (2999, 4183), (2941, 4084), (2916, 4128)]
Round 004: test acc mean=0.7783 ± 0.0076 | min=0.7565 max=0.7902
         : test loss mean=0.7181 ± 0.0230
         : individual accs = ['0.774225', '0.780157', '0.775545', '0.777060', '0.762405', '0.783298', '0.784641', '0.785238', '0.786447', '0.779285', '0.756457', '0.776294', '0.780357', '0.777698', '0.790227', '0.782576', '0.774621', '0.779106', '0.784280', '0.775436']
         : correct/total = [(3196, 4128), (3279, 4203), (3165, 4081), (3367, 4333), (3119, 4091), (3358, 4287), (3290, 4193), (3415, 4349), (3296, 4191), (3333, 4277), (3134, 4143), (3255, 4193), (3194, 4093), (3264, 4197), (3202, 4052), (3153, 4029), (3217, 4153), (3259, 4183), (3203, 4084), (3201, 4128)]
Round 005: test acc mean=0.8079 ± 0.0077 | min=0.7866 max=0.8169
         : test loss mean=0.6110 ± 0.0206
         : individual accs = ['0.799176', '0.812753', '0.807155', '0.810293', '0.794182', '0.813856', '0.816599', '0.812831', '0.814364', '0.807108', '0.786628', '0.805867', '0.808209', '0.807482', '0.816881', '0.814346', '0.805683', '0.815443', '0.809500', '0.799903']
         : correct/total = [(3299, 4128), (3416, 4203), (3294, 4081), (3511, 4333), (3249, 4091), (3489, 4287), (3424, 4193), (3535, 4349), (3413, 4191), (3452, 4277), (3259, 4143), (3379, 4193), (3308, 4093), (3389, 4197), (3310, 4052), (3281, 4029), (3346, 4153), (3411, 4183), (3306, 4084), (3302, 4128)]
Round 006: test acc mean=0.8232 ± 0.0058 | min=0.8079 max=0.8311
         : test loss mean=0.5511 ± 0.0199
         : individual accs = ['0.816376', '0.826790', '0.820877', '0.824833', '0.814471', '0.826919', '0.828285', '0.830536', '0.831067', '0.826046', '0.807869', '0.820176', '0.818959', '0.825828', '0.828727', '0.826011', '0.822538', '0.827397', '0.822478', '0.817103']
         : correct/total = [(3370, 4128), (3475, 4203), (3350, 4081), (3574, 4333), (3332, 4091), (3545, 4287), (3473, 4193), (3612, 4349), (3483, 4191), (3533, 4277), (3347, 4143), (3439, 4193), (3352, 4093), (3466, 4197), (3358, 4052), (3328, 4029), (3416, 4153), (3461, 4183), (3359, 4084), (3373, 4128)]
Round 007: test acc mean=0.8335 ± 0.0059 | min=0.8202 max=0.8425
         : test loss mean=0.5150 ± 0.0198
         : individual accs = ['0.824128', '0.840590', '0.835334', '0.837064', '0.824737', '0.836716', '0.839256', '0.837434', '0.842520', '0.835399', '0.820179', '0.828285', '0.829465', '0.835835', '0.839832', '0.838421', '0.830725', '0.834090', '0.832272', '0.828246']
         : correct/total = [(3402, 4128), (3533, 4203), (3409, 4081), (3627, 4333), (3374, 4091), (3587, 4287), (3519, 4193), (3642, 4349), (3531, 4191), (3573, 4277), (3398, 4143), (3473, 4193), (3395, 4093), (3508, 4197), (3403, 4052), (3378, 4029), (3450, 4153), (3489, 4183), (3399, 4084), (3419, 4128)]
Round 008: test acc mean=0.8393 ± 0.0051 | min=0.8257 max=0.8459
         : test loss mean=0.4909 ± 0.0206
         : individual accs = ['0.830184', '0.842493', '0.840235', '0.843526', '0.833781', '0.840681', '0.844264', '0.845942', '0.844906', '0.842881', '0.825730', '0.836155', '0.838016', '0.839647', '0.841066', '0.842144', '0.843005', '0.839589', '0.840108', '0.832607']
         : correct/total = [(3427, 4128), (3541, 4203), (3429, 4081), (3655, 4333), (3411, 4091), (3604, 4287), (3540, 4193), (3679, 4349), (3541, 4191), (3605, 4277), (3421, 4143), (3506, 4193), (3430, 4093), (3524, 4197), (3408, 4052), (3393, 4029), (3501, 4153), (3512, 4183), (3431, 4084), (3437, 4128)]
Round 009: test acc mean=0.8453 ± 0.0058 | min=0.8331 max=0.8547
         : test loss mean=0.4696 ± 0.0208
         : individual accs = ['0.833091', '0.848917', '0.846116', '0.845604', '0.835737', '0.845580', '0.851658', '0.853989', '0.854689', '0.850596', '0.834420', '0.843549', '0.841437', '0.847034', '0.846002', '0.846860', '0.846135', '0.847239', '0.847209', '0.839874']
         : correct/total = [(3439, 4128), (3568, 4203), (3453, 4081), (3664, 4333), (3419, 4091), (3625, 4287), (3571, 4193), (3714, 4349), (3582, 4191), (3638, 4277), (3457, 4143), (3537, 4193), (3444, 4093), (3555, 4197), (3428, 4052), (3412, 4029), (3514, 4153), (3544, 4183), (3460, 4084), (3467, 4128)]
Round 010: test acc mean=0.8498 ± 0.0055 | min=0.8380 max=0.8572
         : test loss mean=0.4553 ± 0.0198
         : individual accs = ['0.840601', '0.857245', '0.852487', '0.853681', '0.839892', '0.850245', '0.854519', '0.856289', '0.856597', '0.853402', '0.838040', '0.846172', '0.846567', '0.852752', '0.849457', '0.854306', '0.850951', '0.848912', '0.847698', '0.845688']
         : correct/total = [(3470, 4128), (3603, 4203), (3479, 4081), (3699, 4333), (3436, 4091), (3645, 4287), (3583, 4193), (3724, 4349), (3590, 4191), (3650, 4277), (3472, 4143), (3548, 4193), (3465, 4093), (3579, 4197), (3442, 4052), (3442, 4029), (3534, 4153), (3551, 4183), (3462, 4084), (3491, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Overall test accuracy: mean=0.8498 ± 0.0055
