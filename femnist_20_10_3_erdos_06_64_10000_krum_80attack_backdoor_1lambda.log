Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 16/20 nodes: [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 4
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Backdoor attack: Created poisoned datasets for 16 compromised nodes
Round 001: test acc mean=0.0157 ± 0.0149 | min=0.0024 max=0.0520
         : test loss mean=128357.3128 ± 64137.4574
         : individual accs = ['0.012597', '0.008089', '0.006616', '0.035772', '0.035199', '0.048752', '0.004293', '0.008508', '0.005011', '0.006547', '0.014482', '0.003816', '0.006597', '0.004289', '0.022458', '0.012906', '0.052011', '0.005498', '0.002449', '0.018653']
         : correct/total = [(52, 4128), (34, 4203), (27, 4081), (155, 4333), (144, 4091), (209, 4287), (18, 4193), (37, 4349), (21, 4191), (28, 4277), (60, 4143), (16, 4193), (27, 4093), (18, 4197), (91, 4052), (52, 4029), (216, 4153), (23, 4183), (10, 4084), (77, 4128)]
         : compromised: 0.0129, honest: 0.0271
Round 002: test acc mean=0.0320 ± 0.0175 | min=0.0117 max=0.0551
         : test loss mean=24153788938.1086 ± 19676197088.8325
         : individual accs = ['0.013808', '0.015941', '0.055134', '0.043157', '0.012955', '0.045253', '0.053899', '0.045068', '0.051539', '0.014730', '0.048033', '0.049606', '0.017102', '0.045747', '0.016782', '0.013403', '0.054418', '0.011714', '0.015671', '0.015504']
         : correct/total = [(57, 4128), (67, 4203), (225, 4081), (187, 4333), (53, 4091), (194, 4287), (226, 4193), (196, 4349), (216, 4191), (63, 4277), (199, 4143), (208, 4193), (70, 4093), (192, 4197), (68, 4052), (54, 4029), (226, 4153), (49, 4183), (64, 4084), (64, 4128)]
         : compromised: 0.0321, honest: 0.0316
Round 003: test acc mean=0.0488 ± 0.0034 | min=0.0432 max=0.0561
         : test loss mean=32440.5826 ± 15136.8786
         : individual accs = ['0.048934', '0.050202', '0.056114', '0.043157', '0.048643', '0.048519', '0.048414', '0.051276', '0.043188', '0.047229', '0.051653', '0.046745', '0.048620', '0.049559', '0.047878', '0.053860', '0.047195', '0.045900', '0.054358', '0.043847']
         : correct/total = [(202, 4128), (211, 4203), (229, 4081), (187, 4333), (199, 4091), (208, 4287), (203, 4193), (223, 4349), (181, 4191), (202, 4277), (214, 4143), (196, 4193), (199, 4093), (208, 4197), (194, 4052), (217, 4029), (196, 4153), (192, 4183), (222, 4084), (181, 4128)]
         : compromised: 0.0487, honest: 0.0490
Round 004: test acc mean=0.0482 ± 0.0025 | min=0.0446 max=0.0549
         : test loss mean=5643.4844 ± 2301.7063
         : individual accs = ['0.044574', '0.048775', '0.048272', '0.044773', '0.047421', '0.048752', '0.046745', '0.045528', '0.054880', '0.047697', '0.047309', '0.045314', '0.049597', '0.046462', '0.046397', '0.051378', '0.049362', '0.051159', '0.050930', '0.048692']
         : correct/total = [(184, 4128), (205, 4203), (197, 4081), (194, 4333), (194, 4091), (209, 4287), (196, 4193), (198, 4349), (230, 4191), (204, 4277), (196, 4143), (190, 4193), (203, 4093), (195, 4197), (188, 4052), (207, 4029), (205, 4153), (214, 4183), (208, 4084), (201, 4128)]
         : compromised: 0.0486, honest: 0.0467
Round 005: test acc mean=0.0317 ± 0.0175 | min=0.0124 max=0.0534
         : test loss mean=386.5087 ± 500.4798
         : individual accs = ['0.015746', '0.012372', '0.053418', '0.048234', '0.015400', '0.045253', '0.050799', '0.045068', '0.049630', '0.013795', '0.048033', '0.049606', '0.013682', '0.049083', '0.013574', '0.013899', '0.052011', '0.014583', '0.014691', '0.014777']
         : correct/total = [(65, 4128), (52, 4203), (218, 4081), (209, 4333), (63, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (59, 4277), (199, 4143), (208, 4193), (56, 4093), (206, 4197), (55, 4052), (56, 4029), (216, 4153), (61, 4183), (60, 4084), (61, 4128)]
         : compromised: 0.0316, honest: 0.0321
Round 006: test acc mean=0.0314 ± 0.0173 | min=0.0124 max=0.0534
         : test loss mean=51.0553 ± 63.4556
         : individual accs = ['0.015746', '0.012372', '0.053418', '0.043157', '0.015400', '0.045253', '0.050799', '0.045068', '0.049630', '0.013795', '0.048033', '0.049606', '0.013682', '0.049083', '0.013574', '0.013899', '0.052011', '0.014583', '0.014691', '0.014777']
         : correct/total = [(65, 4128), (52, 4203), (218, 4081), (187, 4333), (63, 4091), (194, 4287), (213, 4193), (196, 4349), (208, 4191), (59, 4277), (199, 4143), (208, 4193), (56, 4093), (206, 4197), (55, 4052), (56, 4029), (216, 4153), (61, 4183), (60, 4084), (61, 4128)]
         : compromised: 0.0313, honest: 0.0321
Round 007: test acc mean=0.0138 ± 0.0011 | min=0.0118 max=0.0157
         : test loss mean=4.4326 ± 0.0106
         : individual accs = ['0.015746', '0.012372', '0.013722', '0.015232', '0.015400', '0.013063', '0.012402', '0.015406', '0.012646', '0.013795', '0.011827', '0.013594', '0.013682', '0.013105', '0.013574', '0.013899', '0.013243', '0.014583', '0.014691', '0.014777']
         : correct/total = [(65, 4128), (52, 4203), (56, 4081), (66, 4333), (63, 4091), (56, 4287), (52, 4193), (67, 4349), (53, 4191), (59, 4277), (49, 4143), (57, 4193), (56, 4093), (55, 4197), (55, 4052), (56, 4029), (55, 4153), (61, 4183), (60, 4084), (61, 4128)]
         : compromised: 0.0136, honest: 0.0149
Round 008: test acc mean=0.0138 ± 0.0011 | min=0.0118 max=0.0157
         : test loss mean=4.3206 ± 0.0070
         : individual accs = ['0.015746', '0.012372', '0.013722', '0.015232', '0.015400', '0.013063', '0.012402', '0.015406', '0.012646', '0.013795', '0.011827', '0.013594', '0.013682', '0.013105', '0.013574', '0.013899', '0.013243', '0.014583', '0.014691', '0.014777']
         : correct/total = [(65, 4128), (52, 4203), (56, 4081), (66, 4333), (63, 4091), (56, 4287), (52, 4193), (67, 4349), (53, 4191), (59, 4277), (49, 4143), (57, 4193), (56, 4093), (55, 4197), (55, 4052), (56, 4029), (55, 4153), (61, 4183), (60, 4084), (61, 4128)]
         : compromised: 0.0136, honest: 0.0149
Round 009: test acc mean=0.0138 ± 0.0011 | min=0.0118 max=0.0157
         : test loss mean=4.3230 ± 0.0094
         : individual accs = ['0.015746', '0.012372', '0.013722', '0.015232', '0.015400', '0.013063', '0.012402', '0.015406', '0.012646', '0.013795', '0.011827', '0.013594', '0.013682', '0.013105', '0.013574', '0.013899', '0.013243', '0.014583', '0.014691', '0.014777']
         : correct/total = [(65, 4128), (52, 4203), (56, 4081), (66, 4333), (63, 4091), (56, 4287), (52, 4193), (67, 4349), (53, 4191), (59, 4277), (49, 4143), (57, 4193), (56, 4093), (55, 4197), (55, 4052), (56, 4029), (55, 4153), (61, 4183), (60, 4084), (61, 4128)]
         : compromised: 0.0136, honest: 0.0149
Round 010: test acc mean=0.0138 ± 0.0011 | min=0.0118 max=0.0157
         : test loss mean=4.2231 ± 0.0072
         : individual accs = ['0.015746', '0.012372', '0.013722', '0.015232', '0.015400', '0.013063', '0.012402', '0.015406', '0.012646', '0.013795', '0.011827', '0.013594', '0.013682', '0.013105', '0.013574', '0.013899', '0.013243', '0.014583', '0.014691', '0.014777']
         : correct/total = [(65, 4128), (52, 4203), (56, 4081), (66, 4333), (63, 4091), (56, 4287), (52, 4193), (67, 4349), (53, 4191), (59, 4277), (49, 4143), (57, 4193), (56, 4093), (55, 4197), (55, 4052), (56, 4029), (55, 4153), (61, 4183), (60, 4084), (61, 4128)]
         : compromised: 0.0136, honest: 0.0149

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: backdoor, 80.0% compromised
Final accuracy - Compromised: 0.0136, Honest: 0.0149
Overall test accuracy: mean=0.0138 ± 0.0011

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 4x4
Overall ASR: 0.0000 ± 0.0000
Honest nodes ASR: 0.0000 ± 0.0000
Compromised nodes ASR: 0.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack
