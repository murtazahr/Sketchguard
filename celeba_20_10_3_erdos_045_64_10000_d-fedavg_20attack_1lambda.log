Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Attack: Compromised 4/20 nodes: [5, 12, 13, 17]
Attack type: directed_deviation, lambda: 1.0
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.5099 ± 0.0205 | min=0.4801 max=0.5625
         : test loss mean=nan ± nan
         : individual accs = ['0.528947', '0.521589', '0.493345', '0.538860', '0.513228', '0.504803', '0.494323', '0.509317', '0.562500', '0.491135', '0.525350', '0.482667', '0.494792', '0.493103', '0.517794', '0.484716', '0.480069', '0.521662', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (604, 1158), (556, 1127), (624, 1158), (582, 1134), (578, 1145), (566, 1145), (574, 1127), (639, 1136), (554, 1128), (601, 1144), (543, 1125), (570, 1152), (572, 1160), (582, 1124), (555, 1145), (554, 1154), (590, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5036, honest: 0.5115
Round 002: test acc mean=0.5158 ± 0.0154 | min=0.4911 max=0.5625
         : test loss mean=7.1416 ± 10.0751
         : individual accs = ['0.528947', '0.506908', '0.493345', '0.528497', '0.521164', '0.511790', '0.522271', '0.502218', '0.562500', '0.491135', '0.526224', '0.496889', '0.522569', '0.506897', '0.517794', '0.517031', '0.516464', '0.505747', '0.522040', '0.516214']
         : correct/total = [(603, 1140), (587, 1158), (556, 1127), (612, 1158), (591, 1134), (586, 1145), (598, 1145), (566, 1127), (639, 1136), (554, 1128), (602, 1144), (559, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (596, 1154), (572, 1131), (604, 1157), (589, 1141)]
         : compromised: 0.5118, honest: 0.5169
Round 003: test acc mean=0.5145 ± 0.0169 | min=0.4794 max=0.5625
         : test loss mean=0.9294 ± 0.0991
         : individual accs = ['0.528947', '0.508636', '0.493345', '0.528497', '0.522046', '0.514410', '0.521397', '0.503993', '0.562500', '0.492908', '0.525350', '0.498667', '0.522569', '0.506897', '0.517794', '0.517031', '0.515598', '0.508400', '0.522040', '0.479404']
         : correct/total = [(603, 1140), (589, 1158), (556, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (568, 1127), (639, 1136), (556, 1128), (601, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (592, 1145), (595, 1154), (575, 1131), (604, 1157), (547, 1141)]
         : compromised: 0.5131, honest: 0.5149
Round 004: test acc mean=0.5677 ± 0.0580 | min=0.4911 max=0.7245
         : test loss mean=6.5646 ± 7.3138
         : individual accs = ['0.660526', '0.641623', '0.493345', '0.724525', '0.604056', '0.551092', '0.526638', '0.511091', '0.582746', '0.491135', '0.576923', '0.570667', '0.543403', '0.506897', '0.550712', '0.544105', '0.523397', '0.581786', '0.620570', '0.547765']
         : correct/total = [(753, 1140), (743, 1158), (556, 1127), (839, 1158), (685, 1134), (631, 1145), (603, 1145), (576, 1127), (662, 1136), (554, 1128), (660, 1144), (642, 1125), (626, 1152), (588, 1160), (619, 1124), (623, 1145), (604, 1154), (658, 1131), (718, 1157), (625, 1141)]
         : compromised: 0.5458, honest: 0.5731
Round 005: test acc mean=0.5484 ± 0.1098 | min=0.4428 max=0.8830
         : test loss mean=0.6817 ± 0.1190
         : individual accs = ['0.528947', '0.508636', '0.863354', '0.528497', '0.522046', '0.514410', '0.521397', '0.512866', '0.442782', '0.882979', '0.525350', '0.498667', '0.522569', '0.512931', '0.517794', '0.517031', '0.517331', '0.508400', '0.522040', '0.500438']
         : correct/total = [(603, 1140), (589, 1158), (973, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (578, 1127), (503, 1136), (996, 1128), (601, 1144), (561, 1125), (602, 1152), (595, 1160), (582, 1124), (592, 1145), (597, 1154), (575, 1131), (604, 1157), (571, 1141)]
         : compromised: 0.5146, honest: 0.5569
Round 006: test acc mean=0.6543 ± 0.0900 | min=0.4929 max=0.8523
         : test loss mean=4.7664 ± 5.5969
         : individual accs = ['0.798246', '0.697755', '0.493345', '0.852332', '0.692240', '0.580786', '0.652402', '0.614907', '0.608275', '0.492908', '0.626748', '0.661333', '0.752604', '0.706897', '0.613879', '0.632314', '0.621317', '0.641026', '0.773552', '0.572305']
         : correct/total = [(910, 1140), (808, 1158), (556, 1127), (987, 1158), (785, 1134), (665, 1145), (747, 1145), (693, 1127), (691, 1136), (556, 1128), (717, 1144), (744, 1125), (867, 1152), (820, 1160), (690, 1124), (724, 1145), (717, 1154), (725, 1131), (895, 1157), (653, 1141)]
         : compromised: 0.6703, honest: 0.6502
Round 007: test acc mean=0.5669 ± 0.1104 | min=0.5058 max=0.8936
         : test loss mean=nan ± nan
         : individual accs = ['0.528947', '0.508636', '0.882875', '0.528497', '0.522046', '0.514410', '0.521397', '0.593611', '0.562500', '0.893617', '0.525350', '0.505778', '0.522569', '0.612069', '0.529359', '0.517031', '0.520797', '0.508400', '0.522040', '0.517967']
         : correct/total = [(603, 1140), (589, 1158), (995, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (669, 1127), (639, 1136), (1008, 1128), (601, 1144), (569, 1125), (602, 1152), (710, 1160), (595, 1124), (592, 1145), (601, 1154), (575, 1131), (604, 1157), (591, 1141)]
         : compromised: 0.5394, honest: 0.5738
Round 008: test acc mean=0.7357 ± 0.0995 | min=0.5359 max=0.8851
         : test loss mean=3.4722 ± 5.0550
         : individual accs = ['0.877193', '0.815199', '0.535936', '0.885147', '0.773369', '0.687336', '0.765939', '0.676131', '0.585387', '0.613475', '0.780594', '0.769778', '0.842882', '0.670690', '0.714413', '0.800873', '0.710572', '0.776304', '0.852204', '0.580193']
         : correct/total = [(1000, 1140), (944, 1158), (604, 1127), (1025, 1158), (877, 1134), (787, 1145), (877, 1145), (762, 1127), (665, 1136), (692, 1128), (893, 1144), (866, 1125), (971, 1152), (778, 1160), (803, 1124), (917, 1145), (820, 1154), (878, 1131), (986, 1157), (662, 1141)]
         : compromised: 0.7443, honest: 0.7335
Round 009: test acc mean=0.5737 ± 0.1119 | min=0.4987 max=0.8989
         : test loss mean=0.6463 ± 0.1298
         : individual accs = ['0.528947', '0.508636', '0.888199', '0.528497', '0.522046', '0.514410', '0.521397', '0.651287', '0.575704', '0.898936', '0.525350', '0.498667', '0.522569', '0.567241', '0.553381', '0.517031', '0.536395', '0.508400', '0.522040', '0.585451']
         : correct/total = [(603, 1140), (589, 1158), (1001, 1127), (612, 1158), (592, 1134), (589, 1145), (597, 1145), (734, 1127), (654, 1136), (1014, 1128), (601, 1144), (561, 1125), (602, 1152), (658, 1160), (622, 1124), (592, 1145), (619, 1154), (575, 1131), (604, 1157), (668, 1141)]
         : compromised: 0.5282, honest: 0.5851
Round 010: test acc mean=0.7393 ± 0.0885 | min=0.5451 max=0.8895
         : test loss mean=3.6599 ± 5.6820
         : individual accs = ['0.889474', '0.805699', '0.685004', '0.884283', '0.804233', '0.668122', '0.731004', '0.669920', '0.580106', '0.731383', '0.709790', '0.744000', '0.834201', '0.702586', '0.719751', '0.785153', '0.691508', '0.755968', '0.848747', '0.545136']
         : correct/total = [(1014, 1140), (933, 1158), (772, 1127), (1024, 1158), (912, 1134), (765, 1145), (837, 1145), (755, 1127), (659, 1136), (825, 1128), (812, 1144), (837, 1125), (961, 1152), (815, 1160), (809, 1124), (899, 1145), (798, 1154), (855, 1131), (982, 1157), (622, 1141)]
         : compromised: 0.7402, honest: 0.7391

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: d-fedavg
Attack: directed_deviation, 20.0% compromised
Final accuracy - Compromised: 0.7402, Honest: 0.7391
Overall test accuracy: mean=0.7393 ± 0.0885
