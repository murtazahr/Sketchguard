Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 6/20 nodes: [5, 12, 13, 14, 17, 18]
Attack type: gaussian, lambda: 1.0
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.7062 ± 0.0271 | min=0.6615 max=0.7569
         : test loss mean=0.6029 ± 0.0407
         : individual accs = ['0.671930', '0.661485', '0.678793', '0.712435', '0.693122', '0.710044', '0.746725', '0.710736', '0.694542', '0.679078', '0.727273', '0.705778', '0.756944', '0.739655', '0.700178', '0.752838', '0.694107', '0.686118', '0.677615', '0.723926']
         : correct/total = [(766, 1140), (766, 1158), (765, 1127), (825, 1158), (786, 1134), (813, 1145), (855, 1145), (801, 1127), (789, 1136), (766, 1128), (832, 1144), (794, 1125), (872, 1152), (858, 1160), (787, 1124), (862, 1145), (801, 1154), (776, 1131), (784, 1157), (826, 1141)]
         : compromised: 0.7118, honest: 0.7038
Round 002: test acc mean=0.8123 ± 0.0170 | min=0.7773 max=0.8356
         : test loss mean=0.4258 ± 0.0171
         : individual accs = ['0.822807', '0.826425', '0.787933', '0.817789', '0.811287', '0.827948', '0.832314', '0.821650', '0.777289', '0.825355', '0.831294', '0.835556', '0.817708', '0.799138', '0.808719', '0.786900', '0.790295', '0.813439', '0.791703', '0.819457']
         : correct/total = [(938, 1140), (957, 1158), (888, 1127), (947, 1158), (920, 1134), (948, 1145), (953, 1145), (926, 1127), (883, 1136), (931, 1128), (951, 1144), (940, 1125), (942, 1152), (927, 1160), (909, 1124), (901, 1145), (912, 1154), (920, 1131), (916, 1157), (935, 1141)]
         : compromised: 0.8098, honest: 0.8133
Round 003: test acc mean=0.8418 ± 0.0181 | min=0.8034 max=0.8777
         : test loss mean=0.3598 ± 0.0318
         : individual accs = ['0.860526', '0.860967', '0.813665', '0.844560', '0.841270', '0.852402', '0.877729', '0.839397', '0.838028', '0.839539', '0.854021', '0.838222', '0.820312', '0.803448', '0.875445', '0.843668', '0.828423', '0.839965', '0.833189', '0.831727']
         : correct/total = [(981, 1140), (997, 1158), (917, 1127), (978, 1158), (954, 1134), (976, 1145), (1005, 1145), (946, 1127), (952, 1136), (947, 1128), (977, 1144), (943, 1125), (945, 1152), (932, 1160), (984, 1124), (966, 1145), (956, 1154), (950, 1131), (964, 1157), (949, 1141)]
         : compromised: 0.8375, honest: 0.8437
Round 004: test acc mean=0.8781 ± 0.0099 | min=0.8515 max=0.8916
         : test loss mean=0.2878 ± 0.0167
         : individual accs = ['0.880702', '0.883420', '0.874002', '0.887737', '0.870370', '0.877729', '0.872489', '0.888199', '0.889965', '0.881206', '0.891608', '0.889778', '0.875000', '0.881897', '0.870107', '0.851528', '0.882149', '0.870027', '0.861711', '0.882559']
         : correct/total = [(1004, 1140), (1023, 1158), (985, 1127), (1028, 1158), (987, 1134), (1005, 1145), (999, 1145), (1001, 1127), (1011, 1136), (994, 1128), (1020, 1144), (1001, 1125), (1008, 1152), (1023, 1160), (978, 1124), (975, 1145), (1018, 1154), (984, 1131), (997, 1157), (1007, 1141)]
         : compromised: 0.8727, honest: 0.8804
Round 005: test acc mean=0.8882 ± 0.0114 | min=0.8488 max=0.9024
         : test loss mean=0.2687 ± 0.0188
         : individual accs = ['0.887719', '0.898964', '0.880213', '0.893782', '0.891534', '0.886463', '0.890830', '0.902396', '0.889965', '0.892730', '0.894231', '0.895111', '0.892361', '0.887069', '0.848754', '0.873362', '0.899480', '0.886826', '0.878997', '0.893953']
         : correct/total = [(1012, 1140), (1041, 1158), (992, 1127), (1035, 1158), (1011, 1134), (1015, 1145), (1020, 1145), (1017, 1127), (1011, 1136), (1007, 1128), (1023, 1144), (1007, 1125), (1028, 1152), (1029, 1160), (954, 1124), (1000, 1145), (1038, 1154), (1003, 1131), (1017, 1157), (1020, 1141)]
         : compromised: 0.8801, honest: 0.8917
Round 006: test acc mean=0.8893 ± 0.0111 | min=0.8646 max=0.9049
         : test loss mean=0.2637 ± 0.0214
         : individual accs = ['0.896491', '0.897237', '0.882875', '0.903282', '0.885362', '0.893450', '0.895197', '0.897072', '0.874120', '0.886525', '0.897727', '0.904889', '0.889757', '0.877586', '0.903025', '0.864629', '0.894281', '0.885942', '0.867761', '0.888694']
         : correct/total = [(1022, 1140), (1039, 1158), (995, 1127), (1046, 1158), (1004, 1134), (1023, 1145), (1025, 1145), (1011, 1127), (993, 1136), (1000, 1128), (1027, 1144), (1018, 1125), (1025, 1152), (1018, 1160), (1015, 1124), (990, 1145), (1032, 1154), (1002, 1131), (1004, 1157), (1014, 1141)]
         : compromised: 0.8863, honest: 0.8906
Round 007: test acc mean=0.8952 ± 0.0094 | min=0.8781 max=0.9102
         : test loss mean=0.2476 ± 0.0158
         : individual accs = ['0.906140', '0.900691', '0.883762', '0.898100', '0.893298', '0.882096', '0.900437', '0.909494', '0.879401', '0.908688', '0.897727', '0.910222', '0.892361', '0.893103', '0.900356', '0.888210', '0.896880', '0.889478', '0.878133', '0.895706']
         : correct/total = [(1033, 1140), (1043, 1158), (996, 1127), (1040, 1158), (1013, 1134), (1010, 1145), (1031, 1145), (1025, 1127), (999, 1136), (1025, 1128), (1027, 1144), (1024, 1125), (1028, 1152), (1036, 1160), (1012, 1124), (1017, 1145), (1035, 1154), (1006, 1131), (1016, 1157), (1022, 1141)]
         : compromised: 0.8893, honest: 0.8978
Round 008: test acc mean=0.9001 ± 0.0088 | min=0.8856 max=0.9148
         : test loss mean=0.2411 ± 0.0142
         : individual accs = ['0.899123', '0.905872', '0.894410', '0.909326', '0.913580', '0.898690', '0.903057', '0.914818', '0.888204', '0.912234', '0.905594', '0.901333', '0.901910', '0.900862', '0.898577', '0.885590', '0.904679', '0.886826', '0.886776', '0.891323']
         : correct/total = [(1025, 1140), (1049, 1158), (1008, 1127), (1053, 1158), (1036, 1134), (1029, 1145), (1034, 1145), (1031, 1127), (1009, 1136), (1029, 1128), (1036, 1144), (1014, 1125), (1039, 1152), (1045, 1160), (1010, 1124), (1014, 1145), (1044, 1154), (1003, 1131), (1026, 1157), (1017, 1141)]
         : compromised: 0.8956, honest: 0.9021
Round 009: test acc mean=0.8988 ± 0.0108 | min=0.8683 max=0.9162
         : test loss mean=0.2430 ± 0.0198
         : individual accs = ['0.905263', '0.898964', '0.885537', '0.916235', '0.907407', '0.903057', '0.904803', '0.909494', '0.893486', '0.902482', '0.905594', '0.901333', '0.899306', '0.901724', '0.888790', '0.886463', '0.909012', '0.868258', '0.886776', '0.902717']
         : correct/total = [(1032, 1140), (1041, 1158), (998, 1127), (1061, 1158), (1029, 1134), (1034, 1145), (1036, 1145), (1025, 1127), (1015, 1136), (1018, 1128), (1036, 1144), (1014, 1125), (1036, 1152), (1046, 1160), (999, 1124), (1015, 1145), (1049, 1154), (982, 1131), (1026, 1157), (1030, 1141)]
         : compromised: 0.8913, honest: 0.9021
Round 010: test acc mean=0.9022 ± 0.0098 | min=0.8721 max=0.9166
         : test loss mean=0.2405 ± 0.0157
         : individual accs = ['0.909649', '0.905872', '0.889973', '0.906736', '0.910935', '0.909170', '0.910917', '0.916593', '0.901408', '0.898050', '0.900350', '0.909333', '0.907118', '0.900862', '0.907473', '0.891703', '0.900347', '0.891247', '0.872083', '0.904470']
         : correct/total = [(1037, 1140), (1049, 1158), (1003, 1127), (1050, 1158), (1033, 1134), (1041, 1145), (1043, 1145), (1033, 1127), (1024, 1136), (1013, 1128), (1030, 1144), (1023, 1125), (1045, 1152), (1045, 1160), (1020, 1124), (1021, 1145), (1039, 1154), (1008, 1131), (1009, 1157), (1032, 1141)]
         : compromised: 0.8980, honest: 0.9040

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: gaussian, 30.0% compromised
Final accuracy - Compromised: 0.8980, Honest: 0.9040
Overall test accuracy: mean=0.9022 ± 0.0098
