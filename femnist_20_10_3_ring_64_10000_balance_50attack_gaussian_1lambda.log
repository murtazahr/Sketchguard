Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Attack: Compromised 10/20 nodes: [1, 2, 5, 11, 12, 13, 14, 15, 17, 18]
Attack type: gaussian, lambda: 1.0
BALANCE algorithm:
  - Model dimension: 6,603,710 parameters
  - Complexity: O(N×d) = O(20×6,603,710)
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.3369 ± 0.1699 | min=0.0039 max=0.4815
         : test loss mean=131539093.7374 ± 265209784.6856
         : individual accs = ['0.347626', '0.447537', '0.342808', '0.435726', '0.456612', '0.431537', '0.451944', '0.466084', '0.402529', '0.382745', '0.444364', '0.481517', '0.018568', '0.009769', '0.004689', '0.455944', '0.003853', '0.475496', '0.344515', '0.334787']
         : correct/total = [(1435, 4128), (1881, 4203), (1399, 4081), (1888, 4333), (1868, 4091), (1850, 4287), (1895, 4193), (2027, 4349), (1687, 4191), (1637, 4277), (1841, 4143), (2019, 4193), (76, 4093), (41, 4197), (19, 4052), (1837, 4029), (16, 4153), (1989, 4183), (1407, 4084), (1382, 4128)]
         : compromised: 0.3012, honest: 0.3726
Round 002: test acc mean=0.5145 ± 0.3121 | min=0.0065 max=0.7521
         : test loss mean=nan ± nan
         : individual accs = ['0.739099', '0.722103', '0.684146', '0.752135', '0.748472', '0.671798', '0.733604', '0.721085', '0.714388', '0.719430', '0.713734', '0.720487', '0.032739', '0.047653', '0.049112', '0.006453', '0.047436', '0.049247', '0.695642', '0.721899']
         : correct/total = [(3051, 4128), (3035, 4203), (2792, 4081), (3259, 4333), (3062, 4091), (2880, 4287), (3076, 4193), (3136, 4349), (2994, 4191), (3077, 4277), (2957, 4143), (3021, 4193), (134, 4093), (200, 4197), (199, 4052), (26, 4029), (197, 4153), (206, 4183), (2841, 4084), (2980, 4128)]
         : compromised: 0.3679, honest: 0.6611
Round 003: test acc mean=0.5590 ± 0.3347 | min=0.0474 max=0.8061
         : test loss mean=nan ± nan
         : individual accs = ['0.794089', '0.790388', '0.782161', '0.806139', '0.791982', '0.668766', '0.791319', '0.788917', '0.778335', '0.783493', '0.772870', '0.776771', '0.047642', '0.047653', '0.049112', '0.054604', '0.047436', '0.049247', '0.778404', '0.780281']
         : correct/total = [(3278, 4128), (3322, 4203), (3192, 4081), (3493, 4333), (3240, 4091), (2867, 4287), (3318, 4193), (3431, 4349), (3262, 4191), (3351, 4277), (3202, 4143), (3257, 4193), (195, 4093), (200, 4197), (199, 4052), (220, 4029), (197, 4153), (206, 4183), (3179, 4084), (3221, 4128)]
         : compromised: 0.4045, honest: 0.7135
Round 004: test acc mean=0.5793 ± 0.3487 | min=0.0327 max=0.8239
         : test loss mean=nan ± nan
         : individual accs = ['0.810804', '0.816798', '0.803235', '0.823910', '0.807382', '0.777700', '0.811829', '0.807312', '0.809831', '0.816226', '0.801834', '0.796804', '0.032739', '0.047653', '0.049112', '0.054604', '0.047436', '0.049247', '0.816601', '0.804021']
         : correct/total = [(3347, 4128), (3433, 4203), (3278, 4081), (3570, 4333), (3303, 4091), (3334, 4287), (3404, 4193), (3511, 4349), (3394, 4191), (3491, 4277), (3322, 4143), (3341, 4193), (134, 4093), (200, 4197), (199, 4052), (220, 4029), (197, 4153), (206, 4183), (3335, 4084), (3319, 4128)]
         : compromised: 0.4244, honest: 0.7341
Round 005: test acc mean=0.5876 ± 0.3542 | min=0.0327 max=0.8350
         : test loss mean=nan ± nan
         : individual accs = ['0.822917', '0.824887', '0.817692', '0.834987', '0.823026', '0.787497', '0.825423', '0.814900', '0.822715', '0.824643', '0.812937', '0.815884', '0.032739', '0.047653', '0.049112', '0.054604', '0.047436', '0.049247', '0.826151', '0.817345']
         : correct/total = [(3397, 4128), (3467, 4203), (3337, 4081), (3618, 4333), (3367, 4091), (3376, 4287), (3461, 4193), (3544, 4349), (3448, 4191), (3527, 4277), (3368, 4143), (3421, 4193), (134, 4093), (200, 4197), (199, 4052), (220, 4029), (197, 4153), (206, 4183), (3374, 4084), (3374, 4128)]
         : compromised: 0.4305, honest: 0.7446
Round 006: test acc mean=0.5947 ± 0.3571 | min=0.0474 max=0.8375
         : test loss mean=nan ± nan
         : individual accs = ['0.825824', '0.831787', '0.832639', '0.837526', '0.826448', '0.811057', '0.832101', '0.834215', '0.833691', '0.827449', '0.814627', '0.829001', '0.047642', '0.047653', '0.049112', '0.054604', '0.047436', '0.049247', '0.833252', '0.828488']
         : correct/total = [(3409, 4128), (3496, 4203), (3398, 4081), (3629, 4333), (3381, 4091), (3477, 4287), (3489, 4193), (3628, 4349), (3494, 4191), (3539, 4277), (3375, 4143), (3476, 4193), (195, 4093), (200, 4197), (199, 4052), (220, 4029), (197, 4153), (206, 4183), (3403, 4084), (3420, 4128)]
         : compromised: 0.4386, honest: 0.7508
Round 007: test acc mean=0.6008 ± 0.3606 | min=0.0474 max=0.8456
         : test loss mean=nan ± nan
         : individual accs = ['0.829457', '0.844873', '0.839745', '0.845604', '0.835248', '0.825986', '0.830909', '0.839273', '0.842997', '0.837737', '0.829592', '0.835202', '0.052040', '0.047653', '0.049112', '0.054604', '0.047436', '0.049247', '0.843291', '0.836967']
         : correct/total = [(3424, 4128), (3551, 4203), (3427, 4081), (3664, 4333), (3417, 4091), (3541, 4287), (3484, 4193), (3650, 4349), (3533, 4191), (3583, 4277), (3437, 4143), (3502, 4193), (213, 4093), (200, 4197), (199, 4052), (220, 4029), (197, 4153), (206, 4183), (3444, 4084), (3455, 4128)]
         : compromised: 0.4442, honest: 0.7575
Round 008: test acc mean=0.6006 ± 0.3614 | min=0.0447 max=0.8488
         : test loss mean=nan ± nan
         : individual accs = ['0.826066', '0.838449', '0.840970', '0.848835', '0.843559', '0.836482', '0.840210', '0.838124', '0.836077', '0.839607', '0.826213', '0.841164', '0.047642', '0.047653', '0.044669', '0.054604', '0.047436', '0.049247', '0.839618', '0.825097']
         : correct/total = [(3410, 4128), (3524, 4203), (3432, 4081), (3678, 4333), (3451, 4091), (3586, 4287), (3523, 4193), (3645, 4349), (3504, 4191), (3591, 4277), (3423, 4143), (3527, 4193), (195, 4093), (200, 4197), (181, 4052), (220, 4029), (197, 4153), (206, 4183), (3429, 4084), (3406, 4128)]
         : compromised: 0.4440, honest: 0.7571
Round 009: test acc mean=0.6060 ± 0.3650 | min=0.0447 max=0.8537
         : test loss mean=nan ± nan
         : individual accs = ['0.840843', '0.847728', '0.835089', '0.853681', '0.841359', '0.842081', '0.847603', '0.851460', '0.853734', '0.848492', '0.838040', '0.839256', '0.047398', '0.047653', '0.044669', '0.054604', '0.047436', '0.049247', '0.848188', '0.841328']
         : correct/total = [(3471, 4128), (3563, 4203), (3408, 4081), (3699, 4333), (3442, 4091), (3610, 4287), (3554, 4193), (3703, 4349), (3578, 4191), (3629, 4277), (3472, 4143), (3519, 4193), (194, 4093), (200, 4197), (181, 4052), (220, 4029), (197, 4153), (206, 4183), (3464, 4084), (3473, 4128)]
         : compromised: 0.4456, honest: 0.7664
Round 010: test acc mean=0.6056 ± 0.3686 | min=0.0068 max=0.8563
         : test loss mean=nan ± nan
         : individual accs = ['0.844234', '0.856293', '0.846606', '0.852296', '0.844048', '0.844647', '0.854042', '0.852610', '0.851348', '0.848258', '0.833695', '0.840687', '0.006841', '0.047653', '0.050592', '0.054604', '0.047436', '0.049247', '0.848188', '0.838663']
         : correct/total = [(3485, 4128), (3599, 4203), (3455, 4081), (3693, 4333), (3453, 4091), (3621, 4287), (3581, 4193), (3708, 4349), (3568, 4191), (3628, 4277), (3454, 4143), (3525, 4193), (28, 4093), (200, 4197), (205, 4052), (220, 4029), (197, 4153), (206, 4183), (3464, 4084), (3462, 4128)]
         : compromised: 0.4445, honest: 0.7667

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: ring, Aggregation: balance
Attack: gaussian, 50.0% compromised
Final accuracy - Compromised: 0.4445, Honest: 0.7667
Overall test accuracy: mean=0.6056 ± 0.3686

=== BALANCE SUMMARY ===
Node 0: acceptance=0.500
Node 1: acceptance=0.500
Node 2: acceptance=0.500
Node 3: acceptance=0.500
Node 4: acceptance=0.500
Node 5: acceptance=0.850
Node 6: acceptance=0.500
Node 7: acceptance=1.000
Node 8: acceptance=1.000
Node 9: acceptance=1.000
Node 10: acceptance=0.500
Node 11: acceptance=0.500
Node 12: acceptance=0.900
Node 13: acceptance=0.000
Node 14: acceptance=0.500
Node 15: acceptance=0.050
Node 16: acceptance=0.000
Node 17: acceptance=0.050
Node 18: acceptance=0.500
Node 19: acceptance=0.500

Performance Summary:
  - Distance computation time: 0.283s (29.5%)
  - Filtering time: 0.404s (42.1%)
  - Aggregation time: 0.272s (28.4%)
  - Total time: 0.960s
  - Mean acceptance rate: 0.518

BALANCE Algorithm Properties:
  - Model dimension: 6,603,710
  - No compression: Full parameter comparison
  - Theoretical complexity: O(deg(i)×d)
  - Approach: Full parameter filtering + averaging
