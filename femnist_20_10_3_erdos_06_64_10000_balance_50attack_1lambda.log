Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Attack: Compromised 10/20 nodes: [1, 2, 5, 11, 12, 13, 14, 15, 17, 18]
Attack type: directed_deviation, lambda: 1.0
BALANCE algorithm:
  - Model dimension: 6,603,710 parameters
  - Complexity: O(N×d) = O(20×6,603,710)
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.4840 ± 0.0397 | min=0.4193 max=0.5533
         : test loss mean=3.7502 ± 0.0277
         : individual accs = ['0.542636', '0.471092', '0.497672', '0.492730', '0.435101', '0.553301', '0.435965', '0.498046', '0.510379', '0.429273', '0.419261', '0.533747', '0.446860', '0.472719', '0.497532', '0.520477', '0.453889', '0.530481', '0.493144', '0.445494']
         : correct/total = [(2240, 4128), (1980, 4203), (2031, 4081), (2135, 4333), (1780, 4091), (2372, 4287), (1828, 4193), (2166, 4349), (2139, 4191), (1836, 4277), (1737, 4143), (2238, 4193), (1829, 4093), (1984, 4197), (2016, 4052), (2097, 4029), (1885, 4153), (2219, 4183), (2014, 4084), (1839, 4128)]
         : compromised: 0.5017, honest: 0.4663
Round 002: test acc mean=0.6728 ± 0.0218 | min=0.6239 max=0.7066
         : test loss mean=3.3298 ± 0.1161
         : individual accs = ['0.687500', '0.667618', '0.644205', '0.705516', '0.675141', '0.706555', '0.623897', '0.678777', '0.663326', '0.700257', '0.671253', '0.691152', '0.686538', '0.659280', '0.688549', '0.665426', '0.640019', '0.644514', '0.678991', '0.677568']
         : correct/total = [(2838, 4128), (2806, 4203), (2629, 4081), (3057, 4333), (2762, 4091), (3029, 4287), (2616, 4193), (2952, 4349), (2780, 4191), (2995, 4277), (2781, 4143), (2898, 4193), (2810, 4093), (2767, 4197), (2790, 4052), (2681, 4029), (2658, 4153), (2696, 4183), (2773, 4084), (2797, 4128)]
         : compromised: 0.6733, honest: 0.6723
Round 003: test acc mean=0.6798 ± 0.0342 | min=0.5893 max=0.7452
         : test loss mean=2.8485 ± 0.2457
         : individual accs = ['0.715359', '0.682132', '0.589316', '0.745211', '0.682474', '0.642174', '0.718340', '0.710508', '0.708423', '0.694412', '0.688631', '0.665633', '0.678720', '0.670955', '0.693485', '0.637627', '0.693715', '0.639732', '0.654995', '0.684109']
         : correct/total = [(2953, 4128), (2867, 4203), (2405, 4081), (3229, 4333), (2792, 4091), (2753, 4287), (3012, 4193), (3090, 4349), (2969, 4191), (2970, 4277), (2853, 4143), (2791, 4193), (2778, 4093), (2816, 4197), (2810, 4052), (2569, 4029), (2881, 4153), (2676, 4183), (2675, 4084), (2824, 4128)]
         : compromised: 0.6555, honest: 0.7041
Round 004: test acc mean=0.6812 ± 0.0393 | min=0.6086 max=0.7394
         : test loss mean=2.0633 ± 0.2736
         : individual accs = ['0.708818', '0.665953', '0.617006', '0.739441', '0.734295', '0.620714', '0.726687', '0.716027', '0.735624', '0.710077', '0.676563', '0.638922', '0.608600', '0.669526', '0.672014', '0.687764', '0.698050', '0.671767', '0.649119', '0.676599']
         : correct/total = [(2926, 4128), (2799, 4203), (2518, 4081), (3204, 4333), (3004, 4091), (2661, 4287), (3047, 4193), (3114, 4349), (3083, 4191), (3037, 4277), (2803, 4143), (2679, 4193), (2491, 4093), (2810, 4197), (2723, 4052), (2771, 4029), (2899, 4153), (2810, 4183), (2651, 4084), (2793, 4128)]
         : compromised: 0.6501, honest: 0.7122
Round 005: test acc mean=0.7330 ± 0.0253 | min=0.6795 max=0.7717
         : test loss mean=1.2659 ± 0.1599
         : individual accs = ['0.746609', '0.679515', '0.742710', '0.756058', '0.742361', '0.732214', '0.745528', '0.754426', '0.769745', '0.765256', '0.740043', '0.699022', '0.710726', '0.703598', '0.704590', '0.715066', '0.771731', '0.710734', '0.721596', '0.747578']
         : correct/total = [(3082, 4128), (2856, 4203), (3031, 4081), (3276, 4333), (3037, 4091), (3139, 4287), (3126, 4193), (3281, 4349), (3226, 4191), (3273, 4277), (3066, 4143), (2931, 4193), (2909, 4093), (2953, 4197), (2855, 4052), (2881, 4029), (3205, 4153), (2973, 4183), (2947, 4084), (3086, 4128)]
         : compromised: 0.7120, honest: 0.7539
Round 006: test acc mean=0.7966 ± 0.0085 | min=0.7828 max=0.8119
         : test loss mean=0.7458 ± 0.0382
         : individual accs = ['0.784157', '0.785391', '0.799314', '0.803139', '0.786605', '0.800327', '0.800859', '0.811911', '0.805297', '0.807575', '0.797007', '0.790842', '0.782800', '0.797236', '0.802073', '0.796724', '0.809535', '0.791298', '0.787708', '0.791424']
         : correct/total = [(3237, 4128), (3301, 4203), (3262, 4081), (3480, 4333), (3218, 4091), (3431, 4287), (3358, 4193), (3531, 4349), (3375, 4191), (3454, 4277), (3302, 4143), (3316, 4193), (3204, 4093), (3346, 4197), (3250, 4052), (3210, 4029), (3362, 4153), (3310, 4183), (3217, 4084), (3267, 4128)]
         : compromised: 0.7934, honest: 0.7998
Round 007: test acc mean=0.8226 ± 0.0047 | min=0.8147 max=0.8310
         : test loss mean=0.5765 ± 0.0212
         : individual accs = ['0.816376', '0.825839', '0.818917', '0.826448', '0.814715', '0.819687', '0.826377', '0.830996', '0.827487', '0.825579', '0.816317', '0.823992', '0.816272', '0.824875', '0.827986', '0.823033', '0.827835', '0.819268', '0.822723', '0.817103']
         : correct/total = [(3370, 4128), (3471, 4203), (3342, 4081), (3581, 4333), (3333, 4091), (3514, 4287), (3465, 4193), (3614, 4349), (3468, 4191), (3531, 4277), (3382, 4143), (3455, 4193), (3341, 4093), (3462, 4197), (3355, 4052), (3316, 4029), (3438, 4153), (3427, 4183), (3360, 4084), (3373, 4128)]
         : compromised: 0.8223, honest: 0.8229
Round 008: test acc mean=0.8289 ± 0.0068 | min=0.8096 max=0.8408
         : test loss mean=0.5261 ± 0.0206
         : individual accs = ['0.823159', '0.830121', '0.825288', '0.832218', '0.823026', '0.836716', '0.834725', '0.835135', '0.830112', '0.834697', '0.819213', '0.833771', '0.823357', '0.829164', '0.840819', '0.829238', '0.827595', '0.829548', '0.830803', '0.809593']
         : correct/total = [(3398, 4128), (3489, 4203), (3368, 4081), (3606, 4333), (3367, 4091), (3587, 4287), (3500, 4193), (3632, 4349), (3479, 4191), (3570, 4277), (3394, 4143), (3496, 4193), (3370, 4093), (3480, 4197), (3407, 4052), (3341, 4029), (3437, 4153), (3470, 4183), (3393, 4084), (3342, 4128)]
         : compromised: 0.8309, honest: 0.8269
Round 009: test acc mean=0.8408 ± 0.0051 | min=0.8323 max=0.8490
         : test loss mean=0.4886 ± 0.0173
         : individual accs = ['0.834060', '0.845586', '0.840480', '0.844219', '0.832315', '0.845113', '0.845218', '0.848011', '0.848962', '0.845219', '0.834420', '0.840210', '0.839238', '0.836550', '0.846742', '0.843882', '0.835059', '0.836959', '0.839128', '0.835271']
         : correct/total = [(3443, 4128), (3554, 4203), (3430, 4081), (3658, 4333), (3405, 4091), (3623, 4287), (3544, 4193), (3688, 4349), (3558, 4191), (3615, 4277), (3457, 4143), (3523, 4193), (3435, 4093), (3511, 4197), (3431, 4052), (3400, 4029), (3468, 4153), (3501, 4183), (3427, 4084), (3448, 4128)]
         : compromised: 0.8414, honest: 0.8403
Round 010: test acc mean=0.8463 ± 0.0051 | min=0.8359 max=0.8558
         : test loss mean=0.4698 ± 0.0192
         : individual accs = ['0.838178', '0.855817', '0.842686', '0.849065', '0.838181', '0.845113', '0.849034', '0.850770', '0.851110', '0.848960', '0.835868', '0.842833', '0.843880', '0.850846', '0.849210', '0.849839', '0.845654', '0.850347', '0.848188', '0.841328']
         : correct/total = [(3460, 4128), (3597, 4203), (3439, 4081), (3679, 4333), (3429, 4091), (3623, 4287), (3560, 4193), (3700, 4349), (3567, 4191), (3631, 4277), (3463, 4143), (3534, 4193), (3454, 4093), (3571, 4197), (3441, 4052), (3424, 4029), (3512, 4153), (3557, 4183), (3464, 4084), (3473, 4128)]
         : compromised: 0.8479, honest: 0.8448

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: balance
Attack: directed_deviation, 50.0% compromised
Final accuracy - Compromised: 0.8479, Honest: 0.8448
Overall test accuracy: mean=0.8463 ± 0.0051

=== BALANCE SUMMARY ===
Node 0: acceptance=0.500
Node 1: acceptance=0.545
Node 2: acceptance=0.417
Node 3: acceptance=0.625
Node 4: acceptance=0.455
Node 5: acceptance=0.467
Node 6: acceptance=0.429
Node 7: acceptance=0.429
Node 8: acceptance=0.400
Node 9: acceptance=0.538
Node 10: acceptance=0.556
Node 11: acceptance=0.500
Node 12: acceptance=0.583
Node 13: acceptance=0.538
Node 14: acceptance=0.467
Node 15: acceptance=0.455
Node 16: acceptance=0.385
Node 17: acceptance=0.667
Node 18: acceptance=0.562
Node 19: acceptance=0.438

Performance Summary:
  - Distance computation time: 1.052s (44.8%)
  - Filtering time: 1.143s (48.7%)
  - Aggregation time: 0.153s (6.5%)
  - Total time: 2.348s
  - Mean acceptance rate: 0.498

BALANCE Algorithm Properties:
  - Model dimension: 6,603,710
  - No compression: Full parameter comparison
  - Theoretical complexity: O(deg(i)×d)
  - Approach: Full parameter filtering + averaging
