Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 99
Degree statistics: avg=9.90, min=7, max=14
Attack: Compromised 12/20 nodes: [1, 2, 3, 5, 8, 11, 12, 13, 14, 15, 17, 18]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0176 ± 0.0147 | min=0.0019 max=0.0480
         : test loss mean=43787.0107 ± 31223.0560
         : individual accs = ['0.008236', '0.042589', '0.008086', '0.040157', '0.005378', '0.004899', '0.008586', '0.025063', '0.005727', '0.007248', '0.009896', '0.045075', '0.027119', '0.010007', '0.005676', '0.014396', '0.020949', '0.001913', '0.012488', '0.047965']
         : correct/total = [(34, 4128), (179, 4203), (33, 4081), (174, 4333), (22, 4091), (21, 4287), (36, 4193), (109, 4349), (24, 4191), (31, 4277), (41, 4143), (189, 4193), (111, 4093), (42, 4197), (23, 4052), (58, 4029), (87, 4153), (8, 4183), (51, 4084), (198, 4128)]
         : compromised: 0.0182, honest: 0.0167
Round 002: test acc mean=0.0487 ± 0.0020 | min=0.0448 max=0.0534
         : test loss mean=104634504.7162 ± 304057019.2241
         : individual accs = ['0.048934', '0.050202', '0.053418', '0.044773', '0.047421', '0.048752', '0.048891', '0.045528', '0.049630', '0.047229', '0.047309', '0.049606', '0.048620', '0.049083', '0.047878', '0.050385', '0.051047', '0.046139', '0.048482', '0.050872']
         : correct/total = [(202, 4128), (211, 4203), (218, 4081), (194, 4333), (194, 4091), (209, 4287), (205, 4193), (198, 4349), (208, 4191), (202, 4277), (196, 4143), (208, 4193), (199, 4093), (206, 4197), (194, 4052), (203, 4029), (212, 4153), (193, 4183), (198, 4084), (210, 4128)]
         : compromised: 0.0489, honest: 0.0484
Round 003: test acc mean=0.0470 ± 0.0023 | min=0.0438 max=0.0539
         : test loss mean=13433.2239 ± 12428.6982
         : individual accs = ['0.047238', '0.048775', '0.045087', '0.044773', '0.047421', '0.048752', '0.048891', '0.045528', '0.044619', '0.047697', '0.047309', '0.045314', '0.049597', '0.045747', '0.046397', '0.053860', '0.044546', '0.045900', '0.048482', '0.043847']
         : correct/total = [(195, 4128), (205, 4203), (184, 4081), (194, 4333), (194, 4091), (209, 4287), (205, 4193), (198, 4349), (187, 4191), (204, 4277), (196, 4143), (190, 4193), (203, 4093), (192, 4197), (188, 4052), (217, 4029), (185, 4153), (192, 4183), (198, 4084), (181, 4128)]
         : compromised: 0.0473, honest: 0.0466
Round 004: test acc mean=0.0450 ± 0.0065 | min=0.0271 max=0.0516
         : test loss mean=2645.3090 ± 4691.5780
         : individual accs = ['0.027132', '0.051630', '0.045087', '0.033003', '0.047421', '0.048752', '0.048891', '0.045528', '0.044619', '0.047697', '0.047309', '0.045314', '0.049597', '0.045747', '0.045656', '0.050881', '0.030821', '0.045900', '0.050196', '0.048692']
         : correct/total = [(112, 4128), (217, 4203), (184, 4081), (143, 4333), (194, 4091), (209, 4287), (205, 4193), (198, 4349), (187, 4191), (204, 4277), (196, 4143), (190, 4193), (203, 4093), (192, 4197), (185, 4052), (205, 4029), (128, 4153), (192, 4183), (205, 4084), (201, 4128)]
         : compromised: 0.0464, honest: 0.0429
Round 005: test acc mean=0.0501 ± 0.0037 | min=0.0432 max=0.0560
         : test loss mean=955.6979 ± 2257.2785
         : individual accs = ['0.051599', '0.050202', '0.053418', '0.043157', '0.047421', '0.045253', '0.050799', '0.045528', '0.044619', '0.053776', '0.055998', '0.049606', '0.054239', '0.049083', '0.051826', '0.051626', '0.044546', '0.050920', '0.052889', '0.054506']
         : correct/total = [(213, 4128), (211, 4203), (218, 4081), (187, 4333), (194, 4091), (194, 4287), (213, 4193), (198, 4349), (187, 4191), (230, 4277), (232, 4143), (208, 4193), (222, 4093), (206, 4197), (210, 4052), (208, 4029), (185, 4153), (213, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0497, honest: 0.0505
Round 006: test acc mean=0.0510 ± 0.0053 | min=0.0414 max=0.0596
         : test loss mean=4.7538 ± 2.2281
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.048891', '0.041389', '0.044619', '0.053776', '0.055998', '0.045314', '0.058637', '0.045747', '0.046397', '0.056590', '0.044546', '0.050920', '0.048482', '0.048692']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (205, 4193), (180, 4349), (187, 4191), (230, 4277), (232, 4143), (190, 4193), (240, 4093), (192, 4197), (188, 4052), (228, 4029), (185, 4153), (213, 4183), (198, 4084), (201, 4128)]
         : compromised: 0.0508, honest: 0.0514
Round 007: test acc mean=0.0501 ± 0.0108 | min=0.0188 max=0.0596
         : test loss mean=4.0447 ± 0.1892
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.050799', '0.045068', '0.020043', '0.053776', '0.055998', '0.018841', '0.058637', '0.049083', '0.051826', '0.056590', '0.052011', '0.050920', '0.052889', '0.054506']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (213, 4193), (196, 4349), (84, 4191), (230, 4277), (232, 4143), (79, 4193), (240, 4093), (206, 4197), (210, 4052), (228, 4029), (216, 4153), (213, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0477, honest: 0.0537
Round 008: test acc mean=0.0532 ± 0.0055 | min=0.0445 max=0.0624
         : test loss mean=4.6451 ± 2.3607
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.048891', '0.045528', '0.044619', '0.053776', '0.055998', '0.045314', '0.058637', '0.062426', '0.061204', '0.056590', '0.044546', '0.050920', '0.055583', '0.048692']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (205, 4193), (198, 4349), (187, 4191), (230, 4277), (232, 4143), (190, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (185, 4153), (213, 4183), (227, 4084), (201, 4128)]
         : compromised: 0.0541, honest: 0.0519
Round 009: test acc mean=0.0524 ± 0.0041 | min=0.0430 max=0.0596
         : test loss mean=4.0108 ± 0.2220
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.043021', '0.050618', '0.050799', '0.045068', '0.049630', '0.053776', '0.055998', '0.049606', '0.058637', '0.049083', '0.051826', '0.056590', '0.052011', '0.050920', '0.052889', '0.054506']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (176, 4091), (217, 4287), (213, 4193), (196, 4349), (208, 4191), (230, 4277), (232, 4143), (208, 4193), (240, 4093), (206, 4197), (210, 4052), (228, 4029), (216, 4153), (213, 4183), (216, 4084), (225, 4128)]
         : compromised: 0.0527, honest: 0.0518
Round 010: test acc mean=0.0536 ± 0.0055 | min=0.0445 max=0.0624
         : test loss mean=4.5662 ± 2.3236
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.045528', '0.044619', '0.053776', '0.055998', '0.045314', '0.058637', '0.062426', '0.061204', '0.056590', '0.044546', '0.050920', '0.055583', '0.048692']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (198, 4349), (187, 4191), (230, 4277), (232, 4143), (190, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (185, 4153), (213, 4183), (227, 4084), (201, 4128)]
         : compromised: 0.0541, honest: 0.0529

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: directed_deviation, 60.0% compromised
Final accuracy - Compromised: 0.0541, Honest: 0.0529
Overall test accuracy: mean=0.0536 ± 0.0055
