Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Projects/Sketchguard/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 8/20 nodes: [1, 5, 11, 12, 13, 14, 17, 18]
Attack type: backdoor, lambda: 1.0
Backdoor target label: 0, trigger size: 8
Model variant: baseline
Model parameters: 2,219,692
BALANCE algorithm:
Balance Config: BALANCEConfig(gamma=2, kappa=1, alpha=0.5, min_neighbors=1)
  - Model dimension: 2,219,692 parameters
  - Complexity: O(N×d) = O(20×2,219,692)
Initial test acc across nodes: mean=0.4978 ± 0.0208
Backdoor attack: Created poisoned datasets for 8 compromised nodes
Round 001: test acc mean=0.6078 ± 0.0840 | min=0.5069 max=0.7362
         : test loss mean=1602.5712 ± 1997.8057
         : individual accs = ['0.702632', '0.508636', '0.594499', '0.708981', '0.602293', '0.514410', '0.702183', '0.631766', '0.627641', '0.713652', '0.644231', '0.520889', '0.522569', '0.506897', '0.517794', '0.736245', '0.715771', '0.508400', '0.522040', '0.653812']
         : correct/total = [(801, 1140), (589, 1158), (670, 1127), (821, 1158), (683, 1134), (589, 1145), (804, 1145), (712, 1127), (713, 1136), (805, 1128), (737, 1144), (586, 1125), (602, 1152), (588, 1160), (582, 1124), (843, 1145), (826, 1154), (575, 1131), (604, 1157), (746, 1141)]
         : compromised: 0.5152, honest: 0.6695
Round 002: test acc mean=0.5953 ± 0.0863 | min=0.4774 max=0.6900
         : test loss mean=8866249.2367 ± 15206669.2976
         : individual accs = ['0.646491', '0.507772', '0.667258', '0.670121', '0.543210', '0.485590', '0.646288', '0.677019', '0.676937', '0.658688', '0.688811', '0.521778', '0.477431', '0.492241', '0.517794', '0.689956', '0.683709', '0.491600', '0.479689', '0.682734']
         : correct/total = [(737, 1140), (588, 1158), (752, 1127), (776, 1158), (616, 1134), (556, 1145), (740, 1145), (763, 1127), (769, 1136), (743, 1128), (788, 1144), (587, 1125), (550, 1152), (571, 1160), (582, 1124), (790, 1145), (789, 1154), (556, 1131), (555, 1157), (779, 1141)]
         : compromised: 0.4967, honest: 0.6609
Round 003: test acc mean=0.6184 ± 0.0896 | min=0.4987 max=0.7237
         : test loss mean=nan ± nan
         : individual accs = ['0.632456', '0.508636', '0.700976', '0.723661', '0.633157', '0.514410', '0.675983', '0.673469', '0.709507', '0.696809', '0.715909', '0.498667', '0.522569', '0.506897', '0.517794', '0.697817', '0.720104', '0.508400', '0.522040', '0.687993']
         : correct/total = [(721, 1140), (589, 1158), (790, 1127), (838, 1158), (718, 1134), (589, 1145), (774, 1145), (759, 1127), (806, 1136), (786, 1128), (819, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (799, 1145), (831, 1154), (575, 1131), (604, 1157), (785, 1141)]
         : compromised: 0.5124, honest: 0.6890
Round 004: test acc mean=0.6462 ± 0.1104 | min=0.4987 max=0.7684
         : test loss mean=nan ± nan
         : individual accs = ['0.711404', '0.508636', '0.737356', '0.753886', '0.709877', '0.514410', '0.741485', '0.718722', '0.745599', '0.731383', '0.768357', '0.498667', '0.522569', '0.506897', '0.517794', '0.745852', '0.757366', '0.508400', '0.522040', '0.703769']
         : correct/total = [(811, 1140), (589, 1158), (831, 1127), (873, 1158), (805, 1134), (589, 1145), (849, 1145), (810, 1127), (847, 1136), (825, 1128), (879, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (854, 1145), (874, 1154), (575, 1131), (604, 1157), (803, 1141)]
         : compromised: 0.5124, honest: 0.7354
Round 005: test acc mean=0.6671 ± 0.1273 | min=0.4987 max=0.7972
         : test loss mean=nan ± nan
         : individual accs = ['0.771053', '0.508636', '0.739130', '0.774611', '0.776014', '0.514410', '0.785153', '0.753327', '0.775528', '0.793440', '0.797203', '0.498667', '0.522569', '0.506897', '0.517794', '0.771179', '0.778163', '0.508400', '0.522040', '0.727432']
         : correct/total = [(879, 1140), (589, 1158), (833, 1127), (897, 1158), (880, 1134), (589, 1145), (899, 1145), (849, 1127), (881, 1136), (895, 1128), (912, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (883, 1145), (898, 1154), (575, 1131), (604, 1157), (830, 1141)]
         : compromised: 0.5124, honest: 0.7702
Round 006: test acc mean=0.6928 ± 0.1477 | min=0.4987 max=0.8444
         : test loss mean=nan ± nan
         : individual accs = ['0.799123', '0.508636', '0.823425', '0.816926', '0.802469', '0.514410', '0.806114', '0.797693', '0.816021', '0.831560', '0.844406', '0.498667', '0.522569', '0.506897', '0.517794', '0.800873', '0.800693', '0.508400', '0.522040', '0.816827']
         : correct/total = [(911, 1140), (589, 1158), (928, 1127), (946, 1158), (910, 1134), (589, 1145), (923, 1145), (899, 1127), (927, 1136), (938, 1128), (966, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (917, 1145), (924, 1154), (575, 1131), (604, 1157), (932, 1141)]
         : compromised: 0.5124, honest: 0.8130
Round 007: test acc mean=0.7149 ± 0.1656 | min=0.4987 max=0.8706
         : test loss mean=nan ± nan
         : individual accs = ['0.842105', '0.508636', '0.844720', '0.847150', '0.838624', '0.514410', '0.855022', '0.838509', '0.854754', '0.864362', '0.870629', '0.498667', '0.522569', '0.506897', '0.517794', '0.827948', '0.855286', '0.508400', '0.522040', '0.858896']
         : correct/total = [(960, 1140), (589, 1158), (952, 1127), (981, 1158), (951, 1134), (589, 1145), (979, 1145), (945, 1127), (971, 1136), (975, 1128), (996, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (948, 1145), (987, 1154), (575, 1131), (604, 1157), (980, 1141)]
         : compromised: 0.5124, honest: 0.8498
Round 008: test acc mean=0.7231 ± 0.1722 | min=0.4987 max=0.8741
         : test loss mean=nan ± nan
         : individual accs = ['0.857018', '0.508636', '0.870453', '0.856649', '0.854497', '0.514410', '0.862882', '0.865129', '0.862676', '0.874113', '0.869755', '0.498667', '0.522569', '0.506897', '0.517794', '0.855022', '0.872617', '0.508400', '0.522040', '0.862401']
         : correct/total = [(977, 1140), (589, 1158), (981, 1127), (992, 1158), (969, 1134), (589, 1145), (988, 1145), (975, 1127), (980, 1136), (986, 1128), (995, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (979, 1145), (1007, 1154), (575, 1131), (604, 1157), (984, 1141)]
         : compromised: 0.5124, honest: 0.8636
Round 009: test acc mean=0.7329 ± 0.1802 | min=0.4987 max=0.8916
         : test loss mean=nan ± nan
         : individual accs = ['0.876316', '0.508636', '0.868678', '0.887737', '0.870370', '0.514410', '0.889956', '0.883762', '0.881162', '0.890957', '0.891608', '0.498667', '0.522569', '0.506897', '0.517794', '0.863755', '0.876083', '0.508400', '0.522040', '0.879053']
         : correct/total = [(999, 1140), (589, 1158), (979, 1127), (1028, 1158), (987, 1134), (589, 1145), (1019, 1145), (996, 1127), (1001, 1136), (1005, 1128), (1020, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (989, 1145), (1011, 1154), (575, 1131), (604, 1157), (1003, 1141)]
         : compromised: 0.5124, honest: 0.8800
Round 010: test acc mean=0.7369 ± 0.1834 | min=0.4987 max=0.9007
         : test loss mean=nan ± nan
         : individual accs = ['0.879825', '0.508636', '0.878438', '0.891192', '0.880071', '0.514410', '0.889083', '0.891748', '0.890845', '0.900709', '0.890734', '0.498667', '0.522569', '0.506897', '0.517794', '0.871616', '0.888215', '0.508400', '0.522040', '0.885188']
         : correct/total = [(1003, 1140), (589, 1158), (990, 1127), (1032, 1158), (998, 1134), (589, 1145), (1018, 1145), (1005, 1127), (1012, 1136), (1016, 1128), (1019, 1144), (561, 1125), (602, 1152), (588, 1160), (582, 1124), (998, 1145), (1025, 1154), (575, 1131), (604, 1157), (1010, 1141)]
         : compromised: 0.5124, honest: 0.8865

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: erdos, Aggregation: balance
Attack: backdoor, 40.0% compromised
Final accuracy - Compromised: 0.5124, Honest: 0.8865
Overall test accuracy: mean=0.7369 ± 0.1834

=== BACKDOOR ATTACK SUCCESS RATE (ASR) ===
Target label: 0
Trigger size: 8x8
Overall ASR: 0.7297 ± 0.2209
Honest nodes ASR: 0.5495 ± 0.0121
Compromised nodes ASR: 1.0000 ± 0.0000
Note: Higher ASR indicates more successful backdoor attack

=== BALANCE SUMMARY ===
Node 0: acceptance=0.562
Node 1: acceptance=0.173
Node 2: acceptance=0.500
Node 3: acceptance=0.625
Node 4: acceptance=0.545
Node 5: acceptance=0.153
Node 6: acceptance=0.500
Node 7: acceptance=0.500
Node 8: acceptance=0.500
Node 9: acceptance=0.692
Node 10: acceptance=0.556
Node 11: acceptance=0.157
Node 12: acceptance=0.167
Node 13: acceptance=0.169
Node 14: acceptance=0.260
Node 15: acceptance=0.545
Node 16: acceptance=0.538
Node 17: acceptance=0.167
Node 18: acceptance=0.169
Node 19: acceptance=0.500

=== PARALLEL EXECUTION TIME (realistic for distributed system) ===
  COMMUNICATION (max across nodes):
    - Full model transfer: 0.000s (0.0%)
  COMPUTATION (max across nodes):
    - Filtering: 0.046s (75.8%)
    - Aggregation: 0.015s (24.2%)
  TOTALS:
    - Total computation: 0.060s (100.0%)
    - Total communication: 0.000s (0.0%)
    - Total parallel time: 0.060s

=== PER-NODE AVERAGE TIME ===
  - Filtering: 0.034s
  - Aggregation: 0.005s
  - Model transfer: 0.000s
  - Total per node: 0.039s

=== TOTAL COMPUTATIONAL WORK (sum across all nodes) ===
  - Total filtering: 0.673s
  - Total aggregation: 0.097s
  - Total model transfer: 0.000s
  - Grand total: 0.770s
  - Mean acceptance rate: 0.399

BALANCE Algorithm Properties:
  - Model dimension: 2,219,692
  - No compression: Full parameter comparison
  - Theoretical complexity: O(deg(i)×d)
  - Approach: Full parameter filtering + averaging
