Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5571 ± 0.0185 | min=0.5194 max=0.5874
         : test loss mean=1.6410 ± 0.0775
         : individual accs = ['0.553779', '0.555556', '0.576329', '0.573506', '0.565143', '0.573361', '0.552111', '0.556450', '0.586018', '0.541501', '0.519430', '0.535416', '0.549230', '0.539909', '0.552073', '0.582278', '0.552613', '0.561798', '0.587414', '0.527616']
         : correct/total = [(2286, 4128), (2335, 4203), (2352, 4081), (2485, 4333), (2312, 4091), (2458, 4287), (2315, 4193), (2420, 4349), (2456, 4191), (2316, 4277), (2152, 4143), (2245, 4193), (2248, 4093), (2266, 4197), (2237, 4052), (2346, 4029), (2295, 4153), (2350, 4183), (2399, 4084), (2178, 4128)]
Round 002: test acc mean=0.7386 ± 0.0150 | min=0.6890 max=0.7563
         : test loss mean=0.8587 ± 0.0446
         : individual accs = ['0.712694', '0.741137', '0.742955', '0.737134', '0.756294', '0.755307', '0.737896', '0.734882', '0.731806', '0.737667', '0.741492', '0.754352', '0.742976', '0.745771', '0.750740', '0.736163', '0.733446', '0.737509', '0.752449', '0.688953']
         : correct/total = [(2942, 4128), (3115, 4203), (3032, 4081), (3194, 4333), (3094, 4091), (3238, 4287), (3094, 4193), (3196, 4349), (3067, 4191), (3155, 4277), (3072, 4143), (3163, 4193), (3041, 4093), (3130, 4197), (3042, 4052), (2966, 4029), (3046, 4153), (3085, 4183), (3073, 4084), (2844, 4128)]
Round 003: test acc mean=0.7840 ± 0.0106 | min=0.7512 max=0.7982
         : test loss mean=0.6879 ± 0.0291
         : individual accs = ['0.773014', '0.795622', '0.786327', '0.792753', '0.791982', '0.783065', '0.790842', '0.787767', '0.786447', '0.780220', '0.779628', '0.789649', '0.794283', '0.789850', '0.771224', '0.798213', '0.777029', '0.784126', '0.751224', '0.775921']
         : correct/total = [(3191, 4128), (3344, 4203), (3209, 4081), (3435, 4333), (3240, 4091), (3357, 4287), (3316, 4193), (3426, 4349), (3296, 4191), (3337, 4277), (3230, 4143), (3311, 4193), (3251, 4093), (3315, 4197), (3125, 4052), (3216, 4029), (3227, 4153), (3280, 4183), (3068, 4084), (3203, 4128)]
Round 004: test acc mean=0.8085 ± 0.0078 | min=0.7925 max=0.8244
         : test loss mean=0.6074 ± 0.0247
         : individual accs = ['0.800145', '0.815132', '0.796373', '0.807062', '0.792471', '0.811756', '0.812068', '0.812141', '0.817227', '0.807575', '0.798214', '0.797758', '0.813340', '0.824398', '0.811451', '0.814346', '0.813629', '0.809706', '0.809256', '0.806686']
         : correct/total = [(3303, 4128), (3426, 4203), (3250, 4081), (3497, 4333), (3242, 4091), (3480, 4287), (3405, 4193), (3532, 4349), (3425, 4191), (3454, 4277), (3307, 4143), (3345, 4193), (3329, 4093), (3460, 4197), (3288, 4052), (3281, 4029), (3379, 4153), (3387, 4183), (3305, 4084), (3330, 4128)]
Round 005: test acc mean=0.8160 ± 0.0060 | min=0.8018 max=0.8284
         : test loss mean=0.5695 ± 0.0217
         : individual accs = ['0.810804', '0.813704', '0.814016', '0.813293', '0.821071', '0.821087', '0.811352', '0.822258', '0.827010', '0.828384', '0.811007', '0.801813', '0.814073', '0.814629', '0.811945', '0.815091', '0.815314', '0.822376', '0.813908', '0.816618']
         : correct/total = [(3347, 4128), (3420, 4203), (3322, 4081), (3524, 4333), (3359, 4091), (3520, 4287), (3402, 4193), (3576, 4349), (3466, 4191), (3543, 4277), (3360, 4143), (3362, 4193), (3332, 4093), (3419, 4197), (3290, 4052), (3284, 4029), (3386, 4153), (3440, 4183), (3324, 4084), (3371, 4128)]
Round 006: test acc mean=0.8232 ± 0.0069 | min=0.8098 max=0.8352
         : test loss mean=0.5433 ± 0.0191
         : individual accs = ['0.809835', '0.822984', '0.825778', '0.820217', '0.819360', '0.827152', '0.822084', '0.822718', '0.831544', '0.835165', '0.811972', '0.813022', '0.823357', '0.834167', '0.828480', '0.823778', '0.832170', '0.822615', '0.818071', '0.818798']
         : correct/total = [(3343, 4128), (3459, 4203), (3370, 4081), (3554, 4333), (3352, 4091), (3546, 4287), (3447, 4193), (3578, 4349), (3485, 4191), (3572, 4277), (3364, 4143), (3409, 4193), (3370, 4093), (3501, 4197), (3357, 4052), (3319, 4029), (3456, 4153), (3441, 4183), (3341, 4084), (3380, 4128)]
Round 007: test acc mean=0.8306 ± 0.0072 | min=0.8172 max=0.8442
         : test loss mean=0.5202 ± 0.0248
         : individual accs = ['0.830184', '0.840590', '0.819652', '0.833141', '0.817160', '0.834383', '0.831147', '0.833065', '0.841804', '0.822305', '0.828868', '0.833771', '0.827999', '0.844174', '0.828480', '0.834947', '0.826150', '0.825962', '0.837904', '0.821221']
         : correct/total = [(3427, 4128), (3533, 4203), (3345, 4081), (3610, 4333), (3343, 4091), (3577, 4287), (3485, 4193), (3623, 4349), (3528, 4191), (3517, 4277), (3434, 4143), (3496, 4193), (3389, 4093), (3543, 4197), (3357, 4052), (3364, 4029), (3431, 4153), (3455, 4183), (3422, 4084), (3390, 4128)]
Round 008: test acc mean=0.8296 ± 0.0105 | min=0.8062 max=0.8458
         : test loss mean=0.5152 ± 0.0282
         : individual accs = ['0.824855', '0.831311', '0.825533', '0.837064', '0.835248', '0.845813', '0.834963', '0.833065', '0.840849', '0.836801', '0.824282', '0.831863', '0.821647', '0.841792', '0.831194', '0.831720', '0.807609', '0.814009', '0.836680', '0.806202']
         : correct/total = [(3405, 4128), (3494, 4203), (3369, 4081), (3627, 4333), (3417, 4091), (3626, 4287), (3501, 4193), (3623, 4349), (3524, 4191), (3579, 4277), (3415, 4143), (3488, 4193), (3363, 4093), (3533, 4197), (3368, 4052), (3351, 4029), (3354, 4153), (3405, 4183), (3417, 4084), (3328, 4128)]
Round 009: test acc mean=0.8360 ± 0.0073 | min=0.8229 max=0.8473
         : test loss mean=0.5009 ± 0.0200
         : individual accs = ['0.822917', '0.836307', '0.829209', '0.828525', '0.833781', '0.845580', '0.839733', '0.841113', '0.846099', '0.847323', '0.835144', '0.827331', '0.827755', '0.844889', '0.843040', '0.839166', '0.827113', '0.840545', '0.835211', '0.828731']
         : correct/total = [(3397, 4128), (3515, 4203), (3384, 4081), (3590, 4333), (3411, 4091), (3625, 4287), (3521, 4193), (3658, 4349), (3546, 4191), (3624, 4277), (3460, 4143), (3469, 4193), (3388, 4093), (3546, 4197), (3416, 4052), (3381, 4029), (3435, 4153), (3516, 4183), (3411, 4084), (3421, 4128)]
Round 010: test acc mean=0.8385 ± 0.0071 | min=0.8271 max=0.8501
         : test loss mean=0.4983 ± 0.0203
         : individual accs = ['0.830911', '0.843921', '0.830679', '0.844911', '0.839159', '0.837182', '0.844980', '0.830076', '0.842520', '0.850129', '0.831040', '0.827808', '0.837772', '0.848225', '0.846496', '0.844875', '0.840597', '0.840545', '0.827130', '0.830911']
         : correct/total = [(3430, 4128), (3547, 4203), (3390, 4081), (3661, 4333), (3433, 4091), (3589, 4287), (3543, 4193), (3610, 4349), (3531, 4191), (3636, 4277), (3443, 4143), (3471, 4193), (3429, 4093), (3560, 4197), (3430, 4052), (3404, 4029), (3491, 4153), (3516, 4183), (3378, 4084), (3430, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: ring, Aggregation: krum
Overall test accuracy: mean=0.8385 ± 0.0071
