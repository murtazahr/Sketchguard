Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: erdos, nodes: 20, edges: 126
Degree statistics: avg=12.60, min=8, max=16
Attack: Compromised 8/20 nodes: [1, 5, 11, 12, 13, 14, 17, 18]
Attack type: krum, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.4593 ± 0.1913 | min=0.0039 max=0.5712
         : test loss mean=10828.7766 ± 42380.4738
         : individual accs = ['0.533672', '0.533191', '0.571184', '0.514193', '0.531899', '0.006998', '0.546387', '0.544033', '0.540682', '0.526070', '0.003862', '0.540663', '0.534816', '0.553252', '0.532083', '0.524696', '0.569468', '0.004542', '0.535994', '0.539244']
         : correct/total = [(2203, 4128), (2241, 4203), (2331, 4081), (2228, 4333), (2176, 4091), (30, 4287), (2291, 4193), (2366, 4349), (2266, 4191), (2250, 4277), (16, 4143), (2267, 4193), (2189, 4093), (2322, 4197), (2156, 4052), (2114, 4029), (2365, 4153), (19, 4183), (2189, 4084), (2226, 4128)]
         : compromised: 0.4052, honest: 0.4954
Round 002: test acc mean=0.5555 ± 0.2923 | min=0.0453 max=0.7355
         : test loss mean=nan ± nan
         : individual accs = ['0.735465', '0.730906', '0.727518', '0.702285', '0.721095', '0.045253', '0.729311', '0.721545', '0.712956', '0.720599', '0.048033', '0.049606', '0.054239', '0.717894', '0.721125', '0.731447', '0.722129', '0.049486', '0.733105', '0.735223']
         : correct/total = [(3036, 4128), (3072, 4203), (2969, 4081), (3043, 4333), (2950, 4091), (194, 4287), (3058, 4193), (3138, 4349), (2988, 4191), (3082, 4277), (199, 4143), (208, 4193), (222, 4093), (3013, 4197), (2922, 4052), (2947, 4029), (2999, 4153), (207, 4183), (2994, 4084), (3035, 4128)]
         : compromised: 0.3877, honest: 0.6673
Round 003: test acc mean=0.6001 ± 0.3181 | min=0.0453 max=0.8018
         : test loss mean=nan ± nan
         : individual accs = ['0.789002', '0.782774', '0.789757', '0.772675', '0.791249', '0.045253', '0.778202', '0.801794', '0.784777', '0.787000', '0.048033', '0.049606', '0.054239', '0.780081', '0.771471', '0.776371', '0.777510', '0.049486', '0.786729', '0.786095']
         : correct/total = [(3257, 4128), (3290, 4203), (3223, 4081), (3348, 4333), (3237, 4091), (194, 4287), (3263, 4193), (3487, 4349), (3289, 4191), (3366, 4277), (199, 4143), (208, 4193), (222, 4093), (3274, 4197), (3126, 4052), (3128, 4029), (3229, 4153), (207, 4183), (3213, 4084), (3245, 4128)]
         : compromised: 0.4150, honest: 0.7235
Round 004: test acc mean=0.6155 ± 0.3269 | min=0.0453 max=0.8163
         : test loss mean=nan ± nan
         : individual accs = ['0.805233', '0.810611', '0.807645', '0.804754', '0.810804', '0.045253', '0.798951', '0.816280', '0.795037', '0.807575', '0.048033', '0.049606', '0.054239', '0.798904', '0.794916', '0.798213', '0.815796', '0.049486', '0.805338', '0.793362']
         : correct/total = [(3324, 4128), (3407, 4203), (3296, 4081), (3487, 4333), (3317, 4091), (194, 4287), (3350, 4193), (3550, 4349), (3332, 4191), (3454, 4277), (199, 4143), (208, 4193), (222, 4093), (3353, 4197), (3221, 4052), (3216, 4029), (3388, 4153), (207, 4183), (3289, 4084), (3275, 4128)]
         : compromised: 0.4260, honest: 0.7418
Round 005: test acc mean=0.6208 ± 0.3301 | min=0.0453 max=0.8234
         : test loss mean=nan ± nan
         : individual accs = ['0.822190', '0.812277', '0.823328', '0.792061', '0.816182', '0.045253', '0.815645', '0.823408', '0.795991', '0.814356', '0.048033', '0.049606', '0.054239', '0.801048', '0.800346', '0.804418', '0.819167', '0.049486', '0.819050', '0.810320']
         : correct/total = [(3394, 4128), (3414, 4203), (3360, 4081), (3432, 4333), (3339, 4091), (194, 4287), (3420, 4193), (3581, 4349), (3336, 4191), (3483, 4277), (199, 4143), (208, 4193), (222, 4093), (3362, 4197), (3243, 4052), (3241, 4029), (3402, 4153), (207, 4183), (3345, 4084), (3345, 4128)]
         : compromised: 0.4289, honest: 0.7488
Round 006: test acc mean=0.6311 ± 0.3359 | min=0.0453 max=0.8353
         : test loss mean=nan ± nan
         : individual accs = ['0.826066', '0.831311', '0.835334', '0.801523', '0.822782', '0.045253', '0.821846', '0.828696', '0.820806', '0.830255', '0.048033', '0.049606', '0.054239', '0.824160', '0.821570', '0.820799', '0.835059', '0.049486', '0.834966', '0.819283']
         : correct/total = [(3410, 4128), (3494, 4203), (3409, 4081), (3473, 4333), (3366, 4091), (194, 4287), (3446, 4193), (3604, 4349), (3440, 4191), (3551, 4277), (199, 4143), (208, 4193), (222, 4093), (3459, 4197), (3329, 4052), (3307, 4029), (3468, 4153), (207, 4183), (3410, 4084), (3382, 4128)]
         : compromised: 0.4388, honest: 0.7592
Round 007: test acc mean=0.6323 ± 0.3367 | min=0.0453 max=0.8436
         : test loss mean=nan ± nan
         : individual accs = ['0.830669', '0.818225', '0.819162', '0.835910', '0.838426', '0.045253', '0.826854', '0.843642', '0.814364', '0.830489', '0.048033', '0.049606', '0.054239', '0.806290', '0.801579', '0.831472', '0.838912', '0.049486', '0.841332', '0.821463']
         : correct/total = [(3429, 4128), (3439, 4203), (3343, 4081), (3622, 4333), (3430, 4091), (194, 4287), (3467, 4193), (3669, 4349), (3413, 4191), (3552, 4277), (199, 4143), (208, 4193), (222, 4093), (3384, 4197), (3248, 4052), (3350, 4029), (3484, 4153), (207, 4183), (3436, 4084), (3391, 4128)]
         : compromised: 0.4333, honest: 0.7649
Round 008: test acc mean=0.6351 ± 0.3382 | min=0.0453 max=0.8399
         : test loss mean=nan ± nan
         : individual accs = ['0.824370', '0.828456', '0.833129', '0.832449', '0.839892', '0.045253', '0.827808', '0.837664', '0.829635', '0.831658', '0.048033', '0.049606', '0.054239', '0.822016', '0.827739', '0.821544', '0.837708', '0.049486', '0.832027', '0.829215']
         : correct/total = [(3403, 4128), (3482, 4203), (3400, 4081), (3607, 4333), (3436, 4091), (194, 4287), (3471, 4193), (3643, 4349), (3477, 4191), (3557, 4277), (199, 4143), (208, 4193), (222, 4093), (3450, 4197), (3354, 4052), (3310, 4029), (3479, 4153), (207, 4183), (3398, 4084), (3423, 4128)]
         : compromised: 0.4386, honest: 0.7661
Round 009: test acc mean=0.6405 ± 0.3414 | min=0.0453 max=0.8526
         : test loss mean=nan ± nan
         : individual accs = ['0.831880', '0.840828', '0.850037', '0.825987', '0.845026', '0.045253', '0.828285', '0.852610', '0.839895', '0.841711', '0.048033', '0.049606', '0.054239', '0.833691', '0.836130', '0.828245', '0.840838', '0.049486', '0.838394', '0.830426']
         : correct/total = [(3434, 4128), (3534, 4203), (3469, 4081), (3579, 4333), (3457, 4091), (194, 4287), (3473, 4193), (3708, 4349), (3520, 4191), (3600, 4277), (199, 4143), (208, 4193), (222, 4093), (3499, 4197), (3388, 4052), (3337, 4029), (3492, 4153), (207, 4183), (3424, 4084), (3428, 4128)]
         : compromised: 0.4435, honest: 0.7719
Round 010: test acc mean=0.6389 ± 0.3405 | min=0.0453 max=0.8460
         : test loss mean=nan ± nan
         : individual accs = ['0.837936', '0.834642', '0.843176', '0.843526', '0.846003', '0.045253', '0.817792', '0.843642', '0.832737', '0.840309', '0.048033', '0.049606', '0.054239', '0.828211', '0.829961', '0.830479', '0.840116', '0.049486', '0.838149', '0.825581']
         : correct/total = [(3459, 4128), (3508, 4203), (3441, 4081), (3655, 4333), (3461, 4091), (194, 4287), (3429, 4193), (3669, 4349), (3490, 4191), (3594, 4277), (199, 4143), (208, 4193), (222, 4093), (3476, 4197), (3363, 4052), (3346, 4029), (3489, 4153), (207, 4183), (3423, 4084), (3408, 4128)]
         : compromised: 0.4412, honest: 0.7708

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: erdos, Aggregation: krum
Attack: krum, 40.0% compromised
Final accuracy - Compromised: 0.4412, Honest: 0.7708
Overall test accuracy: mean=0.6389 ± 0.3405
