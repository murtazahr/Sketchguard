Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 4500 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Degree statistics: avg=2.00, min=2, max=2
Model variant: baseline
Model parameters: 2,219,692
Initial test acc across nodes: mean=0.4978 ± 0.0208
Round 001: test acc mean=0.7138 ± 0.0218 | min=0.6797 max=0.7678
         : test loss mean=0.5770 ± 0.0237
         : individual accs = ['0.702632', '0.693437', '0.700089', '0.699482', '0.693122', '0.718777', '0.724891', '0.709849', '0.749120', '0.720745', '0.705420', '0.728000', '0.745660', '0.702586', '0.679715', '0.702183', '0.767764', '0.689655', '0.734659', '0.708151']
         : correct/total = [(801, 1140), (803, 1158), (789, 1127), (810, 1158), (786, 1134), (823, 1145), (830, 1145), (800, 1127), (851, 1136), (813, 1128), (807, 1144), (819, 1125), (859, 1152), (815, 1160), (764, 1124), (804, 1145), (886, 1154), (780, 1131), (850, 1157), (808, 1141)]
Round 002: test acc mean=0.8241 ± 0.0253 | min=0.7746 max=0.8671
         : test loss mean=0.3985 ± 0.0421
         : individual accs = ['0.774561', '0.835924', '0.782609', '0.821244', '0.820106', '0.851528', '0.854148', '0.821650', '0.786972', '0.856383', '0.867133', '0.857778', '0.830729', '0.807759', '0.826512', '0.802620', '0.822357', '0.802829', '0.837511', '0.821209']
         : correct/total = [(883, 1140), (968, 1158), (882, 1127), (951, 1158), (930, 1134), (975, 1145), (978, 1145), (926, 1127), (894, 1136), (966, 1128), (992, 1144), (965, 1125), (957, 1152), (937, 1160), (929, 1124), (919, 1145), (949, 1154), (908, 1131), (969, 1157), (937, 1141)]
Round 003: test acc mean=0.8641 ± 0.0147 | min=0.8347 max=0.8895
         : test loss mean=0.3160 ± 0.0223
         : individual accs = ['0.842982', '0.889465', '0.856256', '0.855786', '0.843034', '0.887336', '0.873362', '0.858030', '0.875000', '0.873227', '0.881119', '0.834667', '0.878472', '0.862069', '0.870107', '0.854148', '0.870884', '0.864721', '0.848747', '0.862401']
         : correct/total = [(961, 1140), (1030, 1158), (965, 1127), (991, 1158), (956, 1134), (1016, 1145), (1000, 1145), (967, 1127), (994, 1136), (985, 1128), (1008, 1144), (939, 1125), (1012, 1152), (1000, 1160), (978, 1124), (978, 1145), (1005, 1154), (978, 1131), (982, 1157), (984, 1141)]
Round 004: test acc mean=0.8768 ± 0.0110 | min=0.8513 max=0.8924
         : test loss mean=0.2891 ± 0.0200
         : individual accs = ['0.885965', '0.885147', '0.874002', '0.872193', '0.875661', '0.880349', '0.885590', '0.880213', '0.874120', '0.890957', '0.877622', '0.892444', '0.884549', '0.860345', '0.882562', '0.852402', '0.871750', '0.876216', '0.851340', '0.882559']
         : correct/total = [(1010, 1140), (1025, 1158), (985, 1127), (1010, 1158), (993, 1134), (1008, 1145), (1014, 1145), (992, 1127), (993, 1136), (1005, 1128), (1004, 1144), (1004, 1125), (1019, 1152), (998, 1160), (992, 1124), (976, 1145), (1006, 1154), (991, 1131), (985, 1157), (1007, 1141)]
Round 005: test acc mean=0.8729 ± 0.0209 | min=0.8253 max=0.8978
         : test loss mean=0.2979 ± 0.0443
         : individual accs = ['0.839474', '0.892919', '0.869565', '0.895509', '0.876543', '0.825328', '0.897817', '0.850932', '0.857394', '0.880319', '0.887238', '0.872000', '0.894097', '0.870690', '0.889680', '0.871616', '0.893414', '0.879752', '0.833189', '0.880806']
         : correct/total = [(957, 1140), (1034, 1158), (980, 1127), (1037, 1158), (994, 1134), (945, 1145), (1028, 1145), (959, 1127), (974, 1136), (993, 1128), (1015, 1144), (981, 1125), (1030, 1152), (1010, 1160), (1000, 1124), (998, 1145), (1031, 1154), (995, 1131), (964, 1157), (1005, 1141)]
Round 006: test acc mean=0.8887 ± 0.0112 | min=0.8580 max=0.9024
         : test loss mean=0.2710 ± 0.0194
         : individual accs = ['0.896491', '0.892919', '0.884650', '0.895509', '0.858025', '0.902183', '0.883843', '0.902396', '0.881162', '0.879433', '0.901224', '0.896000', '0.888021', '0.891379', '0.899466', '0.867249', '0.896014', '0.885942', '0.881590', '0.891323']
         : correct/total = [(1022, 1140), (1034, 1158), (997, 1127), (1037, 1158), (973, 1134), (1033, 1145), (1012, 1145), (1017, 1127), (1001, 1136), (992, 1128), (1031, 1144), (1008, 1125), (1023, 1152), (1034, 1160), (1011, 1124), (993, 1145), (1034, 1154), (1002, 1131), (1020, 1157), (1017, 1141)]
Round 007: test acc mean=0.8921 ± 0.0096 | min=0.8760 max=0.9125
         : test loss mean=0.2644 ± 0.0204
         : individual accs = ['0.898246', '0.890328', '0.888199', '0.904145', '0.886243', '0.901310', '0.896943', '0.907720', '0.880282', '0.890071', '0.898601', '0.889778', '0.889757', '0.887931', '0.884342', '0.875983', '0.912478', '0.885057', '0.877269', '0.897458']
         : correct/total = [(1024, 1140), (1031, 1158), (1001, 1127), (1047, 1158), (1005, 1134), (1032, 1145), (1027, 1145), (1023, 1127), (1000, 1136), (1004, 1128), (1028, 1144), (1001, 1125), (1025, 1152), (1030, 1160), (994, 1124), (1003, 1145), (1053, 1154), (1001, 1131), (1015, 1157), (1024, 1141)]
Round 008: test acc mean=0.8922 ± 0.0068 | min=0.8777 max=0.9021
         : test loss mean=0.2664 ± 0.0150
         : individual accs = ['0.900000', '0.897237', '0.886424', '0.898964', '0.891534', '0.896943', '0.889956', '0.889973', '0.883803', '0.899823', '0.890734', '0.900444', '0.895833', '0.894828', '0.890569', '0.877729', '0.902080', '0.883289', '0.881590', '0.891323']
         : correct/total = [(1026, 1140), (1039, 1158), (999, 1127), (1041, 1158), (1011, 1134), (1027, 1145), (1019, 1145), (1003, 1127), (1004, 1136), (1015, 1128), (1019, 1144), (1013, 1125), (1032, 1152), (1038, 1160), (1001, 1124), (1005, 1145), (1041, 1154), (999, 1131), (1020, 1157), (1017, 1141)]
Round 009: test acc mean=0.8929 ± 0.0131 | min=0.8574 max=0.9142
         : test loss mean=0.2652 ± 0.0286
         : individual accs = ['0.886842', '0.896373', '0.897072', '0.902418', '0.897707', '0.905677', '0.911790', '0.895297', '0.871479', '0.895390', '0.895105', '0.897778', '0.889757', '0.887931', '0.897687', '0.875109', '0.914211', '0.882405', '0.857390', '0.900088']
         : correct/total = [(1011, 1140), (1038, 1158), (1011, 1127), (1045, 1158), (1018, 1134), (1037, 1145), (1044, 1145), (1009, 1127), (990, 1136), (1010, 1128), (1024, 1144), (1010, 1125), (1025, 1152), (1030, 1160), (1009, 1124), (1002, 1145), (1055, 1154), (998, 1131), (992, 1157), (1027, 1141)]
Round 010: test acc mean=0.8924 ± 0.0114 | min=0.8634 max=0.9084
         : test loss mean=0.2664 ± 0.0275
         : individual accs = ['0.899123', '0.898100', '0.888199', '0.903282', '0.895062', '0.901310', '0.907424', '0.894410', '0.882923', '0.880319', '0.888112', '0.908444', '0.893229', '0.896552', '0.887011', '0.876856', '0.906412', '0.878868', '0.863440', '0.898335']
         : correct/total = [(1025, 1140), (1040, 1158), (1001, 1127), (1046, 1158), (1015, 1134), (1032, 1145), (1039, 1145), (1008, 1127), (1003, 1136), (993, 1128), (1016, 1144), (1022, 1125), (1029, 1152), (1040, 1160), (997, 1124), (1004, 1145), (1046, 1154), (994, 1131), (999, 1157), (1025, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: ring, Aggregation: krum
Overall test accuracy: mean=0.8924 ± 0.0114
