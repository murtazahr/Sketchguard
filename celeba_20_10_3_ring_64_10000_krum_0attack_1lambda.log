Device: cuda
Seed: 987654321
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA train files...
LEAF CelebA train: 9343 users (celebrities), 177457 samples
Looking for images in: /home/student.unimelb.edu.au/mrangwala/Trust-Monitor/leaf/data/celeba/data/raw/img_align_celeba
Loading 1 LEAF CelebA test files...
LEAF CelebA test: 9343 users (celebrities), 22831 samples
Found 9343 train users, 9343 test users, 9343 common users
User sample counts range: 31 (max) to 4 (min)
Distributed ALL 9343 users across 20 clients
Users per client: 467 (with 3 clients getting +1 user)
Train partition sizes: [8843, 8998, 8728, 9034, 8866, 8946, 8873, 8776, 8816, 8801, 8913, 8656, 9115, 8921, 8699, 8823, 8912, 8766, 9102, 8869]
Test partition sizes: [1140, 1158, 1127, 1158, 1134, 1145, 1145, 1127, 1136, 1128, 1144, 1125, 1152, 1160, 1124, 1145, 1154, 1131, 1157, 1141]
  Client 0: 8843 train samples, 2 unique classes
  Client 1: 8998 train samples, 2 unique classes
  Client 2: 8728 train samples, 2 unique classes
  Client 3: 9034 train samples, 2 unique classes
  Client 4: 8866 train samples, 2 unique classes
  Client 5: 8946 train samples, 2 unique classes
  Client 6: 8873 train samples, 2 unique classes
  Client 7: 8776 train samples, 2 unique classes
  Client 8: 8816 train samples, 2 unique classes
  Client 9: 8801 train samples, 2 unique classes
  Client 10: 8913 train samples, 2 unique classes
  Client 11: 8656 train samples, 2 unique classes
  Client 12: 9115 train samples, 2 unique classes
  Client 13: 8921 train samples, 2 unique classes
  Client 14: 8699 train samples, 2 unique classes
  Client 15: 8823 train samples, 2 unique classes
  Client 16: 8912 train samples, 2 unique classes
  Client 17: 8766 train samples, 2 unique classes
  Client 18: 9102 train samples, 2 unique classes
  Client 19: 8869 train samples, 2 unique classes
Will sample 10000 samples per client per epoch
Graph: ring, nodes: 20, edges: 20
Initial test acc across nodes: mean=0.4969 ± 0.0214
Round 001: test acc mean=0.8952 ± 0.0111 | min=0.8756 max=0.9158
         : test loss mean=0.2631 ± 0.0358
         : individual accs = ['0.915789', '0.896373', '0.882875', '0.875648', '0.907407', '0.901310', '0.889956', '0.907720', '0.889965', '0.902482', '0.897727', '0.903111', '0.889757', '0.903448', '0.900356', '0.876856', '0.884749', '0.885057', '0.884183', '0.908852']
         : correct/total = [(1044, 1140), (1038, 1158), (995, 1127), (1014, 1158), (1029, 1134), (1032, 1145), (1019, 1145), (1023, 1127), (1011, 1136), (1018, 1128), (1027, 1144), (1016, 1125), (1025, 1152), (1048, 1160), (1012, 1124), (1004, 1145), (1021, 1154), (1001, 1131), (1023, 1157), (1037, 1141)]
Round 002: test acc mean=0.9028 ± 0.0096 | min=0.8782 max=0.9147
         : test loss mean=0.2501 ± 0.0325
         : individual accs = ['0.896491', '0.878238', '0.895297', '0.900691', '0.898589', '0.912664', '0.909170', '0.910382', '0.904049', '0.913121', '0.903846', '0.914667', '0.910590', '0.884483', '0.904804', '0.897817', '0.914211', '0.902741', '0.895419', '0.909728']
         : correct/total = [(1022, 1140), (1017, 1158), (1009, 1127), (1043, 1158), (1019, 1134), (1045, 1145), (1041, 1145), (1026, 1127), (1027, 1136), (1030, 1128), (1034, 1144), (1029, 1125), (1049, 1152), (1026, 1160), (1017, 1124), (1028, 1145), (1055, 1154), (1021, 1131), (1036, 1157), (1038, 1141)]
Round 003: test acc mean=0.9009 ± 0.0101 | min=0.8851 max=0.9175
         : test loss mean=0.2697 ± 0.0272
         : individual accs = ['0.885088', '0.896373', '0.889086', '0.895509', '0.906526', '0.914410', '0.913537', '0.902396', '0.889965', '0.914007', '0.904720', '0.902222', '0.917535', '0.885345', '0.908363', '0.891703', '0.900347', '0.902741', '0.887640', '0.910605']
         : correct/total = [(1009, 1140), (1038, 1158), (1002, 1127), (1037, 1158), (1028, 1134), (1047, 1145), (1046, 1145), (1017, 1127), (1011, 1136), (1031, 1128), (1035, 1144), (1015, 1125), (1057, 1152), (1027, 1160), (1021, 1124), (1021, 1145), (1039, 1154), (1021, 1131), (1027, 1157), (1039, 1141)]
Round 004: test acc mean=0.9058 ± 0.0091 | min=0.8897 max=0.9231
         : test loss mean=0.2932 ± 0.0418
         : individual accs = ['0.919298', '0.902418', '0.898846', '0.909326', '0.912698', '0.893450', '0.923144', '0.898846', '0.901408', '0.914007', '0.898601', '0.920000', '0.900174', '0.889655', '0.900356', '0.903930', '0.913345', '0.906278', '0.897148', '0.912358']
         : correct/total = [(1048, 1140), (1045, 1158), (1013, 1127), (1053, 1158), (1035, 1134), (1023, 1145), (1057, 1145), (1013, 1127), (1024, 1136), (1031, 1128), (1028, 1144), (1035, 1125), (1037, 1152), (1032, 1160), (1012, 1124), (1035, 1145), (1054, 1154), (1025, 1131), (1038, 1157), (1041, 1141)]
Round 005: test acc mean=0.9047 ± 0.0095 | min=0.8853 max=0.9188
         : test loss mean=0.3230 ± 0.0596
         : individual accs = ['0.910526', '0.900691', '0.895297', '0.888601', '0.914462', '0.918777', '0.915284', '0.902396', '0.902289', '0.895390', '0.904720', '0.913778', '0.903646', '0.885345', '0.909253', '0.913537', '0.915078', '0.908930', '0.889369', '0.906223']
         : correct/total = [(1038, 1140), (1043, 1158), (1009, 1127), (1029, 1158), (1037, 1134), (1052, 1145), (1048, 1145), (1017, 1127), (1025, 1136), (1010, 1128), (1035, 1144), (1028, 1125), (1041, 1152), (1027, 1160), (1022, 1124), (1046, 1145), (1056, 1154), (1028, 1131), (1029, 1157), (1034, 1141)]
Round 006: test acc mean=0.9072 ± 0.0068 | min=0.8930 max=0.9205
         : test loss mean=0.3346 ± 0.0662
         : individual accs = ['0.912281', '0.908463', '0.903283', '0.905872', '0.913580', '0.920524', '0.913537', '0.901508', '0.905810', '0.909574', '0.904720', '0.908444', '0.907986', '0.893103', '0.911032', '0.914410', '0.910745', '0.893015', '0.897148', '0.908852']
         : correct/total = [(1040, 1140), (1052, 1158), (1018, 1127), (1049, 1158), (1036, 1134), (1054, 1145), (1046, 1145), (1016, 1127), (1029, 1136), (1026, 1128), (1035, 1144), (1022, 1125), (1046, 1152), (1036, 1160), (1024, 1124), (1047, 1145), (1051, 1154), (1010, 1131), (1038, 1157), (1037, 1141)]
Round 007: test acc mean=0.9058 ± 0.0089 | min=0.8868 max=0.9177
         : test loss mean=0.3467 ± 0.0780
         : individual accs = ['0.913158', '0.907599', '0.909494', '0.892919', '0.908289', '0.903930', '0.915284', '0.910382', '0.897007', '0.910461', '0.898601', '0.911111', '0.895833', '0.889655', '0.913701', '0.912664', '0.917678', '0.907162', '0.886776', '0.914110']
         : correct/total = [(1041, 1140), (1051, 1158), (1025, 1127), (1034, 1158), (1030, 1134), (1035, 1145), (1048, 1145), (1026, 1127), (1019, 1136), (1027, 1128), (1028, 1144), (1025, 1125), (1032, 1152), (1032, 1160), (1027, 1124), (1045, 1145), (1059, 1154), (1026, 1131), (1026, 1157), (1043, 1141)]
Round 008: test acc mean=0.9084 ± 0.0087 | min=0.8850 max=0.9205
         : test loss mean=0.3514 ± 0.0710
         : individual accs = ['0.913158', '0.911917', '0.892635', '0.908463', '0.910935', '0.907424', '0.920524', '0.913931', '0.906690', '0.914007', '0.900350', '0.911111', '0.905382', '0.895690', '0.916370', '0.914410', '0.909012', '0.912467', '0.885048', '0.918493']
         : correct/total = [(1041, 1140), (1056, 1158), (1006, 1127), (1052, 1158), (1033, 1134), (1039, 1145), (1054, 1145), (1030, 1127), (1030, 1136), (1031, 1128), (1030, 1144), (1025, 1125), (1043, 1152), (1039, 1160), (1030, 1124), (1047, 1145), (1049, 1154), (1032, 1131), (1024, 1157), (1048, 1141)]
Round 009: test acc mean=0.9122 ± 0.0069 | min=0.8974 max=0.9238
         : test loss mean=0.3657 ± 0.0651
         : individual accs = ['0.915789', '0.916235', '0.904170', '0.911054', '0.914462', '0.916157', '0.919651', '0.915705', '0.905810', '0.917553', '0.910839', '0.921778', '0.906250', '0.897414', '0.918149', '0.908297', '0.914211', '0.904509', '0.901469', '0.923751']
         : correct/total = [(1044, 1140), (1061, 1158), (1019, 1127), (1055, 1158), (1037, 1134), (1049, 1145), (1053, 1145), (1032, 1127), (1029, 1136), (1035, 1128), (1042, 1144), (1037, 1125), (1044, 1152), (1041, 1160), (1032, 1124), (1040, 1145), (1055, 1154), (1023, 1131), (1043, 1157), (1054, 1141)]
Round 010: test acc mean=0.9109 ± 0.0082 | min=0.8894 max=0.9226
         : test loss mean=0.3765 ± 0.0616
         : individual accs = ['0.917544', '0.913644', '0.899734', '0.909326', '0.913580', '0.918777', '0.917904', '0.914818', '0.908451', '0.917553', '0.906469', '0.915556', '0.904514', '0.895690', '0.922598', '0.910917', '0.913345', '0.908930', '0.889369', '0.918493']
         : correct/total = [(1046, 1140), (1058, 1158), (1014, 1127), (1053, 1158), (1036, 1134), (1052, 1145), (1051, 1145), (1031, 1127), (1032, 1136), (1035, 1128), (1037, 1144), (1030, 1125), (1042, 1152), (1039, 1160), (1037, 1124), (1043, 1145), (1054, 1154), (1028, 1131), (1029, 1157), (1048, 1141)]

=== FINAL RESULTS ===
Dataset: celeba, Nodes: 20, Graph: ring, Aggregation: krum
Overall test accuracy: mean=0.9109 ± 0.0082
