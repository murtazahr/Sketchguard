Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 4500 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Degree statistics: avg=19.00, min=19, max=19
Attack: Compromised 2/20 nodes: [5, 13]
Attack type: directed_deviation, lambda: 1.0
Model variant: baseline
Model parameters: 6,603,710
Initial test acc across nodes: mean=0.0168 ± 0.0139
Round 001: test acc mean=0.0225 ± 0.0166 | min=0.0017 max=0.0579
         : test loss mean=34.4676 ± 13.3639
         : individual accs = ['0.030523', '0.051630', '0.026464', '0.024694', '0.057932', '0.013296', '0.010017', '0.045068', '0.012169', '0.039280', '0.019792', '0.004770', '0.016858', '0.008101', '0.037759', '0.006453', '0.001686', '0.032991', '0.006121', '0.005087']
         : correct/total = [(126, 4128), (217, 4203), (108, 4081), (107, 4333), (237, 4091), (57, 4287), (42, 4193), (196, 4349), (51, 4191), (168, 4277), (82, 4143), (20, 4193), (69, 4093), (34, 4197), (153, 4052), (26, 4029), (7, 4153), (138, 4183), (25, 4084), (21, 4128)]
         : compromised: 0.0107, honest: 0.0238
Round 002: test acc mean=0.0121 ± 0.0014 | min=0.0098 max=0.0144
         : test loss mean=17.3713 ± 0.1263
         : individual accs = ['0.013566', '0.011896', '0.012742', '0.011078', '0.012222', '0.012130', '0.013356', '0.014256', '0.012408', '0.014262', '0.011827', '0.012163', '0.010506', '0.009769', '0.012093', '0.014396', '0.010354', '0.012670', '0.011263', '0.009932']
         : correct/total = [(56, 4128), (50, 4203), (52, 4081), (48, 4333), (50, 4091), (52, 4287), (56, 4193), (62, 4349), (52, 4191), (61, 4277), (49, 4143), (51, 4193), (43, 4093), (41, 4197), (49, 4052), (58, 4029), (43, 4153), (53, 4183), (46, 4084), (41, 4128)]
         : compromised: 0.0109, honest: 0.0123
Round 003: test acc mean=0.0472 ± 0.0022 | min=0.0445 max=0.0539
         : test loss mean=4.0640 ± 0.0013
         : individual accs = ['0.047238', '0.048775', '0.045087', '0.044773', '0.047421', '0.048752', '0.048891', '0.045528', '0.044619', '0.047697', '0.047309', '0.045314', '0.049597', '0.045747', '0.046397', '0.053860', '0.044546', '0.045900', '0.048482', '0.048692']
         : correct/total = [(195, 4128), (205, 4203), (184, 4081), (194, 4333), (194, 4091), (209, 4287), (205, 4193), (198, 4349), (187, 4191), (204, 4277), (196, 4143), (190, 4193), (203, 4093), (192, 4197), (188, 4052), (217, 4029), (185, 4153), (192, 4183), (198, 4084), (201, 4128)]
         : compromised: 0.0472, honest: 0.0472
Round 004: test acc mean=0.0851 ± 0.0055 | min=0.0699 max=0.0943
         : test loss mean=4.1603 ± 0.0431
         : individual accs = ['0.087936', '0.083274', '0.094340', '0.069928', '0.088242', '0.085841', '0.079418', '0.084387', '0.078263', '0.085574', '0.090031', '0.090627', '0.086489', '0.082440', '0.084156', '0.089849', '0.085721', '0.084628', '0.092556', '0.078973']
         : correct/total = [(363, 4128), (350, 4203), (385, 4081), (303, 4333), (361, 4091), (368, 4287), (333, 4193), (367, 4349), (328, 4191), (366, 4277), (373, 4143), (380, 4193), (354, 4093), (346, 4197), (341, 4052), (362, 4029), (356, 4153), (354, 4183), (378, 4084), (326, 4128)]
         : compromised: 0.0841, honest: 0.0852
Round 005: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.8019 ± 0.0097
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0561
Round 006: test acc mean=0.3572 ± 0.0091 | min=0.3296 max=0.3711
         : test loss mean=2.8271 ± 0.0371
         : individual accs = ['0.357074', '0.352605', '0.363146', '0.329564', '0.361525', '0.357593', '0.350346', '0.366061', '0.345741', '0.357961', '0.356022', '0.357739', '0.349377', '0.356683', '0.367966', '0.370563', '0.371057', '0.354291', '0.360921', '0.357800']
         : correct/total = [(1474, 4128), (1482, 4203), (1482, 4081), (1428, 4333), (1479, 4091), (1533, 4287), (1469, 4193), (1592, 4349), (1449, 4191), (1531, 4277), (1475, 4143), (1500, 4193), (1430, 4093), (1497, 4197), (1491, 4052), (1493, 4029), (1541, 4153), (1482, 4183), (1474, 4084), (1477, 4128)]
         : compromised: 0.3571, honest: 0.3572
Round 007: test acc mean=0.0561 ± 0.0032 | min=0.0506 max=0.0624
         : test loss mean=3.6960 ± 0.0153
         : individual accs = ['0.059593', '0.052344', '0.057584', '0.052850', '0.057932', '0.050618', '0.057000', '0.058174', '0.053209', '0.053776', '0.055998', '0.053899', '0.058637', '0.062426', '0.061204', '0.056590', '0.058271', '0.050920', '0.055583', '0.055475']
         : correct/total = [(246, 4128), (220, 4203), (235, 4081), (229, 4333), (237, 4091), (217, 4287), (239, 4193), (253, 4349), (223, 4191), (230, 4277), (232, 4143), (226, 4193), (240, 4093), (262, 4197), (248, 4052), (228, 4029), (242, 4153), (213, 4183), (227, 4084), (229, 4128)]
         : compromised: 0.0565, honest: 0.0561
Round 008: test acc mean=0.2031 ± 0.0051 | min=0.1903 max=0.2105
         : test loss mean=3.7132 ± 0.0547
         : individual accs = ['0.208576', '0.204140', '0.205342', '0.197092', '0.210462', '0.208071', '0.190317', '0.209703', '0.204247', '0.198270', '0.208786', '0.200572', '0.204495', '0.196092', '0.207058', '0.203773', '0.203227', '0.199139', '0.203232', '0.199855']
         : correct/total = [(861, 4128), (858, 4203), (838, 4081), (854, 4333), (861, 4091), (892, 4287), (798, 4193), (912, 4349), (856, 4191), (848, 4277), (865, 4143), (841, 4193), (837, 4093), (823, 4197), (839, 4052), (821, 4029), (844, 4153), (833, 4183), (830, 4084), (825, 4128)]
         : compromised: 0.2021, honest: 0.2032
Round 009: test acc mean=0.1260 ± 0.0112 | min=0.1082 max=0.1516
         : test loss mean=3.6654 ± 0.0167
         : individual accs = ['0.151647', '0.112301', '0.132075', '0.108239', '0.116353', '0.139725', '0.139041', '0.119798', '0.115724', '0.112930', '0.122134', '0.125924', '0.114097', '0.119133', '0.125370', '0.132787', '0.139176', '0.125747', '0.133203', '0.133721']
         : correct/total = [(626, 4128), (472, 4203), (539, 4081), (469, 4333), (476, 4091), (599, 4287), (583, 4193), (521, 4349), (485, 4191), (483, 4277), (506, 4143), (528, 4193), (467, 4093), (500, 4197), (508, 4052), (535, 4029), (578, 4153), (526, 4183), (544, 4084), (552, 4128)]
         : compromised: 0.1294, honest: 0.1256
Round 010: test acc mean=0.2565 ± 0.0058 | min=0.2464 max=0.2666
         : test loss mean=3.8787 ± 0.0601
         : individual accs = ['0.261628', '0.258863', '0.261456', '0.248558', '0.260572', '0.266620', '0.246363', '0.263509', '0.253400', '0.247837', '0.256577', '0.253995', '0.258979', '0.258041', '0.263574', '0.248945', '0.260775', '0.248625', '0.256611', '0.254845']
         : correct/total = [(1080, 4128), (1088, 4203), (1067, 4081), (1077, 4333), (1066, 4091), (1143, 4287), (1033, 4193), (1146, 4349), (1062, 4191), (1060, 4277), (1063, 4143), (1065, 4193), (1060, 4093), (1083, 4197), (1068, 4052), (1003, 4029), (1083, 4153), (1040, 4183), (1048, 4084), (1052, 4128)]
         : compromised: 0.2623, honest: 0.2558

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: d-fedavg
Attack: directed_deviation, 10.0% compromised
Final accuracy - Compromised: 0.2623, Honest: 0.2558
Overall test accuracy: mean=0.2565 ± 0.0058
