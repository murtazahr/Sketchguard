Device: cuda
Seed: 987654321
Loading 36 LEAF FEMNIST train files...
LEAF FEMNIST train: 3597 users, 734463 samples
Loading 36 LEAF FEMNIST test files...
LEAF FEMNIST test: 3597 users, 83388 samples
Found 3597 train users, 3597 test users, 3597 common users
User sample counts range: 525 (max) to 17 (min)
Distributed ALL 3597 users across 20 clients
Users per client: 179 (with 17 clients getting +1 user)
Train partition sizes: [36360, 37070, 35957, 38262, 36024, 37732, 36921, 38328, 36867, 37683, 36507, 36915, 36007, 37001, 35681, 35453, 36585, 36801, 35964, 36345]
Test partition sizes: [4128, 4203, 4081, 4333, 4091, 4287, 4193, 4349, 4191, 4277, 4143, 4193, 4093, 4197, 4052, 4029, 4153, 4183, 4084, 4128]
  Client 0: 36360 train samples, 62 unique classes
  Client 1: 37070 train samples, 62 unique classes
  Client 2: 35957 train samples, 62 unique classes
  Client 3: 38262 train samples, 62 unique classes
  Client 4: 36024 train samples, 62 unique classes
  Client 5: 37732 train samples, 62 unique classes
  Client 6: 36921 train samples, 62 unique classes
  Client 7: 38328 train samples, 62 unique classes
  Client 8: 36867 train samples, 62 unique classes
  Client 9: 37683 train samples, 62 unique classes
  Client 10: 36507 train samples, 62 unique classes
  Client 11: 36915 train samples, 62 unique classes
  Client 12: 36007 train samples, 62 unique classes
  Client 13: 37001 train samples, 62 unique classes
  Client 14: 35681 train samples, 62 unique classes
  Client 15: 35453 train samples, 62 unique classes
  Client 16: 36585 train samples, 62 unique classes
  Client 17: 36801 train samples, 62 unique classes
  Client 18: 35964 train samples, 62 unique classes
  Client 19: 36345 train samples, 62 unique classes
Will sample 10000 samples per client per epoch
Graph: fully, nodes: 20, edges: 190
Initial test acc across nodes: mean=0.0162 ± 0.0138
Round 001: test acc mean=0.5391 ± 0.0115 | min=0.5257 max=0.5654
         : test loss mean=1.7554 ± 0.0422
         : individual accs = ['0.538275', '0.540804', '0.529282', '0.530118', '0.538010', '0.554934', '0.539232', '0.539204', '0.540205', '0.525836', '0.525706', '0.547579', '0.549230', '0.530141', '0.565400', '0.531646', '0.526848', '0.539565', '0.563173', '0.527616']
         : correct/total = [(2222, 4128), (2273, 4203), (2160, 4081), (2297, 4333), (2201, 4091), (2379, 4287), (2261, 4193), (2345, 4349), (2264, 4191), (2249, 4277), (2178, 4143), (2296, 4193), (2248, 4093), (2225, 4197), (2291, 4052), (2142, 4029), (2188, 4153), (2257, 4183), (2300, 4084), (2178, 4128)]
Round 002: test acc mean=0.7424 ± 0.0070 | min=0.7248 max=0.7557
         : test loss mean=0.8601 ± 0.0253
         : individual accs = ['0.743702', '0.748275', '0.735359', '0.750288', '0.739917', '0.747609', '0.745290', '0.746149', '0.747793', '0.740238', '0.724837', '0.736466', '0.755680', '0.744579', '0.741856', '0.747828', '0.730797', '0.739900', '0.745837', '0.735465']
         : correct/total = [(3070, 4128), (3145, 4203), (3001, 4081), (3251, 4333), (3027, 4091), (3205, 4287), (3125, 4193), (3245, 4349), (3134, 4191), (3166, 4277), (3003, 4143), (3088, 4193), (3093, 4093), (3125, 4197), (3006, 4052), (3013, 4029), (3035, 4153), (3095, 4183), (3046, 4084), (3036, 4128)]
Round 003: test acc mean=0.7687 ± 0.0089 | min=0.7522 max=0.7840
         : test loss mean=0.7195 ± 0.0253
         : individual accs = ['0.757510', '0.783964', '0.755207', '0.777752', '0.765827', '0.772335', '0.779633', '0.776270', '0.781675', '0.774375', '0.754526', '0.765323', '0.767163', '0.772218', '0.765548', '0.765450', '0.773898', '0.765240', '0.768364', '0.752180']
         : correct/total = [(3127, 4128), (3295, 4203), (3082, 4081), (3370, 4333), (3133, 4091), (3311, 4287), (3269, 4193), (3376, 4349), (3276, 4191), (3312, 4277), (3126, 4143), (3209, 4193), (3140, 4093), (3241, 4197), (3102, 4052), (3084, 4029), (3214, 4153), (3201, 4183), (3138, 4084), (3105, 4128)]
Round 004: test acc mean=0.8000 ± 0.0065 | min=0.7871 max=0.8139
         : test loss mean=0.6328 ± 0.0255
         : individual accs = ['0.795543', '0.812277', '0.794903', '0.798523', '0.795405', '0.801726', '0.807059', '0.809841', '0.813887', '0.799158', '0.790490', '0.801336', '0.798681', '0.801048', '0.801086', '0.799454', '0.794606', '0.799187', '0.799461', '0.787064']
         : correct/total = [(3284, 4128), (3414, 4203), (3244, 4081), (3460, 4333), (3254, 4091), (3437, 4287), (3384, 4193), (3522, 4349), (3411, 4191), (3418, 4277), (3275, 4143), (3360, 4193), (3269, 4093), (3362, 4197), (3246, 4052), (3221, 4029), (3300, 4153), (3343, 4183), (3265, 4084), (3249, 4128)]
Round 005: test acc mean=0.8083 ± 0.0077 | min=0.7942 max=0.8237
         : test loss mean=0.6082 ± 0.0251
         : individual accs = ['0.801357', '0.813704', '0.798824', '0.811678', '0.794182', '0.811523', '0.821130', '0.815360', '0.823670', '0.807809', '0.794352', '0.814930', '0.813584', '0.804146', '0.807009', '0.802184', '0.810258', '0.805881', '0.808766', '0.806444']
         : correct/total = [(3308, 4128), (3420, 4203), (3260, 4081), (3517, 4333), (3249, 4091), (3479, 4287), (3443, 4193), (3546, 4349), (3452, 4191), (3455, 4277), (3291, 4143), (3417, 4193), (3330, 4093), (3375, 4197), (3270, 4052), (3232, 4029), (3365, 4153), (3371, 4183), (3303, 4084), (3329, 4128)]
Round 006: test acc mean=0.8162 ± 0.0084 | min=0.8032 max=0.8370
         : test loss mean=0.5781 ± 0.0273
         : individual accs = ['0.804990', '0.818939', '0.816467', '0.814216', '0.803227', '0.815955', '0.823754', '0.826857', '0.837032', '0.819266', '0.803765', '0.820415', '0.815294', '0.819157', '0.814413', '0.822288', '0.812184', '0.808750', '0.823213', '0.804021']
         : correct/total = [(3323, 4128), (3442, 4203), (3332, 4081), (3528, 4333), (3286, 4091), (3498, 4287), (3454, 4193), (3596, 4349), (3508, 4191), (3504, 4277), (3330, 4143), (3440, 4193), (3337, 4093), (3438, 4197), (3300, 4052), (3313, 4029), (3373, 4153), (3383, 4183), (3362, 4084), (3319, 4128)]
Round 007: test acc mean=0.8175 ± 0.0067 | min=0.8057 max=0.8349
         : test loss mean=0.5634 ± 0.0255
         : individual accs = ['0.808140', '0.821080', '0.813526', '0.822294', '0.810071', '0.823420', '0.820176', '0.825247', '0.834884', '0.819967', '0.809558', '0.815645', '0.819204', '0.822969', '0.814659', '0.811368', '0.817241', '0.815204', '0.819785', '0.805717']
         : correct/total = [(3336, 4128), (3451, 4203), (3320, 4081), (3563, 4333), (3314, 4091), (3530, 4287), (3439, 4193), (3589, 4349), (3499, 4191), (3507, 4277), (3354, 4143), (3420, 4193), (3353, 4093), (3454, 4197), (3301, 4052), (3269, 4029), (3394, 4153), (3410, 4183), (3348, 4084), (3326, 4128)]
Round 008: test acc mean=0.8168 ± 0.0084 | min=0.8021 max=0.8377
         : test loss mean=0.5510 ± 0.0289
         : individual accs = ['0.802083', '0.823459', '0.813281', '0.824140', '0.809826', '0.820854', '0.821369', '0.826857', '0.837748', '0.822539', '0.808351', '0.817315', '0.814317', '0.822969', '0.814906', '0.806652', '0.815555', '0.818073', '0.813418', '0.802810']
         : correct/total = [(3311, 4128), (3461, 4203), (3319, 4081), (3571, 4333), (3313, 4091), (3519, 4287), (3444, 4193), (3596, 4349), (3511, 4191), (3518, 4277), (3349, 4143), (3427, 4193), (3333, 4093), (3454, 4197), (3302, 4052), (3250, 4029), (3387, 4153), (3422, 4183), (3322, 4084), (3314, 4128)]
Round 009: test acc mean=0.8222 ± 0.0078 | min=0.8054 max=0.8413
         : test loss mean=0.5430 ± 0.0266
         : individual accs = ['0.810320', '0.828932', '0.820632', '0.822756', '0.805427', '0.816188', '0.828524', '0.827087', '0.841327', '0.828384', '0.813179', '0.824231', '0.822624', '0.828925', '0.822557', '0.823281', '0.819648', '0.823811', '0.824682', '0.812258']
         : correct/total = [(3345, 4128), (3484, 4203), (3349, 4081), (3565, 4333), (3295, 4091), (3499, 4287), (3474, 4193), (3597, 4349), (3526, 4191), (3543, 4277), (3369, 4143), (3456, 4193), (3367, 4093), (3479, 4197), (3333, 4052), (3317, 4029), (3404, 4153), (3446, 4183), (3368, 4084), (3353, 4128)]
Round 010: test acc mean=0.8200 ± 0.0081 | min=0.8057 max=0.8418
         : test loss mean=0.5457 ± 0.0302
         : individual accs = ['0.811289', '0.826790', '0.808380', '0.820217', '0.810560', '0.823420', '0.826854', '0.827317', '0.841804', '0.823942', '0.805696', '0.820415', '0.820181', '0.826543', '0.820336', '0.819806', '0.818444', '0.820464', '0.818315', '0.809109']
         : correct/total = [(3349, 4128), (3475, 4203), (3299, 4081), (3554, 4333), (3316, 4091), (3530, 4287), (3467, 4193), (3598, 4349), (3528, 4191), (3524, 4277), (3338, 4143), (3440, 4193), (3357, 4093), (3469, 4197), (3324, 4052), (3303, 4029), (3399, 4153), (3432, 4183), (3342, 4084), (3340, 4128)]

=== FINAL RESULTS ===
Dataset: femnist, Nodes: 20, Graph: fully, Aggregation: krum
Overall test accuracy: mean=0.8200 ± 0.0081
